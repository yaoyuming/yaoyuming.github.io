<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Chrome 常见问题</title>
    <url>/posts/5a881178/</url>
    <content><![CDATA[chrome 插件无法正常安装浏览器地址栏输入chrome://flags/
然后搜索extension关键字，将 disabled 改成 enabled 即可，如下图所示：
]]></content>
      <categories>
        <category>Chrome</category>
      </categories>
      <tags>
        <tag>chrome</tag>
        <tag>浏览器</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx 安装 &amp; FTP美化</title>
    <url>/posts/1b4fede6/</url>
    <content><![CDATA[目录配置 nginx 美化下载 fancyindexgit clone git@github.com:aperezdc/ngx-fancyindex.git ngx-fancyindex-0.5.2# 或者wget https://github.com/aperezdc/ngx-fancyindex/archive/refs/tags/v0.5.2.zipunzip v0.5.2.zip





下载 fancyindex-themegit clone git@github.com:Naereen/Nginx-Fancyindex-Theme.git# 或者wget https://github.com/Naereen/Nginx-Fancyindex-Theme/archive/refs/heads/master.zip

下载好的目录结构剔除不需要的文件后的最终目录结构如下图所示：
├── fancyindex.conf├── Nginx-Fancyindex│   ├── addNginxFancyIndexForm.js│   ├── footer.html│   ├── header.html│   ├── jquery.min.js│   ├── showdown.min.js│   └── styles.css├── Nginx-Fancyindex-Theme-dark│   ├── addNginxFancyIndexForm.js│   ├── footer.html│   ├── header.html│   ├── jquery.min.js│   ├── showdown.min.js│   └── styles.css├── Nginx-Fancyindex-Theme-light│   ├── addNginxFancyIndexForm.js│   ├── footer.html│   ├── header.html│   ├── HEADER.md│   ├── jquery.min.js│   ├── README.md│   ├── showdown.min.js│   └── styles.css

将 Nginx-Fancyindex、Nginx-Fancyindex-Theme-dark 以及 Nginx-Fancyindex-Theme-light 移动至 &#x2F;etc&#x2F;nginx&#x2F;html 目录下，然后将 fancyindex.conf 移动至 &#x2F;etc&#x2F;nginx 主目录下，使用如下命令：
cp -r Nginx-Fancyindex Nginx-Fancyindex-Theme-dark Nginx-Fancyindex-Theme-light /etc/nginx/htmlcp fancyindex.conf /etc/nginx

安装 nginxyum 安装（不推荐）1. 安装 Nginxyum 安装 nginx 非常简单，就输入一条命令即可。
$ sudo yum -y install nginx   # 安装 nginx$ sudo yum remove nginx  # 卸载 nginx

使用 yum 进行 Nginx 安装时，Nginx 配置文件在 /etc/nginx 目录下。
2. 配置 Nginx 服务$ sudo systemctl enable nginx # 设置开机启动 $ sudo service nginx start # 启动 nginx 服务$ sudo service nginx stop # 停止 nginx 服务$ sudo service nginx restart # 重启 nginx 服务$ sudo service nginx reload # 重新加载配置，一般是在修改过 nginx 配置文件时使用。

源码包安装（推荐）Nginx 源码包安装方式步骤比较繁琐，并且需要提前安装一些 Nginx 依赖库。
1. 依赖库安装安装基础环境yum -y install redhat-rpm-config perl-ExtUtils-Embed gd-devel GeoIP GeoIP-devel GeoIP-data libxslt-devel gperftools

安装 gcc 环境$ sudo yum -y install gcc gcc-c++ # nginx 编译时依赖 gcc 环境

安装 pcre$ sudo yum -y install pcre pcre-devel # 让 nginx 支持重写功能

安装 zlib# zlib 库提供了很多压缩和解压缩的方式，nginx 使用 zlib 对 http 包内容进行 gzip 压缩$ sudo yum -y install zlib zlib-devel

安装 openssl# 安全套接字层密码库，用于通信加密$ sudo yum -y install openssl openssl-devel

以上安装完成后，进行 nginx 安装。
2. nginx 源码包安装创建用户组和用户创建 nginx 用户组
groupadd nginx

创建 nginx 用户并添加进 nginx 用户组
useradd -g nginx -m nginx

设置 nginx 用户密码
passwd nginx

下载配置将准备好的 nginx-1.22.1.tar.gz 包，拷贝至 home 目录下（一般习惯在此目录下进行安装）进行解压缩。
源码包下载地址：nginx: download
$ sudo tar -zxvf nginx-1.22.1.tar.gz # 解压缩

在完成解压缩后，进入 nginx-1.22.1 目录进行源码编译安装。
这里编译的时候需要原有的编译的基础上加上以下参数：
--add-module=../ngx-fancyindex-0.5.2

命令会显示一些环境信息。如果出现错误，一般是依赖库没有安装完成，可按照错误提示信息进行所缺的依赖库安装。
预先创建好如下目录
mkdir -p /var/cache/nginx/&#123;client_temp,proxy_temp,fastcgi_temp,uwsgi_temp,scgi_temp&#125;

完整编译命令如下：
./configure \--prefix=/etc/nginx \--sbin-path=/usr/sbin/nginx \--modules-path=/usr/lib64/nginx/modules \--conf-path=/etc/nginx/nginx.conf \--error-log-path=/var/log/nginx/error.log \--http-log-path=/var/log/nginx/access.log \--pid-path=/var/run/nginx.pid \--lock-path=/var/run/nginx.lock \--http-client-body-temp-path=/var/cache/nginx/client_temp \--http-proxy-temp-path=/var/cache/nginx/proxy_temp \--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \--http-scgi-temp-path=/var/cache/nginx/scgi_temp \--user=nginx \--group=nginx \--with-compat \--with-file-aio \--with-threads \--with-http_addition_module \--with-http_auth_request_module \--with-http_dav_module \--with-http_flv_module \--with-http_gunzip_module \--with-http_gzip_static_module \--with-http_mp4_module \--with-http_random_index_module \--with-http_realip_module \--with-http_secure_link_module \--with-http_slice_module \--with-http_ssl_module \--with-http_stub_status_module \--with-http_sub_module \--with-http_v2_module \--with-mail \--with-mail_ssl_module \--with-stream \--with-stream_realip_module \--with-stream_ssl_module \--with-stream_ssl_preread_module \--with-cc-opt=&#x27;-I/usr/local/opt/pcre/include -I/usr/local/opt/openssl/include&#x27; \--with-ld-opt=&#x27;-L/usr/local/opt/pcre/lib -L/usr/local/opt/openssl/lib&#x27; \--add-module=../ngx-fancyindex

查看 fancy 是否安装成功
[root@yahya ~]# 2&gt;&amp;1 ./nginx -V | tr &#x27; &#x27; &#x27;\n&#x27;|grep fan--add-module=ngx-fancyindex-0.5.2

目录结构一览nginx 运行主 bin 文件已放至 /usr/sbin 目录下，可以直接使用 nginx 的相关命令而不需要定位到绝对路径，目录结构功能一览如下：
主配置文件目录[root@yahya ~]# tree /etc/nginx/etc/nginx├── fastcgi.conf├── fastcgi.conf.default├── fastcgi_params├── fastcgi_params.default├── html│   ├── 50x.html│   ├── fancyindex.conf│   ├── index.html│   ├── Nginx-Fancyindex│   │   ├── addNginxFancyIndexForm.js│   │   ├── footer.html│   │   ├── header.html│   │   ├── jquery.min.js│   │   ├── showdown.min.js│   │   └── styles.css│   ├── Nginx-Fancyindex-Theme-dark│   │   ├── addNginxFancyIndexForm.js│   │   ├── footer.html│   │   ├── header.html│   │   ├── jquery.min.js│   │   ├── showdown.min.js│   │   └── styles.css│   └── Nginx-Fancyindex-Theme-light│       ├── addNginxFancyIndexForm.js│       ├── footer.html│       ├── header.html│       ├── HEADER.md│       ├── jquery.min.js│       ├── README.md│       ├── showdown.min.js│       └── styles.css├── koi-utf├── koi-win├── mime.types├── mime.types.default├── nginx.conf├── nginx.conf.default├── pass_file├── scgi_params├── scgi_params.default├── uwsgi_params├── uwsgi_params.default└── win-utf

日志目录[root@yahya ~]# tree /var/log/nginx/var/log/nginx├── access.log└── error.log

临时文件目录[root@yahya ~]# tree /var/cache/nginx/var/cache/nginx├── client_temp├── fastcgi_temp├── proxy_temp├── scgi_temp└── uwsgi_temp

运行目录[root@yahya ~]# tree /var/run/var/run├── nginx.pid

编译安装进行源码编译并安装 nginx
$ make # 编译$ make install # 安装

3. 添加登录认证安装 htpasswd
sudo yum install -y httpd-tools

设置用户名密码
htpasswd -c -d /etc/nginx/pass_file &lt;username&gt;

回车，按提示输入两次密码。再次访问网站会弹出登录框做认证，这里设置用户名密码均为 admin。
4. 配置 nginx.conf#user  nobody;worker_processes  1;#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#pid        logs/nginx.pid;events &#123;    worker_connections  1024;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;    #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;    #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    charset utf-8;    #access_log  logs/access.log  main;    sendfile        on;    #tcp_nopush     on;    keepalive_timeout  65;    gzip  on;    server &#123;        listen       80;        server_name  localhost;        client_max_body_size 4G;        #charset koi8-r;        #access_log  logs/host.access.log  main;        error_page   500 502 503 504  /50x.html;        location / &#123;            root   html;            index  index.html index.htm;        &#125;        location /download &#123;            include /etc/nginx/fancyindex.conf; # 目录美化配置            auth_basic &quot;You are not authorized&quot;;            auth_basic_user_file /etc/nginx/pass_file;            alias /usr/local/download/; # 指定目录所在路径            autoindex on; # 开启目录浏览            autoindex_format html; # 以html风格将目录展示在浏览器中            autoindex_exact_size off; # 切换为 off 后，以可读的方式显示文件大小，单位为 KB、MB 或者 GB            autoindex_localtime on; # 以服务器的文件时间作为显示的时间            charset utf-8,gbk; # 展示中文文件名        &#125;        #error_page  404              /404.html;        # redirect server error pages to the static page /50x.html        #        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;    &#125;&#125;

常用命令查找当前 nginx 安装目录
which nginx

启动服务
nginx

重新加载服务
nginx -s reload

停止服务
nginx -s stop

查看 nginx 服务进程
ps -ef | grep nginx # 查看服务进程

参考链接linux添加用户，用户组（centos7）
How To Set Up Basic HTTP Authentication With Nginx on CentOS 7
CentOS 7 安装 Nginx
Nginx 文件服务器页面美化，按时间倒叙
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx SSL 配置</title>
    <url>/posts/6da6896d/</url>
    <content><![CDATA[目录编译安装为了给 nginx 增加 ssl 安全证书配置，需要在编译的时候增加以下选项：
--with-http_ssl_module

如果之前的 nginx 编译的时候已经加上上述选项，可以直接跳过，否则可以参考下面命令的基础用法：
./configure --prefix=&lt;安装位置&gt; --with-http_ssl_module

然后执行下面的命令进行 nginx 的安装
make &amp;&amp; make install

配置 nginx.confserver &#123;    listen       443 ssl;    server_name  localhost vless.yahyav2rayssr.top;    # ssl证书地址    ssl_certificate     /etc/nginx/cert/cloudflare-ssl.pem;  # pem文件的路径    ssl_certificate_key  /etc/nginx/cert/cloudflare-ssl.key; # key文件的路径    # ssl验证相关配置    ssl_session_timeout  5m;    #缓存有效期    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;    #加密算法    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;    #安全链接可选的加密协议    ssl_prefer_server_ciphers on;   #使用服务器端的首选算法    location / &#123;        root   html;        index  index.html index.htm;    &#125;&#125;

将 http 重定向 httpsserver &#123;    listen       80;    server_name  localhost vless.yahyav2rayssr.top;    return 301 https://$server_name$request_uri;&#125;

重启 nginxnginx -s reload

参考链接Nginx 安装 SSL 配置 HTTPS 超详细完整全过程
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx 常用命令</title>
    <url>/posts/ffa59763/</url>
    <content><![CDATA[测试文件是否正确nginx -t

指定外部配置文件nginx -c &lt;path_to_config&gt;

显示 nginx 版本号nginx -v

显示 nginx 的版本号以及编译环境信息以及编译时的参数nginx -V

]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx 常用配置</title>
    <url>/posts/59e56e3a/</url>
    <content><![CDATA[nginx使用非80端口时url带端口号的解决办法
注意这里$server_port要和浏览器你想显示的端口号保持一致，因为我listen是80所以是80，如果你listen是8080，又想浏览器显示80，这里server_port 就设置成80。

server &#123;    listen 80;    server_name localhost;			# 参数之一    port_in_redirect off        proxy_set_header Host $host:$server_port;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    location / &#123;        proxy_pass http://127.0.0.1:8080/;    &#125;&#125;

proxy_pass反向代理cookie,session丢失server &#123;    listen 80;    server_name le.qin.com le.qin.cn;    location / &#123;        proxy_pass http://127.0.0.1:9002/;        root html;        index index.html;        rewrite &quot;^/+$&quot; /officialsite/initLedaIndex last;        proxy_cookie_path /offIcialsite/initLedaIndex /;        proxy_set_header Cookie $http_cookie;        proxy_set_header Host $http_host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    &#125;&#125;

proxy header 端口错误
nginx监听端口为非80端口时需要配置如下：

proxy_set_header Host $host:$server_port

proxy_redirect 使用
如果需要修改从被代理服务器传来的应答头中的”Location”和”Refresh”字段，可以用这个指令设置。

proxy_redirect 语法：proxy_redirect [ default | off | redirect replacement ] 默认值：proxy_redirect default 使用字段：http, server, location
示例：
server &#123;    listen 80;    server_name www.boke.com;    location / &#123;        proxy_pass http://192.168.1.154:8080;        proxy_redirect ~^http://192.168.1.154:8080(.*) http://www.boke.com$1;    &#125;&#125;

[root@localhost nginx]# curl -I http://www.boke.com/wumanHTTP/1.1 301 Moved PermanentlyServer: nginxDate: Thu, 24 Dec 2015 12:02:00 GMTContent-Type: text/html; charset=iso-8859-1Connection: keep-alive# 修改前Location: http://192.168.1.154:8080/wuman/# 修改后Location: http://www.boke.com/wuman/

location配置直接输出文本直接返回文本：
location / &#123;    default_type    text/plain;    return 502 &quot;服务正在升级，请稍后再试……&quot;;&#125;

也可以使用html标签格式：
location / &#123;    default_type    text/html;    return 502 &quot;服务正在升级，请稍后再试……&quot;;&#125;

也可以直接返回json文本：
location / &#123;    default_type    application/json;    return 502 &#x27;&#123;&quot;status&quot;:502,&quot;msg&quot;:&quot;服务正在升级，请稍后再试……&quot;&#125;&#x27;;&#125;

配置resolver指定DNS解析resolver可以指定多个DNS，使用valid来设置缓存时间，如下：
resolver 119.29.29.29 114.114.114.114 valid=3600s;

如果不填写端口则默认使用53，还可以向下面这样指定DNS端口：
resolver 127.0.0.1:5353 valid=30s;

强制更新解析：
resolver 127.0.0.1;set $backend &quot;foo.example.com&quot;;proxy_pass http://$backend;

server_name 配置前言虚拟主机是一种在单一主机或主机群上运行多个网站或服务的技术，可以用来解决IP地址资源有限而网站数目日益增多的问题。实现方式主要有以下三种:

基于域名(Name-based)
基于IP地址(IP-based)
基于Port端口(Port-based)

其中使用最广泛无疑是基于域名的方式,不同的域名通过DNS最终可以解析到相同的IP地址,在对应的机器上我们可以使用Nginx等Web服务器软件对不同的域名请求进行相应的处理。这里再提及一点,我们平时访问一个网站，是通过DNS将其解析到某一个IP上,我们的客户端（通常是浏览器）最终是和这个IP对应的机器建立连接，从而发送请求的。那么Nginx等服务器是如何知道一个请求对应的是哪个域名的呢？
答案在于HTTP协议中的Host请求头,其值为我们要访问的域名。这里需要注意的是,在HTTP&#x2F;1.0中是不支持Host请求头字段的,所以HTTP&#x2F;1.0是不支持虚拟主机技术的，而根据 rfc2616规范 HTTP&#x2F;1.1协议中客户端发送的请求必须带上Host这个请求头,否则服务器必须返回400 Bad Request响应。
而nginx正是通过http模块下的server指令块来配置虚拟主机。
配置语法Syntax:    server_name name ...;Default:    server_name &quot;&quot;;Context: server

server_name形式sever_name指令后面的参数值可以是以下几种:

精确的域名,例如www.example.com
通配符名称,可用表示任意多字符(类似Linux Shell中的),但是通配符必须在域名的最前面或者最后面,例如*.example.com、www.example.*
正则表达式,最前面是一个波浪号,例如&#96;^www\d+.example.com$&#96;表示可以匹配以www开头，后跟一个到多个数字，然后以.example.com结尾的域名

除了以上几种形式，还有下面几种表示特殊含义的域名:

.example.com,相当于*.example.com + example.com
“” 可以匹配没有带Host头的请求
国际化域名（用得不多,了解即可）,用ASCII码表示，例如xn--e1afmkfd.xn--80akhbyknj4f可表示пример.испытание
_、__或者!@#等无效的域名，可以理解为其可以匹配任意域名，但是优先级最低，最常见的用法是用来设置默认的server,即当一个请求的Host没有命中其他规则时，会采用默认server的配置。配置如下:

server &#123;    listen       80  default_server;    server_name  _;    return       444;&#125;

server_name匹配顺序当需要决定采用哪个server块的配置处理请求时,会根据以下的顺序查找:

精确匹配
以 * 开头的最长通配符名称
以 * 结尾的最长通配符名称
根据在配置文件出现的顺序第一个匹配上的正则表示式名称
默认配置，在 listen 指令中指明了 default_server 的 server 块，若无，为配置文件中第一个声明的 server 块

配置默认serverserver &#123;    listen 80 default_server;    server_name _;    return 200 &quot;default_server&quot;;&#125;

关于listen指令,有几点需要注意的地方:

如果server指令块里没有指定listen指令,则根据运行nginx的用户不同，默认监听的端口也不同,root用户启动默认监听80端口，否则默认监听8000端口
如果配置了listen且只指定了IP,则监听端口为80,此时操作系统可能会不允许非root用户启动nginx，提示

nginx: [emerg] bind() to 127.0.0.1:80 failed (13: Permission denied)

location 配置配置语法Syntax:    location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;location @name &#123; ... &#125;Default: —Context: server, location

根据配置语法我们知道location可以有以下几种形式:

其中 &#x3D; 和 ^~ 修饰符都可以认为是特殊形式的前缀匹配，正则匹配比普通前缀匹配优先级高


&#x3D;，精确匹配
～，正则匹配,大小写敏感
～*，正则匹配, 大小写不敏感
^~，忽略正则表达式的前缀匹配
没有修饰符，普通前缀匹配
@，命名location,可用来做内部重定向

匹配过程根据请求的 URI 和 location 的配置,查找请求对应的 location 过程如下:

将请求URI标准化,包括将”%xx”形式编码的文本进行解码，解析相对路径”.”和”..”以及合并两个或多个相邻的”&#x2F;“成单个”&#x2F;“。
根据请求URI找到并记录匹配上的最长前缀匹配，这里有两个特殊的场景:
找到了&#x3D;修饰的精确匹配,结束查找,采用它的配置。
如果该步骤最终记录下的前缀以^~修饰，则采用它的配置，不会进行后续的查找步骤。


根据在配置文件出现的顺序，检查相应的正则匹配，若有一个匹配上，则应用该配置，且不会继续检查后续的正则配置。
若第3步没有找到匹配上的正则匹配，则采用第2步中找到的最长前缀匹配对应的配置。

根据上面的查找过程，可以得到一些配置优化点：

对于经常要访问的路径，可以使用精确匹配或^&#x3D;修饰的匹配,可以避免进行正则匹配检查。
如果一定要用到正则表达式，可以把最经常被访问的location规则配置在最前面，因为正则匹配命中一个就不会继续验证后续的匹配规则。

注意：
关于最后一条测试结果,需要注意的是，/a/.*$这个正则表达式,并不要求请求URI以/a开头，这也是很容易疏漏的地方,若想匹配以/a开头的请求，应改为^/a/.*$
@name的用法location /try &#123;    try_files $uri $uri/ @name;&#125;location /error &#123;    error_page 404 = @name;    return 404;&#125;location @name &#123;    return 200 &quot;@name&quot;;&#125;

]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx 基本概念</title>
    <url>/posts/56e587e1/</url>
    <content><![CDATA[目录$host 和 $http_host 的区别$host 是 core 模块内部的一个变量

当请求头里不存在 Host 属性或者是个空值，$host 则等于 server_name
如果请求头里有 Host 属性，那么 $host 等于 Host 属性除了端口号的部分，例如 Host 属性是 www.example.com，那么 $host 就是 www.example.com

$http_host 不是一个固定的变量，他其实是 $http_HEADER 通配后的结果。
$http_HEADER，注意，这里的HEADER是一个通配符，通配的是请求头里的header属性，例如 $http_content_type 表示请求头里 content-type 属性的值，同理，$http_host 指的就是请求头里的 host 属性，也就是说，如果请求头里面 Host 为空，$http_host 取到的值也就是空。
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx 常见错误</title>
    <url>/posts/516ff0b8/</url>
    <content><![CDATA[目录413错误
fastcgi_intercept_errors 语法: fastcgi_intercept_errors on|off 默认: fastcgi_intercept_errors off 添加位置: http, server, location 默认情况下，nginx不支持自定义404错误页面，只有这个指令被设置为on，nginx才支持将404错误重定向

修改nginx配置文件，配置客户端请求大小和缓存大小
在http&#123;&#125;中输入
client_max_body_size 8M;(配置请求体缓存区大小) client_body_buffer_size 128k;(设置客户端请求体最大值) fastcgi_intercept_errors on;

post 解决办法针对post请求解决办法： 
修改nginx.conf里面的几个相关的配置参数 
client_body_buffer_size 10m(配置请求体缓存区大小, 不配的话) client_max_body_size 20m(设置客户端请求体最大值) client_body_temp_path /data/temp (设置临时文件存放路径。只有当上传的请求体超出缓存区大小时，才会写到临时文件中,注意临时路径要有写入权限) 

如果上传文件大小超过client_max_body_size时，会报413 entity too large的错误。 
get 解决办法
为什么修改 http header 的大小就能解决 get 请求串过长的问题？因为 get 请求参数会拼在 http header 中，所以，修改了 http header 的大小，就能解决上面问题。

针对get请求，我们可以通过修改另外两个配置来解决请求串超长的问题： 
使用字段：http, server 
client_header_buffer_size 16k;large_client_header_buffers 4 16k;

下面讲讲这两个参数以及他们之间的关联关系：
对nginx处理header时的方法：


先处理请求的request_line，之后才是request_header。
这两者的buffer分配策略相同。
先根据client_header_buffer_size配置的值分配一个buffer，如果分配的buffer无法容纳 request_line&#x2F;request_header，那么就会再次根据large_client_header_buffers配置的参数分配large_buffer，如果large_buffer还是无法容纳，那么就会返回414（处理request_line）&#x2F;400（处理request_header）错误。


400错误：HTTP头&#x2F;Cookie过大　　nginx400错误是由于request header过大，通常是由于cookie中写入了较长的字符串所引起的。
​		解决方法是不要在cookie里记录过多数据，如果实在需要的话可以考虑调整在nginx.conf中的client_header_buffer_size(默认1k)
　　若cookie太大，可能还需要调整large_client_header_buffers(默认4k)，该参数说明如下：
　　请求行如果超过buffer，就会报HTTP 414错误(URI Too Long)
　　nginx接受最长的HTTP头部大小必须比其中一个buffer大，否则就会报400的HTTP错误(Bad Request)。
504错误1、修改&#x2F;etc&#x2F;nginx&#x2F;nginx.conf，添加如下信息：
http &#123;    include       /etc/nginx/mime.types;    default_type  application/octet-stream;    log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    access_log  /var/log/nginx/access.log  main;    sendfile on;    # tcp_nopush on;    keepalive_timeout 65;    # gzip on;    include /etc/nginx/conf.d/*.conf;            # 用于tomcat反向代理,解决nginx 504错误     proxy_connect_timeout 300; #单位秒     proxy_send_timeout 300; #单位秒     proxy_read_timeout 300; #单位秒     proxy_buffer_size 16k;     proxy_buffers 4 64k;     proxy_busy_buffers_size 128k;     proxy_temp_file_write_size 128k;    # ps:以timeout结尾配置项时间要配置大点&#125;

2、修改server{}，添加如下信息：
location / &#123;        proxy_pass http://182.61.131.62:33060/;        proxy_redirect  off;    	    #用于tomcat反向代理,解决nginx 504错误        proxy_send_timeout 300;        proxy_read_timeout 300;        proxy_connect_timeout 300;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#125;

http header丢失
header键尽量不要带下划线的命名，不然必须得在nginx里面手动打开如下配置：

underscores_in_headers on;

rewrite post数据丢失rewrite 外部跳转和内部跳转的区别

外部跳转 http:&#x2F;&#x2F; 触发301，POST数据丢失
内部跳转 POST数据不丢失

使用rewrite 与proxy_pass处理此事
location / &#123;    rewrite (.*) /app$1;&#125;location /app &#123;    proxy_pass http://was;&#125;

http 411 length requiredhttp模块添加参数：chunked_transfer_encoding on;
301 URI路径错误问题前端的Nginx负责把http://www.a.com/b/c/开头的url反向代理到后端的 http://127.0.0.1/c/ 上，对于有完整的
路径，如http://www.a.com/b/c/的代理没有问题，Server对应后台服务器的一个目录。
但当访问http://www.a.com/b/c时，后端Nginx会发送一个301到/上，于是返回到前端后URL变成了
http://www.a.com/c/，这个url显然不是我们想要的。

在Apache中有个ProxyPassReverse的参数，用来调整反向代理服务器发送的http应答头的url，可以解决这个问题。

在Nginx代理配置，可以使用proxy_redirect这个参数，它实现的功能和ProxyPassReverse类似，例如增加如下配置：
location ^~ /b &#123;   proxy_pass http://127.0.0.1/;   proxy_redirect http://www.a.com/ /b/; &#125; 

Location 携带错误端口号抓包发现服务器给客户端的跳转指令里加了端口号，如Location: http://www.a.com:9080/abc.html 。因为nginx服务器侦听的是80端口，所以这样的URL给了客户端,必然会出错.针对这种情况, 加一条proxy_redirect指令: proxy_redirect http://www.kevin.com:9080/ / ,即把所有&quot;http://www.a.com:9080/&quot;的内容替换成&quot;/&quot;再发给客户端，就解决了。
server &#123;    listen 80;    server_name www.a.com;    proxy_redirect http://www.a.com:9080/ /; # 增加此行    location / &#123;        proxy_pass http://127.0.0.1:9080;    &#125;&#125;

]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx 证书概念</title>
    <url>/posts/4b23af26/</url>
    <content><![CDATA[目录编码格式X.509 - 这是一种证书标准,主要定义了证书中应该包含哪些内容.其详情可以参考 RFC5280，SSL使用的就是这种证书标准。
目前有以下两种编码格式。
PEMPrivacy Enhanced Mail，打开看文本格式，以”—–BEGIN…”开头，”—–END…”结尾，内容是 BASE64 编码。
查看 PEM 格式证书的信息：
openssl x509 -in cloudflare-ssl.pem -text -noout

Apache 和 NGINX 服务器偏向于使用这种编码格式.
PEM – Openssl 使用 PEM（Privacy Enhanced Mail）格式来存放各种信息，它是 openssl 默认采用的信息存放方式。
Openssl 中的 PEM 文件一般包含如下信息:

内容类型：表明本文件存放的是什么信息内容,它的形式为“——-BEGIN XXXX ——”，与结尾的“——END XXXX——”对应。
头信息：表明数据是如果被处理后存放，openssl 中用的最多的是加密信息，比如加密算法以及初始化向量 iv。
信息体：为 BASE64 编码的数据。可以包括所有私钥（RSA 和 DSA）、公钥（RSA 和 DSA）和 (x509) 证书。它存储用 Base64 编码的 DER 格式数据，用 ascii 报头包围，因此适合系统之间的文本模式传输。

举个栗子：
使用 PEM 格式存储的证书（.pem 格式结尾）：
—–BEGIN CERTIFICATE—–MIICJjCCAdCgAwIBAgIBITANBgkqhkiG9w0BAQQFADCBqTELMAkGA1UEBhMCVVMx………1p8h5vkHVbMu1frD1UgGnPlOO/K7Ig/KrsU=—–END CERTIFICATE—–

使用 PEM 格式存储的私钥（.key 格式结尾）：
—–BEGIN RSA PRIVATE KEY—–MIICJjCCAdCgAwIBAgIBITANBgkqhkiG9w0BAQQFADCBqTELMAkGA1UEBhMCVVMx………1p8h5vkHVbMu1frD1UgGnPlOO/K7Ig/KrsU=—–END RSA PRIVATE KEY—–

使用 PEM 格式存储的证书请求文件(.csr 格式结尾 )：
—–BEGIN CERTIFICATE REQUEST—–MIICJjCCAdCgAwIBAgIBITANBgkqhkiG9w0BAQQFADCBqTELMAkGA1UEBhMCVVMx………1p8h5vkHVbMu1frD1UgGnPlOO/K7Ig/KrsU=—–END CERTIFICATE REQUEST—–

DERDistinguished Encoding Rules，辨别编码规则 (DER) 可包含所有私钥、公钥和证书。它是大多数浏览器的缺省格式，并按 ASN1 DER 格式存储。它是无报头的 － PEM 是用文本报头包围的 DER，打开看是二进制格式,不可读.
查看DER格式证书的信息：
openssl x509 -in cloudflare-ssl.der -inform der -text -noout

Java 和 Windows 服务器偏向于使用这种编码格式。
证书转换PEM 转 CRTopenssl x509 -in cloudflare-ssl.pem -out cloudflare-ssl.crt

CRT 转 PEMopenssl x509 -in cloudflare-ssl.crt -outform pem -out cloudflare-ssl.pem

PEM 转为 DERopenssl x509 -in cloudflare-ssl.pem -outform der -out cloudflare-ssl.der

DER 转为 PEMopenssl x509 -in cloudflare-ssl.der -inform der -outform pem -out cloudflare-ssl.pem

CRT 转 DERopenssl x509 -in cloudflare-ssl.crt -outform der -out cloudflare-ssl.der

从上面的命令我们看出证书的转换是支持三边两两转换的，除了不支持 der 直接转成 crt 之外，如下图所示：

提示：要转换 KEY 文件也类似,只不过把 x509 换成 rsa，要转 CSR 的话，把 x509 换成 req。






]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>证书</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 基本概念</title>
    <url>/posts/f69de184/</url>
    <content><![CDATA[git rebase 和 git merge 的区别merge

执行以下命令：
git checkout featuregit merge master

或者执行更简单的：
git merge master feature

那么此时在feature上git 自动会产生一个新的commit(merge commit)


marge 特点：自动创建一个新的commit 如果合并的时候遇到冲突，仅需要修改后重新commit 优点：记录了真实的commit情况，包括每个分支的详情 缺点：因为每次merge会自动产生一个merge commit，所以在使用一些git 的GUI tools，特别是commit比较频繁时，看到分支很杂乱。
rebase执行以下命令：
git checkout featuregit rebase master



rebase 特点：会合并之前的commit历史 优点：得到更简洁的项目历史，去掉了merge  commit 缺点：如果合并出现代码问题不容易定位，因为re-write了history
解决冲突合并时如果出现冲突需要按照如下步骤解决

修改冲突部分
git add
git rebase --continue
（如果第三步无效可以执行  git rebase --skip）

不要在git add 之后习惯性的执行 git commit命令
git merge --no-ff 和 git merge --squash 区别--no-ff指的是强行关闭fast-forward方式。
fast-forward方式就是当条件允许的时候，git直接把HEAD指针指向合并分支的头，完成合并。属于“快进方式”，不过这种情况如果删除分支，则会丢失分支信息。因为在这个过程中没有创建commit
git merge --squash 是用来把一些不必要commit进行压缩，比如说，你的feature在开发的时候写的commit很乱，那么我们合并的时候不希望把这些历史commit带过来，于是使用--squash进行合并，此时文件已经同合并后一样了，但不移动HEAD，不提交。需要进行一次额外的commit来“总结”一下，然后完成最终的合并。
总结：--no-ff：不使用fast-forward方式合并，保留分支的commit历史--squash：使用squash方式合并，把多次分支commit历史压缩为一次


git commit –amend有时提交过代码之后，发现一个地方改错了，但是下次提交时不想保留上一次的记录；或者上一次的commit message的描述有误，这时候可以使用 git commit --amend。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim 基本命令</title>
    <url>/posts/154baef/</url>
    <content><![CDATA[目录跳至行首&#x2F;行尾跳至当前行行首
# shift+4命令可以敲出$字母$# 或者数字00

跳至当前行行尾
# 大写的AA

                      
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 常用命令</title>
    <url>/posts/5fddf106/</url>
    <content><![CDATA[查看系统配置git config --system --list

查看全局配置git config --global --list

查看当前配置git config --local --list

全局设置用户名和密码git config --global user.name &quot;yourName&quot;git config --global user.email &quot;yourEmail&quot;

删除配置git config --unset user.name

对比差异导出文件git archive -o [输出文件] HEAD $(git diff [SHA值1] [SHA值2] --name-only)# 例git archive -o code-compare.zip HEAD $(git diff c43278d3b5ee4fb2e4644dce3b5081371d068e14 1a91b349a593616d35bfbd035af8ae1053d58d48 --name-only)

代理

解决 Failed to connect to github.com port 443:connection timed out 的问题。
解决  Proxy CONNECT aborted 的问题。


设置全局http、https代理
如果是 socks5 代理，需要将下面命令的http://替换为socks://

git config --global http.proxy http://127.0.0.1:1080 git config --global https.proxy http://127.0.0.1:1080

设置局部http、https代理如果只针对某项目设置，在项目根目录下
git config --local http.proxy socks5://127.0.0.1:1080git config --local https.proxy socks5://127.0.0.1:1080

查看http、https代理配置情况git config --global --get http.proxygit config --global --get https.proxy

取消http、https代理配置git config --global --unset http.proxygit config --global --unset https.proxygit config --local --unset http.proxygit config --local --unset https.proxy

仓库关联查看仓库信息查看关联的远程仓库的名称
git remote

查看关联的远程仓库的详细信息
git remote -v

方式一：查看当前仓库地址基本语法：
git remote get-url &lt;remote_repo_name&gt;

举个栗子：
git remote get-url origin

移除远程仓库的关联基本语法：
git remote remove &lt;remote_repo_name&gt;

举个栗子：
git remote remove origin

添加仓库地址
添加对远程仓库的关联。

基本语法：
git remote add &lt;remote_repo_name&gt; &lt;repo_url&gt;

举个栗子：
git remote add origin https://gitee.com/findmoon/xxx.git

方式二：更新远程仓库映射基本语法：
git remote set-url origin &lt;remote_url&gt;

举个栗子：
git remote set-url origin https://gitee.com/findmoon/xxx.git

分支关联基本语法：
git branch --set-upstream-to=origin/&lt;remote_branch_name&gt; &lt;local_branch_name&gt;

举个栗子：
git branch --set-upstream-to=origin/master master

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 常见错误</title>
    <url>/posts/f11796dd/</url>
    <content><![CDATA[Add correct host key in &#x2F;root&#x2F;.ssh&#x2F;known_hosts to get rid of this message.问题现象ssh 远程到远端服务器报错
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host isSHA256:NHg/pDwRdtQThZzY3Z4Uwq/Rz93FgmL3UdBAFleWFWk.Please contact your system administrator.Add correct host key in /Users/yuanting/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /Users/yuanting/.ssh/known_hosts:102ECDSA host key for 192.168.198.190 has changed and you have requested strict checking.Host key verification failed.

原因因为服务器的ip发生变更了第一次SSH连接时，会生成一个认证，储存在客户端（也就是用SSH连线其他电脑的那个，自己操作的那个）中的known_hosts，但是如果服务器验证过了，认证资讯当然也会更改，服务器端与客户端不同时，就会跳出错误啦。
解决办法方式一输入命令：
ssh-keygen -R + &lt;输入服务器的IP&gt;

例如：
ssh-keygen -R 192.168.198.147# Host 192.168.198.147 found: line 36/Users/renwoxing/.ssh/known_hosts updated.

方式二在连接的目标主机上的~&#x2F;.ssh&#x2F;known_hosts文件，去除过时的认证。
举个栗子：
# vim ~/.ssh/known_hosts// 删除下列内容192.168.118.98 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBO7yIeXPP4/dSuaV/0hObmbc0Si1rtGLFbi7Lz75SAzMO5dseLe1w5TwJKDJ+vQ5GgZaWmqhIrXgx0o8VdWSEQA=

彻底解决【“curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused”】错误临时方案用如下命令下载安装msf时，提示curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused
curl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb &gt; msfinstall &amp;&amp; \chmod 755 msfinstall &amp;&amp; \./msfinstall

之前也遇到过类似的错误，用的解决方法是，fq工具打开全局模式，然后打开curl后面的地址（这里是：https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb），之后另存为文件，并依次执行后续命令。
上面是最简单便捷的方法，详细内容可以参考： Homebrew installation on Mac OS X Failed to connect to raw.githubusercontent.com port 443 
最终解决方案最近再次遇到该问题，详细了解了下，发现是 github 的一些域名的 DNS 解析被污染，导致 DNS 解析过程无法通过域名取得正确的IP地址。可以通过修改 &#x2F;etc&#x2F;hosts 文件可解决该问题。
具体而言：
打开 https://www.ipaddress.com/ 输入访问不了的域名，获得对应的IP。
使用 vim &#x2F;etc&#x2F;hosts 命令打开不能访问的机器的hosts文件，添加如下内容：
185.199.108.133 raw.githubusercontent.com185.199.108.133 user-images.githubusercontent.com185.199.108.133 avatars2.githubusercontent.com185.199.108.133 avatars1.githubusercontent.com

注：上面内容中 185.199.108.133 是 raw.githubusercontent.com 所在的服务器IP（通过  https://www.ipaddress.com/ 获知）。
保存该文件，再使用即可正常访问。
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 其他命令</title>
    <url>/posts/436d559e/</url>
    <content><![CDATA[命令行更新gitgit update-git-for-windows

生成公钥和私钥传统方式ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;

最新方式ssh-keygen -t ed25519 -C &quot;your_email@example.com&quot;

测试连通性ssh -T git@github.com

命令行指定密钥基本语法：
ssh-add &lt;id_rsa_path&gt;

举个栗子：
ssh-add ~/.ssh/id_rsa

密码重置git config --system --unset credential.helper

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>gitkraken 破解</title>
    <url>/posts/8aace767/</url>
    <content><![CDATA[1. 下载客户端
gitkraken windows版本 6.5.1下载地址-1
gitkraken windows版本 6.5.1下载地址-2
gitkraken Mac版本 6.5.1下载地址
gitkraken linux deb 6.5.1下载地址

2. 屏蔽更新host# gitKraken 更新屏蔽127.0.0.1 release.gitkraken.com

3. 打开gitkraken并登陆4. 下载破解脚本git clone https://github.com/5cr1pt/GitCracken.gitcd GitCracken/GitCrackenrm yarn.lockyarn installyarn build# windows gitbashnode dist/bin/gitcracken.js patcher --asar ~/AppData/Local/gitkraken/app-6.5.0/resources/app.asar# mac node dist/bin/gitcracken.js patcher --asar 你的gitkraken的目录/resources/app.asar

5. 禁用更新删掉Update.exe, 查找和Gitkraken目录有关的Update.exe(一般在C:\Users\你的用户名\AppData\Local\gitkraken目录下)。

参考：
插件github
破解插件
才发现 gitkraken 现在要给钱才能打开私有库了
]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>破解</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务的解决方案</title>
    <url>/posts/d8e228f5/</url>
    <content><![CDATA[目录事务的四大特性 ACID说到事务，就不得不提一下事务著名的四大特性。

原子性 原子性要求，事务是一个不可分割的执行单元，事务中的所有操作要么全都执行，要么全都不执行。
一致性 一致性要求，事务在开始前和结束后，数据库的完整性约束没有被破坏。
隔离性 事务的执行是相互独立的，它们不会相互干扰，一个事务不会看到另一个正在运行过程中的事务的数据。
持久性 持久性要求，一个事务完成之后，事务的执行结果必须是持久化保存的。即使数据库发生崩溃，在数据库恢复后事务提交的结果仍然不会丢失。

事务的隔离级别事务并发执行会出现的问题
更新丢失 当有两个并发执行的事务，更新同一行数据，那么有可能一个事务会把另一个事务的更新覆盖掉。 当数据库没有加任何锁操作的情况下会发生。
脏读 一个事务读到另一个尚未提交的事务中的数据。 该数据可能会被回滚从而失效。 如果第一个事务拿着失效的数据去处理那就发生错误了。
不可重复读 不可重复度的含义：一个事务对同一行数据读了两次，却得到了不同的结果。它具体分为如下两种情况：


虚读：在事务1两次读取同一记录的过程中，事务2对该记录进行了修改，从而事务1第二次读到了不一样的记录。
幻读：事务1在两次查询的过程中，事务2对该表进行了插入、删除操作，从而事务1第二次查询的结果发生了变化。


不可重复读 与 脏读 的区别？ 脏读读到的是尚未提交的数据，而不可重复读读到的是已经提交的数据，只不过在两次读的过程中数据被另一个事务改过了。

数据库的四种隔离级别
Read uncommitted 读未提交 在该级别下，一个事务对一行数据修改的过程中，不允许另一个事务对该行数据进行修改，但允许另一个事务对该行数据读。 因此本级别下，不会出现更新丢失，但会出现脏读、不可重复读。
Read committed 读提交 在该级别下，未提交的写事务不允许其他事务访问该行，因此不会出现脏读；但是读取数据的事务允许其他事务的访问该行数据，因此会出现不可重复读的情况。
Repeatable read 重复读 在该级别下，读事务禁止写事务，但允许读事务，因此不会出现同一事务两次读到不同的数据的情况（不可重复读），且写事务禁止其他一切事务。
Serializable 序列化 该级别要求所有事务都必须串行执行，因此能避免一切因并发引起的问题，但效率很低。


隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed。它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、幻读和第二类丢失更新这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。

CAP理论CAP理论说的是：在一个分布式系统中，最多只能满足C、A、P中的两个需求。
CAP的含义：

C：Consistency 一致性 同一数据的多个副本是否实时相同。
A：Availability 可用性 可用性：一定时间内系统返回一个明确的结果 则称为该系统可用。
P：Partition tolerance 分区容错性 将同一服务分布在多个系统中，从而保证某一个系统宕机，仍然有其他系统提供相同的服务。

BASE理论CAP理论告诉我们一个悲惨但不得不接受的事实——我们只能在C、A、P中选择两个条件。而对于业务系统而言，我们往往选择牺牲一致性来换取系统的可用性和分区容错性。不过这里要指出的是，所谓的“牺牲一致性”并不是完全放弃数据一致性，而是牺牲强一致性换取弱一致性。下面来介绍下BASE理论。

BA：Basic Available 基本可用
整个系统在某些不可抗力的情况下，仍然能够保证“可用性”，即一定时间内仍然能够返回一个明确的结果。只不过“基本可用”和“高可用”的区别是：
“一定时间”可以适当延长 当举行大促时，响应时间可以适当延长
给部分用户返回一个降级页面 给部分用户直接返回一个降级页面，从而缓解服务器压力。但要注意，返回降级页面仍然是返回明确结果。




S：Soft State：柔性状态 同一数据的不同副本的状态，可以不需要实时一致。
E：Eventual Consisstency：最终一致性 同一数据的不同副本的状态，可以不需要实时一致，但一定要保证经过一定时间后仍然是一致的。

酸碱平衡ACID能够保证事务的强一致性，即数据是实时一致的。这在本地事务中是没有问题的，在分布式事务中，强一致性会极大影响分布式系统的性能，因此分布式系统中遵循BASE理论即可。但分布式系统的不同业务场景对一致性的要求也不同。如交易场景下，就要求强一致性，此时就需要遵循ACID理论，而在注册成功后发送短信验证码等场景下，并不需要实时一致，因此遵循BASE理论即可。因此要根据具体业务场景，在ACID和BASE之间寻求平衡。 
Paxos一致性协议基本概念Paxos 可以分为两种：

Single-Decree Paxos：决策单个 Value
Multi-Paxos：连续决策多个 Value，并且保证每个节点上的顺序完全一致，多 Paxos 往往是同事运行多个单 Paxos 协议共同执行的结果。

Paxos协议中的三种角色
倡议者（Proposer）：倡议者可以提出提议（数值或者操作命令）以供投票表决
接受者（Acceptor）：接受者可以对倡议者提出的提议进行投票表决，提议有超半数的接受者投票即被选中
学习者（Learner）：学习者无投票权，只是从接受者那里获知哪个提议被选中

Paxos的特点
一个或多个节点可以提出提议
系统必须针对所有提案中的某个提案达成一致（超过半数的接受者选中）
最多只能对一个确定的提议达成一致
只要超半数的节点存活且可互相通信，整个系统一定能达成一致状态，即选择一个确定的提议



分布式事务的解决方案全局事务（DTP模型）全局事务基于DTP模型实现。DTP是由X&#x2F;Open组织提出的一种分布式事务模型——X&#x2F;Open Distributed Transaction Processing Reference Model。它规定了要实现分布式事务，需要三种角色：

AP：Application 应用系统 它就是我们开发的业务系统，在我们开发的过程中，可以使用资源管理器提供的事务接口来实现分布式事务。
TM：Transaction Manager 事务管理器
分布式事务的实现由事务管理器来完成，它会提供分布式事务的操作接口供我们的业务系统调用。这些接口称为TX接口。
事务管理器还管理着所有的资源管理器，通过它们提供的XA接口来同一调度这些资源管理器，以实现分布式事务。
DTP只是一套实现分布式事务的规范，并没有定义具体如何实现分布式事务，TM可以采用2PC、3PC、Paxos等协议实现分布式事务。


RM：Resource Manager 资源管理器
能够提供数据服务的对象都可以是资源管理器，比如：数据库、消息中间件、缓存等。大部分场景下，数据库即为分布式事务中的资源管理器。
资源管理器能够提供单数据库的事务能力，它们通过XA接口，将本数据库的提交、回滚等能力提供给事务管理器调用，以帮助事务管理器实现分布式的事务管理。
XA是DTP模型定义的接口，用于向事务管理器提供该资源管理器(该数据库)的提交、回滚等能力。
DTP只是一套实现分布式事务的规范，RM具体的实现是由数据库厂商来完成的。



基于可靠消息服务的分布式事务这种实现分布式事务的方式需要通过消息中间件来实现。




上游系统和消息中间件之间采用异步通信是为了提高系统并发度。业务系统直接和用户打交道，用户体验尤为重要，因此这种异步通信方式能够极大程度地降低用户等待时间。此外，异步通信相对于同步通信而言，没有了长时间的阻塞等待，因此系统的并发性也大大增加。但异步通信可能会引起Commit&#x2F;Rollback指令丢失的问题，这就由消息中间件的超时询问机制来弥补。
那么，消息中间件和下游系统之间为什么要采用同步通信呢？
异步能提升系统性能，但随之会增加系统复杂度；而同步虽然降低系统并发度，但实现成本较低。因此，在对并发度要求不是很高的情况下，或者服务器资源较为充裕的情况下，我们可以选择同步来降低系统的复杂度。 我们知道，消息中间件是一个独立于业务系统的第三方中间件，它不和任何业务系统产生直接的耦合，它也不和用户产生直接的关联，它一般部署在独立的服务器集群上，具有良好的可扩展性，所以不必太过于担心它的性能，如果处理速度无法满足我们的要求，可以增加机器来解决。而且，即使消息中间件处理速度有一定的延迟那也是可以接受的，因为前面所介绍的BASE理论就告诉我们了，我们追求的是最终一致性，而非实时一致性，因此消息中间件产生的时延导致事务短暂的不一致是可以接受的
最大努力通知（定期校对）


上游系统在完成任务后，向消息中间件同步地发送一条消息，确保消息中间件成功持久化这条消息，然后上游系统可以去做别的事情了；
消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行；
当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成。

上面是一个理想化的过程，但在实际场景中，往往会出现如下几种意外情况：

消息中间件向下游系统投递消息失败
上游系统向消息中间件发送消息失败

对于第一种情况，消息中间件具有重试机制，我们可以在消息中间件中设置消息的重试次数和重试时间间隔，对于网络不稳定导致的消息投递失败的情况，往往重试几次后消息便可以成功投递，如果超过了重试的上限仍然投递失败，那么消息中间件不再投递该消息，而是记录在失败消息表中，消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费，这就是所谓的定期校对。
TCC（两阶段型、补偿型）TCC即为Try Confirm Cancel，它属于补偿型分布式事务。顾名思义，TCC实现分布式事务一共有三个步骤：

Try：尝试待执行的业务
这个过程并未执行业务，只是完成所有业务的一致性检查，并预留好执行所需的全部资源


Confirm：执行业务
这个过程真正开始执行业务，由于Try阶段已经完成了一致性检查，因此本过程直接执行，而不做任何检查。并且在执行的过程中，会使用到Try阶段预留的业务资源。


Cancel：取消执行的业务
若业务执行失败，则进入Cancel阶段，它会释放所有占用的业务资源，并回滚Confirm阶段执行的操作。



TCC事务框架应该提供Confirm&#x2F;Cancel服务的幂等性保障
幂等性原本是数学上的概念，即使公式：f(x)&#x3D;f(f(x)) 能够成立的数学性质。用在编程领域，则意为对同一个系统，使用同样的条件，一次请求和重复的多次请求对系统资源的影响是一致的。

]]></content>
      <categories>
        <category>八股文</category>
        <category>分布式事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>jrebel 破解</title>
    <url>/posts/b92b7720/</url>
    <content><![CDATA[1. 生成 GUID 的网址https://www.guidgen.com/
2. 用这个网址 + 生成的 GUID 激活https://jrebel.qekang.com/
例如:
https://jrebel.qekang.com/738b776f-6cc9-4ac5-9574-960a057392db


3. 设置离线模式 来防止失效]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>破解</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP 基础知识</title>
    <url>/posts/e5fda0b2/</url>
    <content><![CDATA[HTTP 基础知识三次握手，四次挥手TCP三次握手过程

主机A通过向主机B发送一个含有同步序列号的标志位的数据段给主机B ,向主机B 请求建立连接,通过这个数据段,

主机A告诉主机B两件事:我想要和你通信;你可以用哪个序列号作为起始数据段来回应我.

主机B收到主机A的请求后,用一个带有确认应答(ACK)和同步序列号(SYN)标志位的数据段响应主机A,也告诉主机A两件事:

我已经收到你的请求了,你可以传输数据了;你要用哪佧序列号作为起始数据段来回应我

主机A收到这个数据段后,再发送一个确认应答,确认已收到主机B的数据段:”我已收到回复,我现在要开始传输实际数据了

这样3次握手就完成了,主机A和主机B就可以传输数据了.
3次握手的特点

没有应用层的数据
SYN这个标志位只有在TCP建立连接时才会被置1
握手完成后SYN标志位被置0



TCP建立连接要进行3次握手,而断开连接要进行4次

当主机A完成数据传输后,将控制位FIN置1,提出停止TCP连接的请求

主机B收到FIN后对其作出响应,确认这一方向上的TCP连接将关闭,将ACK置1

由B端再提出反方向的关闭请求,将FIN置1

主机A对主机B的请求进行确认,将ACK置1,双方向的关闭结束.


由TCP的三次握手和四次断开可以看出,TCP使用面向连接的通信方式,大大提高了数据通信的可靠性,使发送数据端和接收端在数据正式传输前就有了交互,为数据正式传输打下了可靠的基础。


名词解释
ACK：TCP报头的控制位之一,对数据进行确认.确认由目的端发出,用它来告诉发送端这个序列号之前的数据段
都收到了.比如,确认号为X,则表示前X-1个数据段都收到了,只有当ACK&#x3D;1时,确认号才有效,当ACK&#x3D;0时,确认号无效,这时会要求重传数据,保证数据的完整性.
SYN：同步序列号,TCP建立连接时将这个位置1
FIN：发送端完成发送任务位,当TCP完成数据传输需要断开时,提出断开连接的一方将这位置1
TCP 与 UDP
TCP（Transmission Control Protocol，传输控制协议）是面向连接的协议，也就是说，在收发数据前，必须和对方建立可靠的连接。一个TCP连接必须要经过三次“对话”才能建立起来，其中的过程非常复杂，只简单的描述下这三次对话的简单过程：主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；主机B向主机A发送同意连接和要求同步（同步就是两台主机一个在发送，一个在接收，协调工作）的数据包：“可以，你什么时候发？”，这是第二次对话；主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。

UDP（User Data Protocol，用户数据报协议）



UDP是一个非连接的协议，传输数据之前源端和终端不建立连接，当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制；在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。

由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息。

UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包的额外开销很小。

吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制。

UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表（这里面有许多参数）。

UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。


我们经常使用“ping”命令来测试两台主机之间TCP&#x2F;IP通信是否正常，其实“ping”命令的原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包，如果数据包是否到达的消息及时反馈回来，那么网络就是通的。
UDP的包头结构：
源端口 16位
目的端口 16位
长度 16位
校验和 16位
小结TCP与UDP的区别：
1.基于连接与无连接；
2.对系统资源的要求（TCP较多，UDP少）；
3.UDP程序结构较简单；
4.流模式与数据报模式 ；
5.TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>有道云笔记去广告</title>
    <url>/posts/c1da566d/</url>
    <content><![CDATA[有道云笔记v6.70去除广告去除文章列表底部广告编辑文件C:\Program Files (x86)\Youdao\YoudaoNote\theme\build.xml
搜索AdWraperMid, 找到如下代码块:
&lt;AdWraperMid type=&quot;panel&quot; css=&quot;public&quot; dockstyle=&quot;bottom&quot; visible=&quot;false&quot; bounds=&quot;0,0,0,161&quot;&gt;

修改成如下部分
&lt;AdWraperMid type=&quot;panel&quot; css=&quot;public&quot; dockstyle=&quot;bottom&quot; visible=&quot;false&quot; bounds=&quot;0,0,0,0&quot;&gt;

其实就是修改了第一行末尾的bounds=&quot;0,0,0,161&quot; 为 bounds=&quot;0,0,0,0&quot;，来隐藏广告位窗口。
去除左下角广告搜索PanelAd, 找到如下代码块，&lt;PanelAd 这一行的 ass=&quot;mainform panelclient PanelAd&quot; 删除即可:
&lt;PanelAd type=&quot;adpanel&quot; css=&quot;public&quot; ass=&quot;mainform panelclient PanelAd&quot;&gt;

修改后：
&lt;PanelAd type=&quot;adpanel&quot; css=&quot;public&quot;&gt;

然后保存文件，重启软件。
]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>破解</tag>
      </tags>
  </entry>
  <entry>
    <title>typora 优化</title>
    <url>/posts/1ed812a6/</url>
    <content><![CDATA[插入的图片左对齐p .md-image:only-child&#123;    width: auto;    text-align: inherit;&#125;

右键打开
Win+R 调出运行窗口
输入 regedit 打开注册表



1. 对文件增加Typora右键打开项设置使用 Typora.exe 打开


首先找到路径计算机\HKEY_CLASSES_ROOT\*\shell\
在 shell 文件夹上右键 新建-&gt;项，文件夹名 Typora
在 Typora 右键 新建-&gt;项，文件夹名 command
单击 command，双击右侧名称中的默认，数值数据 中输入&quot;C:\Program Files\Typora\typora.exe&quot; &quot;%1&quot;  (你自己程序所在位置)
此时已经可以在文件上右键通过Typora打开文件了

设置图标和右键中显示的提示

单击Typora
右侧双击默认 数值数据 是右键时提示的文字，这里填写Open With Typora
右侧右键 新建 -&gt; 字符串值，输入icon，双击icon 数值数据输入&quot;C:\Program Files\Typora\typora.exe&quot;  (你自己程序所在位置)


2. 对文件夹增加Typora右键打开项
首先找到路径  计算机\HKEY_CLASSES_ROOT\Folder\shell\
按照上面的方法
新建 Typora 及子项 command
单击 command 右侧设置指令
单击 Typora 右侧设置右键显示的内容和 icon

3. 命令解释
指令要用双引号，若不用双引号window对带有空格的路径识别是有问题的

&quot;C:\Program Files\Typora\typora.exe&quot; &quot;%1&quot;

%1 或获取当前选择的内容，可能是文件的路径，也可能是文件夹的路径
当你cmd终端中输入如下的指令时Typora会打开hello.markdown文件
&quot;C:\Program Files\Typora\typora.exe&quot; &quot;F:\hello.markdown&quot;

4. 简易设置方式在桌面新建 typora-file.reg 和 typora-folder.reg 两个文件
用记事本分别录入两个内容
然后分别双击两个文件会，注册表会自动设置
Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\*\shell\Typora]&quot;icon&quot;=&quot;C:\\Program Files\\Typora\\typora.exe&quot;@=&quot;Open With Typora&quot;[HKEY_CLASSES_ROOT\*\shell\Typora\command]@=&quot;\&quot;C:\\Program Files\\Typora\\typora.exe\&quot; \&quot;%1\&quot;&quot;

Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\Folder\shell\Typora]&quot;icon&quot;=&quot;C:\\Program Files\\Typora\\typora.exe&quot;@=&quot;Open With Typora&quot;[HKEY_CLASSES_ROOT\Folder\shell\Typora\command]@=&quot;\&quot;C:\\Program Files\\Typora\\typora.exe\&quot; \&quot;%1&quot;&quot;

荧光笔高亮开启高亮打开方式：文件 &gt; 偏好设置 &gt; Markdown &gt; Markdown扩展语法中把 高亮 选中 &gt; 重启Typora，如下图所示：


更改高亮配色打开方式：文件 &gt; 偏好设置 &gt; 外观 &gt; 打开主题文件夹 &gt; drake-light.css文件 &gt; Ctrl+F 搜索 mark &gt; 修改喜欢的 background(背景颜色) 和 color(字体颜色) 保存。
这里修改后的最终效果如下：
/* height light */#write mark &#123;    background-color: #f8f840;    padding: .1rem .5rem;    margin: 0 .2rem;&#125;

设置高亮快捷键设置方式：文件 &gt; 偏好设置 &gt; 通用 &gt; 打开高级设置 &gt; 会看到两个json文件，添加绑定快捷键，如下所示：
&#123;   ...	&quot;keyBinding&quot;: &#123;    &quot;Highlight&quot;: &quot;Ctrl + q&quot;  &#125;,  ...&#125;

]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>破解</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql 面试题</title>
    <url>/posts/34945828/</url>
    <content><![CDATA[1、MySQL 中有哪几种锁？
表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

2、MySQL 中有哪些不同的表格？
MyISAM
Heap
Merge
INNODB
ISAM

3、简述在 MySQL 数据库中 MyISAM 和 InnoDB 的区别MyISAM：

不支持事务，但是每次查询都是原子的；
支持表级锁，即每次操作是对整个表加锁；
存储表的总行数；
一个 MYISAM 表有三个文件：索引文件、表结构文件、数据文件；
采用非聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。

InnoDb：

支持 ACID 的事务，支持事务的四种隔离级别；
支持行级锁及外键约束，因此可以支持写并发；
不存储总行数；
一个 InnoDb 引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为2G），受操作系统文件大小的限制；
主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为了维持 B+树结构，文件的大调整。

4、MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐 级之间的区别？SQL 标准定义的四个隔离级别为：

Read uncommitted 读未提交 在该级别下，一个事务对一行数据修改的过程中，不允许另一个事务对该行数据进行修改，但允许另一个事务对该行数据读。 因此本级别下，不会出现更新丢失，但会出现脏读、不可重复读。
Read committed 读提交 在该级别下，未提交的写事务不允许其他事务访问该行，因此不会出现脏读；但是读取数据的事务允许其他事务的访问该行数据，因此会出现不可重复读的情况。
Repeatable read 重复读 在该级别下，读事务禁止写事务，但允许读事务，因此不会出现同一事务两次读到不同的数据的情况（不可重复读），且写事务禁止其他一切事务。
Serializable 序列化 该级别要求所有事务都必须串行执行，因此能避免一切因并发引起的问题，但效率很低。

5、CHAR 和 VARCHAR 的区别？
CHAR 和 VARCHAR 类型在存储和检索方面有所不同
CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255 当 CHAR 值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。

6、主键和候选键有什么区别？表格的每一行都由主键唯一标识,一个表只有一个主键。
主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。
7、myisamchk 是用来做什么的？它用来压缩 MyISAM 表，这减少了磁盘或内存使用。
MyISAM Static 和 MyISAM Dynamic 有什么区别？
在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT， BLOB 等字段，以适应不同长度的数据类型。
MyISAM Static 在受损情况下更容易恢复。
8、如果一个表有一列定义为 TIMESTAMP，将发生什么？每当行被更改时，时间戳字段将获取当前时间戳。

列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。
怎样才能找出最后一次插入时分配了哪个自动增量？LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名称。

9、你怎么看到为表格定义的所有索引？索引是通过以下方式为表格定义的：
SHOW INDEX FROM ;
10、LIKE 声明中的％和_是什么意思？％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。

如何在 Unix 和 MySQL 时间戳之间进行转换？
UNIX_TIMESTAMP 是从 MySQL 时间戳转换为 Unix 时间戳的命令 
FROM_UNIXTIME 是从 Unix 时间戳转换为 MySQL 时间戳的命令。


11、列对比运算符是什么？在 SELECT 语句的列比较中使用&#x3D;，&lt;&gt;，&lt;&#x3D;，&lt;，&gt; &#x3D;，&gt;，&lt;&lt;，&gt;&gt;，&lt;&#x3D;&gt;，AND， OR 或 LIKE 运算符。
12、BLOB 和 TEXT 有什么区别？BLOB 是一个二进制对象，可以容纳可变数量的数据。TEXT 是一个不区分大小写的 BLOB。
BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT 值不区分大小写。
13、MySQL_fetch_array 和 MySQL_fetch_object 的区别是 什么？以下是 MySQL_fetch_array 和 MySQL_fetch_object 的区别：
MySQL_fetch_array（） – 将结果行作为关联数组或来自数据库的常规数组返回。
MySQL_fetch_object – 从数据库返回结果行作为对象。
14、MyISAM 表格将在哪里存储，并且还提供其存储格式？每个 MyISAM 表格以三种格式存储在磁盘上：

文件存储表具有“.frm”扩展名
数据文件具有“.MYD”（MYData）扩展名
索引文件具有“.MYI”（MYIndex）扩展名

15、MySQL 如何优化 DISTINCT？DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。
17、可以使用多少列创建索引？任何标准表最多可以创建 16 个索引列。
18、NOW（）和 CURRENT_DATE（）有什么区别？NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。
CURRENT_DATE（）仅显示当前年份，月份和日期。
19、什么是非标准字符串类型？
TINYTEXT
TEXT
MEDIUMTEXT
LONGTEXT

20、什么是通用 SQL 函数？
CONCAT(A, B) – 连接两个字符串值以创建单个字符串输出。通常用于将两个 或多个字段合并为一个字段
FORMAT(X, D)- 格式化数字 X 到 D 有效数字。
CURRDATE(), CURRTIME()- 返回当前日期或时间。
NOW（） – 将当前日期和时间作为一个值返回。
MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） – 从日期 值中提取给定数据。
HOUR（），MINUTE（），SECOND（） – 从时间值中提取给定数据。
DATEDIFF（A，B） – 确定两个日期之间的差异，通常用于计算年龄
SUBTIMES（A，B） – 确定两次之间的差异。
FROMDAYS（INT） – 将整数天数转换为日期值。

21、MySQL 支持事务吗？在缺省模式下，MySQL 是 autocommit 模式的，所有的数据库更新操作都会即时 提交，所以在缺省情况下，MySQL 是不支持事务的。
但是如果你的 MySQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的 MySQL 就可以使用事务处理,使用 SET AUTOCOMMIT&#x3D;0 就可以使 MySQL 允许在非 autocommit 模式，在非 autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK 来回滚你的更改。
22、MySQL 里记录货币用什么字段类型好NUMERIC 和 DECIMAL 类型被 MySQL 实现为同样的类型，这在 SQL92 标准允许。他们被用于保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是这些类型之一时，精度和规模的能被(并且通常是)指定。
例如：
salary DECIMAL(9,2)
在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代 表将被用于存储小数点后的位数。
因此，在这种情况下，能被存储在 salary 列中的值的范围是从-9999999.99 到 9999999.99。
23、MySQL 有关权限的表都有哪几个？MySQL 服务器通过权限表来控制用户对数据库的访问，权限表存放在 MySQL 数据库里，由 MySQL_install_db 脚本初始化。这些权限表分别 user，db，table_priv， columns_priv 和 host。
24、列的字符串类型可以是什么？字符串类型是：
1、SET
2、BLOB
3、ENUM
4、CHAR
5、TEXT
25、MySQL 数据库作发布系统的存储，一天五万条以上的增量， 预计运维三年,怎么优化？1、设计良好的数据库结构，允许部分数据冗余，尽量避免 join 查询，提高效率。
2、选择合适的表字段数据类型和存储引擎，适当的添加索引。
3、 MySQL 库主从读写分离。
4、找规律分表，减少单表中的数据量提高查询速度。
5、添加缓存机制，比如 memcached，apc 等。
6、不经常改动的页面，生成静态页面。
7、书写高效率的 SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE。
26、锁的优化策略
读写分离
分段加锁
减少锁持有的时间
多个线程尽量以相同的顺序去获取资源

不能将锁的粒度过于细化，不然可能会出现线程的加锁和释放次数过多，反而效 率不如一次加一把大锁。
27、索引的底层实现原理和优化B+树，经过优化的 B+树
主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此 InnoDB 建议为大部分表使用默认自增的主键作为主索引。
28、什么情况下设置了索引但无法使用
以“%”开头的 LIKE 语句，模糊匹配
OR 语句前后没有同时使用索引
数据类型出现隐式转化（如 varchar 不加单引号的话可能会自动转换为 int 型）

30、优化数据库的方法
选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置 NOTNULL， 例如’省份’、’性别’最好适用 ENUM
使用连接(JOIN)来代替子查询
适用联合(UNION)来代替手动创建的临时表
事务处理
锁定表、优化事务处理
适用外键，优化锁定表
建立索引
优化查询语句

31、简单描述 MySQL 中，索引，主键，唯一索引，联合索引 的区别，对数据库的性能有什么影响（从读写两方面）索引是一种特殊的文件(InnoDB 数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。

普通索引(由关键字 KEY 或 INDEX 定义的索引)的唯一任务是加快对数据的访问速度。
普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字 UNIQUE 把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。

主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，使用关键字 PRIMARY KEY 来创建。

索引可以覆盖多个数据列，如像 INDEX(columnA, columnB)索引，这就是联合索引。


索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度， 因为在执行这些写操作时，还要操作索引文件。
32、数据库中的事务是什么?事务（transaction）是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功，则认为事务成功，即使只有一个操作失败，事务也不成功。如果所有操作完成，事务则提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有操作的影响都将取消。
事务特性：
1、原子性：即不可分割性，事务要么全部被执行，要么就全部不被执行。
2、一致性或可串性：事务的执行使得数据库从一种正确状态转换成另一种正确状态
3、隔离性：在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务，
4、持久性：事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存。
或者这样理解：
事务就是被绑定在一起作为一个逻辑工作单元的 SQL 语句分组，如果任何一个语句操作失败那么整个操作就被失败，以后操作就会回滚到操作前状态，或者是上有个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过 ACID 测试，即原子性，一致性，隔离性和持久性。
33、SQL 注入漏洞产生的原因？如何防止？SQL 注入产生的原因：程序开发过程中不注意规范书写 sql 语句和对特殊字符行过滤，导致客户端可以通过全局变量 POST 和 GET 提交一些 sql 语句正常执行。
防止 SQL 注入的方式：
开启配置文件中的 magic_quotes_gpc 和 magic_quotes_runtime 设执行 sql 语句时使用 addslashes 进行 sql 语句转换
Sql 语句书写尽量不要省略双引号和单引号。
过滤掉 sql 语句中的一些关键词：update、insert、delete、select、 * 。
提高数据库表和字段的命名技巧，对一些重要的字段根据程序的特点命名，取不易被猜到的。
34、为表中得字段选择合适得数据类型字段类型优先级: 整形&gt;date,time&gt;enum,char&gt;varchar&gt;blob,tex
优先考虑数字类型，其次是日期或者二进制类型，最后是字符串类型，同级别得数据类型，应该优先选择占用空间小的数据类型
35、存储时期Datatime：以 YYYY-MM-DD HH:MM:SS 格式存储时期时间，精确到秒，占用 8 个字节得存储空间，datatime 类型与时区无关
Timestamp：以时间戳格式存储，占用 4 个字节，范围小 1970-1-1 到 2038-1-19，显示依赖于所指定得时区，默认在第一个列行的数据修改时可以自动得修改
timestamp列得值
Date:（生日）占用得字节数比使用字符串储存要少，使用 date 只 需要 3 个字节，存储日期月份，还可以利用日期时间函数进行日期间得计算
Time：存储时间部分得数据
注意：不要使用字符串类型来存储日期时间数据（通常比字符串占用得储存空间小， 在进行查找过滤可以利用日期得函数）
使用 int 存储日期时间不如使用 timestamp 类型
36、对于关系型数据库而言，索引是相当重要的概念，请回答 有关索引的几个问题：1、索引的目的是什么？
快速访问数据表中的特定信息，提高检索速度
创建唯一性索引，保证数据库表中每一行数据的唯一性。
加速表和表之间的连接
使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间
2、索引对数据库系统的负面影响是什么？
负面影响：
创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间； 当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。
3、为数据表建立索引的原则有哪些？
在最频繁使用的、用以缩小查询范围的字段上建立索引。
在频繁使用的、需要排序的字段上建立索引
4、什么情况下不宜建立索引？
对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。
对于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等
37、解释 MySQL 外连接、内连接与自连接的区别先说什么是交叉连接: 交叉连接又叫笛卡尔积，它是指不使用任何条件，直接将一个表的所有记录和另一个表中的所有记录一一匹配。
内连接则是只有条件的交叉连接，根据某个条件筛选出符合条件的记录，不符合条件的记录不会出现在结果集中，即内连接只连接匹配的行。
外连接其结果集中不仅包含符合连接条件的行，而且还会包括左表、右表或两个表中的所有数据行，这三种情况依次称之为左外连接，右外连接，和全外连接。
左外连接，也称左连接，左表为主表，左表中的所有记录都会出现在结果集中，对于那些在右表中并没有匹配的记录，仍然要显示，右边对应的那些字段值以 NULL 来填充。
右外连接，也称右连接，右表为主表，右表中的所有记录都会出现在结果集中。左连接和右连接可以互换，MySQL 目前还不支持全外连接。
38、Myql 中的事务回滚机制概述事务是用户定义的一个数据库操作序列，这些操作要么全做要么全不做，是一个不可分割的工作单位，事务回滚是指将该事务已经完成的对数据库的更新操作撤销。
要同时修改数据库中两个不同表时，如果它们不是一个事务的话，当第一个表改完，可能第二个表修改过程中出现了异常而没能修改，此时就只有第二个表依旧是未修改之前的状态，而第一个表已经被修改完毕。而当你把它们设定为一个事务的时候，当第一个表修改完，第二表修改出现异常而没能修改，第一个表和第二个表都要回到未修改的状态，这就是所谓的事务回滚。
39、SQL 语言包括哪几部分？每部分都有哪些操作关键字？SQL 语言包括数据定义(DDL)、数据操纵(DML)，数据控制(DCL)和数据查询（DQL）四个部分。

数据定义：Create Table，Alter Table，Drop Table, Create&#x2F;Drop Index 等
数据操纵：select，insert，update，delete
数据控制：grant，revoke
数据查询：select

40、完整性约束包括哪些？数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。
分为以下四类：

实体完整性：规定表的每一行在表中是唯一的实体。
域完整性：是指表中的列必须满足某种特定的数据类型约束，其中约束又包括取值范围、精度等规定。
参照完整性：是指两个表的主关键字和外关键字的数据应一致，保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。
用户定义的完整性：不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件，它反映某一具体应用必须满足的语义要求。

与表有关的约束：包括列约束(NOT NULL（非空约束）)和表约束(PRIMARY KEY、 foreign key、check、UNIQUE) 。
41、什么是锁？数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。
加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。
基本锁类型：锁包括行级锁和表级锁。
42、什么叫视图？游标是什么？视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增改查操作，视图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。
游标是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。
43、什么是存储过程？用什么来调用？存储过程是一个预编译的 SQL 语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次 SQL， 使用存储过程比单纯 SQL 语句执行要快。可以用一个命令对象来调用存储过程。
44、如何通俗地理解三个范式？第一范式：1NF 是对属性的原子性约束，要求属性具有原子性，不可再分解。
第二范式：2NF 是对记录的唯一性约束，要求记录有惟一标识，即实体的唯一性。
第三范式：3NF 是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。
范式化设计优缺点:
优点：可以尽量得减少数据冗余，使得更新快，体积小 
缺点：对于查询需要多个表进行关联，减少写得效率增加读得效率，更难进行索引优化
反范式化:
优点：可以减少表得关联，可以更好得进行索引优化
缺点：数据冗余以及数据异常，数据得修改需要更多的成本
46、试述视图的优点？
视图能够简化用户的操作；
视图使用户能以多种角度看待同一数据；
视图为数据库提供了一定程度的逻辑独立性；
视图能够对机密数据提供安全保护。

47、 NULL 是什么意思答：NULL 这个值表示 UNKNOWN(未知)。它不表示“”(空字符串)。对 NULL 这个值的任何比较都会生产一个 NULL 值。不能把任何值与一个 NULL 值进行比较，并在逻辑上希望获得一个答案。
使用 IS NULL 来进行 NULL 判断。
48、主键、外键和索引的区别？定义：

主键：唯一标识一条记录，不能有重复的，不允许为空 
外键：表的外键是另一表的主键，外键可以有重复的，可以是空值
索引：该字段没有重复值，但可以有一个空值

作用：

主键：用来保证数据完整性
外键：用来和其他表建立联系用的
索引：是提高查询排序的速度

个数：

主键：主键只能有一个
外键：一个表可以有多个外键
索引：一个表可以有多个索引

49、你可以用什么来确保表格里的字段只接受特定范围里的值?Check 限制，它在数据库表格里被定义，用来限制输入该列的值。
触发器也可以被用来限制数据库表格里的字段能够接受的值，但是这种办法要求触发器在表格里被定义，这可能会在某些情况下影响到性能。
50、说说对 SQL 语句优化有哪些方法？（选择几条）
Where 子句中 where 表之间的连接必须写在其他 Where 条件之前，那些可以过滤掉最大数量记录的条件必须写在 Where 子句的末尾，HAVING 放在最后。
用 EXISTS 替代 IN、用 NOT EXISTS 替代 NOT IN。
避免在索引列上使用计算
避免在索引列上使用 IS NULL 和 IS NOT NULL
对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描
应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。

count(1)和count(*)的区别count(1) and count(字段)
两者的主要区别是
（1） count(1) 会统计表中的所有的记录数， 包含字段为null 的记录。
（2） count(字段) 会统计该字段在表中出现的次数，忽略字段为null 的情况。即 不统计字段为null 的记录。 
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP 状态码</title>
    <url>/posts/e1434ae1/</url>
    <content><![CDATA[HTTP 状态码一览状态信息：1xx代表请求已被接受，需要继续处理。这类响应是临时响应，只包含状态行和某些可选的响应头信息，并以空行结束。



消息：
描述：



100 Continue
服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求


101 Switching Protocols
服务器转换协议，服务器将遵从客户的请求转换到另外一种协议


102 Processing
代表处理将被继续执行


成功：2xx代表请求已成功被服务器接收、理解、并接受。



消息：
描述：



200 OK
请求成功，表示正常状态


201 Created
请求被创建完成，同时新的资源被创建立


202 Accepted
处理的请求已被接受，但处理未完成


203 Non-authoritative Information
服务器已成功处理了请求，但一些应答头可能不正确，因为使用的是文档的拷贝


204 No Content
服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息


205 Reset Content
服务器成功处理了请求，且没有返回任何内容，返回此状态码的响应要求请求者重置文档视图


206 Partial Content
服务器已经成功处理了部分 GET 请求


207 Multi-Status
代表之后的消息体将是一个XML消息


重定向：3xx代表需要客户端采取进一步的操作才能完成请求。



消息：
描述：



300 Multiple Choices
被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向


301 Moved Permanently
所请求的资源已经转移至新的url


302 Move temporarily
请求的资源临时从不同的 URI响应请求


303 See Other
所请求的页面可在别的url下被找到，客户端应当采用 GET 的方式访问那个资源


304 Not Modified
服务器告诉客户，原来缓冲的文档还可以继续使用


305 Use Proxy
被请求的资源必须通过指定的代理才能被访问


306 Switch Proxy
目前已不再使用，但是代码依然被保留


307 Temporary Redirect
请求的资源临时从不同的URI 响应请求


客户端错误：4xx代表了客户端看起来可能发生了错误，妨碍了服务器的处理。



消息:
描述:



400 Bad Request
语义有误，服务器未能理解请求。或请求参数有误


401 Unauthorized
被请求的页面需要用户名和密码


402 Payment Required
为了将来可能的需求而预留的


403 Forbidden
对被请求资源的访问被禁止


404 Not Found
服务器无法找到被请求的资源


405 Method Not Allowed
请求中指定的方法不被允许


406 Not Acceptable
服务器生成的响应无法被客户端所接受


407 Proxy Authentication Required
用户必须首先使用代理服务器进行验证，这样请求才会被处理


408 Request Timeout
请求超出了服务器的等待时间


409 Conflict
和被请求的资源的当前状态之间存在冲突，请求无法完成


410 Gone
被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址


411 Length Required
“Content-Length” 未被定义。如果无此内容，服务器不会接受请求


412 Precondition Failed
请求中的前提条件被服务器评估为失败


413 Request Entity Too Large
由于所请求的实体数据太大，服务器不会接受请求


414 Request-url Too Long
由于url太长，服务器不会接受请求。当post请求被转换为带有很长的查询信息的get请求时，就会发生这种情况


415 Unsupported Media Type
由于请求中格式类型不被支持，服务器不会接受请求


416 Requested Range Not Satisfiable
客户在请求中指定的Range头与当前资源的可用范围不重合


417 Expectation Failed
在请求头 Expect 中指定的预期内容无法被服务器满足


421 too many connections
当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围


422 Unprocessable Entity
请求格式正确，但是由于含有语义错误，无法响应


423 Locked
当前资源被锁定


424 Failed Dependency
之前的某个请求发生的错误，导致当前请求失败


425 Unordered Collectiond



449 Retry With
客户端应当切换到TLS&#x2F;1.0


425 Unordered Collectiond
由微软扩展，代表请求应当在执行完适当的操作后进行重试


451 Unavailable For Legal Reasons
该请求因法律原因不可用


服务器错误：5xx， 6xx代表了服务器在处理请求的过程中有错误或者异常状态发生，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理



消息:
描述:



500 Internal Server Error
请求未完成，服务器遇到不可预知的情况。一般为服务器源码出现问题


501 Not Implemented
请求未完成，服务器不支持所请求的功能


502 Bad Gateway
请求未完成，网关或者代理工作的服务器尝试执行请求，从上游服务器收到一个无效的响应


503 Service Unavailable
请求未完成，服务器临时过载或维护


504 Gateway Timeout
网关或者代理工作的服务器尝试执行请求超时


505 HTTP Version Not Supported
服务器不支持或拒绝请求中指明的HTTP协议版本


506 Variant Also Negotiates
服务器存在内部配置错误


507 Insufficient Storage
服务器无法存储完成请求所必须的内容


509 Bandwidth Limit Exceeded
服务器达到带宽限制


510 Not Extended
获取资源所需要的策略并没有被满足


600 Unparseable Response Headers
没有返回响应头部，只返回实体内容


]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatis 面试题</title>
    <url>/posts/2e4af39/</url>
    <content><![CDATA[1、解析全局配置文件的时候，做了什么？Configuration
MappedStatement
2、没有实现类，Mybatis的方法是怎么执行的？动态代理MapperProxy
3、接口方法和映射器的statement id是怎么绑定起来的？（怎么根据接口方法拿到SQL语句的？）MappedStatement
4、四大对象是什么时候创建的？openSession()方法里面

Executor

执行SQL语句的时候

StatementHandler

ParameterHandler

ResultSetHandler


5、JDK动态代理，代理能不能被代理能
6、Mybatis集成到Spring的原理是什么？SqlSessionTemplate
MapperFactoryBean
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>rabbitmq 面试题</title>
    <url>/posts/217b8ff8/</url>
    <content><![CDATA[消息堆积一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。
一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：
先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。 mq 中的消息过期失效了
假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。
这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。
假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。
mq 都快写满了
如果消息积压在mq里，你很长时间都没有处理掉，此时导致mq都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。
confirm机制投递消息的高延迟性绝对不能以同步写消息 + 等待ack的方式来投递消息，用来临时存放未ack消息的存储需要承载高并发写入，而且我们不需要什么复杂的运算操作，这种存储首选绝对不是MySQL之类的关系数据库，而建议采用kv存储。kv存储承载高并发能力极强，而且kv操作性能很高。
生产者消息投递出去之后并且在kv存储器存储，这个投递的线程其实就可以返回了，至于每个消息的异步回调，是通过在channel注册一个confirm监听器实现的。生产者收到一个消息ack之后，就从kv存储中删除这条临时消息；收到一个消息nack之后，就从kv存储提取这条消息然后重新投递一次即可；也可以自己对kv存储里的消息做监控，如果超过一定时长没收到ack，就主动重发消息。
异步confirm模式
Channel channel = channelManager.getPublisherChannel(namespaceName);ProxiedConfirmListener confirmListener = new ProxiedConfirmListener();//监听类confirmListener.setChannelManager(channelManager);confirmListener.setChannel(channel);confirmListener.setNamespace(namespaceName);confirmListener.addSuccessCallbacks(successCallbacks);channel.addConfirmListener(confirmListener);channel.confirmSelect();//开启confirm模式AMQP.BasicProperties messageProperties = null;if (message.getProperty() instanceof AMQP.BasicProperties) &#123;    messageProperties = (AMQP.BasicProperties) message.getProperty();&#125;confirmListener.toConfirm(channel.getNextPublishSeqNo(), rawMsg);for(int i = 0;i&lt;50;i++)&#123;    channel.basicPublish(            exchange, routingKey,            mandatory, immediate,            messageProperties,            message.getContent()    );&#125;

异步模式需要自己多写一部分复杂的代码实现，异步监听类，监听server端的通知消息，异步的好处性能会大幅度提升，发送完毕之后，可以继续发送其他消息。 MQServer通知生产端ConfirmListener监听类：用户可以继承接口实现自己的实现类，处理消息确认机制，此处继承类代码省略，就是上面 ProxiedConfirmListener 类： 下面贴下要实现的接口：
package com.rabbitmq.client;import java.io.IOException;/** * Implement this interface in order to be notified of Confirm events. * Acks represent messages handled successfully; Nacks represent * messages lost by the broker.  Note, the lost messages could still * have been delivered to consumers, but the broker cannot guarantee * this. */public interface ConfirmListener &#123;    /**    ** handleAck RabbitMQ消息接收成功的方法，成功后业务可以做的事情    ** 发送端投递消息前，需要把消息先存起来，比如用KV存储，接收到ack后删除    **/    void handleAck(long deliveryTag, boolean multiple)        throws IOException;    //handleNack RabbitMQ消息接收失败的通知方法，用户可以在这里重新投递消息    void handleNack(long deliveryTag, boolean multiple)        throws IOException;&#125;

]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper 面试题</title>
    <url>/posts/3647b27d/</url>
    <content><![CDATA[Zookeeper 工作原理Zookeeper 的核心是原子广播，这个机制保证了各个 Server 之间的同步。实现这个机制的协议叫做 Zab 协 议。Zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃 后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>查缺补漏</title>
    <url>/posts/d7158ead/</url>
    <content><![CDATA[SpringMVC执行流程:
用户发送请求至前端控制器DispatcherServlet

DispatcherServlet收到请求调用处理器映射器HandlerMapping。

处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。

DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作

执行处理器Handler(Controller，也叫页面控制器)。

Handler执行完成返回ModelAndView

HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet

DispatcherServlet将ModelAndView传给ViewResolver视图解析器

ViewResolver解析后返回具体View

DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。

DispatcherServlet响应用户。


spring的反射有什么问题java的反射破坏了封装，性能也是一个问题；反射不能用jit加速。
springboot启动过程@SpringBootConfiguration 通过与 @Bean 结合完成Bean的 JavaConfig配置；
@ComponentScan 通过范围扫描的方式，扫描特定注解注释的类，将其注册到Spring容器；
@EnableAutoConfiguration 通过 spring.factories 的配置，并结合 @Condition 条件，完成bean的注册；
@Import 通过导入的方式，将指定的class注册解析到Spring容器；


我们将各步骤总结精炼如下：

通过 SpringFactoriesLoader 加载 META-INF/spring.factories 文件，获取并创建 SpringApplicationRunListener 对象
然后由 SpringApplicationRunListener 来发出 starting 消息
创建参数，并配置当前 SpringBoot 应用将要使用的 Environment
完成之后，依然由 SpringApplicationRunListener 来发出 environmentPrepared 消息
创建 ApplicationContext
初始化 ApplicationContext，并设置 Environment，载相关配置等
由 SpringApplicationRunListener 来发出 contextPrepared 消息，告知SpringBoot 应用使用的 ApplicationContext 已准备OK
将各种 beans 装载入 ApplicationContext，继续由 SpringApplicationRunListener 来发出 contextLoaded 消息，告知 SpringBoot 应用使用的 ApplicationContext 已装填OK
refresh ApplicationContext，完成IoC容器可用的最后一步
由 SpringApplicationRunListener 来发出 started 消息
完成最终的程序的启动
由 SpringApplicationRunListener 来发出 running 消息，告知程序已运行起来了

问：Spring Boot Starter 的工作原理是什么？答：Spring Boot 在启动的时候会干这几件事情：

① Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources&#x2F;META-INF&#x2F;spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。
② 根据 spring.factories 配置加载 AutoConfigure 类
③ 根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context

1、Spring Boot 的自动配置是如何实现的？Spring Boot 项目的启动注解是：@SpringBootApplication，其实它就是由下面三个注解组成的：

@Configuration
@ComponentScan
@EnableAutoConfiguration

其中 @EnableAutoConfiguration 是实现自动配置的入口，该注解又通过 @Import 注解导入了AutoConfigurationImportSelector，在该类中加载 META-INF&#x2F;spring.factories 的配置信息。然后筛选出以 EnableAutoConfiguration 为 key 的数据，加载到 IOC 容器中，实现自动配置功能！
21、描述一下JVM加载class文件的原理机制？答：JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。
由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。
类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap）、扩展加载器（Extension）、系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。下面是关于几个类加载器的说明：
​    Bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）；
​    Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap；
​    System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。
Comparable和Comparator接口是干什么的，其区别Comparable &amp; Comparator 都是用来实现集合中元素的比较、排序的，只是 Comparable 是在集合内部定义的方法实现的排序，Comparator 是在集合外部实现的排序，所以，如想实现排序，就需要在集合外定义 Comparator 接口的方法或在集合内实现 Comparable 接口的方法。
Comparator位于包java.util下，而Comparable位于包 java.lang下 Comparable 是一个对象本身就已经支持自比较所需要实现的接口（如 String、Integer 自己就可以完成比较大小操作，已经实现了Comparable接口） 自定义的类要在加入list容器中后能够排序，可以实现Comparable接口，在用Collections类的sort方法排序时，如果不指定Comparator，那么就以自然顺序排序， 这里的自然顺序就是实现Comparable接口设定的排序方式。 
而 Comparator 是一个专用的比较器，当这个对象不支持自比较或者自比较函数不能满足你的要求时，你可以写一个比较器来完成两个对象之间大小的比较。 可以说一个是自已完成比较，一个是外部程序实现比较的差别而已。 
用 Comparator 是策略模式（strategy design pattern），就是不改变对象自身，而用一个策略对象（strategy object）来改变它的行为。 比如：你想对整数采用绝对值大小来排序，Integer 是不符合要求的，你不需要去修改 Integer 类（实际上你也不能这么做）去改变它的排序行为，只要使用一个实现了 Comparator 接口的对象来实现控制它的排序就行了。
分布式Session的几种实现方式
session复制：在支持session复制的服务器上进行，同步session，保持session一致
方案：tomcat-redis-session-manager

session粘滞：强行分发session到各个服务器
方案：负载均衡

cookie存储session：把sessionid存储到cookie中(不安全，cookie容易被盗取，可以存储不重要的数据)

session集中管理：把用户的session存储在单台或者集群服务器的缓存中，所有web服务器从中拿取session，实现session共享
方案：Redis存储用户生成的sessionId或者存储保存sessionId的cookie


Mybatis的mapper文件中resultType和resultMap的区别。1、查询结果为Map时，使用resultType;
2、简单查询且结果为Pojo类，也可以使用resultType,另外，查询字段名与Pojo属性名不一致，可以通过使用别名的方式；
3、复杂的映射或级联，可以使用resultMap;
Spring中七种事务传播行为


事务传播行为类型
说明



PROPAGATION_REQUIRED
如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。


PROPAGATION_SUPPORTS
支持当前事务，如果当前没有事务，就以非事务方式执行。


PROPAGATION_MANDATORY
使用当前的事务，如果当前没有事务，就抛出异常。


PROPAGATION_REQUIRES_NEW
新建事务，如果当前存在事务，把当前事务挂起。


PROPAGATION_NOT_SUPPORTED
以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。


PROPAGATION_NEVER
以非事务方式执行，如果当前存在事务，则抛出异常。


PROPAGATION_NESTED
如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。


REQUIRED,REQUIRES_NEW,NESTED异同NESTED和REQUIRED修饰的内部方法都属于外围方法事务，如果外围方法抛出异常，这两种方法的事务都会被回滚。但是REQUIRED是加入外围方法事务，所以和外围事务同属于一个事务，一旦REQUIRED事务抛出异常被回滚，外围方法事务也将被回滚。而NESTED是外围方法的子事务，有单独的保存点，所以NESTED方法抛出异常被回滚，不会影响到外围方法的事务。
NESTED和REQUIRES_NEW都可以做到内部方法事务回滚而不影响外围方法事务。但是因为NESTED是嵌套事务，所以外围方法回滚之后，作为外围方法事务的子事务也会被回滚。而REQUIRES_NEW是通过开启新的事务实现的，内部事务和外围事务是两个事务，外围事务回滚不会影响内部事务。
nginx负载均衡的5种策略轮询（默认）upstream backserver &#123;    server 192.168.0.14;    server 192.168.0.15;&#125;

weightupstream backserver &#123;    server 192.168.0.14 weight=3;    server 192.168.0.15 weight=7;&#125;

ip_hashupstream backserver &#123;    ip_hash;    server 192.168.0.14:88;    server 192.168.0.15:80;&#125;

fair按后端服务器的响应时间来分配请求，响应时间短的优先分配。
upstream backserver &#123;    server server1;    server server2;    fair;&#125;

url_hashupstream backserver &#123;    server squid1:3128;    server squid2:3128;    hash $request_uri;    hash_method crc32;&#125;

spring是如何解决循环依赖的？构造器的循环依赖：这种依赖spring是处理不了的，直接抛出BeanCurrentlylnCreationException异常。 
单例模式下的setter循环依赖：通过“三级缓存”处理循环依赖。 

singletonObjects &#x2F;&#x2F; 一级缓存
earlySingletonObjects &#x2F;&#x2F; 二级缓存
singletonFactories &#x2F;&#x2F; 三级缓存

非单例循环依赖：无法处理。
幂等性实现方案乐观锁如果只是更新已有的数据，没有必要对业务进行加锁，设计表结构时使用乐观锁，一般通过version来做乐观锁，这样既能保证执行效率，又能保证幂等。
防重表使用订单号 orderNo 做为去重表的唯一索引，每次请求都根据订单号向去重表中插入一条数据。第一次请求查询订单支付状态，订单没有支付，进行支付操作，无论成功与否，执行完后更新订单状态为成功或失败，删除去重表中的数据。后续的订单因为表中唯一索引而插入失败，则返回操作失败，直到第一次的请求完成（成功或失败）。


分布式锁对于防重表可以用分布式锁代替，比如 Redis 和 Zookeeper
Redis

订单发起支付请求，支付系统会去 Redis 缓存中查询是否存在该订单号的 Key，如果不存在，则向 Redis 增加 Key 为订单号
查询订单支付状态，如果未支付，则进行支付流程，支付完成后删除该订单号的 key

Zookeeper

订单发起支付请求，支付系统会去 Zookeeper 中创建一个 node，如果创建失败，则表示订单已经被支付
如果创建成功，则进行支付流程，支付完成后删除 node

Token 机制这种方式分成两个阶段：申请 Token 阶段和支付阶段。 第一阶段，在进入到提交订单页面之前，需要订单系统根据用户信息向支付系统发起一次申请 Token 的请求，支付系统将 Token 保存到 Redis 缓存中，为第二阶段支付使用。 第二阶段，订单系统拿着申请到的 Token 发起支付请求，支付系统会检查 Redis 中是否存在该 Token ，如果存在，表示第一次发起支付请求，删除缓存中 Token 后开始支付逻辑处理；如果缓存中不存在，表示非法请求。
消息队列缓冲将订单的支付请求全部发送到消息队列中，然后使用异步任务处理队列中的数据，过滤掉重复的待支付订单，再进行支付流程。
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>查缺补漏</tag>
      </tags>
  </entry>
  <entry>
    <title>spring cloud 面试题</title>
    <url>/posts/238ae934/</url>
    <content><![CDATA[1、什么是 Spring Cloud？Spring cloud 流应用程序启动器是基于 Spring Boot 的 Spring 集成应用程序，提供与外部系统的集成。Spring cloud Task，一个生命周期短暂的微服务框架，用于快速构建执行有限数据处理的应用程序。
2、使用 Spring Cloud 有什么优势？使用 Spring Boot 开发分布式微服务时，我们面临以下问题
（1）与分布式系统相关的复杂性：这种开销包括网络问题，延迟开销，带宽问题，安全问题。
（2）服务发现：服务发现工具管理群集中的流程和服务如何查找和互相交谈。它涉及一个服务目录，在该目录中注册服务，然后能够查找并连接到该目录中的服务。
（3）冗余：分布式系统中的冗余问题。
（4）负载平衡：负载平衡改善跨多个计算资源的工作负荷，诸如计算机，计算机集群，网络链路，中央处理单元，或磁盘驱动器的分布。
（5）性能问题：由于各种运营开销导致的性能问题。
（6）部署复杂性：Devops 技能的要求。
3、服务注册和发现是什么意思？Spring Cloud 如何实现？当我们开始一个项目时，我们通常在属性文件中进行所有的配置。随着越来越多的服务开发和部署，添加和修改这些属性变得更加复杂。有些服务可能会下降，而某些位置可能会发生变化。手动更改属性可能会产生问题。 Eureka 服务注册和发现可以在这种情况下提供帮助。由于所有服务都在 Eureka 服务器上注册并通过调用 Eureka 服务器完成查找，因此无需处理服务地点的任何更改和处理。
4、Spring Cloud 和dubbo区别?（1）服务调用方式 dubbo是RPC springcloud Rest Api
（2）注册中心，dubbo 是zookeeper springcloud是eureka，也可以是zookeeper
（3）服务网关，dubbo本身没有实现，只能通过其他第三方技术整合，springcloud有Zuul路由网关，作为路由服务器，进行消费者的请求分发，springcloud支持断路器，与git完美集成配置文件支持版本控制，事物总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素。
5、SpringBoot和SpringCloud的区别？SpringBoot专注于快速方便的开发单个个体微服务。
SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，
为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务
SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系.
SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。
6、负载平衡的意义什么？在计算中，负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。
7、什么是 Hystrix？它如何实现容错？Hystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。
通常对于使用微服务架构开发的系统，涉及到许多微服务。这些微服务彼此协作。
思考以下微服务


假设如果上图中的微服务 9 失败了，那么使用传统方法我们将传播一个异常。但这仍然会导致整个系统崩溃。
随着微服务数量的增加，这个问题变得更加复杂。微服务的数量可以高达 1000。这是 hystrix 出现的地方 我们将使用 Hystrix 在这种情况下的 Fallback 方法功能。我们有两个服务 employee-consumer 使用由 employee-consumer 公开的服务。
简化图如下所示


现在假设由于某种原因，employee-producer 公开的服务会抛出异常。我们在这种情况下使用 Hystrix 定义了一个回退方法。这种后备方法应该具有与公开服务相同的返回类型。如果暴露服务中出现异常，则回退方法将返回一些值。
8、什么是 Hystrix 断路器？我们需要它吗？由于某些原因，employee-consumer 公开服务会引发异常。在这种情况下使用 Hystrix 我们定义了一个回退方法。如果在公开服务中发生异常，则回退方法返回一些默认值。


如果 firstPage method() 中的异常继续发生，则 Hystrix 电路将中断，并且员工使用者将一起跳过 firtsPage 方法，并直接调用回退方法。 断路器的目的是给第一页方法或第一页方法可能调用的其他方法留出时间，并导致异常恢复。可能发生的情况是，在负载较小的情况下，导致异常的问题有更好的恢复机会 。


9、什么是 Netflix Feign？它的优点是什么？Feign 是受到 Retrofit，JAXRS-2.0 和 WebSocket 启发的 java 客户端联编程序。
Feign 的第一个目标是将约束分母的复杂性统一到 http apis，而不考虑其稳定性。
在 employee-consumer 的例子中，我们使用了 employee-producer 使用 REST 模板公开的 REST 服务。
但是我们必须编写大量代码才能执行以下步骤
（1）使用功能区进行负载平衡。
（2）获取服务实例，然后获取基本 URL。
（3）利用 REST 模板来使用服务。 前面的代码如下
@Controllerpublic class ConsumerControllerClient &#123;    @Autowired    private LoadBalancerClient loadBalancer;    public void getEmployee() throws RestClientException， IOException &#123;        ServiceInstance serviceInstance=loadBalancer.choose(&quot;employee-producer&quot;);        System.out.println(serviceInstance.getUri());        String baseUrl=serviceInstance.getUri().toString();        baseUrl=baseUrl+&quot;/employee&quot;;        RestTemplate restTemplate = new RestTemplate();        ResponseEntity&lt;String&gt; response=null;        try&#123;            response=restTemplate.exchange(baseUrl，                        HttpMethod.GET， getHeaders()，String.class);        &#125;        catch (Exception ex)            &#123;            System.out.println(ex);        &#125;        System.out.println(response.getBody());    &#125;

之前的代码，有像 NullPointer 这样的例外的机会，并不是最优的。我们将看到如何使用 Netflix Feign 使呼叫变得更加轻松和清洁。如果 Netflix Ribbon 依赖关系也在类路径中，那么 Feign 默认也会负责负载平衡。
10、什么是 Spring Cloud Bus？我们需要它吗？考虑以下情况：我们有多个应用程序使用 Spring Cloud Config 读取属性，而Spring Cloud Config 从 GIT 读取这些属性。
下面的例子中多个员工生产者模块从 Employee Config Module 获取 Eureka 注册的财产。


如果假设 GIT 中的 Eureka 注册属性更改为指向另一台 Eureka 服务器，会发生什么情况。在这种情况下，我们将不得不重新启动服务以获取更新的属性。
还有另一种使用执行器端点&#x2F;刷新的方式。但是我们将不得不为每个模块单独调用这个 url。例如，如果 Employee Producer1 部署在端口 8080 上，则调用 http://localhost:8080/refresh。同样对于 Employee Producer2 http://localhost:8081/refresh 等等。这又很麻烦。这就是 Spring Cloud Bus 发挥作用的地方。


Spring Cloud Bus 提供了跨多个实例刷新配置的功能。因此，在上面的示例中，如果我们刷新 Employee Producer1，则会自动刷新所有其他必需的模块。如果我们有多个微服务启动并运行，这特别有用。这是通过将所有微服务连接到单个消息代理来实现的。无论何时刷新实例，此事件都会订阅到侦听此代理的所有微服务，并且它们也会刷新。可以通过使用端点&#x2F;总线&#x2F;刷新来实现对任何单个实例的刷新。
11、springcloud 断路器的作用当一个服务调用另一个服务由于网络原因或自身原因出现问题，调用者就会等待被调用者的响应 当更多的服务请求到这些资源导致更多的请求等待，发生连锁效应（雪崩效应）
断路器有完全打开状态:一段时间内 达到一定的次数无法调用 并且多次监测没有恢复的迹象 断路器完全打开 那么下次请求就不会请求到该服务
半开：短时间内 有恢复迹象 断路器会将部分请求发给该服务，正常调用时 断路器关闭
关闭：当服务一直处于正常状态 能正常调用
12、什么是SpringCloud Config?在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。
使用：
（1）添加pom依赖
（2）配置文件添加相关配置
（3）启动类添加注解@EnableConfigServer
13、Spring Cloud Gateway?Spring Cloud Gateway是Spring Cloud官方推出的第二代网关框架，取代Zuul网关。网关作为流量的，在微服务系统中有着非常作用，网关常见的功能有路由转发、权限校验、限流控制等作用。
使用了一个RouteLocatorBuilder的bean去创建路由，除了创建路由RouteLocatorBuilder可以让你添加各种predicates和filters，predicates断言的意思，顾名思义就是根据具体的请求的规则，由具体的route去处理，filters是各种过滤器，用来对请求做各种判断和修改。
14、dubbo是什么
dubbo是一个分布式的服务框架，致力于提高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。
简言之，dubbo就是一个服务框架，如果没有分布式的需求，其实不需要用的，只有分布式的时候，才需要dubbo这样的分布式框架
本质里，dubbo就是个服务调用的东东。。
说白了就是个远程服务调用的分布式框架(告别webservice模式中的wsdl，以服务者与消费者的方式在dubbo上注册)
dubbo可以和spring无缝集成
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题</title>
    <url>/posts/5205ee75/</url>
    <content><![CDATA[redis线程模型
单线程，NIO，异步事件处理



rabbitmq集群架构


rabbitmq引入的问题好处：异步、解耦、削峰
坏处：
重复消息（幂等性保障）

设置唯一消息主键
redis setnx 命令（redis分布式锁）

消息丢失

备份交换机
死信队列
mandantory &#x3D; true + ReturnListener 保证消息不丢失

消息积压

增加消费者的消费能力，或者临时增加

顺序消费怎么解决

单一消费者

zookeeperzookeeper分布式锁
监听回调、临时节点
分布式事务
如果超时就会出现分布式事务问题。

二阶段提交atomikos框架实现二阶段提交，可以做到重试机制，日志记录等逻辑，但是无法解决微服务中跨JVM的问题。
可靠消息最终一致性方案可以通过自定义一个消息信息体Message，给消息设置INIT，SEND，END三种状态，然后搭建一个独立的消息服务来补偿消息发送过程可能出现异常的问题，或者是因为网络超时导致消息状态没有修改成功，定时的调用业务系统的相关接口，比如订单是否成功生成，库存是否成功减掉来修复消息本身的状态，进而对操作消息的下一步执行过程。

TCC与XA&#x2F;JTA对比

XA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁
TCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁


TCC的开源框架实现
 Atomikos，tcc-transaction，ByteTcc，支付宝GTS


可靠消息最终一致性方案

TCC(Try-Confirm-Cancel)两阶段补偿型方案

秒杀系统spring session实现分布式session
zookeeper节点通过watcher机制保证本地ConcurrentHashMap中的当前商品库存数量一致，防止超卖问题
redis setnx分布式锁保证接口多次请求只有一次能成功，类似于占位标识，一个用户只能有一个订单的请求，搭配rabbitmq中间件异步消费订单消息，消费成功后解除占位标识，同时在redis中生成订单信息
通过redis的incr实现限流防刷
详情页优化使用动态化渲染，用nginx+lua实现页面动态化，nginx层面做了两层，一层通过hash取模实现负载转发，一层用于缓存热点数据以减少redis缓存的压力

缓存失效
由于大量的key设置相同的过期时间导致，可以采用随机数来设置过期时间避免大量缓存同一时间失效。

缓存击穿
打个比方，某个黑客想要攻击网站，那么他通过URL访问一个不存在的商品来跳过nginx的本地缓存，web应用里面的ecache缓存和redis缓存来直接访问数据库，造成数据库压力暴涨导致系统直接宕机；这个可以通过在redis里面设置某个商品的键值对为&lt;key ,null&gt;来避免直接访问数据库，如果查询到一个值为null的key，直接返回商品不存在的提示信息。

缓存雪崩
缓存雪崩是因为大量的并发请求流入，超过了服务器的负载能力，直接压爆了nginx缓存和redis缓存以及各种缓存从而直接导致系统瘫痪，本质上没法根本解决，为了避免缓存雪崩可以通过水平扩展nginx机器增加nginx缓存或者增加redis cluster内的机器，响应更多的并发请求。


计算机所能处理的最小的数据项位。
优化Hibernate所鼓励的7大措施：
尽量使用many-to-one，避免使用单项one-to-many

灵活使用单向one-to-many

不用一对一，使用多对一代替一对一

配置对象缓存，不使用集合缓存

一对多使用Bag 多对一使用Set

继承使用显示多态 HQL:from object polymorphism&#x3D;”exlicit” 避免查处所有对象

消除大表，使用二级缓存


JSP内置对象一共有9个内置对象

pageContext javax.servlet.jsp.PageContext
request javax.servlet.http.HttpServletRequest
response javax.servlet.http.HttpServletResponse
session javax.servlet.http.HttpSession
application javax.servlet.ServletContext
config javax.serlvet.ServletConfig
exception java.lang.Throwable
page java.lang.Object
out javax.servlet.jsp.JspWriter

作用：

pageContext 表示页容器 EL表达式、 标签 、上传

request 服务器端取得客户端的信息：头信息 、Cookie 、请求参数 ，最大用处在MVC设计模式上

response 服务器端回应客户端信息：Cookie、重定向

session 表示每一个用户，用于登录验证上

application 表示整个服务器

config 取得初始化参数，初始化参数在web.xml文件中配置

exception 表示的是错误页的处理操作

page 如同 this 一样，代表整个 jsp 页面自身

out 输出，但是尽量使用表达式输出


怎样使JAVA栈内存快速溢出？方法区和堆所有线程共享。虚拟机栈和本地方法栈和程序计数器每个线程独享。  每个线程的栈大小可以通过  参数 ：-Xss512k 来决定每新启动一个线程分配的栈大小。
如果方法迭代度过深就会出现栈内存溢出。 每一个方法在执行的同时会创建一个栈帧（用来存储局部变量，操作数栈，动态链接，动态出口等信息。）从调用到执行完成的过程就对应着
一个栈帧在虚拟机中入栈到出栈的过程。（方法执行完成后会释放所有的局部变量）
堆内存则是绝大部分用来存储生成的对象。 创建对象过多或强引用使GC无法回收则会报堆内存不足的异常。 （GC主要关注区域）
方法区\元空间\永久代  : 用来存储被虚拟机加载的类信息，常量，静态变量。（jdk8取消了这部分内存区域，一部分放入heap中）
运行时常量池： 用来存储编译器生成的各种字面量和符号引用。  字面量（new String(“你好”） 你好就是字面量
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>黑苹果安装教程</title>
    <url>/posts/479c48ec/</url>
    <content><![CDATA[目录镜像下载macOS Monterey 12.6.3 (21G419) 正式版 ISO、IPSW、PKG 下载
BIOS 设置官方建议OpenCore 官方建议的 10 代 CPU 架构的 BISO 调整如下：
禁用

Fast Boot
Secure Boot
Serial&#x2F;COM Port
Parallel Port
VT-d (如果设置了 DisableIoMapper 为 YES，则可以打开这个选项)
CSM
Thunderbolt (建议关闭雷电，第一次安装可能出现玄学问题)
Intel SGX
Intel Platform Trust
CFG Lock

开启

VT-x
Above 4G decoding
Hyper-Threading
Execute Disable Bit
EHCI&#x2F;XHCI Hand-off
OS type: Windows 8.1&#x2F;10 UEFI Mode
DVMT Pre-Allocated(iGPU Memory): 64MB
SATA Mode: AHCI

ASUS-11th
disable igpu（Otherwise, you will not be able to sleep normally）
disable Intel Rapid Storage Technology 最后需要按键盘上的F10键保存退出即可.

ASUS-10th
Disabe
Fast Boot
VT-d
CSM
Intel SGX
CFG Lock
Enable
VT-x (no option in BIOS, it’s enabled by default)
Above 4G decoding
Hyper-Threading
EHCI&#x2F;XHCI Hand-off
OS type: Windows UEFI Mode (Clear Secure Boot Keys or choose Other type)
DVMT Pre-Allocated(iGPU Memory): 64MB 最后需要按键盘上的F10键保存退出即可.

MSI-10th
Boot – Fast Boot -&gt; Disabled
Advanced – PCH Sorage Configuration – SATA Mode Selection -&gt; AHCI
Boot – CSM(Compatibility Support Module) -&gt; Disabled
Ai Tweaker – Ai Overclock Tuner -&gt; XMP
Advanced – CPU configuration – Intel Virtualization Technology -&gt; Disabled
Advanced – System Agent (SA) Configuration – VT-D -&gt; Disabled
Advanced – System Agent (SA) Configuration – Above 4G Decoding -&gt; Disabled
Advanced – System Agent (SA) Configuration – Graphics Configuration – Primary Display -&gt; CPU Graphics 集成显卡配置1
Advanced – System Agent (SA) Configuration – Graphics Configuration – iGPU Multi-Monitor -&gt; Disabled 集成显卡配置2
Advanced – PCH configruation - IOAPIC 24-119 Entries -&gt; Enabled
Advanced – PCH-FW Configuration – TPM Device Selection -&gt; Discrete TPM
Advanced – APM Configuration – ErP Ready -&gt; Disabled
Advanced – Network Stack Configuration – Network Stack -&gt; Disabled
Boot – Secure Boot – OS Type – Other OS 最后需要按键盘上的F10键保存退出即可.

MSI-11th
Boot – Fast Boot -&gt; Disabled
Advanced – PCH Sorage Configuration – SATA Mode Selection -&gt; AHCI
Boot – CSM(Compatibility Support Module) -&gt; Disabled
Ai Tweaker – Ai Overclock Tuner -&gt; XMP
Advanced – CPU configuration – Intel Virtualization Technology -&gt; Disabled
Advanced – System Agent (SA) Configuration – VT-D -&gt; Disabled
Advanced – System Agent (SA) Configuration – Above 4G Decoding -&gt; Disabled
Advanced – System Agent (SA) Configuration – Graphics Configuration – Primary Display -&gt; PCIE 独立显卡配置 1
Advanced – System Agent (SA) Configuration – Graphics Configuration – iGPU Multi-Monitor -&gt; Enabled 独立显卡配置 2
Advanced – PCH configruation - IOAPIC 24-119 Entries -&gt; Enabled
Advanced – PCH-FW Configuration – TPM Device Selection -&gt; Discrete TPM
Advanced – APM Configuration – ErP Ready -&gt; Disabled
Advanced – Network Stack Configuration – Network Stack -&gt; Disabled
Boot – Secure Boot – OS Type – Other OS 最后需要按键盘上的F10键保存退出即可.

USB 定制1、从仓库下载 「Windows.exe」到 Windows 平台，双击即可运行
 
2、输入D然后回车来探测电脑上的端口
 
3、分别在各个 USB 接口插入USB2.0和USB 3.X的设备，每插入一次停留 5 秒钟，如果有Type-C设备的话，正反都要分别插入记录都挨个插一遍后，输入 B 回车即可返回主菜单
 
4、回到主菜单，输入S来查看端口探测的结果，此时结果查看感觉没问题的话，输入K回车，即可导出UTBMap.kext文件（一般情况下会保存在当前程序的同级目录下） 
5、除了上述生成的UTBMap.kext文件以外，我们还需要配合USBToolBox.kext使用（仓库）将上述两个 Kext 放到 OC 的 Kexts 文件夹下面并加载，去除 usbport.kext
 
6、重启即可生效，至此你的 USB 基本上定制完了，尽情使用吧。
蓝牙配置
2021 年 6 月初的 WWDC2021 上，苹果发布了下一代 macOS，代号 Monterey（蒙特雷），大版本号 12.0。爱折腾爱尝鲜的黑苹果小伙伴们已经通过各种折腾安装上了新版 macOS。但是很快出现了各种各样的驱动问题，其中比较突出的是蓝牙掉驱动并且卡跑码问题。Monterey 大幅精简了蓝牙框架，原因是 macOS 12.0 砍掉了 2015 年之前机型的支持，另外可能也是为通用控制做准备。
很快，OC 团队做出反应添加了解决方案。说起来也简单，就是新加一个驱动：BlueToolFixup.kext，然后在 macOS 12.0 取消蓝牙 injector（注入器）的加载。
「注意」

BlueToolFixup.kext 目前是 BrcmPatchRAM 文件包中的一部分，新版本发布会直接包括这个文件，英特尔蓝牙也需要这个驱动；
使用奋威 T919 或其它免驱动型网卡的，无需担心蓝牙兼容性问题，在 Monterey 里依旧无需任何驱动。




解决方法
将 Lilu 升级到 1.5.7 及以上；
博通卡：将 BrcmPatchRAM 升级到 2.6.1 及以上；
英特尔：将 IntelBluetoothFirmware 升级到 2.0.1 及以上；
关闭 OpenCore 的 XhciPortLimit，位于 config → Kernel → Quirks 区域，在升级或安装 macOS Monterey 之前，建议定制好 USB 接口；
将 BlueToolFixup.kext 放到 Clover&#x2F;OpenCore 对应的 kext 目录
OpenCore：&#x2F;EFI&#x2F;OC&#x2F;Kexts&#x2F;
Clover：&#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;Other&#x2F;


最后，按照下一章节的说明修改 config.plist 文件。

Clover 方法Clover 使用文件夹名称来区别各个系统加载的 kext，所以可以这么操作：

博通卡：把 BrcmBluetoothInjector.kext 从 &#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;Other&#x2F; 挪到 &#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;11.0&#x2F;，将 BlueToolFixup.kext 放到 &#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;12.0&#x2F;
英特尔：把 IntelBluetoothInjector.kext 从 &#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;Other&#x2F; 挪到 &#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;11.0&#x2F;，将 BlueToolFixup.kext 放到 &#x2F;EFI&#x2F;CLOVER&#x2F;Kexts&#x2F;12.0&#x2F;

如果没有 11.0&#x2F;12.0 的文件夹，自己新建就可以。这样一来 Clover 在引导 11.0 时会加载 Injector，但是引导 12.0 时则不会加载 Injector，会加载 BlueToolFixup.kext 。其它 Kext 文件继续放在 Other 目录无影响。
「注意」以上方法如果不起作用，那么在迁移到 Monterey 时，需要手动从 Kext 目录移除 Injector 文件。「提示」如果你没有从 12.0 切换到低版本 macOS 的需求，xxxxInjector .kext 可以直接删除（无论博通和英特尔都一样），无需设置文件夹；
OpenCore 方法OpenCore 用户推荐使用另一种方法，利用 OpenCore 的最小内核（MinKernel）和最大内核（MaxKernel）特性，给 injector 设置最大内核 20.99.99，也就是对应 macOS Big Sur 11.0，给 BlueToolFixup.kext 设置最小内核 21.0.0，对应 macOS Monterey 12.0。
「提示」如果你没有从 12.0 切换到低版本 macOS 的需求，xxxxInjector .kext 可以直接删除（无论博通和英特尔都一样），也无需设置最大最小内核；
可以直接看图操作：
博通免驱网卡
升级 macos 12 方式：
使用 BlueToolFixup.kext 替代掉 BrcmBluetoothInjector.kext 即可。
最终使用驱动如下：

BlueToolFixup.kext
BrcmFirmwareData.kext
BrcmPatchRAM3.kext




Intel无线网卡
升级 macos 12 方式：
使用 BlueToolFixup.kext 替代掉 IntelBluetoothInjector.kext 即可。
BlueToolFixup.kext 可以从这里下载：https://github.com/acidanthera/BrcmPatchRAM/releases
最终使用驱动如下：

BlueToolFixup.kext
IntelBluetoothFirmware.kext




完成后，记得保存然后重启，如果无效，请关机冷启动，清除 Kext 缓存，或尝试重置 NVRAM。
设置启动参数
下面是 macOS 系统可以使用的启动参数列表，功能解释同时列出，使用要点有两个：

参数之间以空格分隔开；
在一个参数中，- 和 &#x3D; 只会同时存在一个，例如：debug&#x3D;0x100，-xcpm。即：有了 &#x3D; 号就不会有 - 号，反之亦然，新手请务必牢记。


参数说明一览：



常用
参数
作用



*
agdpmod&#x3D;pikera
Navi 核心避免黑屏使用，其它显卡如 RX400&#x2F;500，Vega56&#x2F;64 无需此参数


*
keepsyms&#x3D;1
辅助上一个参数


*
debug&#x3D;0x100 或 debug&#x3D;0x200
防止自动重启，禁用五国图直接输出错误信息


*
-v
用于安装前期启动时显示代码界面，在安装macOS时，应添加此参数以获取明确的错误信息。



-x
安全启动模式，类似 Windows 的安全模式。此模式下 macOS 会尽可能少的加载 Kext 文件。



-s
单用户模式。这一模式将会启动终端模式，可以用这种方式修复你的系统。



-f
关闭 Kext 缓存模式，等于强制重建 Kext 缓存。



-l
在系统日志中输出内存泄漏的相关记录。



arch&#x3D;x86_64
该参数会强制 macOS 以 64 位内核模式启动，在 10.15 及以上没有什么作用。对应的是 arch&#x3D;i386，将强制以 32 位模式启动。



iog&#x3D;0x0
此参数将强制 MacBook 机型在合盖后，接入外部显示器和键盘时系统保持开启状态；但同时，此参数会在接入外部显示器时关闭笔记本的内屏，这可能对保护屏幕以及省电有帮助。



platform&#x3D;X86PC
此参数将强制禁用 ACPI 电源管理。而 platform&#x3D;ACPI 将强制启用 ACPI 电源管理。



idlehalt&#x3D;1
强制 CPU 进入低功耗模式。



debug&#x3D;0x100
此参数用于禁用五国图，把 Kernel Panic（内核崩溃）的相关数据直接输出在屏幕上，可用于禁止发生内核崩溃时自动重启，这将对排查错误有助益，这一参数还可以用于 Core Dump。其它可用值还有：0x200，这可以在内核崩溃后使用快捷键（C 继续、R 重启、K 进入 KDB）；0x400 可用于触发内核崩溃后自动进行 Core Dump；0x2000 将只生成并发送 Kernel Panic 日志，不包括完整的 Core Dump。除此之外还有很多其他值，但一般以上几个已经足够安装 macOS 时使用。



keepsyms&#x3D;1
此参数可以为 debug&#x3D;0xN 提供更多错误信息。



dart&#x3D;0
此参数会关闭 64 位硬件上的系统 PCI 地址映射器（DART）。DART 在拥有 2GB 以上物理内存的机器上是必需的，在默认情况下 DART 都是加载的。当使用 Clover 引导系统且 BIOS 无法关闭 VT-d 时可尝试此参数。gg



darkwake&#x3D;0
在拥有完全定制好的 USB 接口时完全不必使用此参数，除非你真的需要操控 HID Tickle 行为。darkwake 是 XNU 的一部分，XNU 是一个混合内核，是 Darwin 系统的一部分（macOS 和 iOS 均使用了 Darwin ）。因启动参数仅用于按位计算，所以可能的值有 0、1、2、3、256、257、258、259 等等以此类推，也因此 darkwake&#x3D;8 实际等于 darkwake&#x3D;0；darkwake&#x3D;10 实际等于 darkwake&#x3D;2，XNU 自 2782.1.97 起删除了这两个值（8 和 10），故这两个值在 Yosemite 及更高版本 macOS 中已失效。黑苹果建议关闭电能小憩，使用 pmset 命令调试休眠。如果实在需要使用，可尝试 darkwake&#x3D;0 或 3。更多信息可参考外网这篇文章。



nvda_drv&#x3D;1
用于启用英伟达显卡驱动，包括开启 NVIDIA Web Driver


*
nv_disable&#x3D;1
关闭英伟达显卡驱动，请勿与 nvda_drv&#x3D;1 同时使用。



-no_compat_check
用于禁用 macOS 兼容性检查。例如，macOS 11.0 BigSur 不再支持 iMac 2014 年之前推出的机型，此时可使用此参数以禁止兼容性检查，以达到安装目的。



kext-dev-mode&#x3D;1
开启 Kext 开发模式，将允许加载未签名的 Kext。在 Yosemite 及更高版本 macOS 中，默认情况下出于安全原因，只会加载已签名的 Kext。此参数可以在 Yosemite 更改此设置，允许加载未签名的 Kext。在比 Yosemite 更新的 macOS 版本（El Capitan）中，引入了另一种安全机制，即系统完整性保护（SIP，也称为 Rootless），该系统会防止修改系统文件，加载未签名的 Kext 等。SIP 可以通过注入正确的 CSR NVRAM 变量来禁用，也可以通过恢复分区运行命令行禁用它。总之，在 10.11 及以后的系统中，已无需此参数。



cpus&#x3D;1
CPU单核模式，用于限制系统中活动 CPU 的数量。苹果的开发者工具有一个选项用于启用或禁用系统中的一些 CPU，但你也可以通过这个参数指定要使用的 CPU 数量。在某些情况下，这也许有助于省电，或者你正在调试 X86 电源驱动。



-xcpm
用于强制开启 xcpm 以实现 CPU 原生电源管理，一般用于较老架构的 CPU，例如 Ivy Bridge。



-gux_no_idle
用于终止英特尔芯片的空闲模式（idle-mode）功能。



slide&#x3D;N
用于引导系统时分配系统内核在内存中的位置，Clover 在一排加号处卡住可以尝试 slide&#x3D;0，其它参考：Slide 值的说明。



rootless&#x3D;0
使用 Rootless 模式，请勿在 El Capitan 及更高版本的 macOS 上使用，因为从 El Capitan 起引入了 SIP（系统完整性保护）机制。一般情况下关闭 SIP 即可达成你的目的。



-disablegfxfirmware
在 WhateverGreen.kext 出现之前，该参数用于关闭苹果的 iGPU firmware 以正确驱动 Intel 核显，在 macOS 10.13 及更高版本中已不使用。



npci&#x3D;0x2000 或 npci&#x3D;0x3000
AMD 系统没有开启 Above 4G Decoding 时使用；此参数会禁用某些与 kIOPCIConfiguratorPFM64 相关的 PCI 调试，另一个相似的选择是 npci&#x3D;0x3000，后者还会禁用与 gIOPCITunnelledKey 相关的调试。当 X299 卡在 PCI Start Configuration 时，应使用此参数，因为存在与 PCI 通道有关的 IRQ 冲突。


*
brcmfx-aspm
解决蓝牙连线问题，结合 AirportBrcmFixup.kext 使用



igfxonln&#x3D;1
使用 HDMI 接口每次开机&#x2F;重启都需要重新插拔才能显示的，添加启动参数 igfxonln&#x3D;1


*
-wegnoegpu
禁用独显（针对笔记本机型）


切换到 NVRAM 选项卡，右侧找到 7C436110-AB2A-4BBB-A880-FE41995C9F82，启动参数即显示在右方面板，目前配置情况如下：


agdpmod=pikera keepsms=1 brcmfx-aspm

设置默认启动项
config.plist 勾上仿冒苹果快捷键 PollAppleHotKey，在启动选择界面，先选中要启动的项，然后按键盘的 Ctrl + Enter 进入系统即可


也有看到说在 设置-启动磁盘 可选择默认启动项,修改后重启


更新 OC
下载最新版本OCAT(https://github.com/ic005k/OCAuxiliaryTools/releases)
挂载你的efi分区（也叫esp分区） [
挂载后先不要着急打开，先把OCAT（即OCAuxiliaryTools）同步一下再打开 [
然后再打开Config.plist。首先点击全选，然后检查kext更新，更新kext，后点击选择opencore版本，选择最新版，获取opencore，后点击同步 保存即可 [

生成三码1、同步完不必急着关闭OCAT，切换到PL选项卡

2、首先点击生成生成三码，然后点击生成生成rom，保存``重启即可
参考文章黑苹果启动参数都是做什么用的？如何添加或删除？
更新macOS Monterey后遇到的各种Bug及解决方法合集（持续更新）
黑苹果修复博通&#x2F;英特尔蓝牙在macOS Monterey 12.0 正式版中失效的方法
macOS 12 蓝牙
驱动英特尔核显，让黑苹果流畅运行「OpenCore专门篇」
国光黑苹果入门安装教程
【黑苹果】手把手黑苹果安装教程-基于 OpenCore（持续更新中）
【黑苹果】macOS 12 Monterey 原版 OC 引导安装教程
国光 2021 年中的黑苹果组装方案以及驱动分享
minisforum HX80G&#x2F;HX90G&#x2F;HX99G兼Ventura安装教程
EFI 下载hackintosh-with-B560-msi-asus
ASUS-MSI-10-11-HACKINTOSH-OPENCORE
AsRock-Z490-Steel-Legend-i7-10700
国光 3k 元不到的 i9 极致性能的 ITX 黑苹果方案分享
国光 微星 B560M Big Sur 黑苹果记录体验
10400 msi b560黑苹果
【黑苹果安装教程】i7 10700+微星B460M 迫击炮 WIFI
]]></content>
      <categories>
        <category>黑苹果</category>
      </categories>
      <tags>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>黑苹果常用配置</title>
    <url>/posts/4a49b547/</url>
    <content><![CDATA[目录macOS 开启或关闭 SIP
参考链接：https://sspai.com/post/55066

SIP 全称为「System Integrity Protection」即「系统完整性保护」，是 OS X El Capitan 时开始采用的一项安全技术，SIP 将一些文件目录和系统应用保护了起来。但这会影响我们一些使用或设置，比如：更改系统应用图标、终端操作系统目录文件提示「Operation not permitted」、Finder 无法编辑系统目录里的文件。
关闭 SIP因为 SIP 是系统级的权限操作，我们无法直接关闭它，需要前往「macOS 恢复功能」下进行。将 Mac 开机，立即在键盘上按住 Command ⌘ + R，直到看到 Apple 标志或旋转的地球时松开。看到「实用工具」窗口时，恢复功能启动即完成。


在上方的菜单栏点击「实用工具」选择「终端」。


在终端中，输入「csrutil disable」后回车。
回车后会提示「成功关闭了系统完整性保护，请重启机器」
点击菜单栏  标志，选择「重新启动」。


就此我们关闭了 SIP。
打开 SIPSIP 是避免软件任意修改或覆盖任意系统文件或应用，日常还是建议保持开启状态的。仍然是进入到「macOS 恢复功能」，但这次在终端输入的是「csrutil enable」开启 SIP，重启 Mac 即可。
和之前不同，这次输入的是「csrutil enable」

查看 SIP 当前状态csrutil status



opencore 重置 nvram在 OpenCore 中，重置 NVRAM 的方法有以下几种：

在 OpenCore 引导界面中，按下 Command + Option + P + R 键。这将在重启电脑后重置 NVRAM。
使用 Terminal 命令重置 NVRAM。在 Terminal 中输入 sudo nvram -c 并回车。这将立即清除 NVRAM 中的所有设置。
通过 OpenCore Configurator 清除 NVRAM。在 OpenCore Configurator 中选择 NVRAM 中的“Reset NVRAM”按钮。

请注意，重置 NVRAM 将清除所有自定义设置，并将需要重新配置。
查看错误日志pmset -g log

引导进入 Recovery 分区OpenCore配置文件中勾选

 UEFI -&gt; APFS -&gt; JumpstartHotPlug


]]></content>
      <categories>
        <category>黑苹果</category>
      </categories>
      <tags>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>黑苹果常见错误</title>
    <url>/posts/42c32bc5/</url>
    <content><![CDATA[目录解决 App Store 无法登录打开终端，输入命令：
sudo nvram -cPassword:nvram: Error clearing firmware variables: (iokit/common) not permitted

输入用户密码，然后回车，不必理会提示信息，然后重启
BIOS 未禁用 CFG LOCK 选项相关错误信息：

卡在 [EB|#LOG:EXITBS:START]

某些用户会忘记或无法禁用BIOS中的CFG-Lock(特别是与用于电源管理的锁定0xE2 MSR位有关，显然更安全地关闭CFG-Lock)。请注意，这仅适用于Intel用户，不适用于AMD。发生这种情况时，有几个可能的解决方法：
开OpenCore的配置文件config.plist，勾选如下三个选项：

Kernel -&gt; Quirks
AppleCpuPmCfgLock
AppleXcpmCfgLock


UEFI -&gt; Quirks
IgnoreInvalidFlexRatio







BIOS 重设或重启 &#x2F; 关机后发送到安全模式AppleRTC 的问题，很简单的解决方法：

打开 Config.plist 配置文件：
Kernel -&gt; Quirks -&gt; DisableRtcChecksum



注意：如果仍然有问题，则需要使用 RTCMemoryFixup.kext 并排除范围。
参考链接Big Sur安装常见问题
]]></content>
      <categories>
        <category>黑苹果</category>
      </categories>
      <tags>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>面试单题</title>
    <url>/posts/1f03d757/</url>
    <content><![CDATA[基础1、String str&#x3D;”i”与 String str&#x3D;new String(“i”)一样吗不一样，因为内存的分配方式不一样。String str&#x3D;”i”的方式，java 虚拟机会将其分配到常量池中；而 String str&#x3D;new String(“i”) 则会被分到堆内存中。
2、抽象类必须要有抽象方法吗？不需要，抽象类不一定非要有抽象方法，以下为示例代码：
abstract class Cat &#123;    public static void sayHi() &#123;        System.out.println(&quot;hi~&quot;);    &#125;&#125;

3、抽象类能使用 final 修饰吗不能，定义抽象类就是让其他类继承的，如果定义为 final 该类就不能被继承，这样彼此就会产生矛盾，所以 final 不能修饰抽象类。
4、接口和抽象类的区别



接口
抽象类



实现
接口必须使用 implements 来实现接口
抽象类的子类使用 extends 来继承


构造函数
无
可以有


main 方法
无
可以有


实现数量
多个
单个


访问修饰符
方法默认public修饰
方法可以是任意访问修饰符（除了private）


5、java 中 IO 流分为几种按功能来分：输入流（input）、输出流（output）。
按类型来分：字节流和字符流。
字节流和字符流的区别是：字节流按 8 位传输以字节为单位输入输出数据，字符流按 16 位传输以字符为单位输入输出数据。
6、BIO、NIO、AIO 有什么区别
BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。
NIO：New IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。
AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。

7、Files的常用方法都有哪些？
Files.exists()：检测文件路径是否存在。
Files.createFile()：创建文件。
Files.createDirectory()：创建文件夹。
Files.delete()：删除一个文件或目录。
Files.copy()：复制文件。
Files.move()：移动文件。
Files.size()：查看文件个数。
Files.read()：读取文件。
Files.write()：写入文件。

容器1、java容器都有哪些

2、Collection 和 Collections 有什么区别
java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。
Collections则是集合类的一个工具类&#x2F;帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。

3、List、Set、Map 之间的区别是什么

4、HashMap 和 Hashtable 有什么区别
hashMap去掉了HashTable 的contains方法，但是保留了containsValue()和containsKey()方法。
hashTable同步的，而HashMap是非同步的，效率上比hashTable要高。
hashMap允许空键值，而hashTable不允许。

5、HashMap,LinkedHashMap,TreeMap的区别HashMap
Map主要用于存储健值对，根据键得到值，因此不允许键重复,但允许值重复。
Hashmap 是一个最常用的Map,它根据键的HashCode 值存储数据,根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。
HashMap最多只允许一条记录的键为Null，允许多条记录的值为 Null。
HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要同步，可以用 Collections的synchronizedMap方法使HashMap具有同步的能力，或者使用ConcurrentHashMap。

LinkedHashMapLinkedHashMap是HashMap子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。
TreeMapTreeMap实现SortMap接口，能够把它保存的记录根据键排序,默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。
6、HashMap底层实现原理概述HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 
HashMap数据结构HashMap实际是一种“数组+链表”数据结构。在put操作中，通过内部定义算法寻止找到数组下标，将数据直接放入此数组元素中，若通过算法得到的该数组元素已经有了元素（俗称hash冲突，链表结构出现的实际意义也就是为了解决hash冲突的问题）。将会把这个数组元素上的链表进行遍历，将新的数据放到链表末尾。


当我们往Hashmap中put元素时，首先根据key的hashcode重新计算hash值，根绝hash值得到这个元素在数组中的位置(下标)，如果该数组在该位置上已经存放了其他元素，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放入链尾。如果数组中该位置没有元素，就直接将该元素放到数组的该位置上。

需要注意Jdk 1.8中对HashMap的实现做了优化,当链表中的节点数据超过八个之后,该链表会转为红黑树来提高查询效率,从原来的O(n)到O(logn)

7、HashSet 的实现原理
HashSet底层由HashMap实现
HashSet的值存放于HashMap的key上
HashMap的value统一为PRESENT

8、Array 和 ArrayList 有何区别？
Array可以容纳基本类型和对象，而ArrayList只能容纳对象。 
Array是指定大小的，而ArrayList大小是固定的。 
Array没有提供ArrayList那么多功能，比如addAll、removeAll和iterator等。

9、在 Queue 中 poll()和 remove()有什么区别？poll() 和 remove() 都是从队列中取出一个元素，但是 poll() 在获取元素失败的时候会返回空，但是 remove() 失败的时候会抛出异常。
10、Iterator 和 ListIterator 有什么区别？
Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。 
Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。 
ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。

多线程1、线程池中 submit()和 execute()方法有什么区别？
接收的参数不一样
submit有返回值，而execute没有
submit方便Exception处理

2、在 java 程序中怎么保证多线程的运行安全？线程安全在三个方面体现：

原子性：提供互斥访问，同一时刻只能有一个线程对数据进行操作，（atomic,synchronized）
可见性：一个线程对主内存的修改可以及时地被其他线程看到，（synchronized,volatile）
有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序，该观察结果一般杂乱无序，（happens-before原则）

3、什么是死锁？死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。是操作系统层面的一个错误，是进程死锁的简称，最早在 1965 年由 Dijkstra 在研究银行家算法时提出的，它是计算机操作系统乃至整个并发程序设计领域最难处理的问题之一。
怎么防止死锁？死锁的四个必要条件：

互斥条件：进程对所分配到的资源不允许其他进程进行访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源
请求和保持条件：进程获得一定的资源之后，又对其他资源发出请求，但是该资源可能被其他进程占有，此事请求阻塞，但又对自己获得的资源保持不放
不可剥夺条件：是指进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放
环路等待条件：是指进程发生死锁后，若干进程之间形成一种头尾相接的循环等待资源关系

这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之 一不满足，就不会发生死锁。
理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和 解除死锁。
所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确 定资源的合理分配算法，避免进程永久占据系统资源。
此外，也要防止进程在处于等待状态的情况下占用资源。因此，对资源的分配要给予合理的规划。
4、synchronized 和 volatile 的区别是什么？
volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。
volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性。
volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。

5、synchronized 和 Lock 有什么区别？
首先synchronized是java内置关键字，在jvm层面，Lock是个java类；
synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；
synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；
用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；
synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）；
Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

6、synchronized 和 ReentrantLock 区别是什么？synchronized是和if、else、for、while一样的关键字，ReentrantLock是类，这是二者的本质区别。既然ReentrantLock是类，那么它就提供了比synchronized更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock比synchronized的扩展性体现在几点上： 

ReentrantLock可以对获取锁的等待时间进行设置，这样就避免了死锁 
ReentrantLock可以获取各种锁的信息
ReentrantLock可以灵活地实现多路通知

另外，二者的锁机制其实也是不一样的：ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word。
反射1、什么是反射？反射主要是指程序可以访问、检测和修改它本身状态或行为的一种能力
Java反射：
在Java运行时环境中，对于任意一个类，能否知道这个类有哪些属性和方法？对于任意一个对象，能否调用它的任意一个方法
Java反射机制主要提供了以下功能：

在运行时判断任意一个对象所属的类。
在运行时构造任意一个类的对象。
在运行时判断任意一个类所具有的成员变量和方法。
在运行时调用任意一个对象的方法。

2、什么是 java 序列化？什么情况下需要序列化？简单说就是为了保存在内存中的各种对象的状态（也就是实例变量，不是方法），并且可以把保存的对象状态再读出来。虽然你可以用你自己的各种各样的方法来保存object states，但是Java给你提供一种应该比你自己好的保存对象状态的机制，那就是序列化。
什么情况下需要序列化：

当你想把的内存中的对象状态保存到一个文件中或者数据库中时候；
当你想用套接字在网络上传送对象的时候；
当你想通过RMI传输对象的时候；

3、动态代理是什么？有哪些应用？动态代理：
当想要给实现了某个接口的类中的方法，加一些额外的处理。比如说加日志，加事务等。可以给这个类创建一个代理，故名思议就是创建一个新的类，这个类不仅包含原来类方法的功能，而且还在原来的基础上添加了额外处理的新类。这个代理类并不是定义好的，是动态生成的。具有解耦意义，灵活，扩展性强。
动态代理的应用：

Spring的AOP
加事务
加权限
加日志

4、JDK和CGLIB动态代理原理

1、JDK动态代理利用拦截器(拦截器必须实现InvocationHanlder)加上反射机制生成一个实现代理接口的匿名类，
在调用具体方法前调用InvokeHandler来处理。
2、CGLIB动态代理利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。
3、何时使用JDK还是CGLIB？
如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP。
如果目标对象实现了接口，可以强制使用CGLIB实现AOP。
如果目标对象没有实现了接口，必须采用CGLIB库，Spring会自动在JDK动态代理和CGLIB之间转换。

4、如何强制使用CGLIB实现AOP？
添加CGLIB库(aspectjrt-xxx.jar、aspectjweaver-xxx.jar、cglib-nodep-xxx.jar)
在Spring配置文件中加入&lt;aop:aspectj-autoproxy proxy-target-class&#x3D;”true”&#x2F;&gt;

5、JDK动态代理和CGLIB字节码生成的区别？
JDK动态代理只能对实现了接口的类生成代理，而不能针对类。
CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法，并覆盖其中方法实现增强，但是因为采用的是继承，所以该类或方法最好不要声明成final，对于final类或方法，是无法继承的。

6、CGlib比JDK快？
使用CGLib实现动态代理，CGLib底层采用ASM字节码生成框架，使用字节码技术生成代理类，在jdk6之前比使用Java反射效率要高。唯一需要注意的是，CGLib不能对声明为final的方法进行代理，因为CGLib原理是动态生成被代理类的子类。
在jdk6、jdk7、jdk8逐步对JDK动态代理优化之后，在调用次数较少的情况下，JDK代理效率高于CGLIB代理效率，只有当进行大量调用的时候，jdk6和jdk7比CGLIB代理效率低一点，但是到jdk8的时候，jdk代理效率高于CGLIB代理，总之，每一次jdk版本升级，jdk代理效率都得到提升，而CGLIB代理消息确有点跟不上步伐。

7、Spring如何选择用JDK还是CGLIB？
当Bean实现接口时，Spring就会用JDK的动态代理。
当Bean没有实现接口时，Spring使用CGlib是实现。
可以强制使用CGlib（在spring配置中加入&lt;aop:aspectj-autoproxy proxy-target-class&#x3D;”true”&#x2F;&gt;）。

总结JDK代理是不需要第三方库支持，只需要JDK环境就可以进行代理，使用条件:

实现InvocationHandler 

使用Proxy.newProxyInstance产生代理对象

被代理的对象必须要实现接口


CGLib必须依赖于CGLib的类库，但是它需要类来实现任何接口代理的是指定的类生成一个子类，覆盖其中的方法，是一种继承但是针对接口编程的环境下推荐使用JDK的代理；
5、深拷贝和浅拷贝区别是什么？
浅拷贝只是复制了对象的引用地址，两个对象指向同一个内存地址，所以修改其中任意的值，另一个值都会随之变化，这就是浅拷贝（例：assign()）
深拷贝是将对象及值复制过来，两个对象修改其中任意的值另一个值不会改变，这就是深拷贝（例：JSON.parse()和JSON.stringify()，但是此方法无法复制函数类型）

异常1、throw 和 throws 的区别？throws是用来声明一个方法可能抛出的所有异常信息，throws是将异常声明但是不处理，而是将异常往上传，谁调用我就交给谁处理。而throw则是指抛出的一个具体的异常类型。
2、final、finally、finalize 有什么区别？
final可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表示该变量是一个常量不能被重新赋值。
finally一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。
finalize是一个方法，属于Object类的一个方法，而Object类是所有类的父类，该方法一般由垃圾回收器来调用，当我们调用System的gc()方法的时候，由垃圾回收器调用finalize(),回收垃圾

3、try-catch-finally 中哪个部分可以省略？答：catch 可以省略
原因：更为严格的说法其实是：try只适合处理运行时异常，try+catch适合处理运行时异常+普通异常。也就是说，如果你只用try去处理普通异常却不加以catch处理，编译是通不过的，因为编译器硬性规定，普通异常如果选择捕获，则必须用catch显示声明以便进一步处理。而运行时异常在编译时没有如此规定，所以catch可以省略，你加上catch编译器也觉得无可厚非。
理论上，编译器看任何代码都不顺眼，都觉得可能有潜在的问题，所以你即使对所有代码加上try，代码在运行期时也只不过是在正常运行的基础上加一层皮。但是你一旦对一段代码加上try，就等于显示地承诺编译器，对这段代码可能抛出的异常进行捕获而非向上抛出处理。如果是普通异常，编译器要求必须用catch捕获以便进一步处理；如果运行时异常，捕获然后丢弃并且+finally扫尾处理，或者加上catch捕获以便进一步处理。
至于加上finally，则是在不管有没捕获异常，都要进行的“扫尾”处理。
4、try-catch-finally 中，如果 catch 中 return 了，finally 还会执行吗？答：会执行，在 return 前执行。
网络1、http 响应码 301 和 302 代表的是什么？有什么区别？答：301，302 都是HTTP状态的编码，都代表着某个URL发生了转移。
区别： 

301 redirect: 301 代表永久性转移(Permanently Moved)。
302 redirect: 302 代表暂时性转移(Temporarily Moved )。

2、简述 tcp 和 udp的区别？
TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接。
TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付。
TCP通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。
UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。
每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信。
TCP对系统资源要求较多，UDP对系统资源要求较少。

3、tcp 为什么要三次握手，两次不行吗？为什么？为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤。
如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认。
4、说一下 tcp 粘包是怎么产生的？①. 发送方产生粘包
采用TCP协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据；但当发送的数据包过于的小时，那么TCP协议默认的会启用Nagle算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。


②. 接收方产生粘包
接收方采用TCP协议接收数据时的过程是这样的：数据到底接收方，从网络模型的下方传递至传输层，传输层的TCP协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C语言用recv、read等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度） 


5、OSI 的七层模型都有哪些？
应用层：网络服务与最终用户的一个接口。
表示层：数据的表示、安全、压缩。
会话层：建立、管理、终止会话。
传输层：定义传输数据的协议端口号，以及流控和差错校验。
网络层：进行逻辑地址寻址，实现不同网络之间的路径选择。
数据链路层：建立逻辑连接、进行硬件地址寻址、差错校验等功能。
物理层：建立、维护、断开物理连接。

6、get 和 post 请求有哪些区别？
GET在浏览器回退时是无害的，而POST会再次提交请求。
GET产生的URL地址可以被Bookmark，而POST不可以。
GET请求会被浏览器主动cache，而POST不会，除非手动设置。
GET请求只能进行url编码，而POST支持多种编码方式。
GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
GET请求在URL中传送的参数是有长度限制的，而POST没有。
对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
GET参数通过URL传递，POST放在Request body中。

7、说一下 JSONP 实现原理？jsonp 即 json+padding，动态创建script标签，利用script标签的src属性可以获取任何域下的js脚本，通过这个特性(也可以说漏洞)，服务器端不在返货json格式，而是返回一段调用某个函数的js代码，在src中进行了调用，这样实现了跨域。
8、如何实现跨域？
方式一：图片ping或script标签跨域
图片ping常用于跟踪用户点击页面或动态广告曝光次数。script标签可以得到从其他来源数据，这也是JSONP依赖的根据。 

方式二：JSONP跨域
JSONP（JSON with Padding）是数据格式JSON的一种“使用模式”，可以让网页从别的网域要数据。根据 XmlHttpRequest 对象受到同源策略的影响，而利用 &lt;script&gt;元素的这个开放策略，网页可以得到从其他来源动态产生的JSON数据，而这种使用模式就是所谓的 JSONP。用JSONP抓到的数据并不是JSON，而是任意的JavaScript，用 JavaScript解释器运行而不是用JSON解析器解析。所有，通过Chrome查看所有JSONP发送的Get请求都是js类型，而非XHR。

方式三：CORS
Cross-Origin Resource Sharing（CORS）跨域资源共享是一份浏览器技术的规范，提供了 Web 服务从不同域传来沙盒脚本的方法，以避开浏览器的同源策略，确保安全的跨域数据传输。现代浏览器使用CORS在API容器如XMLHttpRequest来减少HTTP请求的风险来源。与 JSONP 不同，CORS 除了 GET 要求方法以外也支持其他的 HTTP 要求。服务器一般需要增加如下响应头的一种或几种：
&quot;Access-Control-Allow-Credentials&quot;: true// Ajax设置&quot;withCredentials&quot;: true

方式四：window.name+iframe
window.name通过在iframe（一般动态创建i）中加载跨域HTML文件来起作用。然后，HTML文件将传递给请求者的字符串内容赋值给window.name。然后，请求者可以检索window.name值作为响应。

iframe标签的跨域能力；
window.name属性值在文档刷新后依旧存在的能力（且最大允许2M左右）。

每个iframe都有包裹它的window，而这个window是top window的子窗口。contentWindow属性返回元素的Window对象。你可以使用这个Window对象来访问iframe的文档及其内部DOM。
&lt;!--  下述用端口  10000表示：domainA 10001表示：domainB--&gt; &lt;!-- localhost:10000 --&gt;&lt;script&gt;  var iframe = document.createElement(&#x27;iframe&#x27;);  iframe.style.display = &#x27;none&#x27;; // 隐藏   var state = 0; // 防止页面无限刷新  iframe.onload = function() &#123;      if(state === 1) &#123;          console.log(JSON.parse(iframe.contentWindow.name));          // 清除创建的iframe          iframe.contentWindow.document.write(&#x27;&#x27;);          iframe.contentWindow.close();          document.body.removeChild(iframe);      &#125; else if(state === 0) &#123;          state = 1;          // 加载完成，指向当前域，防止错误(proxy.html为空白页面)          // Blocked a frame with origin &quot;http://localhost:10000&quot; from accessing a cross-origin frame.          iframe.contentWindow.location = &#x27;http://localhost:10000/proxy.html&#x27;;      &#125;  &#125;;   iframe.src = &#x27;http://localhost:10001&#x27;;  document.body.appendChild(iframe);&lt;/script&gt; &lt;!-- localhost:10001 --&gt;&lt;!DOCTYPE html&gt;...&lt;script&gt;  window.name = JSON.stringify(&#123;a: 1, b: 2&#125;);&lt;/script&gt;&lt;/html&gt;

方式五：window.postMessage()
HTML5新特性，可以用来向其他所有的 window 对象发送消息。需要注意的是我们必须要保证所有的脚本执行完才发送 MessageEvent，如果在函数执行的过程中调用了它，就会让后面的函数超时无法执行。
方式六：修改document.domain跨子域
前提条件：这两个域名必须属于同一个基础域名!而且所用的协议，端口都要一致，否则无法利用document.domain进行跨域，所以只能跨子域
在根域范围内，允许把domain属性的值设置为它的上一级域。例如，在”aaa.xxx.com”域内，可以把domain设置为 “xxx.com” 但不能设置为 “xxx.org” 或者”com”。
方式七：WebSocket
WebSocket protocol 是HTML5一种新的协议。它实现了浏览器与服务器全双工通信，同时允许跨域通讯，是server push技术的一种很棒的实现。
需要注意：WebSocket对象不支持DOM 2级事件侦听器，必须使用DOM 0级语法分别定义各个事件。
方式八：代理
同源策略是针对浏览器端进行的限制，可以通过服务器端来解决该问题
DomainA客户端（浏览器） &#x3D;&#x3D;&gt; DomainA服务器 &#x3D;&#x3D;&gt; DomainB服务器 &#x3D;&#x3D;&gt; DomainA客户端（浏览器）
Spring &#x2F; Spring MVC1、解释一下什么是 ioc？IoC（Inverse of Control:控制反转）是一种设计思想，就是 将原本在程序中手动创建对象的控制权，交由Spring框架来管理。  IoC 在其他语言中也有应用，并非 Spring 特有。 IoC 容器是 Spring 用来实现 IoC 的载体，IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。
将对象之间的相互依赖关系交给 IOC 容器来管理，并由 IOC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。  IOC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件&#x2F;注解即可，完全不用考虑对象是如何被创建出来的。 在实际项目中一个 Service 类可能有几百甚至上千个类作为它的底层，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IOC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。
Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。
Spring IOC的初始化过程：




IOC理论提出的观点大体是这样的：借助于“第三方”实现具有依赖关系的对象之间的解耦。如下图：


大家看到了吧，由于引进了中间位置的“第三方”，也就是IOC容器，使得A、B、C、D这4个对象没有了耦合关系，齿轮之间的传动全部依靠“第三方”了，全部对象的控制权全部上缴给“第三方”IOC容器，所以，IOC容器成了整个系统的关键核心，它起到了一种类似“粘合剂”的作用，把系统中的所有对象粘合在一起发挥作用，如果没有这个“粘合剂”，对象与对象之间会彼此失去联系，这就是有人把IOC容器比喻成“粘合剂”的由来。
2、spring 有哪些主要模块？Spring框架至今已集成了20多个模块。这些模块主要被分如下图所示的核心容器、数据访问&#x2F;集成、Web、AOP（面向切面编程）、工具、消息和测试模块。
3、spring 常用的注入方式有哪些？Spring通过DI（依赖注入）实现IOC（控制反转），常用的注入方式主要有三种：

构造方法注入
setter注入
基于注解的注入

4、spring 支持几种 bean 的作用域？当通过spring容器创建一个Bean实例时，不仅可以完成Bean实例的实例化，还可以为Bean指定特定的作用域。Spring支持如下5种作用域：

singleton：单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例
prototype：原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例
request：对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作用域才有效
session：对于每次HTTP Session，使用session定义的Bean都将产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效
globalsession：每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中使用Spring时，该作用域才有效

其中比较常用的是singleton和prototype两种作用域。对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。
如果不指定Bean的作用域，Spring默认使用singleton作用域。Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。
5、Spring 中的单例 bean 的线程安全问题了解吗？大部分时候我们并没有在系统中使用多线程，所以很少有人会关注这个问题。单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。
常见的有两种解决办法：

在Bean对象中尽量避免定义可变的成员变量（不太现实）。
在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。

6、说一下 spring 的事务隔离级别？事务隔离级别指的是一个事务对数据的修改与另一个并行的事务的隔离程度，当多个事务同时访问相同数据时，如果没有采取必要的隔离机制，就可能发生以下问题：

脏读：一个事务读到另一个事务未提交的更新数据。
幻读：例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还存在没有修改的数据行，就好象发生了幻觉一样。
不可重复读：比方说在同一个事务中先后执行两条一模一样的select语句，期间在此次事务中没有执行过任何DDL语句，但先后得到的结果不一致，这就是不可重复读。

7、Spring 事务中的隔离级别有哪几种?TransactionDefinition 接口中定义了五个表示隔离级别的常量：

TransactionDefinition.ISOLATION_DEFAULT:使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.
TransactionDefinition.ISOLATION_READ_UNCOMMITTED:最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
TransactionDefinition.ISOLATION_READ_COMMITTED:允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
TransactionDefinition.ISOLATION_REPEATABLE_READ:对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
TransactionDefinition.ISOLATION_SERIALIZABLE:最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

8、Spring 事务中哪七种事务传播行为?支持当前事务的情况：

TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。
TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）

不支持当前事务的情况：

TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。
TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。
TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。

其他情况：

TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。

9、说一下 spring mvc 运行流程？Spring MVC运行流程图：


Spring运行流程描述：

用户向服务器发送请求，请求被Spring前端控制Servlet DispatcherServlet捕获；

DispatcherServlet对请求URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回；

DispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter；（附注：如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler(…)方法）

提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)。 在填充Handler的入参过程中，根据你的配置，Spring将帮你做一些额外的工作：

HttpMessageConveter： 将请求消息（如Json、xml等数据）转换成一个对象，将对象转换为指定的响应信息

数据转换：对请求消息进行数据转换。如String转换成Integer、Double等

数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等

数据验证： 验证数据的有效性（长度、格式等），验证结果存储到BindingResult或Error中



Handler执行完成后，向DispatcherServlet返回一个ModelAndView对象；

根据返回的ModelAndView，选择一个适合的ViewResolver（必须是已经注册到Spring容器中的ViewResolver)返回给DispatcherServlet ；

ViewResolver结合Model和View，来渲染视图；

将渲染结果返回给客户端。


10、spring mvc 有哪些组件？Spring MVC的核心组件：

DispatcherServlet：中央控制器，把请求给转发到具体的控制类
Controller：具体处理请求的控制器
HandlerMapping：映射处理器，负责映射中央处理器转发给controller时的映射策略
ModelAndView：服务层返回的数据和视图层的封装类
ViewResolver：视图解析器，解析具体的视图
Interceptors ：拦截器，负责拦截我们定义的请求然后做处理工作

11、Spring AOP 和 AspectJ AOP 有什么区别？Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。
Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，
如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ，它比Spring AOP 快很多。
12、Spring 中的 bean 生命周期?中文版本图


英文版本图



Bean 容器找到配置文件中 Spring Bean 的定义。
Bean 容器利用 Java Reflection API 创建一个Bean的实例。

如果涉及到一些属性值 利用 set()方法设置一些属性值。

如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入Bean的名字。
如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。
如果Bean实现了 BeanFactoryAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader 对象的实例。
与上面的类似，如果实现了其他 *.Aware接口，就调用相应的方法。

如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法

如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。

如果 Bean 在配置文件中的定义包含  init-method 属性，执行指定的方法。

如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法

当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。
当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。


13、@Component 和 @Bean 的区别是什么？
作用对象不同: @Component 注解作用于类，而@Bean注解作用于方法。
@Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了Spring这是某个类的示例，当我需要用它的时候还给我。
@Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。

14、将一个类声明为Spring的 bean 的注解有哪些?我们一般使用 @Autowired 注解自动装配 bean，要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,采用以下注解可实现：

@Component ：通用的注解，可标注任意类为 Spring 组件。如果一个Bean不知道属于拿个层，可以使用@Component 注解标注。
@Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。
@Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao层。
@Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。

15、区分 BeanFactory 和 ApplicationContext

16、@Required 注解有什么用？@Required 应用于 bean 属性 setter 方法。此注解仅指示必须在配置时使用bean 定义中的显式属性值或使用自动装配填充受影响的 bean 属性。如果尚未填充受影响的 bean 属性，则容器将抛出 BeanInitializationException。
public class Employee &#123;	private String name;	@Required	public void setName(String name)&#123;		this.name=name;	&#125;	public string getName()&#123;		return name;	&#125;&#125;

17、@Autowired 注解有什么用？@Autowired 可以更准确地控制应该在何处以及如何进行自动装配。此注解用于在 setter 方法，构造函数，具有任意名称或多个参数的属性或方法上自动装配bean。默认情况下，它是类型驱动的注入。
public class Employee &#123;	private String name;	@Autowired	public void setName(String name) &#123;		this.name=name;	&#125;	public string getName()&#123;		return name;	&#125;&#125;

18、@Qualifier 注解有什么用？当您创建多个相同类型的 bean 并希望仅使用属性装配其中一个 bean 时，您可以使用@Qualifier 注解和 @Autowired 通过指定应该装配哪个确切的 bean来消除歧义。 例如，这里我们分别有两个类，Employee 和 EmpAccount。在 EmpAccount中，使用@Qualifier 指定了必须装配 id 为 emp1 的 bean。 
Employee.java
public class Employee &#123;	private String name;	@Autowired	public void setName(String name) &#123;		this.name=name;	&#125;	public string getName() &#123;		return name;	&#125;&#125;

EmpAccount.java
public class EmpAccount &#123;	private Employee emp;    	@Autowired	@Qualifier(emp1)	public void showName() &#123;		System.out.println(“Employee name : ”+emp.getName);	&#125;&#125;

19、列举 Spring DAO 抛出的异常。

20、spring JDBC API 中存在哪些类？
JdbcTemplate 
SimpleJdbcTemplate 
NamedParameterJdbcTemplate 
SimpleJdbcInsert 
SimpleJdbcCall

21、列举 spring 支持的事务管理类型Spring 支持两种类型的事务管理：

程序化事务管理：在此过程中，在编程的帮助下管理事务。它为您提供极大的灵活性，但维护起来非常困难。
声明式事务管理：在此，事务管理与业务代码分离。仅使用注解或基于 XML的配置来管理事务。

22、spring 支持哪些 ORM 框架
Hibernate
iBatis 
JPA
JDO 
OJB

23、指出在 spring aop 中 concern 和 cross-cuttingconcern 的不同之处。concern 是我们想要在应用程序的特定模块中定义的行为。它可以定义为我们想要实现的功能。
cross-cutting concern 是一个适用于整个应用的行为，这会影响整个应用程序。例如，日志记录，安全性和数据传输是应用程序几乎每个模块都需要关注的问题，因此它们是跨领域的问题。
24、AOP 有哪些实现方式？实现 AOP 的技术，主要分为两大类：
静态代理 指使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强；

编译时编织（特殊编译器实现）
类加载时编织（特殊的类加载器实现）。

动态代理 在运行时在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。

JDK 动态代理 
CGLIB

25、如何理解 Spring 中的代理？将 Advice 应用于目标对象后创建的对象称为代理。在客户端对象的情况下，目标对象和代理对象是相同的。 Advice + Target Object &#x3D; Proxy
26、介绍一下 WebApplicationContextWebApplicationContext 是 ApplicationContext 的扩展。它具有 Web 应用程序所需的一些额外功能。它与普通的 ApplicationContext 在解析主题和决定与哪个 servlet 关联的能力方面有所不同。
27、Bean 工厂和 Application contexts 有什么区别？Application contexts 提供一种方法处理文本消息，一个通常的做法是加载文件资源（比如镜像），它们可以向注册为监听器的 bean 发布事件。另外，在容器或容器内的对象上执行的那些不得不由 bean 工厂以程序化方式处理的操作，可以在Application contexts 中以声明的方式处理。
Application contexts 实现了 MessageSource 接口，该接口的实现以可插拔的方式提供获取本地化消息的方法。
28、自动装配有哪些局限性 ?自动装配的局限性是：

重写：你仍需用配置来定义依赖，意味着总要重写自动装配。
基本数据类型：你不能自动装配简单的属性，如基本数据类型，String字符串，和类。
模糊特性：自动装配不如显式装配精确，如果有可能，建议使用显式装配。

29、你可以在 Spring 中注入一个 null 和一个空字符串吗？可以。
30、有几种不同类型的自动代理？
BeanNameAutoProxyCreator
DefaultAdvisorAutoProxyCreator
Metadata autoproxying

拦截器和过滤器的区别过滤器（filter）：

过滤器处于客户端与Web资源（Servlet、JSP、HTML）之间，客户端与Web资源之间的请求和响应都要通过过滤器进行过滤。举例：在过滤器中定义了禁止访问192.10.10.1这个地址，那么当客户端发出访问192.10.10.1的请求时，经过过滤器后，客户端得到的响应是出现该IP禁止访问的提示。
在java web中，你传入的request,response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者struts的 action进行业务逻辑，比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）,或者在传入servlet或者 struts的action前统一设置字符集，或者去除掉一些非法字符

**拦截器（interceptor）:**，

拦截器是一种面向方面&#x2F;切面编程（AOP Aspect-Oriented Programming）.
面向切面就是将多个模块的的通用服务进行分离，如权限管理、日志服务，他们在多个模块中都会用到，就可以将其各自封装为一个可重用模块。而这些通用服务的具体实现是通过拦截器来完成，比如用户客户端访问一些保密模块都应先通过权限审查的拦截器来进行权限审查，确定用户是否具有该项操作的权限后方能向下执行。
在面向切面编程的就是在你的service或者一个方法，前调用一个方法，或者在方法后调用一个方法比如动态代理就是拦截器的简单实现，在你调用方法前打印出字符串（或者做其它业务逻辑的操作），也可以在你调用方法后打印出字符串，甚至在你抛出异常的时候做业务逻辑的操作。

两者的区别

拦截器是基于java反射机制的，而过滤器是基于函数回调。
拦截器不依赖于Servlet容器，而过滤器依赖于servlet容器。
拦截器只能对action请求起作用，而过滤器可以对几乎所以的请求起作用。
拦截器可以访问action上下文，值栈里的对象，而过滤器不能。
在Action的生命周期周，拦截器可以被多次调用，而过滤器只能在容器初始化的时候被调用一次。

执行顺序 ：过滤前 - 拦截前 - Action处理 - 拦截后 - 过滤后。个人认为过滤是一个横向的过程，首先把客户端提交的内容进行过滤(例如未登录用户不能访问内部页面的处理)；过滤通过后，拦截器将检查用户提交数据的验证，做一些前期的数据处理，接着把处理后的数据发给对应的Action；Action处理完成返回后，拦截器还可以做其他过程(还没想到要做啥)，再向上返回到过滤器的后续操作。
拦截器 ：是在面向切面编程的就是在你的service或者一个方法前调用一个方法，或者在方法后调用一个方法比如动态代理就是拦截器的简单实现，在你调用方法前打印出字符串（或者做其它业务逻辑的操作），也可以在你调用方法后打印出字符串，甚至在你抛出异常的时候做业务逻辑的操作。
过滤器：是在java web中，你传入的request,response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者struts的 action进行业务逻辑，比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）,或者在传入servlet或者 struts的action前统一设置字符集，或者去除掉一些非法字符.
Java 中，嵌套公共静态类与顶级类有什么不同？类的内部可以有多个嵌套公共静态类，但是一个 Java 源文件只能有一个顶级公共类，并且顶级公共类的名称与源文件名称必须一致。
Java 中，Serializable 与 Externalizable 的区别？Serializable 接口是一个序列化 Java 类的接口，以便于它们可以在网络上传输或者可以将它们的状态保存在磁盘上，是 JVM 内嵌的默认序列化方式，成本高、脆弱而且不安全。Externalizable 允许你控制整个序列化过程，指定特定的二进制格式，增加安全机制。
Java 中，DOM 和 SAX 解析器有什么不同？DOM 解析器将整个 XML 文档加载到内存来创建一棵 DOM 模型树，这样可以更快的查找节点和修改 XML 结构，而 SAX 解析器是一个基于事件的解析器，不会将整个 XML 文档加载到内存。由于这个原因，DOM 比 SAX 更快，也要求更多的内存，不适合于解析大 XML 文件。
说出 JDK 1.7 中的三个新特性？虽然 JDK 1.7 不像 JDK 5 和 8 一样的大版本，但是，还是有很多新的特性，如

try-with-resource 语句，这样你在使用流或者资源的时候，就不需要手动关闭，Java 会自动关闭。
Fork-Join 池某种程度上实现 Java 版的 Map-reduce。
允许 Switch 中有 String 变量和文本。
菱形操作符(&lt;&gt;)用于类型推断，不再需要在变量声明的右边申明泛型，因此可以写出可读写更强、更简洁的代码。
另一个值得一提的特性是改善异常处理，如允许在同一个 catch 块中捕获多个异常。

说出 5 个 JDK 1.8 引入的新特性？Java 8 在 Java 历史上是一个开创新的版本，下面 JDK 8 中 5 个主要的特性：

Lambda 表达式,允许像对象一样传递匿名函数
Stream API,充分利用现代多核 CPU，可以写出很简洁的代码
Date 与 Time API,最终，有一个稳定、简单的日期和时间库可供你使用
扩展方法，现在，接口中可以有静态、默认方法。
重复注解，现在你可以将相同的注解在同一类型上使用多次。

8、&amp;和&amp;&amp;的区别？&amp;和&amp;&amp;都可以用作逻辑与的运算符，表示逻辑与（and），当运算符两边的表达式的结果都为true时，整个运算结果才为true，否则，只要有一方为false，则结果为false。
区别：

&amp;&amp;还具有短路的功能，即如果第一个表达式为false，则不再计算第二个表达式以及后面的表达式。(如果遇到true就一直向下判断条件直到遇到false的表达式返回)

&amp;不具有短路的功能,逻辑运算表达式条件都会执行。


9、解释内存中的栈(stack)、堆(heap)和方法区(method area)的用法。通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用JVM中的栈空间；而通过new关键字和构造器创建的对象则放在堆空间，堆是垃圾收集器管理的主要区域，由于现在的垃圾收集器都采用分代收集算法，所以堆空间还可以细分为新生代和老生代，再具体一点可以分为Eden、Survivor（又可分为From Survivor和To Survivor）、Tenured；方法区和堆都是各个线程共享的内存区域，用于存储已经被JVM加载的类信息、常量、静态变量、JIT编译器编译后的代码等数据；程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在常量池中，常量池是方法区的一部分。栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，栈和堆的大小都可以通过JVM的启动参数来进行调整，栈空间用光了会引发StackOverflowError，而堆和常量池空间不足则会引发OutOfMemoryError。
11、switch 是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上？switch可作用于char byte short int
switch可作用于char byte short int对应的包装类
switch不可作用于long double float boolean，包括他们的包装类
13、数组有没有 length()方法？String 有没有 length()方法？数组没有length()这个方法，有length的属性。String有length()这个方法。
int a[];a.length; //返回a的长度String s;s.length(); //返回s的长度

14、在 Java 中，如何跳出当前的多重嵌套循环？一、标号方式在Java中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号break语句，即可跳出外层循环。
例如：
ok:for (int i = 0; i &lt; 10; i++) &#123;    for (int j = 0; j &lt; 10; j++) &#123;        System.out.println(&quot;i=&quot; + i + &quot;,j=&quot; + j);        if (j == 5) break ok;    &#125;&#125;

二、break跳出当前循环，通过内部跳出条件控制跳出外部循环
for (int i = 0; i &lt; 4; i++) &#123;    for (int j = 0; j &lt; 5; j++) &#123;        System.out.println(&quot;i=&quot; + i + &quot;; j=&quot; + j);        if (j == 3) &#123;            i = 4;            break;        &#125;    &#125;&#125;

三、抛出异常也可以跳出多重循环
try &#123;    for (int i = 0; i &lt; 4; i++) &#123;        for (int j = 0; j &lt; 5; j++) &#123;            System.out.println(&quot;i=&quot; + i + &quot;; j=&quot; + j);            if (j == 3) &#123;                throw new Exception();            &#125;        &#125;    &#125;&#125; catch (Exception e) &#123;    System.out.println(&quot;e&quot;);&#125;

通常并不使用标号这种方式，而是让外层的循环条件表达式的结果可以受到里层循环体代码的控制，例如，要在二维数组中查找到某个数字。
int arr[][] = &#123;&#123;1, 2, 3&#125;, &#123;4, 5, 6, 7&#125;, &#123;9&#125;&#125;;boolean found = false;for (int i = 0; i &lt; arr.length &amp;&amp; !found; i++) &#123;    for (int j = 0; j &lt; arr[i].length; j++) &#123;        System.out.println(&quot;i=&quot; + i + &quot;,j=&quot; + j);        if (arr[i][j] == 5) &#123;            found = true;            break;        &#125;    &#125;&#125;

18、当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递？是值传递。Java编程语言中只有由值传递参数的。当一个对象实例作为一个参数被传递到方法中时，参数的值就是该对象的引用。对象的内容可以在被调用的方法中改变，但对象的引用是永远不会改变的。
19、String 和 StringBuilder、StringBuffer 的区别？都是final类，都不允许被继承；
String类长度是不可变的，StringBuffer和StringBuilder类长度是可以改变的；
StringBuffer类是线程安全的，StringBuilder不是线程安全的。
20、重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。
重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；
重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。
重载对返回类型没有特殊的要求。
21、描述一下 JVM 加载 class 文件的原理机制？Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。
类装载方式，有两种：

隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中，
显式装载：通过调用ClassLoader加载class对象，比如Class.forName(String name)和this.getClass().getClassLoader().loadClass()加载类。

Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。
Java的类加载器有三个，对应Java的三种类:

Bootstrap Loader  ：启动类加载器，是虚拟机自身的一部分。负责将存放在\lib目录中的类库加载到虚拟机中。其无法被Java程序直接引用。 负责加载系统类 (指的是内置类，像是String，对应于C#中的System类和C&#x2F;C++标准库中的类)
ExtClassLoader  ： 负责加载扩展类(就是继承类和实现类)
AppClassLoader  ：负责加载用户类路径（ClassPath）上所指定的类库(程序员自定义的类)

三个加载器各自完成自己的工作，但它们是如何协调工作呢？哪一个类该由哪个类加载器完成呢？为了解决这个问题，Java采用了委托模型机制。
委托模型机制的工作原理很简单：当类加载器需要加载类的时候，先请示其Parent(即上一层加载器)在其搜索路径载入，如果找不到，才在自己的搜索路径搜索该类。这样的顺序其实就是加载器层次上自顶而下的搜索，因为加载器必须保证基础类的加载。之所以是这种机制，还有一个安全上的考虑：如果某人将一个恶意的基础类加载到jvm，委托模型机制会搜索其父类加载器，显然是不可能找到的，自然就不会将该类加载进来。
我们可以通过这样的代码来获取类加载器:
ClassLoader loader = ClassName.class.getClassLoader();ClassLoader ParentLoader = loader.getParent();

注意一个很重要的问题，就是Java在逻辑上并不存在BootstrapKLoader的实体！因为它是用C++编写的，所以打印其内容将会得到null。
前面是对类加载器的简单介绍，它的原理机制非常简单，就是下面几个步骤:

装载：查找和导入class文件;
连接：
检查：检查载入的class文件数据的正确性;
准备：为类的静态变量分配存储空间;
解析：将符号引用转换成直接引用(这一步是可选的)
初始化：初始化静态变量，静态代码块。这样的过程在程序调用类的静态成员的时候开始执行，所以静态方法main()才会成为一般程序的入口方法。类的构造器也会引发该动作。

22、char 型变量中能不能存贮一个中文汉字，为什么？在Java中，char类型占2个字节，而且Java默认采用Unicode编码，一个Unicode码是16位，所以一个Unicode码占两个字节，Java中无论汉字还是英文字母都是用Unicode编码来表示的。所以，在Java中，char类型变量可以存储一个中文汉字。
24、静态嵌套类(Static Nested Class)和内部类（Inner Class）的不同？Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。
而通常的内部类(Inner Class)需要在外部类实例化后才能实例化。
25、Java 中会存在内存泄漏吗，请简单描述。内存泄露就是指一个不再被程序使用的对象或变量一直被占据在内存中。Java使用有向图的方式进行垃圾回收管理，可以消除引用循环的问题，例如有两个对象，相互引用，只要它们和根进程不可达的，那么GC也是可以回收它们的
java中内存泄露的发生场景，通俗地说，就是程序员可能创建了一个对象，以后一直不再使用这个对象，这个对象却一直被引用，即这个对象无用但是却无法被垃圾回收器回收的，这就是java中的内存泄露，一定要让程序将各种分支情况都完整执行到程序结束，然后看某个对象是否被使用过，如果没有，则才能判定这个对象属于内存泄露。
举个例子：

如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持久外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。

当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露。


26、抽象的（abstract）方法是否可同时是静态的（static）,是否可同时是本地方法（native），是否可同时被 synchronized 修饰？都不能。
抽象方法需要子类重写，而静态的方法是无法被重写的，因此二者是矛盾的。
本地方法是由本地代码（如C代码）实现的方法，而抽象方法是没有实现的，也是矛盾的。
synchronized 和方法的实现细节有关，抽象方法不涉及实现细节，因此也是相互矛盾的。
27、阐述静态变量和实例变量的区别。在语法定义上的区别：
静态变量前要加static关键字，而实例变量前则不加。
在程序运行时的区别：
实例变量属于某个对象的属性，必须创建了实例对象，其中的实例变量才会被分配空间，才能使用这个实例变量。
静态变量不属于某个实例对象，而是属于类，所以也称为类变量，只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。
总之，实例变量必须创建对象后才可以通过这个对象来使用，静态变量则可以直接使用类名来引用。
28、是否可以从一个静态（static）方法内部发出对非静态（non-static）方法的调用？不可以。
静态方法只能访问静态成员，因为非静态方法的调用要先创建对象，在调用静态方法时可能对象并没有被初始化。
29、如何实现对象克隆？两种不同的克隆方法，浅克隆(ShallowClone)和深克隆(DeepClone)。
在Java语言中，数据类型分为值类型（基本数据类型）和引用类型，值类型包括int、double、byte、boolean、char等简单数据类型，引用类型包括类、接口、数组等复杂类型。浅克隆和深克隆的主要区别在于是否支持引用类型的成员变量的复制。

浅克隆
在浅克隆中，如果原型对象的成员变量是值类型，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说原型对象和克隆对象的成员变量指向相同的内存地址。


在Java语言中，通过覆盖Object类的clone()方法可以实现浅克隆。
深克隆
在深克隆中，无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象，深克隆将原型对象的所有引用对象也复制一份给克隆对象。简单来说，在深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。


在Java语言中，如果需要实现深克隆，可以通过覆盖Object类的clone()方法实现，也可以通过序列化(Serialization)等方式来实现。

克隆有两种方式：

实现Cloneable接口并重写Object类中的clone()方法；


clone()方法是定义在java.lang.Object类中，该方法是一个protected的方法，所以重载时要把clone()方法的属性设置为public，这样其它类才能调用这个clone类的clone()方法
实现Cloneable接口：Cloneable接口是不包含任何方法的！其实这个接口仅仅是一个标志，而且这个标志也仅仅是针对Object类中clone()方法的，如果clone类没有实现Cloneable接口，并调用了Object的clone()方法（也就是调用了super.Clone()方法），那么Object的clone()方法就会抛出 CloneNotSupportedException异常。


实现Serializable接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆；

30、GC 是什么？为什么要有 GC？GC是垃圾收集的意思（Gabage Collection），内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。
GC是垃圾收集器。Java 程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一：

System.gc()
Runtime.getRuntime().gc()

Java是由C++发展来的。
它摈弃了C++中一些繁琐容易出错的东西。其中有一条就是这个GC。
写C&#x2F;C++程序，程序员定义了一个变量，就是在内存中开辟了一段相应的空间来存值。内存再大也是有限的，所以当程序不再需要使用某个变量的时候，就需要释放这个内存空间资源，好让别的变量来用它。在C&#x2F;C++中，释放无用变量内存空间的事情要由程序员自己来解决。就是说当程序员认为变量没用了，就应当写一条代码，释放它占用的内存。这样才能最大程度地避免内存泄露和资源浪费。
但是这样显然是非常繁琐的。程序比较大，变量多的时候往往程序员就忘记释放内存或者在不该释放的时候释放内存了。而且释放内存这种事情，从开发角度说，不应当是程序员所应当关注的。程序员所要做的应该是实现所需要的程序功能，而不是耗费大量精力在内存的分配释放上。
Java有了GC，就不需要程序员去人工释放内存空间。当Java虚拟机发觉内存资源紧张的时候，就会自动地去清理无用变量所占用的内存空间。当然，如果需要，程序员可以在Java程序中显式地使用System.gc()来强制进行一次立即的内存清理。
因为显式声明是做堆内存全扫描，也就是 Full GC，是需要停止所有的活动的（Stop The World Collection），你的应用能承受这个吗？而其显示调用System.gc()只是给虚拟机一个建议，不一定会执行，因为System.gc()在一个优先级很低的线程中执行。
33、一个”.java”源文件中是否可以包含多个类（不是内部类）？有什么限制？可以，但一个源文件中最多只能有一个公开类（public class）而且文件名必须和公开类的类名完全保持一致。
34、Anonymous Inner Class(匿名内部类)是否可以继承其它类？是否可以实现接口？可以。
抽象类的匿名内部类：
abstract class Person &#123;    public abstract void eat();&#125; public class Demo &#123;    public static void main(String[] args) &#123;        Person p = new Person() &#123;            @Override  //此处方法重载 说明是实现父类  即内部类可以继承其他类 而且是必须            public void eat() &#123;                System.out.println(&quot;eat something&quot;);            &#125;        &#125;;        p.eat();    &#125;&#125;

接口类的匿名内部类：
interface Person &#123;    public void eat();&#125; public class Demo &#123;    public static void main(String[] args) &#123;        Person p = new Person() &#123;            @Override  //此处方法重载 说明是实现父类  即内部类可以实现其他类 而且是必须            public void eat() &#123;                System.out.println(&quot;eat something&quot;);            &#125;        &#125;;        p.eat();    &#125;&#125;

35、内部类可以引用它的包含类（外部类）的成员吗？有没有什么限制？完全可以。

静态内部类：它是用static修饰的，在访问限制上它只能访问外部类中的static所修饰的成员变量或者是方法：

成员内部类：成员内部类是最普通的内部类，它可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员）。
当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：

外部类.this.成员变量

外部类.this.成员方法



局部内部类：局部内部类是定义在外围类的方法中的，在访问的时候它可以直接访问外围类的所有成员！但是不能随便访问局部变量，除非这个局部变量被final修饰。

匿名内部类：匿名内部类其实就是局部内部类的简写格式，只能使用一次。


39、如何实现字符串的反转及替换？使用递归实现字符串反转，代码如下所示：
public static String reverse(String originStr) &#123;     if(originStr == null || originStr.length() &lt;= 1)         return originStr;     return reverse(originStr.substring(1)) + originStr.charAt(0); &#125;

每次取第一个字符拼到字符串最后，依次递归，如图所示：


40、怎样将 GB2312 编码的字符串转换为 ISO-8859-1 编码的字符串？String s1 = &quot;你好&quot;;try &#123;    String s2 = new String(s1.getBytes(&quot;GB2312&quot;), &quot;ISO-8859-1&quot;);&#125; catch (UnsupportedEncodingException e) &#123;    e.printStackTrace();&#125;

42、打印昨天的当前时刻。public class test &#123;    public static void main(String[] args) &#123;        Calendar cal = Calendar.getInstance();        cal.add(Calendar.DATE, -1);        System.out.println(cal.getTime());    &#125;   &#125;

43、比较一下 Java 和 JavaSciprt。Java与JavaScript是两个公司开发的不同的两个产品。Java是原Sun Microsystems公司推出的面向对象的程序设计语言，特别适合于互联网应用程序开发；而JavaScript是Netscape公司的产品，为了扩展Netscape浏览器的功能而开发的一种可以嵌入Web页面中运行的基于对象和事件驱动的解释性语言。JavaScript的前身是LiveScript；而Java的前身是Oak语言。
下面对两种语言间的异同作如下比较：

基于对象和面向对象：Java是一种真正的面向对象的语言，即使是开发简单的程序，必须设计对象；JavaScript是种脚本语言，它可以用来制作与网络无关的，与用户交互的复杂软件。它是一种基于对象（Object-Based）和事件驱动（Event-Driven）的编程语言，因而它本身提供了非常丰富的内部对象供设计人员使用。
解释和编译：Java的源代码在执行之前，必须经过编译。JavaScript是一种解释性编程语言，其源代码不需经过编译，由浏览器解释执行（目前的浏览器几乎都使用了JIT（即时编译）技术来提升JavaScript的运行效率）。
强类型变量和弱类型变量：Java采用强类型变量检查，即所有变量在编译之前必须作声明；JavaScript中变量是弱类型的，甚至在使用变量前可以不作声明，JavaScript的解释器在运行时检查推断其数据类型。
代码格式不一样。

44、什么时候用断言（assert）？断言在软件开发中是一种常用的调试方式，很多开发语言中都支持这种机制。一般来说，断言用于保证程序最基本、最关键的正确性。断言检查通常在开发和测试时开启。为了保证程序的执行效率，在软件发布后断言检查通常是关闭的。断言是一个包含布尔表达式的语句，在执行这个语句时假定该表达式为true；如果表达式的值为false，那么系统会报告一个AssertionError。
注意：断言不应该以任何方式改变程序的状态。简单的说，如果希望在不满足某些条件时阻止代码的执行，就可以考虑用断言来阻止它。
断言可以有两种形式：

assert Expression1;

assert Expression1 : Expression2;
Expression1表示一个boolean表达式；
Expression2表示一个基本类型、表达式或者是一个Object，用于在失败时输出错误信息，它是一个传到AssertionError构造函数的值，如果断言失败，该值被转化为它对应的字符串


要在运行时启用断言，可以在启动JVM时使用-enableassertions或者-ea标记。要在运行时选择禁用断言，可以在启动JVM时使用-da或者-disableassertions标记。要在系统类中启用或禁用断言，可使用-esa或-dsa标记。还可以在包的基础上启用或者禁用断言。
45、Error 和 Exception 有什么区别？

异常发生的原因有很多，通常包含以下几大类：

用户输入了非法数据。
要打开的文件不存在。
网络通信时连接中断，或者JVM内存溢出。

异常主要分三种类型：

检查性异常：最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。
运行时异常：运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。
错误：错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。

Java异常又可以分为不受检查异常（Unchecked Exception）和检查异常（Checked Exception）。
下面将详细讲述这些异常之间的区别与联系：

Error：Error类对象由 Java虚拟机生成并抛出，大多数错误与代码编写者所执行的操作无关。例如，Java虚拟机运行错误（VirtualMachineError），当JVM不再有继续执行操作所需的内存资源时，将出现OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止；还有发生在虚拟机试图执行应用时，如类定义错误（NoClassDefFoundError）、链接错误（LinkageError）。这些错误是不可查的，因为它们在应用程序的控制和处理能力之外，而且绝大多数是程序运行时不允许出现的状况。对于设计合理的应用程序来说，即使确实发生了错误，本质上也不应该试图去处理它所引起的异常状况。在Java中，错误通常是使用Error的子类描述。
Exception：在Exception分支中有一个重要的子类RuntimeException（运行时异常），该类型的异常自动为你所编写的程序定义ArrayIndexOutOfBoundsException（数组下标越界）、NullPointerException（空指针异常）、ArithmeticException（算术异常）、MissingResourceException（丢失资源）、ClassNotFoundException（找不到类）等异常，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生；而RuntimeException之外的异常我们统称为非运行时异常，类型上属于Exception类及其子类，从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。



47、Java 语言如何进行异常处理，关键字：throws、throw、try、catch、finally 分别如何使用？Java通过面向对象的方法进行异常处理，把各种不同的异常进行分类，并提供了良好的接口。在Java中，每个异常都是一个对象，它是Throwable类或其子类的实例。当一个方法出现异常后便抛出一个异常对象，该对象中包含有异常信息，调用这个对象的方法可以捕获到这个异常并可以对其进行处理。Java的异常处理是通过5个关键词来实现的：try、catch、throw、throws和finally。
一般情况下是用try来执行一段程序，如果系统会抛出（throw）一个异常对象，可以通过它的类型来捕获（catch）它，或通过总是执行代码块（finally）来处理；
try用来指定一块预防所有异常的程序；catch子句紧跟在try块后面，用来指定你想要捕获的异常的类型；
throw语句用来明确地抛出一个异常；
throws用来声明一个方法可能抛出的各种异常（当然声明异常时允许无病呻吟）；
finally为确保一段代码不管发生什么异常状况都要被执行；
try语句可以嵌套，每当遇到一个try语句，异常的结构就会被放入异常栈中，直到所有的try语句都完成。如果下一级的try语句没有对某种异常进行处理，异常栈就会执行出栈操作，直到遇到有处理这种异常的try语句或者最终将异常抛给JVM。
48、运行时异常与受检异常有何异同？异常表示程序运行过程中可能出现的非正常状态。
运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。
受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。
Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。异常和继承一样，是面向对象程序设计中经常被滥用的东西，在Effective Java中对异常的使用给出了以下指导原则：

不要将异常处理用于正常的控制流（设计良好的API不应该强迫它的调用者为了正常的控制流而使用异常）
对可以恢复的情况使用受检异常，对编程错误使用运行时异常
避免不必要的使用受检异常（可以通过一些状态检测手段来避免异常的发生）
优先使用标准的异常
每个方法抛出的异常都要有文档
保持异常的原子性
不要在catch中忽略掉捕获到的异常

49、列出一些你常见的运行时异常？
ArithmeticException（算术异常）
ClassCastException （类转换异常）
IllegalArgumentException （非法参数异常）
IndexOutOfBoundsException （下标越界异常）
NullPointerException （空指针异常）
SecurityException （安全异常）

50、阐述 final、finally、finalize 的区别。
final：修饰符（关键字）有三种用法：如果一个类被声明为 final，意味 着它不能再派生出新的子类，即不能被继承，因此它和 abstract 是反义词。将 变量声明为 final，可以保证它们在使用中不被改变，被声明为 final 的变量必须 在声明时给定初值，而在以后的引用中只能读取不可修改。被声明为 final 的方 法也同样只能使用，不能在子类中被重写。
finally：通常放在 try…catch…的后面构造总是执行代码块，这就意味着 程序无论正常执行还是发生异常，这里的代码只要 JVM 不关闭都能执行，可以 将释放外部资源的代码写在 finally 块中。
finalize：Object 类中定义的方法，Java 中允许使用 finalize()方法在垃 圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在销毁对象时调用的，通过重写 finalize()方法可以整理系统资源或者执行其他清理工作。

52、List、Set、Map 是否继承自 Collection 接口？List、Set 是，Map 不是。Map 是键值对映射容器，与 List 和 Set 有明显的区别， 而 Set 存储的零散的元素且不允许有重复元素（数学中的集合也是如此），List 是线性结构的容器，适用于按数值索引访问元素的情形。
53、阐述 ArrayList、Vector、LinkedList 的存储性能和特性。ArrayList 和 Vector 都是使用数组方式存储数据，此数组元素数大于实际存储的 数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉 及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector 中的方法由 于添加了 synchronized 修饰，因此 Vector 是线程安全的容器，但性能上ArrayList 差，因此已经是 Java 中的遗留容器。LinkedList 使用双向链表实现存 储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索 引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更 高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录项的前后项即可，所以插入速度较快。Vector 属于遗留容器（Java 早期的版本中 提供的容器，除此之外，Hashtable、Dictionary、BitSet、Stack、Properties 都是遗留容器），已经不推荐使用，但是由于 ArrayList 和 LinkedListed 都是非 线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类 Collections 中的 synchronizedList 方法将其转换成线程安全的容器后再使用（这是对装潢模式的应用，将已有对象传入另一个类的构造器中创建新的对象来增强实现）。
54、Collection 和 Collections 的区别？答： Collection 是一个接口，它是 Set、List 等容器的父接口；Collections 是个一个 工具类，提供了一系列的静态方法来辅助容器操作，这些方法包括对容器的搜索、 排序、线程安全化等等。
55、List、Map、Set 三个接口存取元素时，各有什么特点？List 以特定索引来存取元素，可以有重复元素。
Set 不能存放重复元素（用对象的 equals()方法来区分元素是否重复）。
Map 保存键值对（key-value pair）映射， 映射关系可以是一对一或多对一。
Set 和 Map 容器都有基于哈希存储和排序树的 两种实现版本，基于哈希存储的版本理论存取时间复杂度为 O(1)，而基于排序树 版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达 到排序和去重的效果。
56、TreeMap 和 TreeSet 在排序时如何比较元素？ Collections 工具类中的 sort()方法如何比较元素？TreeSet 要求存放的对象所属的类必须实现 Comparable 接口，该接口提供了比较元素的 compareTo()方法，当插入元素时会回调该方法比较元素的大小。
TreeMap 要求存放的键值对映射的键必须实现 Comparable 接口从而根据键对元素进行排序。
Collections 工具类的 sort 方法有两种重载的形式，第一种要求传入 的待排序容器中存放的对象比较实现 Comparable 接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是 Comparator 接口的子类型（需要重写 compare 方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持）。
57、Thread 类的 sleep()方法和对象的 wait()方法都可以让线程暂停执行，它们有什么区别?sleep()方法（休眠）是线程类（Thread）的静态方法，调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复。
wait()是 Object 类的方法，调用对象的 wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或 notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。
58、线程的 sleep()方法和 yield()方法有什么区别？
sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；
线程执行 sleep()方法后转入阻塞（blocked）状态，而执行 yield()方法后转入就绪（ready）状态；
sleep()方法声明抛出 InterruptedException，而 yield()方法没有声明任何异常；
sleep()方法比 yield()方法（跟操作系统 CPU 调度相关）具有更好的可移植性。

59、当一个线程进入一个对象的 synchronized 方法A之后， 其它线程是否可进入此对象的 synchronized 方法B？不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的 synchronized 修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池）中等待对象的锁。
68、Java 中如何实现序列化，有什么意义？序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。 序列化是为了解决对象流读写操作时可能引发的问题（如果不进行序列化可能会存在数据乱序的问题）。要实现序列化，需要让一个类实现 Serializable 接口，该接口是一个标识性接口，标注该类对象是可被序列化的，然后使用一个输出流来构造一个对象输出流并通过 writeObject(Object)方法就可以将实现对象写出（即保存其状态）；如果需要反序列化则可以用一个输入流建立对象输入流，然后通过 readObject 方法从流中读取对象。序列化除了能够实现对象的持久化之外，还能够用于对象的深度克隆。
69、Java 中有几种类型的流？字节流和字符流。字节流继承于 InputStream、OutputStream，字符流继承Reader、Writer。在 java.io 包中还有许多其他的流，主要是为了提高性能和使用方便。关于 Java 的 I&#x2F;O 需要注意的有两点：一是两种对称性（输入和输出的对 称性，字节和字符的对称性）；二是两种设计模式（适配器模式和装潢模式）。
73、XML 文档定义有几种形式？它们之间有何本质区别？解析 XML 文档有哪几种方式？
XML 文档定义分为 DTD 和 Schema 两种形式，二者都是对 XML 语法的约束。
其本质区别在于 Schema 本身也是一个 XML 文件，可以被 XML 解析器解析，而且 可以为 XML 承载的数据定义类型，约束能力较之 DTD 更强大。

对 XML 的解析主 要有 DOM（文档对象模型，Document Object Model）、SAX（Simple API foXML）和 StAX（Java 6 中引入的新的解析 XML 的方式，Streaming API for XML）。

其中 DOM 处理大型文件时其性能下降的非常厉害，这个问题是由 DOM 树结构用的内存较多造成的，而且 DOM 解析方式必须在解析文件之前把整个文档装入内存，适合对 XML 的随机访问（典型的用空间换取时间的策略）。

SAX 是事件驱动型的 XML 解析方式，它顺序读取 XML 文件，不需要一次全部装载整个文件。当遇到像文件开头，文档结束，或者标签开头与标签结束时，它会触发一个事件， 用户通过事件回调代码来处理 XML 文件，适合对 XML 的顺序访问。

顾名思义， StAX 把重点放在流上，实际上 StAX 与其他解析方式的本质区别就在于应用程能够把 XML 作为一个事件流来处理。将 XML 作为一组事件来处理的想法并不新颖（SAX 就是这样做的），但不同之处在于 StAX 允许应用程序代码把这些事件逐个拉出来，而不用提供在解析器方便时从解析器中接收事件的处理程序。




75、阐述 JDBC 操作数据库的步骤。
加载驱动。
创建连接。
创建语句。
执行语句。
处理结果。
关闭资源。

关闭外部资源的顺序应该和打开的顺序相反，也就是说先关闭 ResultSet、 再关闭 Statement、在关闭 Connection。上面的代码只关闭了 Connection，虽然通常情况下在关闭连接时，连接上创建的语句和打开的游标也会关闭，但不能保证总是如此，因此应该按照刚才说的顺序分别关闭。此外，第一步加载驱动在 JDBC 4.0 中是可以省略的（自动从类路径中加载驱动），但是我们建议保留。
76、Statement 和 PreparedStatement 有什么区别？哪个性能更好？
PreparedStatement 接口代表预编译的语句，它主要的优势在于可以减少 SQL 的编译错误并增加 SQL 的安全性（减少 SQL 注射攻击的可 能性）；
PreparedStatement 中的 SQL 语句是可以带参数的，避免了用字符串连接拼接 SQL 语句的麻烦和不安全；
当批量处理 SQL 或频繁执行相同的查询时， PreparedStatement 有明显的性能上的优势，由于数据库可以将编译优化后的 SQL 语句缓存起来，下次执行相同结构的语句时就会很快（不用再次编译和生成执行计划）。

补充：为了提供对存储过程的调用，JDBC API 中还提供了 CallableStatement 接 口。存储过程（Stored Procedure）是数据库中一组为了完成特定功能的 SQL 语句的集合，经编译后存储在数据库中，用户通过指定存储过程的名字并给出参数 （如果该存储过程带有参数）来执行它。虽然调用存储过程会在网络开销、安全性、性能上获得很多好处，但是存在如果底层数据库发生迁移时就会有很多麻烦， 因为每种数据库的存储过程在书写上存在不少的差别。
77、使用 JDBC 操作数据库时，如何提升读取数据的性能？如何提升更新数据的性能？要提升读取数据的性能，可以指定通过结果集（ResultSet）对象的 setFetchSize()方法指定每次抓取的记录数（典型的空间换时间策略）
要提升更新数据的性能 可以使用 PreparedStatement 语句构建批处理，将若干 SQL 语句置于一个批处理中执行。
78、在进行数据库编程时，连接池有什么作用？由于创建连接和释放连接都有很大的开销（尤其是数据库服务器不在本地时，每次建立连接都需要进行 TCP 的三次握手，释放连接需要进行 TCP 四次握手，造成的开销是不可忽视的），为了提升系统访问数据库的性能，可以事先创建若干连接置于连接池中，需要时直接从连接池获取，使用结束时归还连接池而不必关闭连接，从而避免频繁创建和释放连接所造成的开销，这是典型的用空间换取时间的策略（浪费了空间存储连接，但节省了创建和释放连接的时间）。池化技术在 Java 开发中是很常见的，在使用线程时创建线程池的道理与此相同。基于 Java 的 开源数据库连接池主要有：C3P0、Proxool、DBCP、BoneCP、Druid 等
补充：在计算机系统中时间和空间是不可调和的矛盾，理解这一点对设计满足性能要求的算法是至关重要的。大型网站性能优化的一个关键就是使用缓存，而缓存跟上面讲的连接池道理非常类似，也是使用空间换时间的策略。可以将热点数据置于缓存中，当用户查询这些数据时可以直接从缓存中得到，这无论如何也快过去数据库中查询。当然，缓存的置换策略等也会对系统性能产生重要影响，对于这个问题的讨论已经超出了这里要阐述的范围。
79、什么是 DAO 模式？DAO（Data Access Object）顾名思义是一个为数据库或其他持久化机制提供了抽象接口的对象，在不暴露底层持久化方案实现细节的前提下提供了各种数据访问操作。
在实际的开发中，应该将所有对数据源的访问操作进行抽象化后封装在一个公共 API 中。用程序设计语言来说，就是建立一个接口，接口中定义了此应用程序中将会用到的所有事务方法。在这个应用程序中，当需要和数据源进行交互的时候则使用这个接口，并且编写一个单独的类来实现这个接口，在逻辑上该类对应一个特定的数据存储。
DAO 模式实际上包含了两个模式，一是 Data Accessor（数据访问器），二是 Data Object（数据对象），前者要解决如何访问数据的问题，而后者要解决的是如何用对象封装数据。
81、JDBC 中如何进行事务处理？Connection 提供了事务处理的方法，通过调用 setAutoCommit(false)可以设置手动提交事务；当事务完成后用 commit()显式提交事务；如果在事务处理过程中发生异常则通过 rollback()进行事务回滚。除此之外，从 JDBC 3.0 中还引入了 Savepoint（保存点）的概念，允许通过代码设置保存点并让事务回滚到指定的保存点。


82、JDBC 能否处理 Blob 和 Clob？答： Blob 是指二进制大对象（Binary Large Object），而 Clob 是指大字符对象（Character Large Object），因此其中 Blob 是为存储大的二进制数据而设计的，而 Clob 是为存储大的文本数据而设计的。JDBC 的 PreparedStatement 和 ResultSet 都提供了相应的方法来支持 Blob 和 Clob 操作。
85、获得一个类的类对象有哪些方式？
方法 1：类型.class，例如：String.class
方法 2：对象.getClass()，例如：”hello”.getClass()
方法 3：Class.forName()，例如：Class.forName(“java.lang.String”)

86、如何通过反射创建对象？
方法 1：通过类对象调用 newInstance()方法，例如： String.class.newInstance()
方法 2：通过类对象的 getConstructor()或 getDeclaredConstructor() 方法获得构造器（Constructor）对象并调用其 newInstance()方法创建对象， 例如：String.class.getConstructor(String.class).newInstance(“Hello”);

87、Java 中能创建 volatile 数组吗？能，Java 中可以创建 volatile 类型数组，不过只是一个指向数组的引用，而不是整个数组。我的意思是，如果改变引用指向的数组，将会受到 volatile 的保护，但是如果多个线程同时改变数组的元素，volatile 标示符就不能起到之前的保护作用了。
88、volatile 能使得一个非原子操作变成原子操作吗？一个典型的例子是在类中有一个 long 类型的成员变量。如果你知道该成员变量会被多个线程访问，如计数器、价格等，你最好是将其设置为 volatile。为什么？因为 Java 中读取 long 类型变量不是原子的，需要分成两步，如果一个线程正在修改该 long 变量的值，另一个线程可能只能看到该值的一半（前 32 位）。但是对一个 volatile 型的 long 或 double 变量的读写是原子。
89、volatile 修饰符的有过什么实践？一种实践是用 volatile 修饰 long 和 double 变量，使其能按原子类型来读写。double 和 long 都是 64 位宽，因此对这两种类型的读是分为两部分的，第一次读取第一个 32 位，然后再读剩下的 32 位，这个过程不是原子的，但 Java 中 volatile 型的 long 或 double 变量的读写是原子的。volatile 修复符的另一个作用是提供内存屏障（memory barrier），例如在分布式框架中的应用。
简单的说，就是当你写一个 volatile 变量之前，Java 内存模型会插入一个写屏障（writebarrier），读一个 volatile 变量之前，会插入一个读屏障（read barrier）。意思就是说，在你写一个 volatile 域时，能保证任何线程都能看到你写的值，同时，在写之前，也能保证任何数值的更新对所有线程是可见的，因为内存屏障会将其他所有写的值更新到缓存。
90、volatile 类型变量提供什么保证？volatile 变量提供顺序和可见性保证，例如，JVM 或者 JIT 为了获得更好的性能会对语句重排序，但是 volatile 类型变量即使在没有同步块的情况下赋值也不会与其他语句重排序。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。某些情况下，volatile 还能提供原子性，如读 64 位数据类型，像 long 和 double 都不是原子的，但 volatile 类型的 double 和 long 就是原子的。
91、10 个线程和 2 个线程的同步代码，哪个更容易写？从写代码的角度来说，两者的复杂度是相同的，因为同步代码与线程数量是相互独立的。但是同步策略的选择依赖于线程的数量，因为越多的线程意味着更大的竞争，所以你需要利用同步技术，如锁分离，这要求更复杂的代码和专业知识。
92、你是如何调用 wait（）方法的？使用 if 块还是循环？为什么？wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。下面是一段标准的使用 wait 和 notify 方法的代码：
// The standard idiom for using the wait methodsynchronized (obj) &#123;	while (condition does not hold)	obj.wait();	// (Releases lock, and reacquires on wakeup)	... // Perform action appropriate to condition&#125;

93、什么是多线程环境下的伪共享（false sharing）？伪共享是多线程系统（每个处理器有自己的局部缓存）中一个众所周知的性能问题。伪共享发生在不同处理器的上的线程对变量的修改依赖于相同的缓存行。
94、什么是 Busy spin？我们为什么要使用它？Busy spin 是一种在不释放 CPU 的基础上等待事件的技术。它经常用于避免丢失 CPU 缓存中的数据（如果线程先暂停，之后在其他 CPU 上运行就会丢失）。所以，如果你的工作要求低延迟，并且你的线程目前没有任何顺序，这样你就可以通过循环检测队列中的新消息来代替调用 sleep() 或 wait() 方法。它唯一的好处就是你只需等待很短的时间，如几微秒或几纳秒。LMAX 分布式框架是一个高性能线程间通信的库，该库有一个 BusySpinWaitStrategy 类就是基于这个概念实现的，使用 busy spin 循环 EventProcessors 等待屏障。
95、Java 中怎么获取一份线程 dump 文件？在 Linux 下，你可以通过命令 kill -3 PID （Java 进程的进程 ID）来获取 Java应用的 dump 文件。在 Windows 下，你可以按下 Ctrl + Break 来获取。这样 JVM 就会将线程的 dump 文件打印到标准输出或错误文件中，它可能打印在控制台或者日志文件中，具体位置依赖应用的配置。如果你使用 Tomcat。
96、Swing 是线程安全的？不是，Swing 不是线程安全的。你不能通过任何线程来更新 Swing 组件，如JTable、JList 或 JPanel，事实上，它们只能通过 GUI 或 AWT 线程来更新。这就是为什么 Swing供 invokeAndWait() 和 invokeLater() 方法来获取其他线程的 GUI 更新请求。这些方法将更新请求放入 AWT 的线程队列中，可以一直等待，也可以通过异步更新直接返回结果。
97、什么是线程局部变量？线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java 提供 ThreadLocal 类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。
98、用 wait-notify 写一段代码来解决生产者-消费者问题？只要记住在同步块中调用 wait() 和 notify() 方法 ，如果阻塞，通过循环来测试等待条件。
99、用 Java 写一个线程安全的单例模式（Singleton）？一步一步创建一个线程安全的 Java 单例类。当我们说线程安全时，意思是即使初始化是在多线程环境中，仍然能保证单个实例。Java 中，使用枚举作为单例类是最简单的方式来创建线程安全单例模式的方式。
100、Java 中 sleep 方法和 wait 方法的区别？虽然两者都是用来暂停当前运行的线程，但是 sleep() 实际上只是短暂停顿，因为它不会释放锁，而 wait() 意味着条件等待，这就是为什么该方法要释放锁，因为只有这样，其他等待的线程才能在满足条件时获取到该锁。
101、什么是不可变对象（immutable object）？Java 中怎么创建一个不可变对象？不可变对象指对象一旦被创建，状态就不能再改变。任何修改都会创建一个新的对象，如 String、Integer 及其它包装类。
102、我们能创建一个包含可变对象的不可变对象吗？是的，我们是可以创建一个包含可变对象的不可变对象的，你只需要谨慎一点，不要共享可变对象的引用就可以了，如果需要变化时，就返回原对象的一个拷贝。最常见的例子就是对象中包含一个日期对象的引用。数据类型和 Java 基础面试问题
103、Java 中应该使用什么数据类型来代表价格？如果不是特别关心内存和性能的话，使用 BigDecimal，否则使用预定义精度的double 类型。
103、怎么将 byte 转换为 String？可以使用 String 接收 byte[] 参数的构造器来进行转换，需要注意的点是要使用的正确的编码，否则会使用平台默认编码，这个编码可能跟原来的编码相同，也可能不同。
104、Java 中怎样将 bytes 转换为 long 类型？bytes[] 到数字类型的转换是个经常用到的代码,解决方式也不止一种。
java代码实现
如果不想借助任何已经有的类，完全可以自己实现这段代码，如下：
/** * 将字节数组转为long&lt;br&gt; * 如果input为null,或offset指定的剩余数组长度不足8字节则抛出异常 * * @param input * @param offset       起始偏移量 * @param littleEndian 输入数组是否小端模式 * @return */public static long longFrom8Bytes(byte[] input, int offset, Boolean littleEndian) &#123;    long value = 0;    // 循环读取每个字节通过移位运算完成long的8个字节拼装    for (int count = 0; count &lt; 8; ++count) &#123;        int shift = (littleEndian ? count : (7 - count)) &lt;&lt; 3;        value |= ((long) 0xff &lt;&lt; shift) &amp; ((long) input[offset + count] &lt;&lt; shift);    &#125;    return value;&#125;

借助java.nio.ByteBuffer实现
java.nio.ByteBuffer 本身就有getLong、getInt，getFloat….方法，只要将byte[]转换为ByteBuffer就可以实现所有primitive类型的数据读取，参见javadoc。
/**     * 利用 &#123;@link java.nio.ByteBuffer&#125;实现byte[]转long     * @param input     * @param offset      * @param littleEndian 输入数组是否小端模式     * @return     */public static long bytesTolong(byte[] input, int offset, Boolean littleEndian) &#123;	// 将byte[] 封装为 ByteBuffer 	ByteBuffer buffer = ByteBuffer.wrap(input,offset,8);	if(littleEndian)&#123;		// ByteBuffer.order(ByteOrder) 方法指定字节序,即大小端模式(BIG_ENDIAN/LITTLE_ENDIAN)		// ByteBuffer 默认为大端(BIG_ENDIAN)模式 		buffer.order(ByteOrder.LITTLE_ENDIAN);	&#125;	return buffer.getlong();&#125;

借助java.io.DataInputStream实现
java.io.DataInputStream 同样提供了 readLong，readLong，readLong….方法，只要将byte[]转换为DataInputStream就可以实现所有primitive类型的数据读取,参见javadoc。
105、我们能将 int 强制转换为 byte 类型的变量吗？如果该值大于 byte 类型的范围，将会出现什么现象？是的，我们可以做强制转换，但是 Java 中 int 是 32 位的，而 byte 是 8 位的，所以，如果强制转化是，int 类型的高 24 位将会被丢弃，byte 类型的范围是从 -128 到 127。
106、存在两个类，B 继承 A，C 继承 B，我们能将 B 转换为C 么？如 C &#x3D; (C) B；这属于强制类型转换，如果被转换的B实例不是C类型，会有异常
比如你的ABC分别对应动物，猫，黑猫。
向上转型就是比如
C c &#x3D; new C();
B b &#x3D; c;
你把c转型为B，黑猫是猫吗？是啊，所以这是ok的。
但是反过来
B b &#x3D; new B();
C c &#x3D; (C)b;
这就不ok了，只知道这个b是一只猫，他不一定是黑猫。
但如果这个b已经确定是一只黑猫了，那就可以转型了
B b &#x3D; new C();
C c &#x3D; (C)b;
这里的b本来就是黑猫啊。
107、哪个类包含 clone 方法？是 Cloneable 还是 Object？java.lang.Cloneable 是一个标示性接口，不包含任何方法，clone 方法在object 类中定义。并且需要知道 clone() 方法是一个本地方法，这意味着它是由 c 或 c++ 或 其他本地语言实现的。
108、Java 中 ++ 操作符是线程安全的吗？不是线程安全的操作。它涉及到多个指令，如读取变量值，增加，然后存储回内存，这个过程可能会出现多个线程交差。
109、a &#x3D; a + b 与 a +&#x3D; b 的区别+&#x3D; 隐式的将加操作的结果类型强制转换为持有结果的类型。如果两这个整型相加，如 byte、short 或者 int，首先会将它们提升到 int 类型，然后在执行加法操作。如果加法操作的结果比 a 的最大值要大，则 a+b 会出现编译错误，但是
byte a = 127;byte b = 127;b = a + b;// error : cannot convert from int to byteb += a;// ok


（译者注：这个地方应该表述的有误，其实无论 a+b 的值为多少，编译器都会报错，因为 a+b 操作会将 a、b 提升为 int 类型，所以将 int 类型赋值给 byte就会编译出错）
110、我能在不进行强制转换的情况下将一个 double 值赋值给 long 类型的变量吗？不行，你不能在没有强制类型转换的前提下将一个 double 值赋值给 long 类型的变量，因为 double 类型的范围比 long 类型更广，所以必须要进行强制转换。
111、3 * 0.1 &#x3D;&#x3D; 0.3 将会返回什么？true 还是 false？false，因为有些浮点数不能完全精确的表示出来。
112、int 和 Integer 哪个会占用更多的内存？Integer 对象会占用更多的内存。Integer 是一个对象，需要存储对象的元数据。但是 int 是一个原始类型的数据，所以占用的空间更少。
113、为什么 Java 中的 String 是不可变的（Immutable）？Java 中的 String 不可变是因为 Java 的设计者认为字符串使用非常频繁，将字符串设置为不可变可以允许多个客户端之间共享相同的字符串。
114、我们能在 Switch 中使用 String 吗？从 Java 7 开始，我们可以在 switch case 中使用字符串，但这仅仅是一个语法糖。内部实现在 switch 中使用字符串的 hash code。
115、Java 中的构造器链是什么？当你从一个构造器中调用另一个构造器，就是 Java 中的构造器链。这种情况只在重载了类的构造器的时候才会出现。
116、64 位 JVM 中，int 的长度是多数？Java 中，int 类型变量的长度是一个固定值，与平台无关，都是 32 位。意思就是说，在32位和64位的java虚拟机中，int 类型的长度是相同的。
117、Serial 与 Parallel GC 之间的不同之处？Serial 与 Parallel 在 GC 执行的时候都会引起 stop-the-world。它们之间主要不同 serial 收集器是默认的复制收集器，执行 GC 的时候只有一个线程，而parallel 收集器使用多个 GC 线程来执行。
118、32 位和 64 位的 JVM，int 类型变量的长度是多数？32 位和 64 位的 JVM 中，int 类型变量的长度是相同的，都是 32 位或者 4个字节。
119、Java 中 WeakReference 与 SoftReference 的区别？虽然 WeakReference 与 SoftReference 都有利于提高 GC 和 内存的效率，但是 WeakReference ，一旦失去最后一个强引用，就会被 GC 回收，而软引用虽然不能阻止被回收，但是可以延迟到 JVM 内存不足的时候。
120、WeakHashMap 是怎么工作的？WeakHashMap 的工作与正常的 HashMap 类似，但是使用弱引用作为 key，意思就是当 key 对象没有任何引用时，key&#x2F;value 将会被回收。
121、JVM 选项 -XX:+UseCompressedOops 有什么作用？为什么要使用？当你将你的应用从 32 位的 JVM 迁移到 64 位的 JVM 时，由于对象的指针从32 位增加到了 64 位，因此堆内存会突然增加，差不多要翻倍。这也会对 CPU缓存（容量比内存小很多）的数据产生不利的影响。因为，迁移到 64 位的 JVM主要动机在于可以指定最大堆大小，通过压缩 OOP 可以节省一定的内存。通过-XX:+UseCompressedOops 选项，JVM 会使用 32 位的 OOP，而不是 64 位的 OOP。
122、怎样通过 Java 程序来判断 JVM 是 32 位 还是 64位？你可以检查某些系统属性如 sun.arch.data.model 或 os.arch 来获取该信息。
123、32 位 JVM 和 64 位 JVM 的最大堆内存分别是多数？理论上说上 32 位的 JVM 堆内存可以到达 2^32，即 4GB，但实际上会比这个小很多。不同操作系统之间不同，如 Windows 系统大约 1.5 GB，Solaris 大约3GB。64 位 JVM 允许指定最大的堆内存，理论上可以达到 2^64，这是一个非常大的数字，实际上你可以指定堆内存大小到 100GB。甚至有的 JVM，如 Azul，堆内存到 1000G 都是可能的。
124、JRE、JDK、JVM 及 JIT 之间有什么不同？JRE 代表 Java 运行 时（Java run-time），是 运 行 Java 引用所必须的。
JDK 代表 Java 开发工具（Java development kit），是 Java 程序的开发工具，如 Java编译器，它也包含 JRE。
JVM 代表 Java 虚拟机（Java virtual machine），它的责任是运行 Java 应用。
JIT 代表即时编译（Just In Time compilation），当代码执行的次数超过一定的阈值时，会将 Java 字节码转换为本地代码，如，主要的热点代码会被准换为本地代码，这样有利大幅度提高 Java 应用的性能。
125、解释 Java 堆空间及 GC？当通过 Java 命令启动 Java 进程的时候，会为它分配内存。内存的一部分用于创建堆空间，当程序中创建对象的时候，就从对空间中分配内存。GC 是 JVM 内部的一个进程，回收无效对象的内存用于将来的分配。
126、你能保证 GC 执行吗？不能，虽然你可以调用 System.gc() 或者 Runtime.gc()，但是没有办法保证 GC的执行。
127、怎么获取 Java 程序使用的内存？堆使用的百分比？可以通过 java.lang.Runtime 类中与内存相关方法来获取剩余的内存，总内存及最大堆内存。通过这些方法你也可以获取到堆使用的百分比及堆内存的剩余空间。Runtime.freeMemory() 方法返回剩余空间的字节数，Runtime.totalMemory()方法总内存的字节数，Runtime.maxMemory() 返回最大内存的字节数。
128、Java 中堆和栈有什么区别？JVM 中堆和栈属于不同的内存区域，使用目的也不同。栈常用于保存方法帧和局部变量，而对象总是在堆上分配。栈通常都比堆小，也不会在多个线程之间共享，而堆被整个 JVM 的所有线程共享。
129、“a &#x3D;&#x3D; b”和”a.equals(b)”有什么区别？如果 a 和 b 都是对象，则 a&#x3D;&#x3D;b 是比较两个对象的引用，只有当 a 和 b 指向的是堆中的同一个对象才会返回 true，而 a.equals(b) 是进行逻辑比较，所以通常需要重写该方法来提供逻辑一致性的比较。例如，String 类重写 equals() 方法，所以可以用于两个不同对象，但是包含的字母相同的比较。
130、a.hashCode() 有什么用？与 a.equals(b) 有什么关系？hashCode() 方法是相应对象整型的 hash 值。它常用于基于 hash 的集合类，如 Hashtable、HashMap、LinkedHashMap 等等。它与 equals() 方法关系特别紧密。根据 Java 规范，两个使用 equal() 方法来判断相等的对象，必须具有相同的 hash code。
131、final、finalize 和 finally 的不同之处？final 是一个修饰符，可以修饰变量、方法和类。如果 final 修饰变量，意味着该变量的值在初始化后不能被改变。finalize 方法是在对象被回收之前调用的方法，给对象自己最后一个复活的机会，但是什么时候调用 finalize 没有保证。finally是一个关键字，与 try 和 catch 一起用于异常的处理。finally 块一定会被执行，无论在 try 块中是否有发生异常。
132、Java 中的编译期常量是什么？使用它又什么风险？公共静态不可变（public static final ）变量也就是我们所说的编译期常量，这里的 public 可选的。实际上这些变量在编译时会被替换掉，因为编译器知道这些变量的值，并且知道这些变量在运行时不能改变。这种方式存在的一个问题是你使用了一个内部的或第三方库中的公有编译时常量，但是这个值后面被其他人改变了，但是你的客户端仍然在使用老的值，甚至你已经部署了一个新的 jar。为了避免这种情况，当你在更新依赖 JAR 文件时，确保重新编译你的程序。
133、poll() 方法和 remove() 方法的区别？poll() 和 remove() 都是从队列中取出一个元素，但是 poll() 在获取元素失败的时候会返回空，但是 remove() 失败的时候会抛出异常。
134、Java 中 LinkedHashMap 和 PriorityQueue 的区别是什么？PriorityQueue 保证最高或者最低优先级的的元素总是在队列头部，但是LinkedHashMap 维持的顺序是元素插入的顺序。当遍历一个 PriorityQueue 时，没有任何顺序保证，但是 LinkedHashMap 课保证遍历顺序是元素插入的顺序。
135、ArrayList 与 LinkedList 的区别？最明显的区别是 ArrrayList 底层的数据结构是数组，支持随机访问，而LinkedList 的底层数据结构书链表，不支持随机访问。使用下标访问一个元素，ArrayList 的时间复杂度是 O(1)，而 LinkedList 是 O(n)。
136、用哪两种方式来实现集合的排序？你可以使用有序集合，如 TreeSet 或 TreeMap，你也可以使用有顺序的的集合，如 list，然后通过 Collections.sort() 来排序。
137、Java 中怎么打印数组？你可以使用 Arrays.toString() 和 Arrays.deepToString() 方法来打印数组。由于数组没有实现 toString() 方法，所以如果将数组传递给 System.out.println()方法，将无法打印出数组的内容，但是 Arrays.toString() 可以打印每个元素。
138、Java 中的 LinkedList 是单向链表还是双向链表？是双向链表，你可以检查 JDK 的源码。
139、Java 中的 TreeMap 是采用什么树实现的？Java 中的 TreeMap 是使用红黑树实现的。
140、Hashtable 与 HashMap 有什么不同之处？这两个类有许多不同的地方，下面列出了一部分：
a) Hashtable 是 JDK 1 遗留下来的类，而 HashMap 是后来增加的。
b）Hashtable 是同步的，比较慢，但 HashMap 没有同步策略，所以会更快。
c）Hashtable 不允许有个空的 key，但是 HashMap 允许出现一个 null key。
141、Java 中的 HashSet，内部是如何工作的？HashSet 的内部采用 HashMap 来实现。由于 Map 需要 key 和 value，所以所有 key 的都有一个默认 value。类似于 HashMap，HashSet 不允许重复的key，只允许有一个 null key，意思就是 HashSet 中只允许存储一个 null 对象。
142、写一段代码在遍历 ArrayList 时移除一个元素？该问题的关键在于面试者使用的是 ArrayList 的 remove() 还是 Iterator 的remove()方法。这有一段示例代码，是使用正确的方式来实现在遍历的过程中移除元素，而不会出现 ConcurrentModificationException 异常的示例代码。
143、我们能自己写一个容器类，然后使用 for-each 循环码？可以，你可以写一个自己的容器类。如果你想使用 Java 中增强的循环来遍历，你只需要实现 Iterable 接口。如果你实现 Collection 接口，默认就具有该属性。
144、ArrayList 和 HashMap 的默认大小是多数？在 Java 7 中，ArrayList 的默认大小是 10 个元素，HashMap 的默认大小是16 个元素（必须是 2 的幂）。这就是 Java 7 中 ArrayList 和 HashMap 类的代码片段：
// from ArrayList.java JDK 1.7private static final int DEFAULT_CAPACITY = 10;//from HashMap.java JDK 7static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;// aka 16

145、有没有可能两个不相等的对象有有相同的 hashcode？有可能，两个不相等的对象可能会有相同的 hashcode 值，这就是为什么在hashmap 中会有冲突。相等 hashcode 值的规定只是说如果两个对象相等，必须有相同的 hashcode 值，但是没有关于不相等对象的任何规定。
146、两个相同的对象会有不同的的 hash code 吗？不能，根据 hash code 的规定，这是不可能的。
147、我们可以在 hashcode() 中使用随机数字吗？不行，因为对象的 hashcode 值必须是相同的。参见答案获取更多关于 Java 中重写 hashCode() 方法的知识。
148、Java 中，Comparator 与 Comparable 有什么不同？Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户定制的顺序。
Comparable 总是只有一个，但是可以有多个 comparator 来定义对象的顺序。
149、为什么在重写 equals 方法的时候需要重写 hashCode 方法？因为有强制的规范指定需要同时重写 hashcode 与 equal 是方法，许多容器类，如 HashMap、HashSet 都依赖于 hashcode 与 equals 的规定。
150、在我 Java 程序中，我有三个 socket，我需要多少个线程来处理？这个需要看你是并行处理还是串行处理了。
151、Java 中怎么创建 ByteBuffer？byte[] bytes = new byte[10];ByteBuffer buf = ByteBuffer.wrap(bytes);

152、Java 中，怎么读写 ByteBuffer ？153、Java 采用的是大端还是小端？154、ByteBuffer 中的字节序是什么？ByteBuffer类中的order(ByteOrder bo) 方法可以设置 ByteBuffer 的字节序。
其中的ByteOrder是枚举：
ByteOrder BIG_ENDIAN 代表大字节序的 ByteOrder 。
ByteOrder LITTLE_ENDIAN 代表小字节序的 ByteOrder 。
ByteOrder nativeOrder() 返回当前硬件平台的字节序。
155、Java 中，直接缓冲区与非直接缓冲器有什么区别？非直接缓冲区：通过allocate()分配缓冲区，将缓冲区建立在JVM的内存中
直接缓冲区：通过allocateDirect()分配直接缓冲区，将缓冲区建立在物理内存中，可以提高效率
156、Java 中的内存映射缓存区是什么？157、socket 选项 TCP NO DELAY 是指什么？158、TCP 协议与 UDP 协议有什么区别？TCP协议和UDP协议特性区别总结：

TCP协议在传送数据段的时候要给段标号；UDP协议不

TCP协议可靠；UDP协议不可靠

TCP协议是面向连接；UDP协议采用无连接

TCP协议负载较高，采用虚电路；UDP采用无连接

TCP协议的发送方要确认接收方是否收到数据段（3次握手协议）

TCP协议采用窗口技术和流控制


159、Java 中，ByteBuffer 与 StringBuffer 有什么区别？160、Java 中，编写多线程程序的时候你会遵循哪些最佳实践？a）给线程命名，这样可以帮助调试。
b）最小化同步的范围，而不是将整个方法同步，只对关键部分做同步。
c）如果可以，更偏向于使用 volatile 而不是 synchronized。
d）使用更高层次的并发工具，而不是使用 wait() 和 notify() 来实现线程间通信，如 BlockingQueue，CountDownLatch 及 Semaphore。
e）优先使用并发集合，而不是对集合进行同步。并发集合提供更好的可扩展性。
161、说出几点 Java 中使用 Collections 的最佳实践a）使用正确的集合类，例如，如果不需要同步列表，使用 ArrayList 而不是Vector。
b）优先使用并发集合，而不是对集合进行同步。并发集合提供更好的可扩展性。
c）使用接口代表和访问集合，如使用 List 存储 ArrayList，使用 Map 存储HashMap 等等。
d）使用迭代器来循环集合。
e）使用集合的时候使用泛型。
162、说出至少 5 点在 Java 中使用线程的最佳实践。这个问题与之前的问题类似，你可以使用上面的答案。对线程来说，你应该：
a）对线程命名
b）将线程和任务分离，使用线程池执行器来执行 Runnable 或 Callable。
c）使用线程池
163、说出 5 条 IO 的最佳实践IO 对 Java 应用的性能非常重要。理想情况下，你不应该在你应用的关键路径上避免 IO 操作。下面是一些你应该遵循的 Java IO 最佳实践：
a）使用有缓冲区的 IO 类，而不要单独读取字节或字符。
b）使用 NIO 和 NIO2
c）在 finally 块中关闭流，或者使用 try-with-resource 语句。
d）使用内存映射文件获取更快的 IO。
164、列出 5 个应该遵循的 JDBC 最佳实践有很多的最佳实践，你可以根据你的喜好来例举。下面是一些更通用的原则：
a）使用批量的操作来插入和更新数据
b）使用 PreparedStatement 来避免 SQL 异常，并提高性能。
c）使用数据库连接池
d）通过列名来获取结果集，不要使用列的下标来获取。
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>黑苹果装机配置</title>
    <url>/posts/f0e37cbf/</url>
    <content><![CDATA[目录电脑配置


类型
型号
价格
渠道



网卡
T919 BCM94360CD
150
闲鱼


显卡
蓝宝石 RX460 4GB 超白金版
229
闲鱼


内存条
镁光 3200 DDR4 32G
790
闲鱼


散热
雅浚 B3 PRO 4 热管 ARGB 神光同步
74.01
闲鱼


SSD 固态硬盘
西数 SN570 1T
350
闲鱼


主板
MSI MAG-B560M-MORTAR-WIFI
580
闲鱼


机箱
爱国者 T9 机箱
83.6
闲鱼


电源
爱国者 G7 全模组 700W
238
闲鱼


风扇
爱国者 冰魄彩虹 V1 * 6
56
闲鱼


CPU
i7-10700
1091
淘宝


螺丝
风扇铁黑&#x2F;镀镍螺丝
3.43
淘宝


转接线
大 4pin 一分五扩展线
12.99
淘宝


转接线
大 4pin 转 6 pin，显卡用
5.79
淘宝


硅脂
信越 7921 导热硅脂
20.90
淘宝


合计

3475.72



参考链接台式装机全程攻略
2022年黑苹果macOS Big Sur&#x2F;Monterey显卡支持列表，持续更新中。
黑苹果无线网卡购买&amp;安装&amp;使用指南2022年版
]]></content>
      <categories>
        <category>黑苹果</category>
      </categories>
      <tags>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>黑苹果驱动下载地址</title>
    <url>/posts/84c0ab93/</url>
    <content><![CDATA[目录kext其他


名称
适用版本
用途
下载地址
备注



Lilu.kext
通用
很多其他著名 kext 的依赖，没有这个其他都跑不了
https://github.com/acidanthera/Lilu/releases
必须得使用


VirtualSMC.kext
通用
模拟在真实 mac 上找到的 SMC 芯片，没有这个 macOS 将无法启动
https://github.com/acidanthera/VirtualSMC/releases
必须得使用


AppleALC.kext
通用
用于 AppleHDA 修补，支持大多数板载声卡
https://github.com/acidanthera/AppleALC/releases
强烈建议用


LucyRTL8125Ethernet.kext
通用
Realtek 的 2.5Gb 网卡驱动，需要 10.15 +
https://github.com/Mieze/LucyRTL8125Ethernet/releases
更多网卡参考


NVMeFix.kext
通用
改善与非 Apple SSD 的兼容性，有助于主动电源管理
https://github.com/acidanthera/NVMeFix/releases
可以试试看


SMCProcessor.kext
通用
用于监控 CPU 温度，AMD 不适用
https://github.com/acidanthera/VirtualSMC/releases
很有必要用


SMCSuperIO.kext
通用
用于监控风扇速度，AMD 不适用
https://github.com/acidanthera/VirtualSMC/releases
很有必要用


WhateverGreen.kext
通用
所有 GPU 都受益于这个 kext，必备插件
https://github.com/acidanthera/WhateverGreen/releases
必须得使用


USBPorts.kext
通用
参考这个文章：使用 Hackintool 定制黑苹果 USB 驱动

需要自定义


博通蓝牙
BrcmPatchRAM 需要按系统版本进行选择：

BrcmPatchRAM3 用于 macOS 10.14 及更高版本，必须搭配 BrcmBluetoothInjector 使用；
BrcmPatchRAM2 用于 macOS 10.11 到 10.14；
BrcmPatchRAM 用于 OS X 10.10 或更老的版本；

如果您有非 PatchRAM 设备（或者不确定），请安装 macOS 版本的 BrcmNonPatchRAM.kext 或 BrcmNonPatchRAM2.kext 之一，请不要同时安装两者。




名称
适用版本
用途
下载地址



AirportBrcmFixup.kext
通用
将旧的 Broadcom 卡注入较新版本的 macOS 的附加功能
https://github.com/acidanthera/AirportBrcmFixup/releases


BlueToolFixup.kext
Monterey
修复系统设置内的蓝牙开关
https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmBluetoothInjector.kext
bigsur
修复系统设置内的蓝牙开关
https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmBluetoothInjectorLegacy.kext
-

https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmFirmwareData.kext
通用
上传固件
https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmFirmwareRepo.kext
-
安装到 &#x2F;System&#x2F;Library&#x2F;Extensions（在10.11及更高版本上为 &#x2F;Library&#x2F;Extensions）。 该 kext 的内存效率比 BrcmFirmwareData.kext 略高，但是不能由引导加载程序注入。
https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmNonPatchRAM.kext
-

https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmNonPatchRAM2.kext
-

https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmPatchRAM.kext
-

https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmPatchRAM2.kext
-

https://github.com/acidanthera/BrcmPatchRAM/releases


BrcmPatchRAM3.kext
通用

https://github.com/acidanthera/BrcmPatchRAM/releases


intel蓝牙
IntelBluetoothFirmware 是一个用于在 macOS 中启用原生蓝牙的固件上传驱动，固件的二进制文件来自 Linux。
经过数月的测试后，这个驱动已经被证实可以正常稳定工作。目前支持 macOS 10.13 及以上，支持的设备 ID 如下：
0x8087, 0x0a2a0x8087, 0x07dc0x8087, 0x0aa70x8087, 0x00250x8087, 0x0aaa0x8087, 0x00260x8087, 0x00290x8087, 0x0a2b
如果驱动程序有问题，请在终端中运行以下命令：
log show --last boot | grep IntelFirmware




名称
适用版本
用途
下载地址



BlueToolFixup.kext
Ventura，Monterey
修复系统设置内的蓝牙开关
https://github.com/acidanthera/BrcmPatchRAM/releases


IntelBluetoothInjector.kext
bigsur
修复系统设置内的蓝牙开关
https://github.com/OpenIntelWireless/IntelBluetoothFirmware/releases


IntelBluetoothFirmware.kext

上传固件
https://github.com/OpenIntelWireless/IntelBluetoothFirmware/releases


IntelBTPatcher.kext
Ventura

https://github.com/OpenIntelWireless/IntelBluetoothFirmware/releases


网卡


名称
适用版本
用途
下载地址



AirportItlwm.kext
通用
网卡驱动
https://github.com/OpenIntelWireless/itlwm/releases


参考链接BrcmPatchRAM 黑苹果WiFi无线网卡蓝牙驱动
使用 WIFI&#x2F;BlueTooth 擴展卡，在Monterey 藍芽無法驅動的解決方案
]]></content>
      <categories>
        <category>黑苹果</category>
      </categories>
      <tags>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 安装</title>
    <url>/posts/594d6108/</url>
    <content><![CDATA[参考文章
设置 yum 源以下方式三选一：
yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo（中央仓库）yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo（阿里仓库）yum-config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo

删除本地文件sudo rm -rf /var/lib/docker

安装指定版本yum list docker-ce --showduplicates | sort -r

可以指定版本安装，版本号可以忽略 : 和 el7，如 docker-ce-18.09.1
yum install docker-ce-&lt;VERSION STRING&gt;

查看当前版本号docker -v

]]></content>
      <categories>
        <category>CICD</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernete 详解</title>
    <url>/posts/aa794d6f/</url>
    <content><![CDATA[基本架构

Master组件API Server顾名思义是用来处理 API 操作的，Kubernetes 中所有的组件都会和 API Server 进行连接，组件与组件之间一般不进行独立的连接，都依赖于 API Server 进行消息的传送，默认情况下在本机8080端口提供rest服务(–insecure-port), 也可以启用HTTPS安全端口 (–secure-port&#x3D;6443)
API Server架构图



api层: 主要提供对外的 rest api
访问控制层: 验证身份与鉴权,根据配置的各种资源访问许可逻辑(Adminssion control) ,判断是否允许访问
注册表层: K8S 将所有对象都保存在registry中, 针对registry中的各种资源对象, 都定义对象类型, 如何创建资源对象, 如何转换不同版本, 以及如何将资源编码和解码为json 或protobuf 格式进行存储.
etcd 数据库: 用于持久化存储资源对象.

API版本控制
Api Server针对每种资源都引入了一个相对不便的interal版本, 所有其他版本的资源对象(数据结构)只要支持能够转换为internal 就可以与其他版本的对象互换.
Controller Manager负责管理集群各种资源，保证资源处于预期的状态。Controller Manager由多种controller组成，包括replication controller、endpoints controller、namespace controller、serviceaccounts controller等 。由控制器完成的主要功能主要包括生命周期功能和API业务逻辑；



资源类型
说明



Deployment
Deployment 是最常用的 Controller，比如前面在线教程中就是通过创建 Deployment 来部署应用的。Deployment 可以管理 Pod 的多个副本，并确保 Pod 按照期望的状态运行。


ReplicaSet
ReplicaSet 实现了 Pod 的多副本管理。使用 Deployment 时会自动创建 ReplicaSet，也就是说 Deployment 是通过 ReplicaSet 来管理 Pod 的多个副本，我们通常不需要直接使用 ReplicaSet。


DaemonSet
用于每个 Node 最多只运行一个 Pod 副本的场景。正如其名称所揭示的，DaemonSet 通常用于运行 daemon。


StatefulSet
StatefuleSet 能够保证 Pod 的每个副本在整个生命周期中名称是不变的。而其他 Controller 不提供这个功能，当某个 Pod 发生故障需要删除并重新启动时，Pod 的名称会发生变化。同时 StatefuleSet 会保证副本按照固定的顺序启动、更新或者删除。


Job
Job 用于运行结束就删除的应用。而其他 Controller 中的 Pod 通常是长期持续运行。


Scheduler是调度器，“调度器”顾名思义就是完成调度的操作，就是我们刚才介绍的第一个例子中，把一个用户提交的 Container，依据它对 CPU、对 memory 请求大小，找一台合适的节点，进行放置；
Etcd是一个分布式的一个存储系统，API Server 中所需要的这些原信息都被放置在 etcd 中，etcd 本身是一个高可用系统，通过 etcd 保证整个 Kubernetes 的 Master 组件的高可用性。
Node组件Kubeletkubelet是node的agent，当Scheduler确定在某个Node上运行Pod后，会将Pod的具体配置信息（image、volume等）发送给该节点的kubelet，kubelet会根据这些信息创建和运行容器，并向master报告运行状态。
Docker Engine每个Node都需要提供一个容器运行时（Container Runtime）环境，它负责下载镜像并运行容器。目前K8S支持的容器运行环境至少包括Docker、RKT、cri-o、Fraki等。
Kube Proxyservice在逻辑上代表了后端的多个Pod，外借通过service访问Pod。service接收到请求就需要kube-proxy完成转发到Pod的。每个Node都会运行kube-proxy服务，负责将访问的service的TCP&#x2F;UDP数据流转发到后端的容器，如果有多个副本，kube-proxy会实现负载均衡，有2种方式：LVS或者Iptables
核心组件KubeDNS在K8S集群中调度并运行提供DNS服务的Pod，同一集群内的其他Pod可以使用该DNS服务来解决主机名。K8S自1.11版本开始默认使用CoreDNS项目来为集群提供服务注册和服务发现的动态名称解析服务。
DashboardK8S集群的全部功能都要基于Web的UI，来管理集群中的应用和集群自身。
Heapster容器和节点的性能监控与分析系统，它收集并解析多种指标数据，如资源利用率、生命周期时间，在最新的版本当中，其主要功能逐渐由Prometheus结合其他的组件进行代替。
Ingress ControllerService是一种工作于4层的负载均衡器，而Ingress是在应用层实现的HTTP(S)的负载均衡。不过，Ingress资源自身并不能进行流量的穿透，它仅仅是一组路由规则的集合，这些规则需要通过Ingress控制器（Ingress Controller）发挥作用。目前该功能项目大概有：Nginx-ingress、Traefik、Envoy和HAproxy等。如下图就是Nginx-ingress的应用，具体可以查看博文：https://www.cnblogs.com/linuxk/p/9706720.html


概念PODPod 是 Kubernetes 的一个最小调度以及资源单元。用户可以通过 Kubernetes 的 Pod API 生产一个 Pod，让 Kubernetes 对这个 Pod 进行调度，也就是把它放在某一个 Kubernetes 管理的节点上运行起来。一个 Pod 简单来说是对一组容器的抽象，它里面会包含一个或多个容器。
VolumeVolume 就是卷的概念，它是用来管理 Kubernetes 存储的，是用来声明在 Pod 中的容器可以访问文件目录的，一个卷可以被挂载在 Pod 中一个或者多个容器的指定路径下面。
而 Volume 本身是一个抽象的概念，一个 Volume 可以去支持多种的后端的存储。比如说 Kubernetes 的 Volume 就支持了很多存储插件，它可以支持本地的存储，可以支持分布式的存储，比如说像 ceph，GlusterFS ；它也可以支持云存储，比如说阿里云上的云盘、AWS 上的云盘、Google 上的云盘等等。
非持久性存储
emptyDir

  使用emptyDir，当Pod分配到Node上时，将会创建emptyDir，并且只要Node上的Pod一直运行，Volume就会一直存。当Pod（不管任何原因）从Node上被删除时，emptyDir也同时会删除，存储的数据也将永久删除。
　　常用于作为临时目录、或缓存使用。

hostPath

　　hostPath允许挂载Node（宿主机）上的文件系统到Pod里面去。如果Pod需要使用Node上的文件，可以使用hostPath。
hostPath类型



值
行为



空
空字符串（默认）用于向后兼容，这意味着在安装hostPath卷之前不会执行任何检查。


DirectoryOrCreate
如果给定路径中不存在任何内容，则将根据需要创建一个空目录，权限设置为0755，与Kubelet具有相同的组和所有权。


Directory
目录必须存在于给定路径中


FileOrCreate
如果给定路径中不存在任何内容，则会根据需要创建一个空文件，权限设置为0644，与Kubelet具有相同的组和所有权。


File
文件必须存在于给定路径中


Socket
UNIX套接字必须存在于给定路径中


CharDevice
字符设备必须存在于给定路径中


BlockDevice
块设备必须存在于给定路径中


网络连接性存储
SAN：iSCSI
NFS：nfs，cfs

分布式存储
glusterfs、RBD(Rados Block Device)、cephfs

云端存储
EBS、Azure Disk、阿里云、gitRepo

DeploymentDeployment 是在 Pod 这个抽象上更为上层的一个抽象，它可以定义一组 Pod 的副本数目、以及这个 Pod 的版本。一般大家用 Deployment 这个抽象来做应用的真正的管理，而 Pod 是组成 Deployment 最小的单元。
ServiceService 提供了一个或者多个 Pod 实例的稳定访问地址。
实现 Service 有多种方式，Kubernetes 支持 Cluster IP，上面我们讲过的 kuber-proxy 的组网，它也支持 nodePort、 LoadBalancer 等其他的一些访问的能力。
NamespaceNamespace 是用来做一个集群内部的逻辑隔离的，它包括鉴权、资源管理等。Kubernetes 的每个资源，比如刚才讲的 Pod、Deployment、Service 都属于一个 Namespace，同一个 Namespace 中的资源需要命名的唯一性，不同的 Namespace 中的资源可以重名。
版本一览

FAGnodePort，targetPort，port的区别nodePort
外部机器可访问的端口，比如一个Web应用需要被其他用户访问，那么需要配置type&#x3D;NodePort，而且配置nodePort&#x3D;30001，那么其他机器就可以通过浏览器访问scheme:&#x2F;&#x2F;node:30001访问到该服务，例如http://node:30001，有的像MySQL数据库可能不需要被外界访问，只需被内部服务访问，那么不必设置NodePort
targetPort
容器的端口，与制作容器时暴露的端口一致（DockerFile中EXPOSE），例如docker.io官方的nginx暴露的是80端口。
port
kubernetes中的服务之间访问的端口，尽管mysql容器暴露了3306端口（参考https://github.com/docker-library/mysql/的DockerFile），但是集群内其他容器需要通过33306端口访问该服务，外部机器不能访问mysql服务，因为他没有配置NodePort类型                      
]]></content>
      <categories>
        <category>CICD</category>
        <category>Kubernete</category>
      </categories>
      <tags>
        <tag>kubernete</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernete 常用命令</title>
    <url>/posts/e1b46314/</url>
    <content><![CDATA[更新镜像1. set-image 方式kubectl set image -n [NAMESPACE] deploy [DEPLOY_NAME] [CONTAINER_NAME]=[IMAGE]

2. edit deploy 方式kubectl edit deploy -n [NAMESPACE] [DEPLOY_NAME]

切换当前 context 默认命名空间kubectl config set-context --current --namespace=&lt;namespace&gt;

切换 contextkubectl config use-context &lt;context-name&gt;

查看 contextkubectl config view

集群信息获取集群信息kubectl config get-contexts

切换集群kubectl config use-context [集群名称]

]]></content>
      <categories>
        <category>CICD</category>
        <category>Kubernete</category>
      </categories>
      <tags>
        <tag>kubernete</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernete 系统</title>
    <url>/posts/9e086c9c/</url>
    <content><![CDATA[查看资源限额kubectl describe limitrange -n [NAMESPACE]

]]></content>
      <categories>
        <category>CICD</category>
        <category>Kubernete</category>
      </categories>
      <tags>
        <tag>kubernete</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring 基础</title>
    <url>/posts/4e9ceea/</url>
    <content><![CDATA[AOP 详解一、AOP 简介AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP只允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志，事务，安全等。这些功能都是横向应用在业务处理中，而与它们对应的方法与其他代码基本没有联系，如异常处理和透明的持续性也都是如此，不仅增加了大量的代码量，还为程序后期的维护增生很多困难。
AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。
二、AOP 基本了解和通知方法
切面（Aspect）：一个关注点的模块化，这个关注点可能会横切多个对象。事务管理是J2EE应用中一个关于横切关注点的很好的例子。在spring AOP中，切面可以使用基于模式）或者基于Aspect注解方式来实现。通俗点说就是我们加入的切面类（比如log类），可以这么理解。
连接点（Joinpoint）：在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候。在Spring AOP中，一个连接点总是表示一个方法的执行。通俗的说就是加入切点的那个点
通知（Advice）：在切面的某个特定的连接点上执行的动作。其中包括了“around”、“before”和“after”等不同类型的通知（通知的类型将在后面部分进行讨论）。许多AOP框架（包括Spring）都是以拦截器做通知模型，并维护一个以连接点为中心的拦截器链。
切入点（Pointcut）：匹配连接点的断言。通知和一个切入点表达式关联，并在满足这个切入点的连接点上运行（例如，当执行某个特定名称的方法时）。切入点表达式如何和连接点匹配是AOP的核心：Spring缺省使用AspectJ切入点语法。
引入（Introduction）：用来给一个类型声明额外的方法或属性（也被称为连接类型声明（inter-type declaration））。Spring允许引入新的接口（以及一个对应的实现）到任何被代理的对象。例如，你可以使用引入来使一个bean实现IsModified接口，以便简化缓存机制。
目标对象（Target Object）： 被一个或者多个切面所通知的对象。也被称做被通知（advised）对象。 既然Spring AOP是通过运行时代理实现的，这个对象永远是一个被代理（proxied）对象。
AOP代理（AOP Proxy）：AOP框架创建的对象，用来实现切面契约（例如通知方法执行等等）。在Spring中，AOP代理可以是JDK动态代理或者CGLIB代理。
织入（Weaving）：把切面连接到其它的应用程序类型或者对象上，并创建一个被通知的对象。这些可以在编译时（例如使用AspectJ编译器），类加载时和运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入。

通知方法：
前置通知（Before advice）：在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程（除非它抛出一个异常）。

后置通知（After returning advice）：在某连接点正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。

异常通知（After throwing advice）：在方法抛出异常退出时执行的通知。

最终通知（After (finally) advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。

环绕通知（Around Advice）：包围一个连接点的通知，如方法调用。这是最强大的一种通知类型。环绕通知可以在方法调用前后完成自定义的行为。
它也会选择是否继续执行连接点或直接返回它自己的返回值或抛出异常来结束执行。


三、Spring对AOP的支持Spring中AOP代理由Spring的IOC容器负责生成，管理，它的依赖关系也有IOC容器负责。因此，AOP代理可以直接使用容器中的其他bean示例作为目标，这种关系可由IOC容器的依赖注入提供(不熟悉依赖注入的可以看看我之前的博文)。Spring创建代理规则为:
  1、默认使用JDK动态代理来创建AOP代理，这样可以为任何接口示例创建代理
  2、当需要代理的类不是代理接口时，Spring会切换为使用CGLIB代理，也可强制使用CGLIB代理。(强制方法：在XML配置中修改 AOP 属性spring.aop.proxy-target-class&#x3D;true或在注释中修改@EnableAspectJAutoProxy(proxyTargetClass &#x3D; true)进行AOP编程的关键就是定义切入点和定义增强处理，一旦定义了合适的切入点和增强处理，AOP框架将自动生成AOP代理，即：代理对象的方法&#x3D;增强处理+被代理对象的方法。
exposeProxy：AOP生成对象时，绑定到ThreadLocal, 可以通过AopContext获取
IOC（依赖注入）的基本实现方式Java中创建一个对象分两步： 

通过关键字new创建一个对象 
通过构造函数或setter函数为对象添加初始化参数 （参数可以是基本数据类型 也可以是引用数据类型（比如依赖的类））

当 Spring 出现后，对象的创建、成员变量的初始化、对象的销毁均由Spring完成。 
那么，要让Spring帮助我们创建对象，我们首先需要将要创建的对象的类型、初始化的值告诉Spring，然后Spring会在程序启动的时候根据我们的要求创建对象。我们通过配置文件来告诉Spring要创建哪些对象，并告诉Spring如何创建这些对象。
Bean的作用域在Spring中，默认情况下bean都是单例。也就是说，当我们向Spring请求一个bean对象时，Spring总给我们返回同一个bean对象。注意：Spring 中所说的“单例”与Java中的单例稍有不同。Spring中的单例是指：在同一个ApplicationContext中相同名字的bean对象是同一个；而Java中的单例是指：整个JVM中单例的对象只有一个。当然，我们可以通过改变bean标签的scope参数来设置bean的作用域。常用的scope对应的值有： 

singleton：在同一个Spring Context中，一个bean只有一个实例对象。(默认) 

prototype：每次向Spring请求一个bean对象，Spring都会创建一个新的实例。

会话（Session）：在web应用中，为每个会话创建一个bean实例。

请求（Request）：在Web应用中，为每个请求创建一个bean实例。


依赖注入的方式分三种

构造函数注入
属性注入
set方法注入

自动装配与自动扫描简化Spring的配置主要分为两类： 

自动装配 
自动扫描

自动装配的种类
byName：根据属性的名字自动装配
在bean标签中添加属性autowire&#x3D;”byName”。当Spring启动时，会寻找与person中成员变量名字相同的bean，并将该bean注给person的成员变量。

byType：根据属性的类型自动装配在bean标签中添加属性autowire&#x3D;”byType”。当Spring启动时，会寻找与person中成员变量类型相同的bean，并将该bean注给person的成员变量。byType的缺点：如果某一类型的bean有多个，那Spring在通过byType为属性寻找同类型的bean时就会抛出异常。 

constructor：根据构造器的参数类型自动装配

autodetect：最佳自动装配。首先采用constructor自动装配，若没有发现与构造器相匹配的Bean时，采用byType进行自动装配。


@Autowired本质上采用byType进行自动装配，因此也存在与byType一样的问题：若同一类型的bean有多个时，或找不到该类型的bean，Spring就会抛出异常。
在注解中使用SpEL表达式将名为father的bean注入给构造函数：
@Value(&quot;#&#123;father&#125;&quot;)  public Person(Father father)&#123;      this.father = father;  &#125;

将father对象中的id注入给id：
@Value(&quot;#&#123;father.id&#125;&quot;)   public void setId(long id)&#123;       this.id = id;   &#125;

自动检测自动装配能够减少bean标签下property标签和constructor-arg标签的数量，而自动检测能降低bean标签的数量。
Spring 注解 @Resource 和 @Autowired 区别对比@Autowired​	@Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。(通过类型匹配找到多个candidate,在没有@Qualifier、@Primary注解的情况下，会使用对象名作为最后的fallback匹配)如下：
public class TestServiceImpl &#123;    @Autowired    @Qualifier(&quot;userDao&quot;)    private UserDao userDao; &#125;

@Resource​	@Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。
​	@Resourced标签是按照bean的名字来进行注入的，如果我们没有在使用@Resource时指定bean的名字，同时Spring容器中又没有该名字的bean,这时候@Resource就会退化为@Autowired即按照类型注入，这样就有可能违背了使用@Resource的初衷。所以建议在使用@Resource时都显示指定一下bean的名字@Resource(name&#x3D;”xxx”) 
public class TestServiceImpl &#123;    // 下面两种@Resource只要使用一种即可    @Resource(name=&quot;userDao&quot;)    private UserDao userDao; // 用于字段上        @Resource(name=&quot;userDao&quot;)    public void setUserDao(UserDao userDao) &#123; // 用于属性的setter方法上        this.userDao = userDao;    &#125;&#125;

结论：

如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。
如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。
如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。
如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。

Spring 中 Bean 的生命周期对于普通的 Java 对象，当我们使用new关键字创建对象的时候，如果它没有任何引用，则其会被垃圾回收机制回收。而由 Spring IoC 容器托管的对象，它们的生命周期则是完全由容器控制。在 Spring 中，每个 Bean 的生命周期大致如下：


实例化 Bean对于BeanFactory容器来说，当用户向容器请求一个尚未初始化的 Bean 或初始化 Bean 的时候，如果需要注入另一个尚未初始化的依赖，容器就会调用createBean进行实例化；对于ApplicationContext容器来说，当容器启动结束后，便实例化所有的 Bean。
容器通过获取BeanDefinition对象中的信息进行实例化。并且这一步仅仅是简单的实例化，并未进行依赖注入。 实例化对象被包装在BeanWrapper对象中，BeanWrapper提供了设置对象属性的接口，从而避免了使用反射机制设置属性。
设置对象属性（依赖注入）实例化后的对象被封装在BeanWrapper对象中，并且此时对象仍然是一个原生的状态，并没有进行依赖注入。 紧接着，Spring 根据BeanDefinition中的信息进行依赖注入，并且通过BeanWrapper提供的设置属性的接口完成依赖注入。
注入 Aware 接口紧接着，Spring 会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给 Bean：
如果 Bean 实现了BeanNameAware接口，Spring 将 Bean 的 ID 传递给setBeanName()方法。实现BeanNameAware主要是为了通过 Bean 的引用来获得 Bean 的 ID，一般业务中是很少有用到 Bean 的 ID 的。如果 Bean 实现了BeanFactoryAware接口，Spring 将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。实现BeanFactoryAware主要目的是为了获取 Spring 容器，如 Bean 通过 Spring 容器发布事件等。如果 Bean 实现了ApplicationContextAware接口，Spring 容器将调用setApplicationContext(ApplicationContext ctx)方法，把应用上下文作为参数传入，作用与BeanFactory类似都是为了获取 Spring 容器，不同的是 Spring 容器在调用setApplicationContext方法时会把它自己作为setApplicationContext的参数传入，而 Spring 容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory。
BeanPostProcessor当经过上述几个步骤后，Bean 对象已经被正确构造，但如果你想要对象被使用前再进行一些自定义的处理，就可以通过BeanPostProcessor接口实现。 该接口提供了两个函数：
postProcessBeforeInitialzation(Object bean, String beanName)当前正在初始化的 Bean 对象会被传递进来，我们就可以对这个 Bean 作任何处理。这个函数会先于InitialzationBean执行，因此称为前置处理。 所有Aware接口的注入就是在这一步完成的。postProcessAfterInitialzation(Object bean, String beanName)当前正在初始化的 Bean 对象会被传递进来，我们就可以对这个 Bean 作任何处理。这个函数会在InitialzationBean完成后执行，因此称为后置处理。
InitializingBean 与 init-method当BeanPostProcessor的前置处理完成后就会进入本阶段。 InitializingBean接口只有一个函数：
afterPropertiesSet()这一阶段也可以在 Bean 正式构造完成前增加我们自定义的逻辑，但它与前置处理不同，由于该函数并不会把当前 Bean 对象传进来，因此在这一步没办法处理对象本身，只能增加一些额外的逻辑。 若要使用它，我们需要让 Bean 实现该接口，并把要增加的逻辑写在该函数中。然后，Spring 会在前置处理完成后检测当前 Bean 是否实现了该接口，并执行afterPropertiesSet函数。
当然，Spring 为了降低对客户代码的侵入性，给 Bean 的配置提供了init-method属性，该属性指定了在这一阶段需要执行的函数名。Spring 便会在初始化阶段执行我们设置的函数。init-method本质上仍然使用了InitializingBean接口。
DisposableBean 和 destroy-method如果 Bean 实现了DispostbleBean接口，Spring 将调用它的destory方法，作用与在配置文件中对 Bean 使用destory-method属性的作用一样，都是在 Bean 实例销毁前执行的方法。
至此，Spring 中 Bean 的经历了从创建到消耗的整个生命周期的过程。
Spring 事务传播行为什么是事务传播行为？事务传播行为用来描述由某一个事务传播行为修饰的方法被嵌套进另一个方法的时事务如何传播。
Spring中七种事务传播行为


事务传播行为类型
说明



PROPAGATION_REQUIRED
如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。


PROPAGATION_SUPPORTS
支持当前事务，如果当前没有事务，就以非事务方式执行。


PROPAGATION_MANDATORY
使用当前的事务，如果当前没有事务，就抛出异常。


PROPAGATION_REQUIRES_NEW
新建事务，如果当前存在事务，把当前事务挂起


PROPAGATION_NOT_SUPPORTED
以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。


PROPAGATION_NEVER
以非事务方式执行，如果当前存在事务，则抛出异常。


PROPAGATION_NESTED
如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。


REQUIRED, REQUIRES_NEW, NESTED 异同
NESTED和REQUIRED修饰的内部方法都属于外围方法事务，如果外围方法抛出异常，这两种方法的事务都会被回滚。
但是REQUIRED是加入外围方法事务，所以和外围事务同属于一个事务，一旦REQUIRED事务抛出异常被回滚，
外围方法事务也将被回滚。而NESTED是外围方法的子事务，有单独的保存点，所以NESTED方法抛出异常被回滚，不会影响到外围方法的事务。

NESTED和REQUIRES_NEW都可以做到内部方法事务回滚而不影响外围方法事务。
但是因为NESTED是嵌套事务，所以外围方法回滚之后，作为外围方法事务的子事务也会被回滚。
而REQUIRES_NEW是通过开启新的事务实现的，内部事务和外围事务是两个事务，外围事务回滚不会影响内部事务。


Bean 的生命周期


开始实例化 person 
设置 name 属性
Person 实现了 BeanNameAware 接口，Spring 将 Person 的 ID&#x3D;person传递给 setBeanName 方法
Person 实现了 BeanFactoryAware 接口，Spring 调用 setBeanFactory()方法，将 BeanFactory 容器实例传入
Person 实现了 ApplicationContextAware 接口，Spring 调用 setApplicationContext()方法，将 person 所在的应用上下文的引用传入进来
初始化 Person 之前执行的方法（BeanPostProcessor 的 postProcessBeforeInitialization 方法）
@PostConstruct 调用自定义的初始化方法
Person 实现了 InitializingBean 接口，Spring 调用它的afterPropertiesSet()方法。类似地，如果 person 使用 init-method 声明了初始化方法，该方法也会被调用
xml 中声明的 init-method 方法
初始化 Person 完成之后执行的方法（BeanPostProcessor 的 postProcessAfterInitialization 方法）
实例化完成使用属性：Person name &#x3D; nasus（main结束方法）
@PreDestory 调用自定义销毁方法
Person 实现了 DisposableBean 接口，Spring 调用它的destroy() 接口方法。同样，如果 person 使用 destroy-method 声明了销毁方法，该方法也会被调用
xml 中声明的 destroy-method 方法

servlet 执行流程

Java SPI 和 Spring SPIservice provider framework是一个系统， 实现了SPI， 在系统里多个服务提供者模块可以提供一个服务的实现， 系统让客户端可以使用这些实现， 从而实现解耦。
一个service provider framework有3个主要的组成部分:

一个服务接口， 供服务提供者实现。
一个注册API， 系统使用这个API来注册服务接口的实现， 从而让客户端使用。
一个service access API， 客户端可以选择获取一个服务的实例。

Java SPI:Service Provider Interface(SPI)是一个可以被第三方扩展或实现的API， 它可以用来实现框架扩展和可替换的模块。
使用步骤：

服务调用方通过 ServiceLoader.load 加载服务接口的实现类实例
服务提供方实现服务接口后， 在自己Jar包的META-INF&#x2F;services目录下新建一个接口名全名的文件， 并将具体实现类全名写入。

Spring SPI很多开源库中都直接或间接地使用了Java的SPI机制， 如Spring中就有类似的SPI机制， 通过SpringFactoriesLoader代替JDK中的ServiceLoader， 通过META-INF&#x2F;spring.factories文件代替META-INF&#x2F;service目录下的描述文件, 原理都是使用了Java的反射机制。
Spring提供的SPI只需要且只有一个文件， 就是META-INF&#x2F;spring.factories
Spring的SPI也更加灵活， 不必要key是接口， 值是实现类， 例如Spring boot使用这种方式来处理自动配置的bean: key是注解(如org.springframework.boot.autoconfig.EnableAutoConfiguration)， 值是被标记@Configuration的类。
另外Spring中还有converter spi和formatter spi。
converter可以用做任意两个类型之间的转换， formatter spi用做string类型和其他类型之间的转换。
Converter和Formatter接口即服务接口
ConersionService实现了ConverterRegistry接口， 提供服务实现的注册， 同时也提供可访问功能。
而FormattingConversionService 则实现了FormatterRegistry接口， 实现了formatter实现类的注册和调用。 同时FormattingConversionService也实现了ConversionService接口。
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 基础</title>
    <url>/posts/a019e08c/</url>
    <content><![CDATA[Java 基础final
注：父类的private成员方法是不能被子类方法覆盖的，因此private类型的方法默认是final类型的

如果在静态方法的声明中加上final，则表示该方法不会被子类的方法隐藏。
final参数不可以赋值，因为在调用方法时，已经对其赋值了。
用final修饰的字符串就是在编译期可知的
public class StringTest &#123;    public static void main(String[] args) &#123;        final String a = &quot;lan&quot;;        final String b = &quot;tao&quot;;      	String c = a + b + &quot;2019&quot;;    &#125;&#125;

上面即使是引用拼接，由于编译期可知，执行效果如下：
public class StringTest &#123;    public static void main(String[] args) &#123;        String str = &quot;lantao2019&quot;;    &#125;&#125;

staticstatic方法：

不可被子类重写（如果子类含有相同静态方法则与父类的静态方法无关）；
直接以类名调用，也可以使用实例调用(避免)；
没有this，因为不依赖于任何实例对象；
不能访问非静态成员变量与非静态成员方法；
static方法必须实现，也就是说他不能是抽象方法abstract；


使用情景：方法不需要访问对象状态，其所需参数均显示参数提供；只需要访问静态域；

List线程安全化Collections.synchronizedListList list = Collections.synchronizedList(new ArrayList());      ...  synchronized (list) &#123;      Iterator i = list.iterator(); // Must be in synchronized block      while (i.hasNext())          foo(i.next());  &#125;

既然封装类内部已经加了对象锁，为什么外部还要加一层对象锁？
看源码可知，Collections.synchronizedList中很多方法，比如equals,hasCode,get,set,add,remove,indexOf,lastIndexOf……
都添加了锁，但是List中
CopyIterator&lt;E&gt; iterator();

这个方法没有加锁，不是线程安全的，所以如果要遍历，还是必须要在外面加一层锁。
SynchronizedList和Vector最主要的区别

Vector扩容为原来的2倍长度，ArrayList扩容为原来1.5倍
SynchronizedList有很好的扩展和兼容功能。他可以将所有的List的子类转成线程安全的类。
使用SynchronizedList的时候，进行遍历时要手动进行同步处理 。
SynchronizedList可以指定锁定的对象。

CopyOnWriteArrayListCopyOnWriteArrayList是ArrayList的线程安全版本，从他的名字可以推测，CopyOnWriteArrayList是在有写操作的时候会copy一份数据，然后写完再设置成新的数据。CopyOnWriteArrayList适用于读多写少的并发场景。

写时复制所谓写时复制（copy-on-write），是在对集合进行“写”操作时，在内部将数据结构全部复制一份的机制。使用这种机制后，即使在多个线程发生读写冲突时ConcurrentModificationException异常也不会被抛出。

Queue集合队列队列与栈是相对的一种数据结构。只允许在一端进行插入操作，而在另一端进行删除操作的线性表。栈的特点是后进先出，而队列的特点是先进先出。队列的用处很大，但大多都是在其他的数据结构中，比如，树的按层遍历，图的广度优先搜索等都需要使用队列做为辅助数据结构。
单向队列  单向队列比较简单，只能向队尾添加元素，从队头删除元素。
双向队列  如果一个队列的头和尾都支持元素入队，出队，那么这种队列就称为双向队列，英文是Deque。
public interface Queue&lt;E&gt; extends Collection&lt;E&gt; &#123;    //插入（抛出异常）    boolean add(E e);    //插入（返回特殊值）    boolean offer(E e);    //移除（抛出异常）    E remove();    //移除（返回特殊值）    E poll();    //检查（抛出异常）    E element();    //检查（返回特殊值）    E peek();&#125;

PriorityQueuePriorityQueue又叫做优先级队列，保存队列元素的顺序不是按照及加入队列的顺序，而是按照队列元素的大小进行重新排序。一句话概括，PriorityQueue使用了一个高效的数据结构：堆。底层是使用数组保存数据。还会进行排序，优先将元素的最小值存到队头。
DequeDeque接口是Queue接口子接口。它代表一个双端队列。
ArrayDequeArrayDeque使用数组实现的Deque;底层是数组，也是可以指定它的capacity,当然也可以不指定，默认长度是16，根据添加的元素个数，动态扩容。
阻塞队列阻塞队列是一种队列，一种可以在多线程环境下使用，并且支持阻塞等待的队列。也就是说，阻塞队列和一般的队列的区别就在于：

多线程环境支持，多个线程可以安全的访问队列
支持生产和消费等待，多个线程之间互相配合，当队列为空的时候，消费线程会阻塞等待队列不为空；当队列满了的时候，生产线程就会阻塞直到队列不满。

根据插入和取出两种类型的操作，具体分为下面一些类型：



操作类型
Throws Exception
Special Value
Timed out
Blocked



插入
add(o)
offer(o)
offer(o, timeout, unit)
put(o)


取出(删除)
remove(o)
poll()
poll(timeout, unit)
take()



Throws Exception 类型的插入和取出在不能立即被执行的时候就会抛出异常。
Special Value 类型的插入和取出在不能被立即执行的情况下会返回一个特殊的值（true 或者 false）。
Blocked 类型的插入和取出操作在不能被立即执行的时候会阻塞线程直到可以操作的时候会被其他线程唤醒。
Timed out 类型的插入和取出操作在不能立即执行的时候会被阻塞一定的时候，如果在指定的时间内没有被执行，那么会返回一个特殊值。

ArrayBlockingQueue

基于数组的阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。
ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。
ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。
LinkedBlockingQueue基于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其 对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。
PriorityBlockingQueuePriorityBlockingQueue是一个优先阻塞队列。所谓优先队列，就是每次从队队列里面获取到的都是队列中优先级最高的，对于优先级，PriorityBlockingQueue需要你为插入其中的元素类型提供一个Comparator，PriorityBlockingQueue使用这个Comparator来确定元素之间的优先级关系。
但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，内部控制线程同步的锁采用的是公平锁。
DelayQueueDelayQueue是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。
SynchronousQueueSynchronousQueue和前面分析的阻塞队列都不同，因为SynchronousQueue不存在容量的说法，任何插入操作都需要等待其他线程来消费，否则就会阻塞等待，也就是说，生产线程生产出一条数据之后就要等待消费者线程来将其消费掉，才能继续生产数据，否则就会阻塞等待消费。
TransferQueue（公平模式）该队列可以创建生产者和消费者程序并协调消息从生产者传输到消费者。
该实现类似于BlockingQueue类，但其可以实现反压形式传输，即当生产者利用transfer()方法发送消息给消费者时，生产者将一直被阻塞，直到消息被使用为止。
TransferStack（非公平模式）非阻塞队列ConcurrentLinkedQueue概念并编程中，一般需要用到安全的队列，如果要自己实现安全队列，可以使用2种方式：

加锁，这种实现方式就是我们常说的阻塞队列。
使用循环CAS算法实现，这种方式实现队列称之为非阻塞队列。

ConcurrentLinkedQueue 是一个基于链接节点的无界线程安全的队列，按照先进先出原则对元素进行排序。新元素从队列尾部插入，而获取队列元素，则需要从队列头部获取；内部的数据结构是分开的，线程之间互不影响，所以也就无需执行互斥处理。
ConcurrentLinkedQueue使用约定：
不允许null入列
在入队的最后一个元素的next为null
队列中所有未删除的节点的item都不能为null且都能从head节点遍历到
删除节点是将item设置为null, 队列迭代时跳过item为null节点
head节点跟tail不一定指向头节点或尾节点，可能存在滞后性

总结
入列出列线程安全，遍历不安全
不允许添加null元素
底层使用列表与CAS算法保证入列出列安全

Exchangerjava.util.concurrent.Exchanger 类用于让两个线程安全的交换对象。
ThreadPoolExecutor类Executors.newFixedThreadPool方法Executors.newFixedThreadPool方法会创建一个线程池，该线程池会创建个数由参数指定的工人线程，而且创建出的线程会被重复利用。如果在这个方法的参数中加上ThreadFactory对象，则线程池会使用该ThreadFactory来创建新的工人线程。
Executors.newCachedThreadPool方法Executors.newCachedThreadPool方法会创建一个线城市，该线程池可以根据需要自动创建工人线程，而且创建的工人线程会被重复利用。没有工作的工人线程会在缓存约60秒后自动终止。如果像这个方法的参数中传入ThreadFactory对象，则线程池会使用这个ThreadFactory来创建新的工人线程。
Executors.newScheduledThreadPool方法
推荐使用newScheduledThreadPool代替 Timer对象
因为不会收到异常中断的影响

Executors.newScheduledThreadPool方法会创建一个线程池，该线程池可以在一定时间后执行请求或是反复执行请求。即使在没有请求时也需要保存的线程数量可以通过参数指定。此外，如果在这个方法的参数中加上ThreadFactory对象，则线程池会使用这个ThreadFactory来创建新的工人线程。
5种创建对象的方法：
使用new关键字
Class对象的newInstance()方法
构造函数对象的newInstance()方法
对象反序列化
Object对象的clone()方法

1. 使用new关键字这是最常用也最简单的方式，看看下面这个例子就知道了。
public class Test &#123;    private String name;    public Test() &#123;    &#125;    public Test(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public static void main(String[] args) &#123;        Test t1 = new Test();        Test t2 = new Test(&quot;张三&quot;);    &#125;&#125;

2. Class对象的newInstance()方法还是上面的Test对象，首先我们通过Class.forName()动态的加载类的Class对象，然后通过newInstance()方法获得Test类的对象
public static void main(String[] args) throws Exception &#123;    String className = &quot;org.b3log.solo.util.Test&quot;;    Class clasz = Class.forName(className);    Test t = (Test) clasz.newInstance();&#125;

3. 构造函数对象的newInstance()方法类Constructor也有newInstance方法，这一点和Class有点像。从它的名字可以看出它与Class的不同，Class是通过类来创建对象，而Constructor则是通过构造器。我们依然使用第一个例子中的Test类。
public static void main(String[] args) throws Exception &#123;    Constructor&lt;Test&gt; constructor;   try &#123;        constructor = Test.class.getConstructor();       Test t = constructor.newInstance();   &#125; catch (InstantiationException |        IllegalAccessException |        IllegalArgumentException |        InvocationTargetException |        NoSuchMethodException |        SecurityException e) &#123;        e.printStackTrace();   &#125;&#125;

4. 对象反序列化使用反序列化来获得类的对象，那么这里必然要用到序列化Serializable接口，所以这里我们将第一个例子中的Test作出一点改变，那就是实现序列化接口。
public class Test implements Serializable&#123;    private String name;    public Test() &#123;    &#125;    public Test(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public static void main(String[] args) throws Exception &#123;       String filePath = &quot;sample.txt&quot;;     Test t1 = new Test(&quot;张三&quot;);     try &#123;        FileOutputStream fileOutputStream =               new FileOutputStream(filePath);        ObjectOutputStream outputStream =               new ObjectOutputStream(fileOutputStream);        outputStream.writeObject(t1);        outputStream.flush();        outputStream.close();        FileInputStream fileInputStream =               new FileInputStream(filePath);        ObjectInputStream inputStream =               new ObjectInputStream(fileInputStream);        Test t2 = (Test) inputStream.readObject();        inputStream.close();        System.out.println(t2.getName());     &#125; catch (Exception ee) &#123;           ee.printStackTrace();     &#125;    &#125;&#125;

5. Object对象的clone()方法Object对象中存在clone方法，它的作用是创建一个对象的副本。看下面的例子，这里我们依然使用第一个例子的Test类。
public static void main(String[] args) throws Exception &#123;    Test t1 = new Test(&quot;张三&quot;);    Test t2 = (Test) t1.clone();    System.out.println(t2.getName());&#125;

happens-before原则　　Java内存模型中定义的两项操作之间的次序关系，如果说操作A先行发生于操作B，操作A产生的影响能被操作B观察到，“影响”包含了修改了内存中共享变量的值、发送了消息、调用了方法等。
　　下面是Java内存模型下一些”天然的“happens-before关系，这些happens-before关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们进行随意地重排序。
　　a. 程序次序规则(Pragram Order Rule)：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环结构。
　　b. 管程锁定规则(Monitor Lock Rule)：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面“是指时间上的先后顺序。
　　c. volatile变量规则(Volatile Variable Rule)：对一个volatile变量的写操作先行发生于后面对这个变量的读取操作，这里的”后面“同样指时间上的先后顺序。
　　d. 线程启动规则(Thread Start Rule)：Thread对象的start()方法先行发生于此线程的每一个动作。
　　e. 线程终止规则(Thread Termination Rule)：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束，Thread.isAlive()的返回值等作段检测到线程已经终止执行。
　　f. 线程中断规则(Thread Interruption Rule)：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测是否有中断发生。
　　g. 对象终结规则(Finalizer Rule)：一个对象初始化完成(构造方法执行完成)先行发生于它的finalize()方法的开始。
　　h. 传递性(Transitivity)：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。
CAS概念CAS，是 compare and swap 的缩写，即比较并交换。它是一种基于乐观锁的操作。它有三个操作数，内存值V，预期值A，更新值B。当且仅当A和V相同时，才会把V修改成B，否则什么都不做。之前说到AtomicInteger用到了CAS，那么先从这个类说起。看如下代码：
public static void main(String[] args)&#123;        AtomicInteger atomicInteger = new AtomicInteger(5);        System.out.println(atomicInteger.compareAndSet(5,50));&#125;

AtomicInteger有一个compareAndSet方法，有两个操作数，第一个是期望值，第二个是希望修改成的值。首先初始值是5，第一次调用compareAndSet方法的时候，将5拷贝回自己的工作空间，然后改成50，写回到主内存中的时候，它期望主内存中的值是5，而这时确实也是5，所以可以修改成功，主内存中的值也变成了50，输出true。第二次调用compareAndSet的时候，在自己的工作内存将值修改成100，写回去的时候，希望主内存中的值是5，但是此时是50，所以set失败，输出false。这就是比较并交换，也即CAS。
工作原理简而言之，CAS工作原理就是UnSafe类和自旋锁。
1、UnSafe类： UnSafe类在jdk的rt.jar下面的一个类，全包名是sun.misc.UnSafe。这个类大多数方法都是native方法。由于Java不能操作计算机系统，所以设计之初就留了一个UnSafe类。通过UnSafe类，Java就可以操作指定内存地址的数据。调用UnSafe类的CAS，JVM会帮我们实现出汇编指令，从而实现原子操作。现在就来分析一下AtomicInteger的getAndIncrement方法是怎么工作的。看下面的代码：
public final int getAndIncrement() &#123;    return U.getAndAddInt(this, VALUE, 1);&#125;@HotSpotIntrinsicCandidatepublic final int getAndAddInt(Object o, long offset, int delta) &#123;    int v;    do &#123;        v = getIntVolatile(o, offset);    &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta));    return v;&#125;

这里的o就是当前对象，offset是内存地址，delta是1，也就是自增步伐。首先把当前对象主内存中的值赋给v，然后进入while循环。判断当前对象此刻主内存中的值是否等于v，如果是，就自增，否则继续循环，重新获取v的值。这里的compareAndSwapInt方法就是一个native方法，这个方法汇编之后是CPU原语指令，原语指令是连续执行不会被打断的，所以可以保证原子性。
2、自旋锁：所谓的自旋，其实就是上面getAndAddInt方法中的do while循环操作。当预期值和主内存中的值不等时，就重新获取主内存中的值，这就是自旋。
缺点1、循环时间长，开销大。 synchronized是加锁，同一时间只能一个线程访问，并发性不好。而CAS并发性提高了，但是由于CAS存在自旋操作，即do while循环，如果CAS失败，会一直进行尝试。如果CAS长时间不成功，会给CPU带来很大的开销。
2、只能保证一个共享变量的原子性。 上面也看到了，getAndAddInt方法的o是代表当前对象，所以它也就是能保证这一个共享变量的原子性。如果要保证多个，那只能加锁了。
3、引来的ABA问题。

什么是ABA问题？

假设现在主内存中的值是A，现有t1和t2两个线程去对其进行操作。t1和t2先将A拷贝回自己的工作内存。这个时候t2线程将A改成B，刷回到主内存。此刻主内存和t2的工作内存中的值都是B。接下来还是t2线程抢到执行权，t2又把B改回A，并刷回到主内存。这时t1终于抢到执行权了，自己工作内存中的值的A，主内存也是A，因此它认为没人修改过，就在工作内存中把A改成了X，然后刷回主内存。也就是说，在t1线程执行前，t2将主内存中的值由A改成B再改回A。这便是ABA问题。看下面的代码演示(代码涉及到原子引用，请参考下面的原子引用的介绍)：
class ABADemo &#123;   static AtomicReference&lt;String&gt; atomicReference = new AtomicReference&lt;&gt;(&quot;A&quot;);   public static void main(String[] args)&#123;          new Thread(() -&gt; &#123;              atomicReference.compareAndSet(&quot;A&quot;,&quot;B&quot;);              atomicReference.compareAndSet(&quot;B&quot;,&quot;A&quot;);              &#125;,&quot;t2&quot;).start();          new Thread(() -&gt; &#123;              try &#123;                    TimeUnit.SECONDS.sleep(1);              &#125; catch (InterruptedException e) &#123;                   e.printStackTrace();               &#125;              System.out.println(atomicReference.compareAndSet(&quot;A&quot;,&quot;C&quot;)                                            + &quot;\t&quot; + atomicReference.get());              &#125;,&quot;t1&quot;).start();   &#125;&#125;

这段代码执行结果是”true C”，这就证明了ABA问题的存在。如果一个业务只管开头和结果，不管这个A中间是否变过，那么出现了ABA问题也没事。如果需要A还是最开始的那个A，中间不许别人动手脚，那么就要规避ABA问题。要解决ABA问题，先看下面的原子引用的介绍。

原子引用：

JUC包下给我们提供了原子包装类，像AtomicInteger。如果我不仅仅想要原子包装类，我自己定义的User类也想具有原子操作，怎么办呢？JUC为我们提供了AtomicReference，即原子引用。看下面的代码：
@AllArgsConstructorclass User &#123;    int age;    String name;    public static void main(String[] args)&#123;        User user = new User(20,&quot;张三&quot;);        AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;();        atomicReference.set(user);    &#125;&#125;

像这样，就把User类变成了原子User类了。

解决ABA问题思路：

我们可以这个共享变量带上一个版本号。比如现在主内存中的是A，版本号是1，然后t1和t2线程拷贝一份到自己工作内存。t2将A改为B，刷回主内存。此时主内存中的是B，版本号为2。然后再t2再改回A，此时主内存中的是A，版本号为3。这个时候t1线程终于来了，自己工作内存是A，版本号是1，主内存中是A，但是版本号为3，它就知道已经有人动过手脚了。那么这个版本号从何而来，这就要说说AtomicStampedReference这个类了。

带时间戳的原子引用(AtomicStampedReference)：这个时间戳就理解为版本号就行了。看如下代码：

class ABADemo &#123;    static AtomicStampedReference&lt;String&gt; atomicReference = new AtomicStampedReference&lt;&gt;(&quot;A&quot;, 1);    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            try &#123;                TimeUnit.SECONDS.sleep(1); // 睡一秒，让t1线程拿到最初的版本号            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            atomicReference.compareAndSet(&quot;A&quot;, &quot;B&quot;, atomicReference.getStamp(), atomicReference.getStamp() + 1);            atomicReference.compareAndSet(&quot;B&quot;, &quot;A&quot;, atomicReference.getStamp(), atomicReference.getStamp() + 1);        &#125;, &quot;t2&quot;).start();        new Thread(() -&gt; &#123;            int stamp = atomicReference.getStamp(); // 拿到最开始的版本号            try &#123;                TimeUnit.SECONDS.sleep(3); // 睡3秒，让t2线程的ABA操作执行完            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(atomicReference.compareAndSet(&quot;A&quot;, &quot;C&quot;, stamp, stamp + 1));        &#125;, &quot;t1&quot;).start();    &#125;&#125;

初始版本号为1，t2线程每执行一次版本号加。等t1线程执行的时候，发现当前版本号不是自己一开始拿到的1了，所以set失败，输出false。这就解决了ABA问题。
总结
什么是CAS?  —— 比较并交换，主内存值和工作内存值相同，就set为更新值。
CAS原理是什么？ —— UnSafe类和自旋锁。理解那个do while循环。
CAS缺点是什么？ —— 循环时间长会消耗大量CPU资源；只能保证一个共享变量的原子性操作；造成ABA问题。
什么是ABA问题？ —— t2线程先将A改成B，再改回A，此时t1线程以为没人修改过。
如何解决ABA问题？—— 使用带时间戳的原子引用。

重排序定义所谓的重排序，英文记作Reorder，是指编译器和Java虚拟机通过改变程序的处理顺序来优化程序。虽然重排序被广泛用于提高性能，不过开发人员几乎不会意识到这一点。实际上，在运行单线程程序时我们无法判断是否进行了重排序。这是因为，虽然处理顺序改变了，但是规范上有很多限制可以避免程序出现运行错误。

没有同步的状态为“存在数据竞争”。

示例代码

重排序可能导致x&lt;y


public class Something &#123;    private int x = 0;    private int y = 0;    public void write() &#123;        x = 100;        y = 50;    &#125;    public void read() &#123;        if (x &lt; y) &#123;            System.out.println(&quot;x &lt; y&quot;);        &#125; else &#123;            System.out.println(&quot;x &gt; y&quot;);        &#125;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        final Something obj = new Something();        // 写数据的线程A        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                obj.write();            &#125;        &#125;).start();        // 读数据的线程B        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                obj.read();            &#125;        &#125;).start();    &#125;&#125;

可见性定义假设线程A将某个值写入了字段X中，而线程B读取到了该值。我们称其为“线程A向X的写值对线程B是可见的（visible）”。“是否是可见的”这个性质就成为可见性，英文记作visibility。
共享内存（堆）定义共享内存是所有线程共享的存储空间，也被称为堆内存（heap memory）。因为实例会被全部保存在共享内存中，所以实例中的字段也存在于共享内存中。此外，数据的元素也被保存在共享内存中。也就是说，可以使用new在共享内存中分配存储空间。
局部变量不会被保存在共享内存中。通常，除局部变量外，方法的形参，catch语句块中编写的异常处理器的参数等也不会被保存在共享内存中，而是被保存在各个线程特有的栈中。
synchronizedsynchronized（lock&#x2F;unlock操作）并不仅仅进行线程的互斥处理。Java内存模型确保了某个线程在进行unlockM操作前进行的所有写入操作对进行lockM操作的线程都是可见的。



进行unlock操作后，写入缓存中的内容会被强制地写入共享内存中
进行lock操作后，缓存中的内容会先失效，然后共享内存中的最新内存会被强制重新读取到缓存中

volatilevolatile write操作时是一种release，而volatile read操作是一种acquire。



release
acquire



volatile write
volatile read


unlock
lock


线程的启动（start）
线程启动后的第一个操作


线程终止前的最后一个操作
检测线程的终止（join、isAlive）


中断（interrupt）
检测中断（isInterrupted、Thread.interrupted、InterruptException）


向字段写入默认值
线程的第一个操作



volatile字段的赋值语句的位置很重要
volatile字段放在最后才可以保证上面声明的变量的值能够被写入主内存。

volatile不会进行线程的互斥处理
访问volatile字段的线程不会进入等待队列。

访问volatile字段会产生性能开销
访问volatile字段与synchronized的处理耗费的时间几乎相同。



对long和double的原子操作
Java规范无法确保对long和double的赋值操作的原子性。但是，即使是long和double的字段，只要它是volatile字段，就可以确保赋值操作的原子性。

final使用final关键字声明的字段（final字段）只能被初始化一次。
final字段的初始化只能在“字段声明时”或是“构造函数中”进行。那么，当final字段的初始化结束后，无论在任何时候，它的值对其他线程都是可见的（变成visible）。Java内存模型可以确保被初始化后的final字段在构造函数的处理结束后是可见的。
Java内存模型可以确保final字段在构造函数执行结束后可以正确的被看到。这样就不再需要通过synchronized和volatile进行同步了。
位移


操作符
补齐方式
结果符号



&lt;&lt;
右边用 0 补齐
和原操作数没有绝对关系，取决于左移后符号位。


&gt;&gt;
左边有原符号位补齐
和原操作数有相同符号。


&gt;&gt;&gt;
左边用 0 补齐
和原操作数无关，一直为正数。


Java 常见的七大设计原则Java常见的设计开发原则，能够帮助我们更好的理解软件设计的方式方法，更方便进行代码的维护以及写出高质量的代码。
1. 开闭原则对扩展开放，对修改关闭。尽量不要修改已有的能够稳定运行的代码，在原有的基础上进行拓展，增加新的功能，避免影响原有功能。
2. 单一职责原则一个类尽量实现一种功能或者提供一种服务。如果类里包含的功能特别多，在后面需要扩展或者修改的时候就要重新修改该类，容易影响代码的稳定性，维护起来也不方便。
3. 迪米特原则也叫最小知道原则，即如果某类A与类B可以没有直接的联系，尽量不要在A中出现B类。这样能够减少代码的耦合度，提高代码的健壮性。
4. 接口隔离原则客户端尽量不要依赖它不需要的接口，在设计接口的时候尽量方法少一些，不要建立非常臃肿的接口。接口功能越细化，系统的灵活性就越高，但是也不能越少越好，尽量细化接口及其方法即可。
5. 里氏替换原则即在任何出现父类的地方，都可以用自子类替代。只有这样，基类才能够被复用，这也是开闭原则的补充。子类可以在父类的基础上扩展新的功能。反过来，在使用子类的地方不能使用父类，因为父类不一定具有子类的新功能。
6. 依赖倒置原则即程序要依赖抽象，而不是依赖实现。这要去我们的在代码方法的参数或者对象关联时，尽量用高层次的抽象类，而不是具体的实现类。其本质就是面向接口编程。
7. 聚合&#x2F;组合复用原则即尽量用聚合&#x2F;组合的方式去复用功能，尽量不要通过继承来达到复用的功能。因为继承关系中，如果基类的功能需要修改，那么子类的功能也可能受到影响。如果使用聚合&#x2F;组合的关系，类的关系不像继承那样耦合度那么高，而且聚合&#x2F;组合可以在运行时动态的进行，新对象可以动态的引用与原有类同样功能的其他对象。
初始化顺序对于一个类而言，按照如下顺序执行：

执行静态代码块
执行构造代码块
执行构造函数

对于静态变量、静态初始化块、变量、初始化块、构造器，它们的初始化顺序依次是（静态变量、静态初始化块）&gt;（变量、初始化块）&gt; 构造器
当涉及到继承时，按照如下顺序执行：

执行父类的静态代码块，并初始化父类静态成员变量
执行子类的静态代码块，并初始化子类静态成员变量
执行父类的构造代码块，执行父类的构造函数，并初始化父类普通成员变量
执行子类的构造代码块， 执行子类的构造函数，并初始化子类普通成员变量



生成实例的方法
new
clone
newInstance

运算符


运算符
含义



&amp;（按位与）
1&amp;1&#x3D;1 , 1&amp;0&#x3D;0 , 0&amp;1&#x3D;0 , 0&amp;0&#x3D;0


|（按位或）
1|1&#x3D;1 , 1|0&#x3D;1 , 0|1&#x3D;1 , 0|0&#x3D;0


^（异或运算符）
1^0 &#x3D; 1 , 1^1 &#x3D; 0 , 0^1 &#x3D; 1 , 0^0 &#x3D; 0


]]></content>
      <categories>
        <category>Java</category>
        <category>Java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud 组件概念</title>
    <url>/posts/b27a891c/</url>
    <content><![CDATA[概念Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 Spring Cloud正是对Netflix的多个开源组件进一步的封装而成，同时又实现了和云端平台，和Spring Boot开发框架很好的集成。 Spring Cloud是一个相对比较新的微服务框架，2016年才推出1.0的release版本. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。 Spring Cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全居琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用、同时能够快速和云平台资源进行对接。




从上图可以看出Spring Cloud各个组件相互配合，合作支持了一套完整的微服务架构。

其中Eureka负责服务的注册与发现，很好将各服务连接起来
Hystrix 负责监控服务之间的调用情况，连续多次失败进行熔断保护。
Hystrix dashboard,Turbine 负责监控 Hystrix的熔断情况，并给予图形化的展示
Spring Cloud Config 提供了统一的配置中心服务
当配置文件发生变化的时候，Spring Cloud Bus 负责通知各服务去获取最新的配置信息
所有对外的请求和服务，我们都通过Zuul来进行转发，起到API网关的作用
最后我们使用Sleuth+Zipkin将所有的请求数据记录下来，方便我们进行后续分析

组成Spring Cloud的子项目，大致可分成两类，一类是对现有成熟框架”Spring Boot化”的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream扮演的就是kafka, ActiveMQ这样的角色。对于我们想快速实践微服务的开发者来说，第一类子项目就已经足够使用，如：Spring Cloud Netflix，是对Netflix开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST客户端、请求路由等。该项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。 通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。
Eureka 服务发现涉及注解：@EnableEurekaServer、@EnableEurekaClient




Eureka两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。
Ribbon 客户端负载均衡涉及注解：@LoadBalanced、@RibbonClient(配置)


Ribbon，主要提供客户侧的软件负载均衡算法。 Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略：

轮询策略（RoundRobinRule）
轮询策略理解起来比较简单，就是拿到所有的server集合，然后根据id进行遍历。这里的id是ip+端口，Server实体类中定义的id属性如下：

随机策略（RandomRule）
随机策略：使用jdk自带的随机数生成工具，生成一个随机数，然后去可用服务列表中拉取服务节点Server。如果当前节点不可用，则进入下一轮随机策略，直到选到可用服务节点为止。

可用过滤策略（AvailabilityFilteringRule）
策略描述：过滤掉连接失败的服务节点，并且过滤掉高并发的服务节点，然后从健康的服务节点中，使用轮询策略选出一个节点返回。

响应时间权重策略（WeightedResponseTimeRule）
策略描述：根据响应时间，分配一个权重weight，响应时间越长，weight越小，被选中的可能性越低。

轮询失败重试策略（RetryRule）
轮询失败重试策略（RetryRule）是这样工作的，首先使用轮询策略进行负载均衡，如果轮询失败，则再使用轮询策略进行一次重试，相当于重试下一个节点，看下一个节点是否可用，如果再失败，则直接返回失败。

并发量最小可用策略（BestAvailableRule）
选择一个并发量最小的server返回。如何判断并发量最小呢？ServerStats有个属性activeRequestCount，这个属性记录的就是server的并发量。轮询所有的server，选择其中activeRequestCount最小的那个server，就是并发量最小的服务节点。

ZoneAvoidanceRule
复合判断server所在区域的性能和server的可用性，来选择server返回。


综述负载均衡策略如下：

轮询策略
随机策略
可用过滤策略
响应时间权重策略
轮询失败重试策略
并发量最小可用策略

Ribbon中还包括以下功能：

易于与服务发现组件（比如Netflix的Eureka）集成
使用Archaius完成运行时配置
使用JMX暴露运维指标，使用Servo发布
多种可插拔的序列化选择
异步和批处理操作（即将推出）
自动SLA框架（即将推出）
系统管理&#x2F;指标控制台（即将推出）

ribbon架构示例



一个服务注册中心，eureka server,端口为8761
service-hi工程跑了两个实例，端口分别为8762,8763，分别向服务注册中心注册
sercvice-ribbon端口为8764,向服务注册中心注册
当sercvice-ribbon通过restTemplate调用service-hi的hi接口时，因为用ribbon进行了负载均衡，会轮流的调用service-hi：8762和8763 两个端口的hi接口；

Config Server涉及注解：@EnableConfigServer
俗称的配置中心，配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。



将配置信息中央化保存, 配置Spring Cloud Bus可以实现动态修改配置文件。这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。



Spring Cloud Config就是我们通常意义上的配置中心。Spring Cloud Config-把应用原本放在本地文件的配置抽取出来放在中心服务器，本质是配置信息从本地迁移到云端。从而能够提供更好的管理、发布能力。 Spring Cloud Config分服务端和客户端，服务端负责将git（svn）中存储的配置文件发布成REST接口，客户端可以从服务端REST接口获取配置。但客户端并不能主动感知到配置的变化，从而主动去获取新的配置，这需要每个客户端通过POST方法触发各自的&#x2F;refresh。
Hystrix 熔断器涉及注解：@HystrixCommad(fallback&#x3D;”方法名”)、结合@FeignClient(fallbackFactory&#x3D;xxx.class)
熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。


断路器(Cricuit Breaker)是一种能够在远程服务不可用时自动熔断(打开开关)，并在远程服务恢复时自动恢复(闭合开关)的设施，Spring Cloud通过Netflix的Hystrix组件提供断路器、资源隔离与自我修复功能。
断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期，而它确定该故障是持久的。断路器模式也使应用程序能够检测故障是否已经解决。如果问题似乎已经得到纠正，应用程序可以尝试调用操作。




断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响。它可以帮助快速地拒绝对一个操作，即很可能失败，而不是等待操作超时（或者不返回）的请求，以保持系统的响应时间。如果断路器提高每次改变状态的时间的事件，该信息可以被用来监测由断路器保护系统的部件的健康状况，或以提醒管理员当断路器跳闸，以在打开状态。










Netflix开源了Hystrix组件，实现了断路器模式，SpringCloud对这一组件进行了整合。 在微服务架构中，一个请求需要调用多个服务是非常常见的，如下图：




较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值（Hystric 是5秒20次） 断路器将会被打开。




断路打开后，可用避免连锁故障，fallback方法可以直接返回一个固定值。
在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。
如下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。




在这种情况下就需要整个服务机构具有故障隔离的功能，避免某一个服务挂掉影响全局。在Spring Cloud 中Hystrix组件就扮演这个角色。 Hystrix会在某个服务连续调用N次不响应的情况下，立即通知调用端调用失败，避免调用端持续等待而影响了整体服务。Hystrix间隔时间会再次检查此服务，如果服务恢复将继续提供服务。
Hystrix Dashboard和Turbine 当熔断发生的时候需要迅速的响应来解决问题，避免故障进一步扩散，那么对熔断的监控就变得非常重要。熔断的监控现在有两款工具：Hystrix-dashboard和Turbine
Hystrix-dashboard是一款针对Hystrix进行实时监控的工具，通过Hystrix Dashboard我们可以直观地看到各Hystrix Command的请求响应时间, 请求成功率等数据。但是只使用Hystrix Dashboard的话, 你只能看到单个应用内的服务信息, 这明显不够. 我们需要一个工具能让我们汇总系统内多个服务的数据并显示到Hystrix Dashboard上, 这个工具就是Turbine. 监控的效果图如下：


Zuul 服务网关，智能路由涉及注解：@EnableZuulProxy
在微服务架构模式下，后端服务的实例数一般是动态的，对于客户端而言很难发现动态改变的服务实例的访问地址信息。因此在基于微服务的项目中为了简化前端的调用逻辑，通常会引入API Gateway作为轻量级网关，同时API Gateway中也会实现相关的认证逻辑从而简化内部服务之间相互调用的复杂度。




Spring Cloud体系中支持API Gateway落地的技术就是Zuul。Spring Cloud Zuul路由是微服务架构中不可或缺的一部分，提供动态路由，监控，弹性，安全等的边缘服务。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。
它的具体作用就是服务转发，接收并转发所有内外部的客户端调用。使用Zuul可以作为资源的统一访问入口，同时也可以在网关做一些权限校验等类似的功能。
Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。










类似Nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。
Netflix Archaius



配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置，原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。
Bus



事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。相当于水浒传中日行八百里的神行太保戴宗，确保各个小弟之间消息保持畅通。
分布式消息队列，是对Kafka, MQ的封装；事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。 Spring cloud bus被国内很多都翻译为消息总线，也挺形象的。大家可以将它理解为管理和传播所有分布式项目中的消息既可，其实本质是利用了MQ的广播机制在分布式的系统中传播消息，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。




根据此图我们可以看出利用Spring Cloud Bus做配置更新的步骤:

提交代码触发post给客户端A发送bus&#x2F;refresh
客户端A接收到请求从Server端更新配置并且发送给Spring Cloud Bus
Spring Cloud bus接到消息并通知给其它客户端
其它客户端接收到通知，请求Server端获取最新配置
全部客户端均获取到最新的配置

Security



对Spring Security的封装，并能配合Netflix使用，安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 基于spring security的安全工具包，为你的应用程序添加安全控制
Zookeeper



对Zookeeper的封装，使之能配置其它Spring Cloud的子项目使用；操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 操作Zookeeper的工具包，用于使用zookeeper方式的服务发现和配置管理，抱了Zookeeper的大腿。
Stream



数据流；数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的／工业级spring应用，使用spring integration提供与消息代理之间的连接。数据流操作开发包，封装了与Redis、Rabbit、Kafka等发送接收消息。 一个业务会牵扯到多个任务，任务之间是通过事件触发的。
Sleuth



随着服务的越来越多，对调用链的分析会越来越复杂，如服务之间的调用关系、某个请求对应的调用链、调用之间消费的时间等，对这些信息进行监控就成为一个问题。在实际的使用中我们需要监控服务和服务之间通讯的各项指标，这些数据将是我们改进系统架构的主要依据。因此分布式的链路跟踪就变的非常重要，Spring Cloud也给出了具体的解决方案：Spring Cloud Sleuth和Zipkin。
服务跟踪；日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。
简介
Spring Cloud Sleuth 主要功能就是在分布式系统中提供追踪解决方案，并且兼容支持了 zipkin，你只需要在pom文件中引入相应的依赖即可。
服务追踪分析
微服务架构上通过业务来划分服务的，通过REST调用，对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂。




随着服务的越来越多，对调用链的分析会越来越复杂。它们之间的调用关系也许如下：




术语

Span：基本工作单元，例如，在一个新建的span中发送一个RPC等同于发送一个回应请求给RPC，span通过一个64位ID唯一标识，trace以另一个64位ID表示，span还有其他数据信息，比如摘要、时间戳事件、关键值注释(tags)、span的ID、以及进度ID(通常是IP地址) span在不断的启动和停止，同时记录了时间信息，当你创建了一个span，你必须在未来的某个时刻停止它。
Trace：一系列spans组成的一个树状结构，例如，如果你正在跑一个分布式大数据工程，你可能需要创建一个trace。
Annotation：用来及时记录一个事件的存在，一些核心annotations用来定义一个请求的开始和结束 cs - Client Sent -客户端发起一个请求，这个annotion描述了这个span的开始 sr - Server Received -服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳便可得到网络延迟 ss - Server Sent -注解表明请求处理的完成(当请求返回客户端)，如果ss减去sr时间戳便可得到服务端需要的处理请求时间 cr - Client Received -表明span的结束，客户端成功接收到服务端的回复，如果cr减去cs时间戳便可得到客户端从服务端获取回复的所有所需时间 将Span和Trace在一个系统中使用Zipkin注解的过程图形化：





Feign 使用HTTP请求远程服务涉及注解：@FeignClient(“微服务名称”)　　注：此注解用于接口




在Spring Cloud Netflix栈中，各个微服务都是以HTTP接口的形式暴露自身服务的，因此在调用远程服务时就必须使用HTTP客户端。我们可以使用JDK原生的URLConnection、Apache的Http Client、Netty的异步HTTP Client, Spring的RestTemplate。但是，用起来最方便、最优雅的还是要属Feign了。 Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 我们可以做到使用HTTP请求远程服务时能与调用本地方法一样的编码体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。 通过Feign， 我们能把HTTP远程调用对开发者完全透明，得到与调用本地方法一致的编码体验。这一点与阿里Dubbo中暴露远程服务的方式类似，区别在于Dubbo是基于私有二进制协议，而Feign本质上还是个HTTP客户端。如果是在用Spring Cloud Netflix搭建微服务，那么Feign无疑是最佳选择。
Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果。
简而言之：

Feign 采用的是基于接口的注解
Feign 整合了ribbon

Cloud Foundry



Cloud Foundry是VMware推出的业界第一个开源PaaS云平台，它支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题 其实就是与CloudFoundry进行集成的一套解决方案，抱了Cloud Foundry的大腿。
Cluster



Spring Cloud Cluster将取代Spring Integration。提供在分布式系统中的集群所需要的基础功能支持，如：选举、集群的状态一致性、全局锁、tokens等常见状态模式的抽象和实现。 如果把不同的帮派组织成统一的整体，Spring Cloud Cluster已经帮你提供了很多方便组织成统一的工具。
Spring Cloud Consul



Consul 是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件,由 HashiCorp 公司用 Go 语言开发, 基于 Mozilla Public License 2.0 的协议进行开源. Consul 支持健康检查,并允许 HTTP 和 DNS 协议调用 API 存储键值对. Spring Cloud Consul 封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。
Data Flow



Data flow 是一个用于开发和执行大范围数据处理其模式包括ETL，批量运算和持续运算的统一编程模型和托管服务。 对于在现代运行环境中可组合的微服务程序来说，Spring Cloud data flow是一个原生云可编配的服务。使用Spring Cloud data flow，开发者可以为像数据抽取，实时分析，和数据导入&#x2F;导出这种常见用例创建和编配数据通道 （data pipelines）。 Spring Cloud data flow 是基于原生云对 spring XD的重新设计，该项目目标是简化大数据应用的开发。Spring XD 的流处理和批处理模块的重构分别是基于 spring boot的stream 和 task&#x2F;batch 的微服务程序。这些程序现在都是自动部署单元而且他们原生的支持像 Cloud Foundry、Apache YARN、Apache Mesos和Kubernetes 等现代运行环境。 Spring Cloud data flow 为基于微服务的分布式流处理和批处理数据通道提供了一系列模型和最佳实践。
Task



Spring Cloud Task 主要解决短命微服务的任务管理，任务调度的工作，比如说某些定时任务晚上就跑一次，或者某项数据分析临时就跑几次。
Spring Cloud Connectors



Spring Cloud Connectors 简化了连接到服务的过程和从云平台获取操作的过程，有很强的扩展性，可以利用Spring Cloud Connectors来构建你自己的云平台。 便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。
Starters



Spring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。
3.20、Spring Cloud CLI




基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。
Netflix Turbine



Turbine是聚合服务器发送事件流数据的一个工具，用来监控集群下hystrix的metrics情况。
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring 启动流程</title>
    <url>/posts/2547f24d/</url>
    <content><![CDATA[目录springboot 启动过程每个SpringBoot程序都有一个主入口，也就是main方法，main里面调用SpringApplication.run()启动整个spring-boot程序，该方法所在类需要使用@SpringBootApplication注解，以及@ImportResource注解(if need)，@SpringBootApplication包括三个注解，功能如下：@EnableAutoConfiguration：SpringBoot根据应用所声明的依赖来对Spring框架进行自动配置@SpringBootConfiguration(内部为@Configuration)：被标注的类等于在spring的XML配置文件中(applicationContext.xml)，装配所有bean事务，提供了一个spring的上下文环境
@ComponentScan：组件扫描，可自动发现和装配Bean，默认扫描SpringApplication的run方法里的Booter.class所在的包路径下文件，所以最好将该启动类放到根包路径下| 
SpringBoot启动类
首先进入run方法


run方法中去创建了一个SpringApplication实例，在该构造方法内，我们可以发现其调用了一个初始化的initialize方法


这里主要是为SpringApplication对象赋一些初值。构造函数执行完毕后，我们回到run方法


该方法中实现了如下几个关键步骤：
1.创建了应用的监听器SpringApplicationRunListeners并开始监听
2.加载SpringBoot配置环境(ConfigurableEnvironment)，如果是通过web容器发布，会加载StandardEnvironment，其最终也是继承了ConfigurableEnvironment，类图如下


可以看出，*Environment最终都实现了PropertyResolver接口，我们平时通过environment对象获取配置文件中指定Key对应的value方法时，就是调用了propertyResolver接口的getProperty方法
3.配置环境(Environment)加入到监听器对象中(SpringApplicationRunListeners)
4.创建run方法的返回对象：ConfigurableApplicationContext(应用配置上下文)，我们可以看一下创建方法：
，如果不存在，再加载默认的环境配置（通过是否是web environment判断），默认选择AnnotationConfigApplicationContext注解上下文（通过扫描所有注解类来加载bean），最后通过BeanUtils实例化上下文对象，并返回，ConfigurableApplicationContext类图如下：
主要看其继承的两个方向：

LifeCycle：生命周期类，定义了start启动、stop结束、isRunning是否运行中等生命周期空值方法
ApplicationContext：应用上下文类，其主要继承了beanFactory(bean的工厂类)
5.回到run方法内，prepareContext方法将listeners、environment、applicationArguments、banner等重要组件与上下文对象关联
6.接下来的refreshContext(context)方法(初始化方法如下)将是实现spring-boot-starter-*(mybatis、redis等)自动化配置的关键，包括spring.factories的加载，bean的实例化等核心工作。


refresh方法
配置结束后，Springboot做了一些基本的收尾工作，返回了应用环境上下文。回顾整体流程，Springboot的启动，主要创建了配置环境(environment)、事件监听(listeners)、应用上下文(applicationContext)，并基于以上条件，在容器中开始实例化我们需要的Bean，至此，通过SpringBoot启动的程序已经构造完成，接下来我们来探讨自动化配置是如何实现。
自动化配置之前的启动结构图中，我们注意到无论是应用初始化还是具体的执行过程，都调用了SpringBoot自动配置模块
SpringBoot自动配置模块

该配置模块的主要使用到了SpringFactoriesLoader，即Spring工厂加载器，该对象提供了loadFactoryNames方法，入参为factoryClass和classLoader，即需要传入上图中的工厂类名称和对应的类加载器，方法会根据指定的classLoader，加载该类加器搜索路径下的指定文件，即spring.factories文件，传入的工厂类为接口，而文件中对应的类则是接口的实现类，或最终作为实现类，所以文件中一般为如下图这种一对多的类名集合，获取到这些实现类的类名后，loadFactoryNames方法返回类名集合，方法调用方得到这些集合后，再通过反射获取这些类的类对象、构造方法，最终生成实例

工厂接口与其若干实现类接口名称
下图有助于我们形象理解自动配置流程
SpringBoot自动化配置关键组件关系图

mybatis-spring-boot-starter、spring-boot-starter-web等组件的META-INF文件下均含有spring.factories文件，自动配置模块中，SpringFactoriesLoader收集到文件中的类全名并返回一个类全名的数组，返回的类全名通过反射被实例化，就形成了具体的工厂实例，工厂实例来生成组件具体需要的bean。
之前我们提到了EnableAutoConfiguration注解，其类图如下
，重点关注一下AutoConfigurationImportSelector的selectImports方法

该方法在springboot启动流程——bean实例化前被执行，返回要实例化的类信息列表。我们知道，如果获取到类信息，spring自然可以通过类加载器将类加载到jvm中，现在我们已经通过spring-boot的starter依赖方式依赖了我们需要的组件，那么这些组建的类信息在select方法中也是可以被获取到的，不要急我们继续向下分析
该方法中的getCandidateConfigurations方法，通过方法注释了解到，其返回一个自动配置类的类名列表，方法调用了loadFactoryNames方法，查看该方法

到项目系统路径下所有的spring.factories文件中找到相应的key，从而加载里面的类。我们就选取这个mybatis-spring-boot-autoconfigure下的spring.factories文件
进入org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration中，主要看一下类头

发现@Spring的Configuration，俨然是一个通过注解标注的springBean，继续向下看，
@ConditionalOnClass({ SqlSessionFactory.class, SqlSessionFactoryBean.class})这个注解的意思是：当存在SqlSessionFactory.class, SqlSessionFactoryBean.class这两个类时才解析MybatisAutoConfiguration配置类,否则不解析这一个配置类，make sence，我们需要mybatis为我们返回会话对象，就必须有会话工厂相关类
@CondtionalOnBean(DataSource.class):只有处理已经被声明为bean的dataSource
@ConditionalOnMissingBean(MapperFactoryBean.class)这个注解的意思是如果容器中不存在name指定的bean则创建bean注入，否则不执行（该类源码较长，篇幅限制不全粘贴）
以上配置可以保证sqlSessionFactory、sqlSessionTemplate、dataSource等mybatis所需的组件均可被自动配置，@Configuration注解已经提供了Spring的上下文环境，所以以上组件的配置方式与Spring启动时通过mybatis.xml文件进行配置起到一个效果。通过分析我们可以发现，只要一个基于SpringBoot项目的类路径下存在SqlSessionFactory.class, SqlSessionFactoryBean.class，并且容器中已经注册了dataSourceBean，就可以触发自动化配置，意思说我们只要在maven的项目中加入了mybatis所需要的若干依赖，就可以触发自动配置，但引入mybatis原生依赖的话，每集成一个功能都要去修改其自动化配置类，那就得不到开箱即用的效果了。所以Spring-boot为我们提供了统一的starter可以直接配置好相关的类，触发自动配置所需的依赖(mybatis)如下：

这里是截取的mybatis-spring-boot-starter的源码中pom.xml文件中所有依赖:
]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title>CountDownLatch 应用</title>
    <url>/posts/18ad812a/</url>
    <content><![CDATA[CountDownLatch 应用应用例子1CountDownLatch latch = new CountDownLatch(3);ExecutorService service = Executors.newFixedThreadPool(4);service.submit(() -&gt; &#123;    log.debug(&quot;begin...&quot;);    sleep(1);    latch.countDown();    log.debug(&quot;end...&#123;&#125;&quot;, latch.getCount());&#125;);service.submit(() -&gt; &#123;    log.debug(&quot;begin...&quot;);    sleep(1.5);    latch.countDown();    log.debug(&quot;end...&#123;&#125;&quot;, latch.getCount());&#125;);service.submit(() -&gt; &#123;    log.debug(&quot;begin...&quot;);    sleep(2);    latch.countDown();    log.debug(&quot;end...&#123;&#125;&quot;, latch.getCount());&#125;);service.submit(()-&gt;&#123;    try &#123;        log.debug(&quot;waiting...&quot;);        latch.await();        log.debug(&quot;wait end...&quot;);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;&#125;);

结果
22:50:55.958 c.TestCountDownLatch [main] - waiting...22:50:55.958 c.TestCountDownLatch [Thread-0] - begin...22:50:55.958 c.TestCountDownLatch [Thread-1] - begin...22:50:55.958 c.TestCountDownLatch [Thread-2] - begin...22:50:56.963 c.TestCountDownLatch [Thread-0] - end...222:50:57.463 c.TestCountDownLatch [Thread-2] - end...122:50:57.964 c.TestCountDownLatch [Thread-1] - end...022:50:57.964 c.TestCountDownLatch [main] - wait end...Process finished with exit code 0

例子2模拟王者农药多人游戏加载进度
AtomicInteger num = new AtomicInteger(0);ExecutorService service = Executors.newFixedThreadPool(10, (r) -&gt; &#123;    return new Thread(r, &quot;t&quot; + num.getAndIncrement());&#125;);CountDownLatch latch = new CountDownLatch(10);String[] all = new String[10];Random r = new Random();for (int j = 0; j &lt; 10; j++) &#123;    int x = j;    service.submit(() -&gt; &#123;        for (int i = 0; i &lt;= 100; i++) &#123;            try &#123;                Thread.sleep(r.nextInt(100));            &#125; catch (InterruptedException e) &#123;            &#125;            all[x] = Thread.currentThread().getName() + &quot;(&quot; + (i + &quot;%&quot;) + &quot;)&quot;;            System.out.print(&quot;\r&quot; + Arrays.toString(all));        &#125;        latch.countDown();    &#125;);&#125;latch.await();System.out.println(&quot;\n游戏开始...&quot;);service.shutdown();

结果
[t0(100%), t1(100%), t2(100%), t3(100%), t4(100%), t5(100%), t6(100%), t7(100%), t8(100%), t9(100%)]游戏开始...Process finished with exit code 0

例子3多个远程接口调用


RestTemplate restTemplate = new RestTemplate();log.debug(&quot;begin&quot;);ExecutorService service = Executors.newCachedThreadPool();CountDownLatch latch = new CountDownLatch(4);Future&lt;Map&lt;String,Object&gt;&gt; f1 = service.submit(() -&gt; &#123;    Map&lt;String, Object&gt; response = restTemplate.getForObject(&quot;http://localhost:8080/order/&#123;1&#125;&quot;, Map.class, 1);    latch.countDown();    return response;&#125;);Future&lt;Map&lt;String, Object&gt;&gt; f2 = service.submit(() -&gt; &#123;    Map&lt;String, Object&gt; response = restTemplate.getForObject(&quot;http://localhost:8080/product/&#123;1&#125;&quot;, Map.class, 1);    latch.countDown();    return response;&#125;);Future&lt;Map&lt;String, Object&gt;&gt; f3 = service.submit(() -&gt; &#123;    Map&lt;String, Object&gt; response = restTemplate.getForObject(&quot;http://localhost:8080/product/&#123;1&#125;&quot;, Map.class, 2);    latch.countDown();    return response;&#125;);Future&lt;Map&lt;String, Object&gt;&gt; f4 = service.submit(() -&gt; &#123;    Map&lt;String, Object&gt; response = restTemplate.getForObject(&quot;http://localhost:8080/logistics/&#123;1&#125;&quot;, Map.class, 1);    latch.countDown();    return response;&#125;);latch.await();log.debug(&quot;执行完毕&quot;);service.shutdown();

]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>AQS 原理</title>
    <url>/posts/9784837e/</url>
    <content><![CDATA[AQS 原理概述



使用
@Slf4j(topic = &quot;c.TestAqs&quot;)public class TestAqs &#123;    public static void main(String[] args) &#123;        MyLock lock = new MyLock();        new Thread(() -&gt; &#123;            lock.lock();            try &#123;                log.debug(&quot;locking...&quot;);                sleep(1);            &#125; finally &#123;                log.debug(&quot;unlocking...&quot;);                lock.unlock();            &#125;        &#125;,&quot;t1&quot;).start();        new Thread(() -&gt; &#123;            lock.lock();            try &#123;                log.debug(&quot;locking...&quot;);            &#125; finally &#123;                log.debug(&quot;unlocking...&quot;);                lock.unlock();            &#125;        &#125;,&quot;t2&quot;).start();    &#125;&#125;// 自定义锁（不可重入锁）class MyLock implements Lock &#123;    // 独占锁  同步器类    class MySync extends AbstractQueuedSynchronizer &#123;        @Override        protected boolean tryAcquire(int arg) &#123;            if(compareAndSetState(0, 1)) &#123;                // 加上了锁，并设置 owner 为当前线程                setExclusiveOwnerThread(Thread.currentThread());                return true;            &#125;            return false;        &#125;        @Override        protected boolean tryRelease(int arg) &#123;            setExclusiveOwnerThread(null);            setState(0);            return true;        &#125;        @Override // 是否持有独占锁        protected boolean isHeldExclusively() &#123;            return getState() == 1;        &#125;        public Condition newCondition() &#123;            return new ConditionObject();        &#125;    &#125;    private MySync sync = new MySync();    @Override // 加锁（不成功会进入等待队列）    public void lock() &#123;        sync.acquire(1);    &#125;    @Override // 加锁，可打断    public void lockInterruptibly() throws InterruptedException &#123;        sync.acquireInterruptibly(1);    &#125;    @Override // 尝试加锁（一次）    public boolean tryLock() &#123;        return sync.tryAcquire(1);    &#125;    @Override // 尝试加锁，带超时    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123;        return sync.tryAcquireNanos(1, unit.toNanos(time));    &#125;    @Override // 解锁    public void unlock() &#123;        sync.release(1);    &#125;    @Override // 创建条件变量    public Condition newCondition() &#123;        return sync.newCondition();    &#125;&#125;

原理

final boolean acquireQueued(final Node node, int arg) &#123;    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head &amp;&amp; tryAcquire(arg)) &#123;                setHead(node);                p.next = null; // help GC                failed = false;                return interrupted;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;









-1 代表该节点有职责唤醒后继节点








可重入原理
通过内部的一个累加计数器实现锁重入，这也意味着只有计数器计数为0才算是真正意义上的释放锁。

// Sync 继承过来的方法，方便阅读，放在此处。final boolean nonfairTryAcquire(int acquires) &#123;          final Thread current = Thread.currentThread();          int c = getState();          if (c == 0) &#123;              if (compareAndSetState(0, acquires)) &#123;                  setExclusiveOwnerThread(current);                  return true;              &#125;          &#125;          else if (current == getExclusiveOwnerThread()) &#123;              // state++;              int nextc = c + acquires;              if (nextc &lt; 0) // overflow                  throw new Error(&quot;Maximum lock count exceeded&quot;);              setState(nextc);              return true;          &#125;          return false;      &#125;// Sync 继承过来的方法，方便阅读，放在此处。      protected final boolean tryRelease(int releases) &#123;          int c = getState() - releases;          if (Thread.currentThread() != getExclusiveOwnerThread())              throw new IllegalMonitorStateException();          boolean free = false;          // 支持锁重入，只有state减为0，才释放成功          if (c == 0) &#123;              free = true;              setExclusiveOwnerThread(null);          &#125;          setState(c);          return free;      &#125;

可打断原理不可打断模式在此模式下，即使它被打断，任会驻留在AQS队列中，等获得锁后方能继续运行（是继续运行！只是打断标记被设置为true）
private final boolean parkAndCheckInterrupt() &#123;       // 如果打断标记是 true，则 park 会失效       LockSupport.park(this);       // interrupted 会清除打断标记       return Thread.interrupted();   &#125;final boolean acquireQueued(final Node node, int arg) &#123;       boolean failed = true;       try &#123;           boolean interrupted = false;           for (;;) &#123;               final Node p = node.predecessor();               if (p == head &amp;&amp; tryAcquire(arg)) &#123;                   setHead(node);                   p.next = null; // help GC                   failed = false;                   // 还是需要获得锁后，才能返回打断标志                   return interrupted;               &#125;               if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                   parkAndCheckInterrupt())                   // 如果是因为 interrupt 被唤醒，返回打断状态为 true                   interrupted = true;           &#125;       &#125; finally &#123;           if (failed)               cancelAcquire(node);       &#125;   &#125;   public final void acquire(int arg) &#123;       if (!tryAcquire(arg) &amp;&amp;           acquireQueued(addWaiter(Node.EXCLUSIVE), arg))           // 如果打断状态为true           selfInterrupt();   &#125;   static void selfInterrupt() &#123;       // 重新产生一次打断       Thread.currentThread().interrupt();   &#125;

可打断模式
通过抛出异常的方式进行打断。

   public final void acquireInterruptibly(int arg)           throws InterruptedException &#123;       if (Thread.interrupted())           throw new InterruptedException();       // 如果没有获得到锁，进入（一）       if (!tryAcquire(arg))           doAcquireInterruptibly(arg);   &#125;// （一）可打断的获取锁流程   private void doAcquireInterruptibly(int arg)       throws InterruptedException &#123;       final Node node = addWaiter(Node.EXCLUSIVE);       boolean failed = true;       try &#123;           for (;;) &#123;               final Node p = node.predecessor();               if (p == head &amp;&amp; tryAcquire(arg)) &#123;                   setHead(node);                   p.next = null; // help GC                   failed = false;                   return;               &#125;               if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                   parkAndCheckInterrupt())                   // 在 park 过程中如果被 interrupt 会进入此                   // 这时候抛出异常，而不会再次进入 for (;;)                   throw new InterruptedException();           &#125;       &#125; finally &#123;           if (failed)               cancelAcquire(node);       &#125;   &#125;

非公平锁实现原理

公平锁实现原理





条件变量实现原理await流程
相当于把当前线程放入到 ConditionObject 链表中，节点状态为-2，等待 signal 方法进行唤醒。









    public final void await() throws InterruptedException &#123;        if (Thread.interrupted())            throw new InterruptedException();        Node node = addConditionWaiter();        int savedState = fullyRelease(node);        int interruptMode = 0;        while (!isOnSyncQueue(node)) &#123;            LockSupport.park(this);            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)                break;        &#125;        if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)            interruptMode = REINTERRUPT;        if (node.nextWaiter != null) // clean up if cancelled            unlinkCancelledWaiters();        if (interruptMode != 0)            reportInterruptAfterWait(interruptMode);    &#125;final int fullyRelease(Node node) &#123;    boolean failed = true;    try &#123;        int savedState = getState();        if (release(savedState)) &#123;            failed = false;            return savedState;        &#125; else &#123;            throw new IllegalMonitorStateException();        &#125;    &#125; finally &#123;        if (failed)            node.waitStatus = Node.CANCELLED;    &#125;&#125;    /**     * Adds a new waiter to wait queue.     * @return its new wait node     */    private Node addConditionWaiter() &#123;        Node t = lastWaiter;        // If lastWaiter is cancelled, clean out.        if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123;            unlinkCancelledWaiters();            t = lastWaiter;        &#125;        Node node = new Node(Thread.currentThread(), Node.CONDITION);        if (t == null)            firstWaiter = node;        else            t.nextWaiter = node;        lastWaiter = node;        return node;    &#125;

signal 流程
相当于从 ConditionObject 链表中获取到第一个节点，放到队列数组里面的最后一个节点，同时将前一个 Node 的标志位置为-1，使其具有换下一个节点的义务。









    /**     * Moves the longest-waiting thread, if one exists, from the     * wait queue for this condition to the wait queue for the     * owning lock.     *     * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125;     *         returns &#123;@code false&#125;     */    public final void signal() &#123;        if (!isHeldExclusively())            throw new IllegalMonitorStateException();        Node first = firstWaiter;        if (first != null)            doSignal(first);    &#125;    private void doSignal(Node first) &#123;        do &#123;            if ( (firstWaiter = first.nextWaiter) == null)                lastWaiter = null;            first.nextWaiter = null;        &#125; while (!transferForSignal(first) &amp;&amp;                 (first = firstWaiter) != null);    &#125;final boolean transferForSignal(Node node) &#123;    /*     * If cannot change waitStatus, the node has been cancelled.     */    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))        return false;    /*     * Splice onto queue and try to set waitStatus of predecessor to     * indicate that thread is (probably) waiting. If cancelled or     * attempt to set waitStatus fails, wake up to resync (in which     * case the waitStatus can be transiently and harmlessly wrong).     */    Node p = enq(node);    int ws = p.waitStatus;    if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))        LockSupport.unpark(node.thread);    return true;&#125;

ReentrantReadWriteLock锁重入升级（不允许）：即持有读锁的情况下去获取写锁


重入时降级：即持有写锁的情况下去获取读锁


应用之缓存读多写少的场景public class TestGenericDao &#123;    public static void main(String[] args) &#123;        GenericDao dao = new GenericDaoCached();        System.out.println(&quot;============&gt; 查询&quot;);        String sql = &quot;select * from emp where empno = ?&quot;;        int empno = 7369;        Emp emp = dao.queryOne(Emp.class, sql, empno);        System.out.println(emp);        emp = dao.queryOne(Emp.class, sql, empno);        System.out.println(emp);        emp = dao.queryOne(Emp.class, sql, empno);        System.out.println(emp);        System.out.println(&quot;============&gt; 更新&quot;);        dao.update(&quot;update emp set sal = ? where empno = ?&quot;, 800, empno);        emp = dao.queryOne(Emp.class, sql, empno);        System.out.println(emp);    &#125;&#125;class GenericDaoCached extends GenericDao &#123;    private GenericDao dao = new GenericDao();    private Map&lt;SqlPair, Object&gt; map = new HashMap&lt;&gt;();    private ReentrantReadWriteLock rw = new ReentrantReadWriteLock();    @Override    public &lt;T&gt; List&lt;T&gt; queryList(Class&lt;T&gt; beanClass, String sql, Object... args) &#123;        return dao.queryList(beanClass, sql, args);    &#125;    @Override    public &lt;T&gt; T queryOne(Class&lt;T&gt; beanClass, String sql, Object... args) &#123;        // 先从缓存中找，找到直接返回        SqlPair key = new SqlPair(sql, args);;        rw.readLock().lock();        try &#123;            T value = (T) map.get(key);            if(value != null) &#123;                return value;            &#125;        &#125; finally &#123;            rw.readLock().unlock();        &#125;        rw.writeLock().lock();        try &#123;            // 多个线程            T value = (T) map.get(key);            if(value == null) &#123;                // 缓存中没有，查询数据库                value = dao.queryOne(beanClass, sql, args);                map.put(key, value);            &#125;            return value;        &#125; finally &#123;            rw.writeLock().unlock();        &#125;    &#125;    @Override    public int update(String sql, Object... args) &#123;        rw.writeLock().lock();        try &#123;            // 先更新库            int update = dao.update(sql, args);            // 清空缓存            map.clear();            return update;        &#125; finally &#123;            rw.writeLock().unlock();        &#125;    &#125;    class SqlPair &#123;        private String sql;        private Object[] args;        public SqlPair(String sql, Object[] args) &#123;            this.sql = sql;            this.args = args;        &#125;        @Override        public boolean equals(Object o) &#123;            if (this == o) &#123;                return true;            &#125;            if (o == null || getClass() != o.getClass()) &#123;                return false;            &#125;            SqlPair sqlPair = (SqlPair) o;            return Objects.equals(sql, sqlPair.sql) &amp;&amp;                    Arrays.equals(args, sqlPair.args);        &#125;        @Override        public int hashCode() &#123;            int result = Objects.hash(sql);            result = 31 * result + Arrays.hashCode(args);            return result;        &#125;    &#125;&#125;



原理加锁 lock

写锁public void lock() &#123;    sync.acquire(1);&#125;public final void acquire(int arg) &#123;    if (!tryAcquire(arg) &amp;&amp;        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;protected final boolean tryAcquire(int acquires) &#123;    /*     * Walkthrough:     * 1. If read count nonzero or write count nonzero     *    and owner is a different thread, fail.     * 2. If count would saturate, fail. (This can only     *    happen if count is already nonzero.)     * 3. Otherwise, this thread is eligible for lock if     *    it is either a reentrant acquire or     *    queue policy allows it. If so, update state     *    and set owner.     */    Thread current = Thread.currentThread();    int c = getState();    int w = exclusiveCount(c);    if (c != 0) &#123;        // (Note: if c != 0 and w == 0 then shared count != 0)        if (w == 0 || current != getExclusiveOwnerThread())            return false;        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)            throw new Error(&quot;Maximum lock count exceeded&quot;);        // Reentrant acquire        setState(c + acquires);        return true;    &#125;    if (writerShouldBlock() ||        !compareAndSetState(c, c + acquires))        return false;    setExclusiveOwnerThread(current);    return true;&#125;

读锁









图2


图3


图4










public void lock() &#123;    sync.acquireShared(1);&#125;public final void acquireShared(int arg) &#123;    // 返回值 -1 代表竞争失败， 1 代表加锁成功了    if (tryAcquireShared(arg) &lt; 0)        doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123;    final Node node = addWaiter(Node.SHARED);    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head) &#123;                // 返回值 -1 代表竞争失败， 1 代表加锁成功了                int r = tryAcquireShared(arg);                if (r &gt;= 0) &#123;                    // 这里说明加锁成功了，剃掉头结点                    setHeadAndPropagate(node, r);                    p.next = null; // help GC                    if (interrupted)                        selfInterrupt();                    failed = false;                    return;                &#125;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;protected final int tryAcquireShared(int unused) &#123;    /*     * Walkthrough:     * 1. If write lock held by another thread, fail.     * 2. Otherwise, this thread is eligible for     *    lock wrt state, so ask if it should block     *    because of queue policy. If not, try     *    to grant by CASing state and updating count.     *    Note that step does not check for reentrant     *    acquires, which is postponed to full version     *    to avoid having to check hold count in     *    the more typical non-reentrant case.     * 3. If step 2 fails either because thread     *    apparently not eligible or CAS fails or count     *    saturated, chain to version with full retry loop.     */    Thread current = Thread.currentThread();    int c = getState();    if (exclusiveCount(c) != 0 &amp;&amp;        getExclusiveOwnerThread() != current)        return -1;    int r = sharedCount(c);    if (!readerShouldBlock() &amp;&amp;        r &lt; MAX_COUNT &amp;&amp;        compareAndSetState(c, c + SHARED_UNIT)) &#123;        if (r == 0) &#123;            firstReader = current;            firstReaderHoldCount = 1;        &#125; else if (firstReader == current) &#123;            firstReaderHoldCount++;        &#125; else &#123;            HoldCounter rh = cachedHoldCounter;            if (rh == null || rh.tid != getThreadId(current))                cachedHoldCounter = rh = readHolds.get();            else if (rh.count == 0)                readHolds.set(rh);            rh.count++;        &#125;        return 1;    &#125;    return fullTryAcquireShared(current);&#125;

解锁 unlock



]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title>CyclicBarrier 应用</title>
    <url>/posts/27d2027c/</url>
    <content><![CDATA[CyclicBarrier 应用应用和CountDownLatch不同，CyclicBarrier的数值可以被重复使用
ExecutorService service = Executors.newFixedThreadPool(3);CyclicBarrier barrier = new CyclicBarrier(2, ()-&gt; &#123;    log.debug(&quot;task1, task2 finish...&quot;);&#125;);for (int i = 0; i &lt; 3; i++) &#123; // task1  task2  task1    service.submit(() -&gt; &#123;        log.debug(&quot;task1 begin...&quot;);        sleep(1);        try &#123;            barrier.await(); // 2-1=1        &#125; catch (InterruptedException | BrokenBarrierException e) &#123;            e.printStackTrace();        &#125;    &#125;);    service.submit(() -&gt; &#123;        log.debug(&quot;task2 begin...&quot;);        sleep(2);        try &#123;            barrier.await(); // 1-1=0        &#125; catch (InterruptedException | BrokenBarrierException e) &#123;            e.printStackTrace();        &#125;    &#125;);&#125;service.shutdown();

]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>StampedLock 应用</title>
    <url>/posts/61ccd33e/</url>
    <content><![CDATA[StampedLock 应用

例子@Slf4j(topic = &quot;c.TestStampedLock&quot;)public class TestStampedLock &#123;    public static void main(String[] args) &#123;        DataContainerStamped dataContainer = new DataContainerStamped(1);        new Thread(() -&gt; &#123;            dataContainer.read(1);        &#125;, &quot;t1&quot;).start();        sleep(0.5);        new Thread(() -&gt; &#123;            dataContainer.read(0);        &#125;, &quot;t2&quot;).start();    &#125;&#125;@Slf4j(topic = &quot;c.DataContainerStamped&quot;)class DataContainerStamped &#123;    private int data;    private final StampedLock lock = new StampedLock();    public DataContainerStamped(int data) &#123;        this.data = data;    &#125;    public int read(int readTime) &#123;        // 先乐观读，如果数据被写锁更改的话再执行锁升级        long stamp = lock.tryOptimisticRead();        log.debug(&quot;optimistic read locking...&#123;&#125;&quot;, stamp);        sleep(readTime);        if (lock.validate(stamp)) &#123;            log.debug(&quot;read finish...&#123;&#125;, data:&#123;&#125;&quot;, stamp, data);            return data;        &#125;        // 锁升级 - 读锁        log.debug(&quot;updating to read lock... &#123;&#125;&quot;, stamp);        try &#123;            stamp = lock.readLock();            log.debug(&quot;read lock &#123;&#125;&quot;, stamp);            sleep(readTime);            log.debug(&quot;read finish...&#123;&#125;, data:&#123;&#125;&quot;, stamp, data);            return data;        &#125; finally &#123;            log.debug(&quot;read unlock &#123;&#125;&quot;, stamp);            lock.unlockRead(stamp);        &#125;    &#125;    public void write(int newData) &#123;        long stamp = lock.writeLock();        log.debug(&quot;write lock &#123;&#125;&quot;, stamp);        try &#123;            sleep(2);            this.data = newData;        &#125; finally &#123;            log.debug(&quot;write unlock &#123;&#125;&quot;, stamp);            lock.unlockWrite(stamp);        &#125;    &#125;&#125;

]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Semaphore 应用</title>
    <url>/posts/bcd2abf0/</url>
    <content><![CDATA[Semaphore 应用public class TestSemaphore &#123;    public static void main(String[] args) &#123;        // 1. 创建 semaphore 对象        Semaphore semaphore = new Semaphore(3);        // 2. 10个线程同时运行        for (int i = 0; i &lt; 10; i++) &#123;            new Thread(() -&gt; &#123;                try &#123;                    semaphore.acquire();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                try &#123;                    log.debug(&quot;running...&quot;);                    sleep(1);                    log.debug(&quot;end...&quot;);                &#125; finally &#123;                    semaphore.release();                &#125;            &#125;).start();        &#125;    &#125;&#125;

应用

public class TestPoolSemaphore &#123;    public static void main(String[] args) &#123;        Pool pool = new Pool(2);        for (int i = 0; i &lt; 5; i++) &#123;            new Thread(() -&gt; &#123;                Connection conn = pool.borrow();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                pool.free(conn);            &#125;).start();        &#125;    &#125;&#125;@Slf4j(topic = &quot;c.Pool&quot;)class Pool &#123;    // 1. 连接池大小    private final int poolSize;    // 2. 连接对象数组    private Connection[] connections;    // 3. 连接状态数组 0 表示空闲， 1 表示繁忙    private AtomicIntegerArray states;    private Semaphore semaphore;    // 4. 构造方法初始化    public Pool(int poolSize) &#123;        this.poolSize = poolSize;        // 让许可数与资源数一致        this.semaphore = new Semaphore(poolSize);        this.connections = new Connection[poolSize];        this.states = new AtomicIntegerArray(new int[poolSize]);        for (int i = 0; i &lt; poolSize; i++) &#123;            connections[i] = new MockConnection(&quot;连接&quot; + (i+1));        &#125;    &#125;    // 5. 借连接    public Connection borrow() &#123;// t1, t2, t3        // 获取许可        try &#123;            semaphore.acquire(); // 没有许可的线程，在此等待        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        for (int i = 0; i &lt; poolSize; i++) &#123;            // 获取空闲连接            if(states.get(i) == 0) &#123;                if (states.compareAndSet(i, 0, 1)) &#123;                    log.debug(&quot;borrow &#123;&#125;&quot;, connections[i]);                    return connections[i];                &#125;            &#125;        &#125;        // 不会执行到这里        return null;    &#125;    // 6. 归还连接    public void free(Connection conn) &#123;        for (int i = 0; i &lt; poolSize; i++) &#123;            if (connections[i] == conn) &#123;                states.set(i, 0);                log.debug(&quot;free &#123;&#125;&quot;, conn);                semaphore.release();                break;            &#125;        &#125;    &#125;&#125;

结果
22:32:45.197 c.Pool [Thread-1] - borrow MockConnection&#123;name=&#x27;连接2&#x27;&#125;22:32:45.197 c.Pool [Thread-0] - borrow MockConnection&#123;name=&#x27;连接1&#x27;&#125;22:32:46.200 c.Pool [Thread-0] - free MockConnection&#123;name=&#x27;连接1&#x27;&#125;22:32:46.200 c.Pool [Thread-1] - free MockConnection&#123;name=&#x27;连接2&#x27;&#125;22:32:46.200 c.Pool [Thread-2] - borrow MockConnection&#123;name=&#x27;连接1&#x27;&#125;22:32:46.200 c.Pool [Thread-3] - borrow MockConnection&#123;name=&#x27;连接2&#x27;&#125;22:32:47.201 c.Pool [Thread-3] - free MockConnection&#123;name=&#x27;连接2&#x27;&#125;22:32:47.201 c.Pool [Thread-2] - free MockConnection&#123;name=&#x27;连接1&#x27;&#125;22:32:47.201 c.Pool [Thread-4] - borrow MockConnection&#123;name=&#x27;连接1&#x27;&#125;22:32:48.202 c.Pool [Thread-4] - free MockConnection&#123;name=&#x27;连接1&#x27;&#125;Process finished with exit code 0



原理acquire



release

]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 多线程入门</title>
    <url>/posts/e5b78a2e/</url>
    <content><![CDATA[多线程入门并发和并行并发：
讲并发之前，要先看一张图：



Concurrency，是并发的意思。并发的实质是一个物理CPU(也可以多个物理CPU) 在若干道程序（或线程）之间多路复用，并发性是对有限物理资源强制行使多用户共享以提高效率。
微观角度：所有的并发处理都有排队等候，唤醒，执行等这样的步骤，在微观上他们都是序列被处理的，如果是同一时刻到达的请求（或线程）也会根据优先级的不同，而先后进入队列排队等候执行。
宏观角度：多个几乎同时到达的请求（或线程）在宏观上看就像是同时在被处理。
通俗点讲，并发就是只有一个CPU资源，程序（或线程）之间要竞争得到执行机会。图中的第一个阶段，在A执行的过程中B，C不会执行，因为这段时间内这个CPU资源被A竞争到了，同理，第二个阶段只有B在执行，第三个阶段只有C在执行。其实，并发过程中，A，B，C并不是同时在进行的（微观角度）。但又是同时进行的（宏观角度）。


并行：
同样，在讲并行之前，要先看一张图：



Parallelism，即并行，指两个或两个以上事件（或线程）在同一时刻发生，是真正意义上的不同事件或线程在同一时刻，在不同CPU资源呢上（多核），同时执行。
并行，不存在像并发那样竞争，等待的概念。
图中，A，B，C都在同时运行（微观，宏观）。

进程与线程



并行与并发





Thread和Runnable

查看进程线程的方法

原理之线程运行

线程上下文切换

LockSupport.parkThread t1 = new Thread(() -&gt; &#123;    log.debug(&quot;park...&quot;);    // 默认为false。interrupt会置为true，park失效    LockSupport.park();    log.debug(&quot;unpark...&quot;);    log.debug(&quot;打断状态：&#123;&#125;&quot;, Thread.currentThread().interrupted()); // 打断标记设置为false        // 打断标记为false才就会生效，阻塞执行下面的逻辑    LockSupport.park();    log.debug(&quot;unpark...&quot;);&#125;, &quot;t1&quot;);t1.start();sleep(0.5);t1.interrupt();

守护线程

原理之wait&#x2F;notify



原理之Park&#x2F;Unpark



线程转换状态

活跃性死锁必要条件（1） 互斥条件：一个资源每次只能被一个进程使用。  
（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。  
（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。  
（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。


Object A = new Object();Object B = new Object();Thread t1 = new Thread(() -&gt; &#123;    synchronized (A) &#123;        log.debug(&quot;lock A&quot;);        sleep(1);        synchronized (B) &#123;            log.debug(&quot;lock B&quot;);            log.debug(&quot;操作...&quot;);        &#125;    &#125;&#125;, &quot;t1&quot;);Thread t2 = new Thread(() -&gt; &#123;    synchronized (B) &#123;        log.debug(&quot;lock B&quot;);        sleep(0.5);        synchronized (A) &#123;            log.debug(&quot;lock A&quot;);            log.debug(&quot;操作...&quot;);        &#125;    &#125;&#125;, &quot;t2&quot;);t1.start();t2.start();

jstack打印结果
Found one Java-level deadlock:=============================&quot;t2&quot;:  waiting to lock monitor 0x000000002174fed8 (object 0x0000000741c9e3d8, a java.lang.Object),  which is held by &quot;t1&quot;&quot;t1&quot;:  waiting to lock monitor 0x0000000021752348 (object 0x0000000741c9e3e8, a java.lang.Object),  which is held by &quot;t2&quot;Java stack information for the threads listed above:

哲学家问题

public class TestDeadLock &#123;    public static void main(String[] args) &#123;        Chopstick c1 = new Chopstick(&quot;1&quot;);        Chopstick c2 = new Chopstick(&quot;2&quot;);        Chopstick c3 = new Chopstick(&quot;3&quot;);        Chopstick c4 = new Chopstick(&quot;4&quot;);        Chopstick c5 = new Chopstick(&quot;5&quot;);        new Philosopher(&quot;苏格拉底&quot;, c1, c2).start();        new Philosopher(&quot;柏拉图&quot;, c2, c3).start();        new Philosopher(&quot;亚里士多德&quot;, c3, c4).start();        new Philosopher(&quot;赫拉克利特&quot;, c4, c5).start();        new Philosopher(&quot;阿基米德&quot;, c1, c5).start();    &#125;&#125;@Slf4j(topic = &quot;c.Philosopher&quot;)class Philosopher extends Thread &#123;    Chopstick left;    Chopstick right;    public Philosopher(String name, Chopstick left, Chopstick right) &#123;        super(name);        this.left = left;        this.right = right;    &#125;    @Override    public void run() &#123;        while (true) &#123;            //　尝试获得左手筷子            synchronized (left) &#123;                // 尝试获得右手筷子                synchronized (right) &#123;                    eat();                &#125;            &#125;        &#125;    &#125;    Random random = new Random();    private void eat() &#123;        log.debug(&quot;eating...&quot;);        Sleeper.sleep(0.5);    &#125;&#125;class Chopstick &#123;    String name;    public Chopstick(String name) &#123;        this.name = name;    &#125;    @Override    public String toString() &#123;        return &quot;筷子&#123;&quot; + name + &#x27;&#125;&#x27;;    &#125;&#125;

改进：
@Slf4j(topic = &quot;c.Test23&quot;)public class Test23 &#123;public static void main(String[] args) &#123;    Chopstick c1 = new Chopstick(&quot;1&quot;);    Chopstick c2 = new Chopstick(&quot;2&quot;);    Chopstick c3 = new Chopstick(&quot;3&quot;);    Chopstick c4 = new Chopstick(&quot;4&quot;);    Chopstick c5 = new Chopstick(&quot;5&quot;);    new Philosopher(&quot;苏格拉底&quot;, c1, c2).start();    new Philosopher(&quot;柏拉图&quot;, c2, c3).start();    new Philosopher(&quot;亚里士多德&quot;, c3, c4).start();    new Philosopher(&quot;赫拉克利特&quot;, c4, c5).start();    new Philosopher(&quot;阿基米德&quot;, c5, c1).start();&#125;&#125;@Slf4j(topic = &quot;c.Philosopher&quot;)class Philosopher extends Thread &#123;    Chopstick left;    Chopstick right;    public Philosopher(String name, Chopstick left, Chopstick right) &#123;        super(name);        this.left = left;        this.right = right;    &#125;    @Override    public void run() &#123;        while (true) &#123;            //　尝试获得左手筷子            if(left.tryLock()) &#123;                try &#123;                    // 尝试获得右手筷子                    if(right.tryLock()) &#123;                        try &#123;                            eat();                        &#125; finally &#123;                            right.unlock();                        &#125;                    &#125;                &#125; finally &#123;                    left.unlock(); // 释放自己手里的筷子                &#125;            &#125;        &#125;    &#125;    Random random = new Random();    private void eat() &#123;        log.debug(&quot;eating...&quot;);        Sleeper.sleep(0.5);    &#125;&#125;class Chopstick extends ReentrantLock &#123;    String name;    public Chopstick(String name) &#123;        this.name = name;    &#125;    @Override    public String toString() &#123;        return &quot;筷子&#123;&quot; + name + &#x27;&#125;&#x27;;    &#125;&#125;

活锁

@Slf4j(topic = &quot;c.TestLiveLock&quot;)public class TestLiveLock &#123;    static volatile int count = 10;    static final Object lock = new Object();    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            // 期望减到 0 退出循环            while (count &gt; 0) &#123;                sleep(0.2);                count--;                log.debug(&quot;count: &#123;&#125;&quot;, count);            &#125;        &#125;, &quot;t1&quot;).start();        new Thread(() -&gt; &#123;            // 期望超过 20 退出循环            while (count &lt; 20) &#123;                sleep(0.2);                count++;                log.debug(&quot;count: &#123;&#125;&quot;, count);            &#125;        &#125;, &quot;t2&quot;).start();    &#125;&#125;

措施：
增加随机睡眠时间来避免活锁
饥饿



顺序加锁容易产生饥饿问题
锁超时ReentrantLock尽量使用tryLock方法来防止无限制的等待
@Slf4j(topic = &quot;c.Test22&quot;)public class Test22 &#123;    private static ReentrantLock lock = new ReentrantLock();    public static void main(String[] args) &#123;        Thread t1 = new Thread(() -&gt; &#123;            log.debug(&quot;尝试获得锁&quot;);            try &#123;                if (! lock.tryLock(2, TimeUnit.SECONDS)) &#123;                    log.debug(&quot;获取不到锁&quot;);                    return;                &#125;            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();                log.debug(&quot;获取不到锁&quot;);                return;            &#125;            try &#123;                log.debug(&quot;获得到锁&quot;);            &#125; finally &#123;                lock.unlock();            &#125;        &#125;, &quot;t1&quot;);        lock.lock();        log.debug(&quot;获得到锁&quot;);        t1.start();        sleep(1);        log.debug(&quot;释放了锁&quot;);        lock.unlock();    &#125;&#125;

控制线程启动顺序方法1@Slf4j(topic = &quot;c.Test25&quot;)public class Test25 &#123;    static final Object lock = new Object();    // 表示 t2 是否运行过    static boolean t2runned = false;    public static void main(String[] args) &#123;        Thread t1 = new Thread(() -&gt; &#123;            synchronized (lock) &#123;                while (!t2runned) &#123;                    try &#123;                        lock.wait();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;1&quot;);            &#125;        &#125;, &quot;t1&quot;);        Thread t2 = new Thread(() -&gt; &#123;            synchronized (lock) &#123;                log.debug(&quot;2&quot;);                t2runned = true;                lock.notify();            &#125;        &#125;, &quot;t2&quot;);        t1.start();        t2.start();    &#125;&#125;

方法2：ReentrantLock实现@Slf4j(topic = &quot;c.Test26&quot;)public class Test26 &#123;    public static void main(String[] args) &#123;        Thread t1 = new Thread(() -&gt; &#123;            LockSupport.park();            log.debug(&quot;1&quot;);        &#125;, &quot;t1&quot;);        t1.start();        new Thread(() -&gt; &#123;            log.debug(&quot;2&quot;);            LockSupport.unpark(t1);        &#125;,&quot;t2&quot;).start();    &#125;&#125;

ReentrantLock条件变量@Slf4j(topic = &quot;c.Test24&quot;)public class Test24 &#123;    static final Object room = new Object();    static boolean hasCigarette = false;    static boolean hasTakeout = false;    static ReentrantLock ROOM = new ReentrantLock();    // 等待烟的休息室    static Condition waitCigaretteSet = ROOM.newCondition();    // 等外卖的休息室    static Condition waitTakeoutSet = ROOM.newCondition();    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            ROOM.lock();            try &#123;                log.debug(&quot;有烟没？[&#123;&#125;]&quot;, hasCigarette);                while (!hasCigarette) &#123;                    log.debug(&quot;没烟，先歇会！&quot;);                    try &#123;                        waitCigaretteSet.await();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;可以开始干活了&quot;);            &#125; finally &#123;                ROOM.unlock();            &#125;        &#125;, &quot;小南&quot;).start();        new Thread(() -&gt; &#123;            ROOM.lock();            try &#123;                log.debug(&quot;外卖送到没？[&#123;&#125;]&quot;, hasTakeout);                while (!hasTakeout) &#123;                    log.debug(&quot;没外卖，先歇会！&quot;);                    try &#123;                        waitTakeoutSet.await();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;可以开始干活了&quot;);            &#125; finally &#123;                ROOM.unlock();            &#125;        &#125;, &quot;小女&quot;).start();        sleep(1);        new Thread(() -&gt; &#123;            ROOM.lock();            try &#123;                hasTakeout = true;                waitTakeoutSet.signal();            &#125; finally &#123;                ROOM.unlock();            &#125;        &#125;, &quot;送外卖的&quot;).start();        sleep(1);        new Thread(() -&gt; &#123;            ROOM.lock();            try &#123;                hasCigarette = true;                waitCigaretteSet.signal();            &#125; finally &#123;                ROOM.unlock();            &#125;        &#125;, &quot;送烟的&quot;).start();    &#125;&#125;

交替输出方法1：@Slf4j(topic = &quot;c.Test27&quot;)public class Test27 &#123;    public static void main(String[] args) &#123;        WaitNotify wn = new WaitNotify(1, 5);        new Thread(() -&gt; &#123;            wn.print(&quot;a&quot;, 1, 2);        &#125;).start();        new Thread(() -&gt; &#123;            wn.print(&quot;b&quot;, 2, 3);        &#125;).start();        new Thread(() -&gt; &#123;            wn.print(&quot;c&quot;, 3, 1);        &#125;).start();    &#125;&#125;/*输出内容       等待标记     下一个标记   a           1             2   b           2             3   c           3             1 */class WaitNotify &#123;    // 打印               a           1             2    public void print(String str, int waitFlag, int nextFlag) &#123;        for (int i = 0; i &lt; loopNumber; i++) &#123;            synchronized (this) &#123;                while(flag != waitFlag) &#123;                    try &#123;                        this.wait();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                System.out.print(str);                flag = nextFlag;                this.notifyAll();            &#125;        &#125;    &#125;    // 等待标记    private int flag; // 2    // 循环次数    private int loopNumber;    public WaitNotify(int flag, int loopNumber) &#123;        this.flag = flag;        this.loopNumber = loopNumber;    &#125;&#125;

方法2：public class Test30 &#123;    public static void main(String[] args) throws InterruptedException &#123;        AwaitSignal awaitSignal = new AwaitSignal(5);        Condition a = awaitSignal.newCondition();        Condition b = awaitSignal.newCondition();        Condition c = awaitSignal.newCondition();        new Thread(() -&gt; &#123;            awaitSignal.print(&quot;a&quot;, a, b);        &#125;).start();        new Thread(() -&gt; &#123;            awaitSignal.print(&quot;b&quot;, b, c);        &#125;).start();        new Thread(() -&gt; &#123;            awaitSignal.print(&quot;c&quot;, c, a);        &#125;).start();        Thread.sleep(1000);        awaitSignal.lock();        try &#123;            System.out.println(&quot;开始...&quot;);            a.signal();        &#125; finally &#123;            awaitSignal.unlock();        &#125;    &#125;&#125;class AwaitSignal extends ReentrantLock&#123;    private int loopNumber;    public AwaitSignal(int loopNumber) &#123;        this.loopNumber = loopNumber;    &#125;    //            参数1 打印内容， 参数2 进入哪一间休息室, 参数3 下一间休息室    public void print(String str, Condition current, Condition next) &#123;        for (int i = 0; i &lt; loopNumber; i++) &#123;            lock();            try &#123;                current.await();                System.out.print(str);                next.signal();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                unlock();            &#125;        &#125;    &#125;&#125;

方法3：@Slf4j(topic = &quot;c.Test31&quot;)public class Test31 &#123;    static Thread t1;    static Thread t2;    static Thread t3;    public static void main(String[] args) &#123;        ParkUnpark pu = new ParkUnpark(5);        t1 = new Thread(() -&gt; &#123;            pu.print(&quot;a&quot;, t2);        &#125;);        t2 = new Thread(() -&gt; &#123;            pu.print(&quot;b&quot;, t3);        &#125;);        t3 = new Thread(() -&gt; &#123;            pu.print(&quot;c&quot;, t1);        &#125;);        t1.start();        t2.start();        t3.start();        LockSupport.unpark(t1);    &#125;&#125;class ParkUnpark &#123;    public void print(String str, Thread next) &#123;        for (int i = 0; i &lt; loopNumber; i++) &#123;            LockSupport.park();            System.out.print(str);            LockSupport.unpark(next);        &#125;    &#125;    private int loopNumber;    public ParkUnpark(int loopNumber) &#123;        this.loopNumber = loopNumber;    &#125;&#125;



JMM

退不出的循环



指令重排序优化



验证

@JCStressTest@Outcome(id = &#123;&quot;1&quot;, &quot;4&quot;&#125;, expect = Expect.ACCEPTABLE, desc = &quot;ok&quot;)@Outcome(id = &quot;0&quot;, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;!!!!&quot;)@Statepublic class ConcurrencyTest &#123;    int num = 0;    volatile boolean ready = false;    @Actor    public void actor1(I_Result r) &#123;        if(ready) &#123;            r.r1 = num + num;        &#125; else &#123;            r.r1 = 1;        &#125;    &#125;    @Actor    public void actor2(I_Result r) &#123;        num = 2;        ready = true;    &#125;&#125;



volatile禁止重排序



happens-before原则
单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。
锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。
volatile的happen-before原则：对一个volatile变量的写操作happen-before对此变量的任意操作(当然也包括写操作了)。
happen-before的传递性原则：如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。
线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。
线程中断的happen-before原则：对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的代码。
线程终结的happen-before原则：线程中的所有操作都happen-before线程的终止检测。
对象创建的happen-before原则：一个对象的初始化完成先于他的finalize方法调用。















原子整数AtomicBooleanAtomicIntegerAtomicLong

updateAndGet
public class Test34 &#123;    public static void main(String[] args) &#123;        AtomicInteger i = new AtomicInteger(5);        /*System.out.println(i.incrementAndGet()); // ++i   1        System.out.println(i.getAndIncrement()); // i++   2        System.out.println(i.getAndAdd(5)); // 2 , 7        System.out.println(i.addAndGet(5)); // 12, 12*/        //             读取到    设置值//        i.updateAndGet(value -&gt; value * 10);        System.out.println(updateAndGet(i, p -&gt; p / 2));//        i.getAndUpdate()        System.out.println(i.get());    &#125;    public static int updateAndGet(AtomicInteger i, IntUnaryOperator operator) &#123;        while (true) &#123;            int prev = i.get();            int next = operator.applyAsInt(prev);            if (i.compareAndSet(prev, next)) &#123;                return next;            &#125;        &#125;    &#125;&#125;

原子引用

AtomicReferenceclass DecimalAccountCas implements DecimalAccount &#123;    private AtomicReference&lt;BigDecimal&gt; balance;    public DecimalAccountCas(BigDecimal balance) &#123;//        this.balance = balance;        this.balance = new AtomicReference&lt;&gt;(balance);    &#125;    @Override    public BigDecimal getBalance() &#123;        return balance.get();    &#125;    @Override    public void withdraw(BigDecimal amount) &#123;        while(true) &#123;            BigDecimal prev = balance.get();            BigDecimal next = prev.subtract(amount);            if (balance.compareAndSet(prev, next)) &#123;                break;            &#125;        &#125;    &#125;&#125;

AtomicStampedReference
带version标记的原子引用

static AtomicStampedReference&lt;String&gt; ref = new AtomicStampedReference&lt;&gt;(&quot;A&quot;, 0);public static void main(String[] args) throws InterruptedException &#123;    log.debug(&quot;main start...&quot;);    // 获取值 A    String prev = ref.getReference();    // 获取版本号    int stamp = ref.getStamp();    log.debug(&quot;版本 &#123;&#125;&quot;, stamp);    // 如果中间有其它线程干扰，发生了 ABA 现象    other();    sleep(1);    // 尝试改为 C    log.debug(&quot;change A-&gt;C &#123;&#125;&quot;, ref.compareAndSet(prev, &quot;C&quot;, stamp, stamp + 1));&#125;

AtomicMarkableReference
只判断是否发生过修改，不在乎修改过多少次

@Slf4j(topic = &quot;c.Test38&quot;)public class Test38 &#123;    public static void main(String[] args) throws InterruptedException &#123;        GarbageBag bag = new GarbageBag(&quot;装满了垃圾&quot;);        // 参数2 mark 可以看作一个标记，表示垃圾袋满了        AtomicMarkableReference&lt;GarbageBag&gt; ref = new AtomicMarkableReference&lt;&gt;(bag, true);        log.debug(&quot;start...&quot;);        GarbageBag prev = ref.getReference();        log.debug(prev.toString());        new Thread(() -&gt; &#123;            log.debug(&quot;start...&quot;);            bag.setDesc(&quot;空垃圾袋&quot;);            ref.compareAndSet(bag, bag, true, false);            log.debug(bag.toString());        &#125;,&quot;保洁阿姨&quot;).start();        sleep(1);        log.debug(&quot;想换一只新垃圾袋？&quot;);        boolean success = ref.compareAndSet(prev, new GarbageBag(&quot;空垃圾袋&quot;), true, false);        log.debug(&quot;换了么？&quot; + success);        log.debug(ref.getReference().toString());    &#125;&#125;class GarbageBag &#123;    String desc;    public GarbageBag(String desc) &#123;        this.desc = desc;    &#125;    public void setDesc(String desc) &#123;        this.desc = desc;    &#125;    @Override    public String toString() &#123;        return super.toString() + &quot; &quot; + desc;    &#125;&#125;

原子数组AtomicIntegerArrayAtomicLongArrayAtomicReferenceArraypublic class Test39 &#123;    public static void main(String[] args) &#123;        demo(                ()-&gt;new int[10],                (array)-&gt;array.length,                (array, index) -&gt; array[index]++,                array-&gt; System.out.println(Arrays.toString(array))        );        demo(                ()-&gt; new AtomicIntegerArray(10),                (array) -&gt; array.length(),                (array, index) -&gt; array.getAndIncrement(index),                array -&gt; System.out.println(array)        );    &#125;    /**     参数1，提供数组、可以是线程不安全数组或线程安全数组     参数2，获取数组长度的方法     参数3，自增方法，回传 array, index     参数4，打印数组的方法     */    // supplier 提供者 无中生有  ()-&gt;结果    // function 函数   一个参数一个结果   (参数)-&gt;结果  ,  BiFunction (参数1,参数2)-&gt;结果    // consumer 消费者 一个参数没结果  (参数)-&gt;void,      BiConsumer (参数1,参数2)-&gt;    private static &lt;T&gt; void demo(            Supplier&lt;T&gt; arraySupplier,            Function&lt;T, Integer&gt; lengthFun,            BiConsumer&lt;T, Integer&gt; putConsumer,            Consumer&lt;T&gt; printConsumer ) &#123;        List&lt;Thread&gt; ts = new ArrayList&lt;&gt;();        T array = arraySupplier.get();        int length = lengthFun.apply(array);        for (int i = 0; i &lt; length; i++) &#123;            // 每个线程对数组作 10000 次操作            ts.add(new Thread(() -&gt; &#123;                for (int j = 0; j &lt; 10000; j++) &#123;                    putConsumer.accept(array, j%length);                &#125;            &#125;));        &#125;        ts.forEach(t -&gt; t.start()); // 启动所有线程        ts.forEach(t -&gt; &#123;            try &#123;                t.join();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;);     // 等所有线程结束        printConsumer.accept(array);    &#125;&#125;

字段更新器AtomicLongFieldUpdaterAtomicIntegerFieldUpdaterAtomicReferenceFieldUpdater@Slf4j(topic = &quot;c.Test40&quot;)public class Test40 &#123;    public static void main(String[] args) &#123;        Student stu = new Student();        AtomicReferenceFieldUpdater updater =                AtomicReferenceFieldUpdater.newUpdater(Student.class, String.class, &quot;name&quot;);        System.out.println(updater.compareAndSet(stu, null, &quot;张三&quot;));        System.out.println(stu);    &#125;&#125;class Student &#123;    volatile String name;    @Override    public String toString() &#123;        return &quot;Student&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;

累加器DoubleAccumulatorDoubleAdderLongAccumulatorLongAdder源码解析











add方法public void add(long x) &#123;    Cell[] as; long b, v; int m; Cell a;    if ((as = cells) != null || !casBase(b = base, b + x)) &#123;        boolean uncontended = true;        if (as == null || (m = as.length - 1) &lt; 0 ||            (a = as[getProbe() &amp; m]) == null ||            !(uncontended = a.cas(v = a.value, v + x)))            longAccumulate(x, null, uncontended);    &#125;&#125;



longAccumulate方法final void longAccumulate(long x, LongBinaryOperator fn,                          boolean wasUncontended) &#123;    int h;    if ((h = getProbe()) == 0) &#123;        ThreadLocalRandom.current(); // force initialization        h = getProbe();        wasUncontended = true;    &#125;    boolean collide = false;                // True if last slot nonempty    for (;;) &#123;        Cell[] as; Cell a; int n; long v;        if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123;            ...        &#125;        else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123;            boolean init = false;            try &#123;                           // Initialize table                if (cells == as) &#123;                    Cell[] rs = new Cell[2];                    rs[h &amp; 1] = new Cell(x);                    cells = rs;                    init = true;                &#125;            &#125; finally &#123;                cellsBusy = 0;            &#125;            if (init)                break;        &#125;        else if (casBase(v = base, ((fn == null) ? v + x :                                    fn.applyAsLong(v, x))))            break;                          // Fall back on using base    &#125;&#125;





Cell[] as; Cell a; int n; long v;if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123;    if ((a = as[(n - 1) &amp; h]) == null) &#123;        if (cellsBusy == 0) &#123;       // Try to attach new Cell            Cell r = new Cell(x);   // Optimistically create            if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;                boolean created = false;                try &#123;               // Recheck under lock                    Cell[] rs; int m, j;                    if ((rs = cells) != null &amp;&amp;                        (m = rs.length) &gt; 0 &amp;&amp;                        rs[j = (m - 1) &amp; h] == null) &#123;                        rs[j] = r;                        created = true;                    &#125;                &#125; finally &#123;                    cellsBusy = 0;                &#125;                if (created)                    break;                continue;           // Slot is now non-empty            &#125;        &#125;        collide = false;    &#125;



Cell[] as; Cell a; int n; long v;if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123;                              else if (!wasUncontended)       // CAS already known to fail                  wasUncontended = true;      // Continue after rehash              else if (a.cas(v = a.value, ((fn == null) ? v + x :                                           fn.applyAsLong(v, x))))                  break;              else if (n &gt;= NCPU || cells != as)                  collide = false;            // At max size or stale              else if (!collide)                  collide = true;              else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;                  try &#123;                      if (cells == as) &#123;      // Expand table unless stale                          Cell[] rs = new Cell[n &lt;&lt; 1];                          for (int i = 0; i &lt; n; ++i)                              rs[i] = as[i];                          cells = rs;                      &#125;                  &#125; finally &#123;                      cellsBusy = 0;                  &#125;                  collide = false;                  continue;                   // Retry with expanded table              &#125;              h = advanceProbe(h);      &#125;



Unsafe

对象属性赋值public class TestUnsafe &#123;    public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123;        Field theUnsafe = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);        theUnsafe.setAccessible(true);        Unsafe unsafe = (Unsafe) theUnsafe.get(null);        System.out.println(unsafe);        // 1. 获取域的偏移地址        long idOffset = unsafe.objectFieldOffset(Teacher.class.getDeclaredField(&quot;id&quot;));        long nameOffset = unsafe.objectFieldOffset(Teacher.class.getDeclaredField(&quot;name&quot;));        Teacher t = new Teacher();        // 2. 执行 cas 操作        unsafe.compareAndSwapInt(t, idOffset, 0, 1);        unsafe.compareAndSwapObject(t, nameOffset, null, &quot;张三&quot;);        // 3. 验证        System.out.println(t);    &#125;&#125;@Dataclass Teacher &#123;    volatile int id;    volatile String name;&#125;

模拟实现原子整数@Slf4j(topic = &quot;c.Test42&quot;)public class Test42 &#123;    public static void main(String[] args) &#123;        Account.demo(new MyAtomicInteger(10000));    &#125;&#125;class MyAtomicInteger implements Account &#123;    private volatile int value;     private static final long valueOffset;    private static final Unsafe UNSAFE;    static &#123;        UNSAFE = UnsafeAccessor.getUnsafe();        try &#123;            valueOffset = UNSAFE.objectFieldOffset(MyAtomicInteger.class.getDeclaredField(&quot;value&quot;));        &#125; catch (NoSuchFieldException e) &#123;            e.printStackTrace();            throw new RuntimeException(e);        &#125;    &#125;    public int getValue() &#123;        return value;    &#125;    public void decrement(int amount) &#123;        while(true) &#123;            int prev = this.value;            int next = prev - amount;            if (UNSAFE.compareAndSwapInt(this, valueOffset, prev, next)) &#123;                break;            &#125;        &#125;    &#125;    public MyAtomicInteger(int value) &#123;        this.value = value;    &#125;    @Override    public Integer getBalance() &#123;        return getValue();    &#125;    @Override    public void withdraw(Integer amount) &#123;        decrement(amount);    &#125;&#125;public class UnsafeAccessor &#123;    private static final Unsafe unsafe;    static &#123;        try &#123;            Field theUnsafe = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);            theUnsafe.setAccessible(true);            unsafe = (Unsafe) theUnsafe.get(null);        &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123;            throw new Error(e);        &#125;    &#125;    public static Unsafe getUnsafe() &#123;        return unsafe;    &#125;&#125;

享元模式

包装类

String串池BigDecimal BigInteger数据库连接池public class Test3 &#123;    public static void main(String[] args) &#123;        Pool pool = new Pool(2);        for (int i = 0; i &lt; 5; i++) &#123;            new Thread(() -&gt; &#123;                Connection conn = pool.borrow();                try &#123;                    Thread.sleep(new Random().nextInt(1000));                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                pool.free(conn);            &#125;).start();        &#125;    &#125;&#125;@Slf4j(topic = &quot;c.Pool&quot;)class Pool &#123;    // 1. 连接池大小    private final int poolSize;    // 2. 连接对象数组    private Connection[] connections;    // 3. 连接状态数组 0 表示空闲， 1 表示繁忙    private AtomicIntegerArray states;    // 4. 构造方法初始化    public Pool(int poolSize) &#123;        this.poolSize = poolSize;        this.connections = new Connection[poolSize];        this.states = new AtomicIntegerArray(new int[poolSize]);        for (int i = 0; i &lt; poolSize; i++) &#123;            connections[i] = new MockConnection(&quot;连接&quot; + (i+1));        &#125;    &#125;    // 5. 借连接    public Connection borrow() &#123;        while(true) &#123;            for (int i = 0; i &lt; poolSize; i++) &#123;                // 获取空闲连接                if(states.get(i) == 0) &#123;                    if (states.compareAndSet(i, 0, 1)) &#123;                        log.debug(&quot;borrow &#123;&#125;&quot;, connections[i]);                        return connections[i];                    &#125;                &#125;            &#125;            // 如果没有空闲连接，当前线程进入等待            // CAS 设置不了状态1会一直空转，这可能会耗尽 CPU 资源，所以要加这个 synchronized 代码块来防止            synchronized (this) &#123;                try &#123;                    log.debug(&quot;wait...&quot;);                    this.wait();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;    // 6. 归还连接    public void free(Connection conn) &#123;        for (int i = 0; i &lt; poolSize; i++) &#123;            if (connections[i] == conn) &#123;                states.set(i, 0);                synchronized (this) &#123;                    log.debug(&quot;free &#123;&#125;&quot;, conn);                    this.notifyAll();                &#125;                break;            &#125;        &#125;    &#125;&#125;class MockConnection implements Connection &#123;    private String name;    public MockConnection(String name) &#123;        this.name = name;    &#125;    @Override    public String toString() &#123;        return &quot;MockConnection&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;



final原理]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 多线程基础</title>
    <url>/posts/71aa5641/</url>
    <content><![CDATA[多线程基础类与对象的区别类是对某一类事物的描述，是抽象的，而对象是一个实实在在的个体，是类的一个实例。
本线程与当前线程“本线程”表示this（以及this对应的线程的意思）。
“当前线程”则是指调用对象方法的线程。
举个例子：
public final void join() throws InterruptedException
让当前线程（调用join方法的线程）等待本线程（this）终止。
start和run的区别start() :它的作用是启动一个新线程。 通过start()方法来启动的新线程，处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行相应线程的run()方法，这里方法run()称为线程体，它包含了要执行的这个线程的内容，run方法运行结束，此线程随即终止。start()不能被重复调用。用start方法来启动线程，真正实现了多线程运行，即无需等待某个线程的run方法体代码执行完毕就直接继续执行下面的代码。这里无需等待run方法执行完毕，即可继续执行下面的代码，即进行了线程切换。
run()   :run()就和普通的成员方法一样，可以被重复调用。 如果直接调用run方法，并不会启动新线程！程序中依然只有主线程这一个线程，其程序执行路径还是只有一条，还是要顺序执行，还是要等待run方法体执行完毕后才可继续执行下面的代码，这样就没有达到多线程的目的。 总结：调用start方法方可启动线程，而run方法只是thread的一个普通方法调用，还是在主线程里执行。
总结一下：

start() 可以启动一个新线程，run()不能
start()不能被重复调用，run()可以
start()中的run代码可以不执行完就继续执行下面的代码，即进行了线程切换。直接调用run方法必须等待其代码全部执行完才能继续执行下面的代码。
start() 实现了多线程，run()没有实现多线程。

Thread.currentThread()与this的区别Thread.currentThread()可以获取当前线程的引用，一般都是在没有线程对象又需要获得线程信息时通过Thread.currentThread()获取当前代码段所在线程的引用
this.XXX()调用的是当前对象的方法
interrupt、interrupted 、isInterrupted 区别interrupt()：将调用该方法的对象所表示的线程标记一个停止标记，并不是真的停止该线程。 
interrupted()：获取当前线程的中断状态，并且会清除线程的状态标记。 是一个是静态方法。 
isInterrupted()：获取调用该方法的对象所表示的线程，不会清除线程的状态标记。



方法名
静态



interrupted
√


isInterrupted
×


停止线程的方式
前提都是要调用判断中断状态的interrupted()或者isInterrupted()方法


阻塞状态（sleep,wait等）
interrupt() + return
抛异常法

suspend()、resume()
暂停&#x2F;恢复线程

isAlive()
判断线程是否在运行

yield()
放弃当前的CPU资源

优先级（priority）
继承性（可继承main或者父级的优先级）
规则性（优先级高执行的机会多）
随机性（优先级高不一定先执行）

表示优先级的静态字段

Thread.MIN_PRIORITY：表示最低优先级的值
Thread.NORM_PRIORITY：表示默认优先级的值
Thread.MAX_PRIORITY：表示最高优先级的值

Daemon守护进程public final void setDaemon(boolean on)
当on为true时，本线程（this）会变成守护进程。
如果本线程已经启动了，异常java.lang.IllegalThreadStateException会被抛出。
如果当前线程无法改变本线程（this），异常java.lang.SecurityException会被抛出。
脏读
发生脏读的情况是在读取实例变量时，此值已经被其他线程更改过了。

锁重入
关键字synchronized拥有锁重入的功能，也就是在使用synchronized时，当一个线程得到一个对象锁后，再次请求此对象锁是可以再次得到对象的锁的。这也证明在一个synchronized方法&#x2F;块的内部调用本类的其他synchronized方法&#x2F;块时，是永远可以得到锁的。


出现异常，锁自动释放
同步锁不能被子类继承

同步机制Semaphore、CountDownLatch、CyclicBarrier、Exchanger&lt;V&gt;都是用于线程同步的类。



名字
内容



Semaphore
计数信号量


CountDownLatch
让线程等待某个操作执行完指定次数的同步机制


CyclicBarrier
让多个线程在特定位置（屏障）等待的同步机制


Exchanger&lt;V&gt;
让两个线程交换对象的同步机制


synchronized关键字synchronized方法和synchronized(this)等效，都是对当前对象进行加锁；而synchronized(非this对象X)则是对某个对象进行加锁，即对象监视器锁。
synchronized可以使多个线程访问同一个资源具有同步性，而且它还具有将线程工作内存中的私有变量与公共内存中的变量同步的功能，即具有volatile同步的功能。
synchronized包含两大特性：

互斥性
可见性

synchronized(非this对象X)格式的写法是将X对象本身作为对象监视器，这样就可以得出以下三个结论：

当多个线程同时执行synchronized(X){} 同步代码块呈同步效果。
当其他线程执行X对象中synchronized同步方法时呈同步效果。
当其他线程执行X对象方法里面的synchronized(this)代码块时也呈现同步效果。


synchronized关键字加到static静态方法上是给Class类上锁，而synchronized关键字加到非static静态方法上是给对象上锁。
Class锁可以对类的所有对象实例起作用，即锁定所有对象锁。
同步synchronized(XX.class)代码块的作用和synchronized static方法的作用一样。

volatile
volatile关键字的作用是强制从公共堆栈中取得变量的值，而不是从线程私有数据栈中取得变量的值。

synchronized和volatile区别：

关键字volatile是线程同步的轻量级实现，所以volatile性能肯定比synchronized要好，并且volatile只能修饰于变量，而synchronized可以修饰方法以及代码块。随着JDK新版本的发布，synchronized关键字在执行效率上得到很大提升，在开发中使用synchronized关键字的比率还是比较大的。
多线程访问volatile不会发生阻塞，而synchronized会出现阻塞。
volatile可以保证数据的可见性，但不能保证原子性；而synchronized可以保证原子性，也可以间接保证可见性，即保证多个线程之间访问资源的同步性，因为它会将私有内存和公共内存中的数据做同步。

等待&#x2F;通知机制
wait()方法可以使调用该方法的线程释放共享资源的锁，然后从运行状态退出，进入等待队列，直到被再次唤醒。
notify()方法可以随机唤醒等待队列中等待同一共享资源的一个线程，并使该线程退出等待队列，进入可运行状态，也就是notify()方法仅通知一个线程。
notifyAll()方法可以使所有正在等待队列中等待同一共享资源的全部线程从等待状态退出，进入可运行状态。此时，优先级最高的那个线程最先执行，但也有可能是随机执行，这要取决于JVM虚拟机的实现。

用一句话来总结一下wait和notify：wait使线程停止运行，而notify使停止的线程继续运行，notify()方法执行后并不立即释放锁，而是等同步代码块&#x2F;同步方法中的逻辑执行完才释放。

如果调用wait()没有适当的锁，则抛出IllegalMonitorStateException，它是RuntimeException的一个子类，因此，不需要try-catch语句进行捕捉异常。


当interrupt方法遇到wait方法后会抛出异常，锁也会释放，即在执行同步代码块的过程中，遇到异常而导致线程终止，锁也会被释放。

每个锁对象都有两个队列，一个是就绪队列，一个是阻塞队列。就绪队列存储了将要获得锁的线程，阻塞队列存储了被阻塞的线程。一个线程被唤醒后，才会进入就绪队列，等待CPU的调度；反之，一个线程被wait后，就会进入阻塞队列，等待下一次被唤醒。
线程的6种状态及切换

初始状态NEW  实现Runnable接口和继承Thread可以得到一个线程类，new一个实例出来，线程就进入了初始状态。
就绪状态RUNNABLE

就绪状态只是说你资格运行，调度程序没有挑选到你，你就永远是就绪状态。
调用线程的start()方法，此线程进入就绪状态。
当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。
当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。
锁池里的线程拿到对象锁后，进入就绪状态。
线程进入Runnable状态大体分为如下5种情况：

调用sleep()方法后经过的时间超过了指定的休眠时间。

线程调用的阻塞IO已经返回，阻塞方法执行完毕。

线程成功地获得了试图同步的监视器。

线程正在等待某个通知，其他线程发出了通知。

处于挂起状态的线程调用resume恢复方法。


运行中状态RUNNING
getState()并没有RUNNING状态，RUNNING和RUNNABLE是合并在一块的。

线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一一种方式。
阻塞状态BLOCKED阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块(获取锁)时的状态，Blocked状态结束后，进入Runnable状态，等待系统重新分配资源。
出现阻塞的情况大致分为如下5种：

线程调用sleep方法，主动放弃占用的处理器资源。

线程调用了阻塞式IO方法，在该方法返回前，该线程被阻塞。

线程识图获得一个同步监视器，但该同步监视器正被其他线程所持有。

线程等待某个通知。

程序调用了suspend方法将该线程挂起。此方法容易导致死活，尽量避免使用该方法。


等待WAITING
有可能被这些方法调用

Object.wait
Thread.join
LockSupport.park


处于这种状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态。
超时等待TIMED_WAITING
有可能被这些方法调用

Object.wait
Thread.join
Thread.sleep
LockSupport.parkNanos
LockSupport.parkUntil


处于这种状态的线程不会被分配CPU执行时间，不过无须无限期等待被其他线程显示地唤醒，在达到一定时间后它们会自动唤醒。
终止状态TERMINATED当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。
join()join的作用是使所属的线程对象X正常执行run()方法中的任务，而使当前线程Z进行无限制的阻塞，等待线程X销毁后再继续执行线程Z后面的代码。
join和synchronized的区别join具有使线程排队运行的作用，有些类似同步的运行效果。join于synchronized的区别是：join在内部使用wait()方法进行等待，而synchronized关键字使用的是“对象监视器”原理作为同步。
join(long)与sleep(long)的区别join(long)的功能在内部是使用wait(long)方法来实现的，所以join(long)方法具有释放锁的特点，而Thread.sleep(long)方法却不释放锁。
ThreadLocal类ThreadLocal主要解决的就是每个线程绑定自己的值，可以将ThreadLocal类比喻成全局存放数据的盒子，盒子中可以存储每个线程的私有数据。
ThreadLocal设置初始化值
public class ThreadLocalExt extends ThreadLocal &#123;    @Override    protected Object initialValue() &#123;        return &quot;设置初始化值&quot;;    &#125;&#125;

InheritableThreadLocal类可以让子线程从父线程中取得值
public class ThreadLocalExt extends InheritableThreadLocal &#123;    @Override    protected Object initialValue() &#123;        return &quot;设置初始化值&quot;;    &#125;    @Override    protected Object childValue(Object parentValue) &#123;        return &quot;子类值&quot;;    &#125;&#125;


ReentrantLockReentrantLock功能上比synchronized关键字更加的强大，比如具有嗅探锁定、多路分支通知等功能，而且在使用上也比synchronized更加的灵活。
关键字synchronized于wait()和notify()&#x2F;notifyAll()方法相结合可以实现等待&#x2F;通知模式，类ReentrantLock也可以实现同样的功能，但需要借助于Condition对象，从而实现有选择性的线程通知。
Condition等待&#x2F;通知方法和synchronized等待&#x2F;通知方法的区别：

Object类中的wait()方法相当于Condition类中的await()方法。
Object类中的wait(long timeout)方法相当于Condition类中的await(long time, TimeUnit unit)方法。
Object类中的notify()方法相当于Condition类中的signal()方法。
Object类中的notifyAll()方法相当于Condition类中的signalAll()方法。

示例代码：
public class MyService &#123;    private Lock lock = new ReentrantLock();    public Condition conditionA = lock.newCondition();    public Condition conditionB = lock.newCondition();    public void awaitA() &#123;        try &#123;            lock.lock();            conditionA.await();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;        public void signalAll_A() &#123;        try &#123;            lock.lock();            conditionA.signalAll();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;

公平锁于非公平锁公平与非公平锁：锁Lock分为“公平锁”和“非公平锁”，公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的FIFO先进先出顺序。而非公平锁就是一种获取锁的抢占机制，是随机获得锁的，和公平锁不一样的就是先来的不一定先得到锁，这个方式可能造成某些线程一直拿不到锁，结果也就是不公平的了。
在默认的情况下，ReentrantLock类使用的是非公平锁。
示例代码：
public class Service &#123;    private ReentrantLock lock;    public Service(boolean isFair) &#123;        super();        lock = new ReentrantLock(isFair);    &#125;&#125;

ReentrantLock对象方法getHoldCount
int getHoldCount()的作用是查询当前线程保持此锁定的个数，也就是调用lock()方法的次数。

getQueueLength
int getQueueLength()的作用是返回正等待获取此锁定的线程估计数，比如有5个线程，1个线程首先执行await()方法，那么在调用getQueue()方法后返回值是4，说明有4个线程同时在等待lock的释放。

getWaitQueueLength
int getWaitQueueLength(Condition condition)的作用是返回等待与此锁定相关的给定条件Conditin的线程估计数，比如有5个线程，每个线程都执行了同一个condition的await方法，则调用getWaitQueueLength(Condition condition)方法时返回的int值是5。

hasQueuedThread
boolean hasQueueThread(Thread thread)的作用是查询指定的线程是否正在等待获取此锁定。

hasQueuedThreads
boolean hasQueueThreads()的作用是获取指定的锁是否有线程正在等待调用。

hasWaiters
boolean hasWaiters(Condition condition)的作用是查询是否有线程正在等待与此锁定有关的condition条件；getWaitQueueLength(Condition condition)可以获取到等待的线程的数量。

isFair
boolean isFair()的作用是判断是不是公平锁。

isHeldByCurrentThread
boolean isHeldByCurrentThread()的作用是查询当前线程是否保持此锁定。

isLocked
boolean isLocked()的作用是查询此锁定是否由任意线程保持。

lockInterruptibly
void lockInterruptibly()的作用是：如果当前线程未被中断，则获取锁定，如果已经被中断interrupt则出现异常。(对比lock()方法)

tryLock
boolean tryLock()的作用是，仅在调用时锁定未被另一个线程保持的情况下，才获取改锁定。
boolean tryLock(long timeout, TimeUnit unit)的作用是，如果锁定在给定等待时间内没有被另一个线程保持，且当前线程未被中断，则获取该锁定。

Condition对象方法
使用好Condition对象可以对线程执行的业务进行排序规划（即利用主内存唯一变量做判断控制，如果不满足条件当当前线程停留在await状态）。

awaitUninterruptibly
void awaitUninterruptibly()的作用是等待时忽略中断，不至于类似于await()那样被中断后会抛出异常。

awaitUntil
boolean awaitUntil(Date deadline)的作用是：等待到特定日期，而且线程在等待时间到达之前，可以被其他线程唤醒。

ReentrantReadWriteLock类ReentrantLock具有完全互斥排他的效果，即同一时间只有一个线程在执行ReentrantLock()方法后面的任务。这样做虽然保证了实例变量的线程安全性，但效率是非常低下的。所以在JDK中提供了一种读写锁ReentrantReadWriteLock类，使用他可以加快运行效率，在某些不需要操作实例的变量中，完全可以使用读写锁ReentrantReadWriteLock来提升该方法的代码运行速度。
读写锁表示也有两个锁，一个是读操作相关的锁，也成为共享锁；另一个是写操作相关的锁，也叫排它锁。也就是多个读锁之间不互斥，读锁和写锁互斥、写锁和写锁互斥。在没有线程Thread进行写入操作时，进行读取操作的多个Thread都可以获取读锁，而进行写入操作的Thread只有在获取写锁之后才能进行写入操作。即多个Thread可以同时进行读取操作，但是同一时刻只允许一个Thread进行写入操作；体现在读读共享，写写互斥，读写互斥，写读互斥。
定时器Timer在JDK库中，Timer类主要负责计划任务的功能，也就是在指定的时间开始执行某一个任务；抽象类为TimerTask。
Timer timer1 = new Timer(); //非守护线程Timer timer2 = new Timer(true); // 守护线程

Timmer执行定时任务如果计划时间早于当前时间，则会提前执行task任务。

TimmerTask是以队列的方式一个一个被顺序的执行，所以执行的时间有可能和预期的时间不一致，因为前面的任务有可能消耗的时间较长，则后面的任务运行的时间也被延后。

cancel
Timer类的cancel()方法有时不一定会停止计划任务，而是正常执行，原因是Timer类中的cancel()方法有时并没有争抢到queue锁，而让TimerTask类中的任务正常执行。


TimerTask类的cancel()方法
TimerTask类的cancel()方法的作用是讲自身从任务队列中进行清除。

Timer类的cancel()方法
和TimerTask类中的cancel方法()清除自身不同，Timer类中的cancel()方法是将自身队列中全部的任务进行清空。


schedule
schedule(TimerTask task, Date firstTime, long period)
该方法的作用是在指定的日期之后按指定的间隔周期，无限循环地执行某一任务。

schedule(TimerTask task, long delay, long period)
该方法的作用是以执行schedule(TimerTask task, long delay, long period)方法当前的时间为参考时间，在此时间基础上延迟指定的毫秒数，再以某一间隔时间无限次数地执行某一任务。


scheduleAtFixedRate
scheduleAtFixedRate(TimerTask task, Date firstTime, long period)
该方法的作用是在指定的日期之后按指定的间隔周期，无限循环地执行某一任务，同schedule的区别在于有没有追赶性。

scheduleAtFixedRate(TimerTask task, long delay, long period)
该方法的作用是以执行scheduleAtFixedRate(TimerTask task, long delay, long period)方法当前的时间为参考时间，在此时间基础上延迟指定的毫秒数，再以某一间隔时间无限次数地执行某一任务。


追赶性如果定时任务计划的时间早于当前时间，schedule方法在提前时间段区间之间的所对应的Task任务就被取消掉，不被执行了，这就是Task任务不追赶；而scheduleAtFixedRate方法在提前时间段区间之间的所对应的Task任务就被“补充性”地执行，直到提前时间区间段的时间区间补充执行完毕，这就是Task任务追赶特性。
单例模式与多线程俄汉模式、懒汉模式立即加载&#x2F;饿汉模式什么是立即加载？立即加载就是使用类的时候已经将对象创建完毕，常见的实现方法就是直接new实例化。而立即加载从中文的语境来看，有“着急”、“急迫”的含义，所以也称为“饿汉模式”。
延迟加载&#x2F;懒汉模式什么是延迟加载？延迟加载就是在调用get()方法时实例才被创建，常见的实现办法就是在get()方法中进行实例化。而延迟加载从中文的语境来看，是“缓慢”、“不急迫”的含义，所以也称为“懒汉模式”。
饿汉模式应用于多线程会产生很大的性能问题，推荐多线程一般都用的懒汉模式，大概分为以下几种：
DCL双检查 机制DCL双检查机制就是在同步代码块调用之前检查一遍，再在同步代码块内部再检查一遍，即使用volatile保证主内存变量一致，同时对逻辑代码块进行加锁，作为一种双重保险的保障。
实例代码：
public class MyObject &#123;    private volatile static MyObject myObject;    public MyObject() &#123;    &#125;        // 使用双检查机制来解决问题，既保证了不需要同步代码的异步执行型    // 又保证了单例的效果        public static MyObject getInstance() &#123;        try &#123;            if (myObject != null) &#123;            &#125; else &#123;                // 模拟在创建对象之前做一些准备性的工作                Thread.sleep(3000);                synchronized (MyObject.class) &#123;                    if (myObject == null) &#123;                        myObject = new MyObject();                    &#125;                &#125;            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        return myObject;    &#125;&#125;

使用静态内置类public class MyObject &#123;    // 内部类方式    private static class MyObjectHandler &#123;        private static MyObject myOjbect = new MyObject();    &#125;    public MyObject() &#123;    &#125;        public static MyObject getInstance() &#123;        return MyObjectHandler.myOjbect;    &#125;&#125;

序列化与反序列化的单例模式
readResolve()的实现是关键所在，可以从ObjectInputStream中的readObject进行延伸，代码如下所示：



示例代码：
public class MyObject implements Serializable &#123;    private static final long serialVersionUID = 4037244617173811007L;    // 内部类方式    private static class MyObjectHandler &#123;        private static MyObject myOjbect = new MyObject();    &#125;    public MyObject() &#123;    &#125;    public static MyObject getInstance() &#123;        return MyObjectHandler.myOjbect;    &#125;    protected Object readResolve() &#123;        System.out.println(&quot;调用了readResolve方法！ &quot;);        return MyObjectHandler.myOjbect;    &#125;&#125;public class SaveAndRead &#123;    public static void main(String[] args) &#123;        try &#123;            MyObject myObject = MyObject.getInstance();            FileOutputStream fosRef = new FileOutputStream(new File(&quot;myObjectFile.txt&quot;));            ObjectOutputStream oosRef = new ObjectOutputStream(fosRef);            oosRef.writeObject(myObject);            oosRef.close();            fosRef.close();            System.out.println(myObject.hashCode());        &#125; catch (FileNotFoundException e) &#123;            e.printStackTrace();        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;        try &#123;            FileInputStream fisRef = new FileInputStream(new File(&quot;myObjectFile.txt&quot;));            ObjectInputStream iosRef = new ObjectInputStream(fisRef);            MyObject myObject = (MyObject)iosRef.readObject();            iosRef.close();            fisRef.close();            System.out.println(myObject.hashCode());        &#125; catch (FileNotFoundException e) &#123;            e.printStackTrace();        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; catch (ClassNotFoundException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;

使用static代码块实现单例模式示例代码：
public class MyObject &#123;    private static MyObject instance;    public MyObject() &#123;    &#125;    static &#123;        instance = new MyObject();    &#125;    public static MyObject getInstance() &#123;        return instance;    &#125;&#125;

使用enum枚举数据类型实现单例模式枚举enum和静态代码块的特性相似，在使用枚举类时，构造方法会被自动调用。
示例代码：
public enum MyObject &#123;    connectionFactory;    private Connection connection;    private MyEnumSingleTon() &#123;        try &#123;            System.out.println(&quot;调用了MyObject的构造 &quot;);            String url = &quot;jdbc:sqlserver://localhost:1079;databaseName=ghydb&quot;;            String username = &quot;sa&quot;;            String password = &quot;&quot;;            String driverName = &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;;            Class.forName(driverName);            connection = DriverManager.getConnection(url, username, password);        &#125; catch (ClassNotFoundException e) &#123;            e.printStackTrace();        &#125; catch (SQLException e) &#123;            e.printStackTrace();        &#125;    &#125;    public Connection getConnection() &#123;        return MyEnumSingleTon.connectionFactory.getConnection();    &#125;&#125;

线程组可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程。
线程组的作用是：可以批量的管理线程或线程组对象，有效地对线程或线程组对象进行组织。

线程组拥有自动归属特性，即自动归到当前线程组中。
优先：通过将线程归属到线程组中，当调用线程组ThreadGroup的interrupt()方法时，可以将该组中的所有正在运行的线程批量停止。

一级关联示例代码：
ThreadGroup group = new ThreadGroup(&quot;姚煜明的线程组&quot;);

多级关联示例代码：
ThreadGroup mainGroup = Thread.currentThread().getThreadGroup();ThreadGroup group = new ThreadGroup(mainGroup, &quot;A&quot;);

递归与非递归取得组内对象
默认是递归获取。

示例代码：
ThreadGroup[] listGroup1 = new ThreadGroup[Thread.currentThread().activeCount()];Thread.currentThread().getThreadGroup().enumerate(listGroup1, true);ThreadGroup[] listGroup2 = new ThreadGroup[Thread.currentThread().activeCount()];Thread.currentThread().getThreadGroup().enumerate(listGroup2, false);

线程出现异常的处理setUncaughtExceptionHandler方法示例代码：
ThreadA t1 = new ThreadA();t1.setName(&quot;线程T1&quot;);t1.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() &#123;    @Override    public void uncaughtException(Thread t, Throwable e) &#123;        System.out.println(&quot;线程：&quot; + t.getName() + &quot; 出现了异常： &quot;);        e.printStackTrace();    &#125;&#125;);t1.start();


在默认的情况下，线程组的一个线程出现异常不会影响其他线程的运行。
如果想出现异常停止所有的线程，前提必须调用父类的uncaughtException(t, e)方法，可以如下操作：

public class MyThreadGroup extends ThreadGroup &#123;    public MyThreadGroup(String name) &#123;        super(name);    &#125;    @Override    public void uncaughtException(Thread t, Throwable e) &#123;        super.uncaughtException(t, e);        this.interrupt();    &#125;&#125;

Executor和ExexcutorService


名字
内容



Executor
提供了用于执行Runnable对象的execute方法的接口


ExecutorService
提供了用于关闭自己的shutdown方法的Executor接口


ScheduledExecutorService
在一定时间后或周期性地执行提交上来的命令的ExecutorService的接口


AbstractExecutorService
ExecutorService的默认实现类


ThreadPoolExecutor
使用了线程池的ExecutorService的实现类


ScheduledThreadPoolExecutor
ScheduledExecutorService的典型的实现类


Future和FutureTaskjava.util.concurrent.Future是表示异步处理的执行结果的接口。该接口的主要实现是FutureTask类。



名字
内容



Future&lt;V&gt;
表示异步处理的结果的接口，该接口是ExecutorService的返回值


ScheduledFuture
ScheduledExecutorService的处理结果


FutureTask&lt;V&gt;
可以调用Runnable对象的run方法或是Callable对象的call方法的任务。该类是Future接口的典型的实现类


CompletionService&lt;V&gt;
将异步任务的创建与使用任务处理结果分离的任务


ExecutorCompletionService&lt;V&gt;
面向Executor的CompletionService




java.util.concurrent.locks包


名字
内容



Lock
可以创建出与synchronized的锁具有不同结构的锁的接口


ReadWriteLock
用于创建Read-Write Lock的接口


ReentrantLock
可以被多次获取的互斥锁


ReentrantReadWriteLock
具有与ReentrantLock类似功能的ReadWriteLock的实现类


ReentrantReadWriteLock.ReadLock
通过ReentrantReadWriteLock.readLock方法获取的Lock对象


ReentrantReadWriteLock
通过ReentrantReadWriteLock.writeLock方法获取的Lock对象


Condition
用于与Lock组合使用，创建线程的等待队列的接口


AbstractQueueSynchronizer
用于创建一个以FIFO方式让线程等待的队列的框架


LockSupport
制作锁和同步机制的基本原语


java.util.concurrent.atomic包


名字
内容



AtomicBoolean
以原子方式操作的boolean类型的变量


AtomicInteger
以原子方式操作的int类型的变量


AtomicLong
以原子方式操作的long类型的变量


AtomicReference&lt;V&gt;
以原子方式操作的对象引用类型的变量


AtomicIntegerFieldUpdater&lt;T&gt;
以原子方式操作的int类型的字段


AtomicLongFieldUpdater&lt;T&gt;
以原子方式操作的long类型的字段


AtomicReferenceFieldUpdater&lt;T&gt;
以原子方式操作的引用类型的字段


AtomicIntegerArray
以原子方式操作的int类型的数组


AtomicLongArray
以原子方式操作的long类型的数组


AtomicReferenceArray&lt;E&gt;
以原子方式操作的对象引用类型的数组


AtomicMarkableReference&lt;E&gt;
以原子方式操作的带有标记的对象引用


AtomicStampedReference&lt;V&gt;
以原子方式操作的带有时间戳的对象引用


]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 多线程设计模式</title>
    <url>/posts/4b405cfc/</url>
    <content><![CDATA[多线程设计模式概念线程的终止Java程序的终止是指除守护进程以外的线程全部终止。
竞态条件线程之间由于相互竞争而引起的与预期相反的情况称为数据竞争（data race）或竞态条件（race condition）。
监视线程的互斥机制称为监视（monitor）。另外，获取锁有时也叫做“拥有监视”或“持有锁”。
当前线程是否已获取某一对象的锁可以通过Thread.holdsLock方法来确认。当前线程已获取对象obj的锁时，可使用assert来像下面表示出来。
assert Thread.holdsLock(obj)

ConcurrentHashMapHashTable中的所有方法都采用Single Threaded Execution模式，而ConcurrentHashMap则将内部数据结构分成多段，针对各段操作的线程互不相干，因而也就无需针对其他线程执行互斥处理。这样看来，HashTable更容易发生线程冲突。
java.util.concurrent.CocurrentHashMap接口是通过分割内部数据结构防止线程冲突的Map。
SemaphoreSemaphore是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做完自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore可以用来构建一些对象池，资源池之类的，比如数据库连接池，我们也可以创建计数为1的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。
资源的许可个数（permits）将通过Semaphore的构造函数来确定。

Semaphore的acquire方法用于确保存在可用资源。
Semephore的release方法用户释放资源。

示例代码：
public class Log &#123;    public static void printLn(String s) &#123;        System.out.println(Thread.currentThread().getName() + &quot;: &quot; + s);    &#125;&#125;public class BoundedResource &#123;    private final Semaphore semaphore;    private final int permits;    private final static Random random = new Random(314159);    public BoundedResource(int permits) &#123;        this.semaphore = new Semaphore(permits);        this.permits = permits;    &#125;    public void use() throws InterruptedException &#123;        semaphore.acquire();        try &#123;            doUse();        &#125; finally &#123;            semaphore.release();        &#125;    &#125;    protected void doUse() throws InterruptedException &#123;        Log.printLn(&quot;BEGIN: used = &quot; + (permits - semaphore.availablePermits()));        Thread.sleep(random.nextInt(500));        Log.printLn(&quot;END: used = &quot; + (permits - semaphore.availablePermits()));    &#125;&#125;public class UserThread extends Thread &#123;    private final static Random random = new Random(26344);    private final BoundedResource resource;    public UserThread(BoundedResource resource) &#123;        this.resource = resource;    &#125;    @Override    public void run() &#123;        try &#123;            while (true) &#123;                resource.use();                Thread.sleep(random.nextInt(3000));            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        BoundedResource resource = new BoundedResource(3);        for (int i = 0; i &lt; 10; i++) &#123;            new UserThread(resource).start();        &#125;    &#125;&#125;

Before&#x2F;After模式before&#x2F;After模式主要在于finally的引入。
示例代码void method() &#123;    lock();    try &#123;    //	业务逻辑    &#125; finally &#123;        unlock();    &#125;&#125;



ThreadFactoryThreadFactory翻译过来是线程工厂，顾名思义，就是用来创建线程的，它用到了工厂模式的思想。它通常和线程池一起使用，主要用来控制创建新线程时的一些行为，比如设置线程的优先级，名字等等。
示例代码：
public class Main &#123;    public static void main(String[] args) &#123;        ThreadFactory factory = Executors.defaultThreadFactory();        factory.newThread(new Printer(&quot;Nice!&quot;)).start();        factory.newThread(new Printer(&quot;Bitch!&quot;)).start();        for (int i = 0; i &lt; 10000; i++) &#123;            System.out.println(&quot;Good&quot;);        &#125;    &#125;&#125;


单线程程序中使用synchronized方法并不会破坏程序的安全性。但是，调用synchronized方法要比调用一般方法花费时间，这会稍微降低程序性能。


long，double的赋值和引用操作并不是原子的。总结如下：

基本类型、引用类型的赋值和引用是原子操作。
long和double的赋值和引用是非原子操作。
long或double在线程间共享时，需要将其放入synchronized中操作，或者声明为volatile。



字符串和实例表达式通过运算符“+”连接时，程序会自动调用实例表达式的toString()方法。


Thread.yield并不会释放锁。

Single Threaded Execution模式定义Single Threaded Execution模式主要是用于确保同一时间内只能让一个线程执行处理，说通俗点就是对synchronized的标准化使用方式，这是比较基础的。
角色Single Threaded Execution 模式的角色如下：
SharedResource(共享资源)参与者 SharedResource就是多线线程会同时访问的资源类，该类通常具有2类方法： ①SafeMethod——从多个线程同时调用也不会发生问题的方法 ②UnsafeMethod——从多个线程同时调用会发生问题，这类方法需要加以防护，指定只能由单线程访问区域，即临界区（critical section）。


Immutable模式定义Immutable是“永恒的”“不会改变”的意思。在Immutable Patttern中，有着能够保证实例状态绝不会改变的类（immutable 类）。因为访问这个实例时，可以省去使用共享互斥机制所会浪费的时间，提高系统性能。java.lang.String就是一个Immutable的类。
模式讲解

Immutable(不变的)参与者Immutable参与者是一个字段值无法更改的类，也没有任何用来更改字段值的方法。当Immutable参与者的实例建立后，状态就完全不再变化。




即便字段是final字段，且不存在setter方法，也有可能不是不可变的。因为即使字段的值不会发生变化，字段引用的实例也有可能会发生变化。

Java标准类库中用到immutable模式

java.lang.String
java.math.BigInteger 和 java.math.BigDecimal。（BigInterger表示所有精度的整数，BigDecimal表示所有精度的数）
java.util.regex.Pattern 正则表达式
java.lang.Integer等基本类型的包装类
java.awt.Color


java.lang.Void类不同于其他的包装类，它无法创建实例。该类用于保存表示基本类型void的Class类的实例，用在反射和序列化中。

Guarded Suspension模式定义guarded是“被保护着的”、“被防卫着的”意思，suspension则是“暂停”的意思。当现在并不适合马上执行某个操作时，就要求想要执行该操作的线程等待。
模式讲解角色： Guarded Suspension Pattern 的角色如下：

GuardedObject  (被防卫的对象)参与者 GuardedObject 参与者是一个拥有被防卫的方法（guardedMethod）的类。当线程执行guardedMethod时，只要满足警戒条件，就能继续执行，否则线程会进入wait  set区等待。警戒条件是否成立随着GuardedObject的状态而变化。 GuardedObject 参与者除了guardedMethod外，可能还有用来更改实例状态的的方法stateChangingMethod。

在Java语言中，是使用while语句和wait方法来实现guardedMethod的；使用notify&#x2F;notifyAll方法实现stateChangingMethod。如案例中的RequestQueue 类。


Balking模式定义
我正坐在餐馆中，合计着吃点什么。想好之后，我举起手示意服务员点菜。于是，看到我举手的服务员就向我走来点菜。这时，另一位服务员也看到我举手示意了，但他看到已经有一位服务员走向了我，所以就没有再过来。
如果现在不适合执行这个操作，或者没必要执行这个操作，就停止处理，直接返回——这就是Balking模式。
所谓Balk，就是 “停止并返回” 的意思。
Balking 模式与Guarded Suspension模式一样，也存在守护条件。在Balking模式中，如果守护条件不成立，则立即中断处理。这与Guarded Suspension模式有所不同，因为Guarded Suspension模式是一直等待至可以运行。

模式详解角色：
GuardedObject（被防护的对象）

GuardedObject角色是一个拥有被防护的方法（guardedMethod）的类。当线程执行guardedMethod方法时，若守护条件成立，则执行实际的处理。而当守护条件不成立时，则不执行实际的处理，直接返回。守护条件的成立与否，会随着GuardedObject角色的状态变化而发生变化。
除了guardedMethod之外，GuardedObject角色还有可能有其他来改变状态的方法（stateChangingMethod）。

类图：





状态仅变化一次的变量，我们通常称为闭锁（latch，门闩）。这个门闩一旦插上，就再也打不开了

在守护条件成立之前等待一段时间，如果到时条件还未成立，则直接balk。我们将这种处理称为guarded timed 或timeout。
在java中，我们使用if来检查守护条件。balk处理的执行则是使用return从方法中退出，或者使用throw抛出异常。守护条件的检查处理则是使用synchronized放在临界区中。
示例代码import java.io.FileWriter;import java.io.IOException;import java.io.Writer;public class Data &#123;    private final String filename;    private String content;    private boolean changed;    public Data(String filename, String content) &#123;        this.filename = filename;        this.content = content;        this.changed = true;    &#125;    //修改了数据内容    public synchronized void change(String newContent) &#123;        content = newContent;        changed = true;    &#125;    //若数据修改过，则保存到文件中    public synchronized void save() throws IOException &#123;        if (!changed) &#123;            //如果没有修改，就不保存了            return;        &#125;        doSave();        changed = false;    &#125;    //将数据内容保存到文件中    public void doSave() throws IOException &#123;        System.out.println(Thread.currentThread().getName() + &quot; calls doSave, content =&quot; + content);        Writer writer = new FileWriter(filename);        writer.write(content);        writer.close();    &#125;&#125;import java.io.IOException;import java.util.Random;public class ChangerThread extends Thread &#123;    private final Data data;    private final Random random = new Random();    public ChangerThread(String name, Data data) &#123;        super(name);        this.data = data;    &#125;    @Override    public void run() &#123;        try &#123;            for (int i = 0; true; i++) &#123;                data.change(&quot;NO.&quot; + i);//修改数据                Thread.sleep(random.nextInt(1000));//执行其他操作                data.save();//显示的保存,用户自己点击保存            &#125;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;import java.io.IOException;public class SaverThread extends Thread &#123;    private final Data data;    public SaverThread(String name, Data data) &#123;        super(name);        this.data = data;    &#125;    @Override    public void run() &#123;        try &#123;            while (true) &#123;                data.save();//要求保存数据                Thread.sleep(1000);//休眠约一秒            &#125;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;public class Test &#123;    public static void main(String[] args) &#123;        Data data = new Data(&quot;data.txt&quot;, &quot;(empty)&quot;);        new ChangerThread(&quot;ChangeThread&quot;, data).start();        new SaverThread(&quot;SaverThread&quot;, data).start();    &#125;&#125;

java.util.cocurrent中的超时通过异常通知超时当发生超时抛出异常时，返回值并不适合用于表示超时，需要使用java.util.concurrent.TimeoutException异常。

java.util.concurrent.Future接口的get方法
java.util.concurrent.Exchanger类的exchange方法
java.util.concurrent.Cyclicarrier类的await方法
java.util.concurrent.CountDownLatch类的await方法

通过返回值通知超时当执行多次try时，则不使用异常，而是使用返回值来表示超时。

java.util.concurrent.BlockingQueue接口
当offer方法的返回值为false，或poll方法的返回值为null时，表示发生了超时。

java.util.concurrent.Semaphore类
当tryAcquire方法的返回值为false时，表示发生了超时。

java.util.concurrent.locks.lock接口
当tryLock方法的返回值为false时，表示发生了超时。


Producer-Consumer模式定义Producer-Consumer Pattern就是生产者-消费者模式。生产者和消费者在为不同的处理线程，生产者必须将数据安全地交给消费者，消费者进行消费时，如果生产者还没有建立数据，则消费者需要等待。一般来说，可能存在多个生产者和消费者，不过也有可能生产者和消费者都只有一个，当双方都只有一个时，我们也称之为Pipe模式。
模式讲解Producer-Consumer模式的角色如下：

Data(数据)参与者Data代表了实际生产或消费的数据。
Producer(生产者)参与者Producer会创建Data，然后传递给Channel参与者。
Consumer(消费者)参与者Consumer从Channel参与者获取Data数据，进行处理。
Channel(通道)参与者Channel从Producer参与者处接受Data参与者，并保管起来，并应Consumer参与者的要求，将Data参与者传送出去。为确保安全性，Producer参与者与Consumer参与者要对访问共享互斥。






在Swing（JFC）框架中，事件处理部分使用的就是这种方法（多个Producer角色对应一个Comsumer角色）。执行Swing事件处理的线程称为事件分发线程。这个线程相当于从Channel角色的事件队列取出事件并进行处理的Comsumer角色。事件分发线程只有一个。

示例代码import java.util.concurrent.ArrayBlockingQueue;/** * 使用 queue */public class BlockingQueueTable extends ArrayBlockingQueue&lt;String&gt; &#123;    public BlockingQueueTable(int size) &#123;        super(size);    &#125;    public void put(final String cakeName) throws InterruptedException &#123;        super.put(cakeName);    &#125;    public String take() throws InterruptedException &#123;        return super.take();    &#125;&#125;/** * @see BlockingQueueTable 可以被这个替换 */public class Table &#123;    private String[] cakeArray;    private int head;    private int tail;    private int count;    private final int size;    public Table(int size) &#123;        this.size = size;        cakeArray = new String[size];        this.head = 0;        this.tail = 0;        this.count = 0;    &#125;    public synchronized void put(final String cakeName) throws InterruptedException &#123;        while (count &gt;= size) &#123;            wait();        &#125;        cakeArray[tail] = cakeName;        count++;        tail = (tail + 1) % size;        System.out.println(Thread.currentThread().getName() + &quot; put cake &quot; + cakeName);        notifyAll();    &#125;    public synchronized String take() throws InterruptedException &#123;        while (count &lt;= 0) &#123;            wait();        &#125;        String result = cakeArray[head];        head = (head + 1) % size;        count--;        System.out.println(Thread.currentThread().getName() + &quot; take cake &quot; + result);        notifyAll();        return result;    &#125;&#125;import java.util.Random;public class ConsumerCakeThread extends Thread &#123;    private String name;    private final Table table;    public ConsumerCakeThread(String name, Table table) &#123;        super(name);        this.table = table;    &#125;    @Override    public void run() &#123;        Random random = new Random(1000L);        try &#123;            while (true) &#123;                Thread.sleep(random.nextInt(1000));                table.take();            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;import java.util.Random;public class ProducerCakeThread extends Thread &#123;    private final Table table;    private static int id = 0;    public ProducerCakeThread(String name, Table table) &#123;        super(name);        this.table = table;    &#125;    @Override    public void run() &#123;        Random random = new Random(1000L);        try &#123;            while (true) &#123;                String cakeName = getName() + &quot;-&quot; + genId();                Thread.sleep(random.nextInt(1000));                table.put(cakeName);            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;    private static synchronized int genId() &#123;        return id++;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Table table = new Table(3);        new ConsumerCakeThread(&quot;ConsumerCake&quot;, table).start();        new ProducerCakeThread(&quot;ProducerCake&quot;, table).start();    &#125;&#125;



Read-Write Lock模式定义Read-Write Lock Pattern将读取与写入分开处理，在读取数据之前必须获取用来读取的锁定，而写入的时候必须获取用来写入的锁定。因为读取时实例的状态不会改变，所以多个线程可以同时读取；但是，写入会改变实例的状态，所以当有一个线程写入的时候，其它线程既不能读取与不能写入。
模式详解Read-Write Lock模式的角色如下：

Reader(读取者)参与者Reader参与者会对SharedResource进行读。
Writer(写入者)参与者Writer参与者会对SharedResource进行写。
SharedResource(共享资源)参与者SharedResource代表Reader和Writer所共享的资源对象，SharedResource提供不改变内部状态的read操作，以及会改变内部状态的write操作。
ReadWriteLock(读写锁)参与者ReadWriteLock提供了对SharedResource参与者进行read操作和write操作时需要的锁定。





总结SharedResource角色提供了read和write两个操作。read不会改变其状态，而write会，当Reader角色在read时，Writer角色必须等，而当Writer角色正在write时，Reader角色和其他Writer角色也必须等待。于是引入了ReadWriteLock角色，该角色提供分别用于read和write的锁，来执行上述的互斥处理，这样，确保了SharedResource角色的安全性，当read操作特别繁重时，程序性能能大大提高，在实现时，必须充分考虑执行互斥处理时采用的Guarded Suspension模式的守护条件。使用finally防止忘记释放锁，这就是Read Write Lock模式。
示例代码public class Data &#123;    private final char[] buffer;    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock(true); //这个其实是java.util.concurrent.locks写好的读写锁类,可以直接调用 不用自己写啦.    private final Lock readLock = lock.readLock(); // 读锁    private final Lock writeLock = lock.writeLock(); // 写锁    private final ReadWriteLock readWriteLock = new ReadWriteLock();//我们自己实现的读写锁类    public Data(int size) &#123;        this.buffer = new char[size];        for (int i = 0; i &lt; buffer.length; i++) &#123;            buffer[i] = &#x27;*&#x27;;        &#125;    &#125;    public char[] read() throws InterruptedException &#123;        readWriteLock.readLock();        try &#123;            return doRead();        &#125; finally &#123;            readWriteLock.unReadLock();        &#125;    &#125;    public void write(char c) throws InterruptedException &#123;        readWriteLock.writeLock();        try &#123;            doWrite(c);        &#125; finally &#123;            readWriteLock.unWriteLock();        &#125;    &#125;    private char[] doRead() &#123;        char[] newbuf = new char[buffer.length];        for (int i = 0; i &lt; newbuf.length; i++) &#123;            newbuf[i] = buffer[i];        &#125;        slowly();        return newbuf;    &#125;    private void slowly() &#123;        try &#123;            Thread.sleep(50);        &#125; catch (InterruptedException e) &#123;            // TODO Auto-generated catch block            e.printStackTrace();        &#125;    &#125;    private void doWrite(char c) &#123;        for (int i = 0; i &lt; buffer.length; i++) &#123;            buffer[i] = c;            slowly();        &#125;    &#125;&#125;public class ReaderThread extends Thread &#123;    private final Data data;    public ReaderThread(Data data) &#123;        this.data = data;    &#125;    public void run() &#123;        try &#123;            while (true) &#123;                char[] read = data.read();                System.out.println(Thread.currentThread().getName() + &quot; reads &quot; + String.valueOf(read));                Thread.sleep(1000);            &#125;        &#125; catch (InterruptedException e) &#123;            // TODO: handle exception        &#125;    &#125;&#125;public class WriterThread extends Thread &#123;    private static final Random random = new Random();    private final Data data;    private final String filler;    private int index = 0;    public WriterThread(Data data, String filler) &#123;        this.data = data;        this.filler = filler;    &#125;    public void run() &#123;        try &#123;            while (true) &#123;                char c = nextchar();                data.write(c);                System.out.println(Thread.currentThread().getName() + &quot; write &quot; + c);                Thread.sleep(random.nextInt(3000));            &#125;        &#125; catch (InterruptedException e) &#123;            // TODO: handle exception        &#125;    &#125;    private char nextchar() &#123;        char c = filler.charAt(index);        index++;        if (index &gt;= filler.length()) &#123;            index = 0;        &#125;        return c;    &#125;&#125;public class ReadWriteLock &#123;    private int readingReaders = 0; // 正在读取的线程数量    private int writingWriters = 0; // 正在写入的线程数量    public synchronized void readLock() throws InterruptedException &#123;        while (writingWriters &gt; 0) &#123; // 如果有线程在执行写入,等待.            wait();        &#125;        readingReaders++;  // 实际在读取的线程+1    &#125;    public synchronized void unReadLock() &#123;        readingReaders--;  // 实际读取线程-1        notifyAll();    &#125;    public synchronized void writeLock() throws InterruptedException &#123;        while (writingWriters &gt; 0 || readingReaders &gt; 0) &#123; // 如果有线程正在写入,或者在读取 等待            wait();        &#125;        writingWriters++; // 正在写入的线程+1    &#125;    public synchronized void unWriteLock() &#123;        writingWriters--; // 正在写入的线程-1        notifyAll();    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Data data = new Data(10);        new ReaderThread(data).start();        new ReaderThread(data).start();        new ReaderThread(data).start();        new ReaderThread(data).start();        new ReaderThread(data).start();        new ReaderThread(data).start();        new WriterThread(data, &quot;abcdefghijklmnopqrstuvwxyz&quot;).start();        new WriterThread(data, &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;).start();    &#125;&#125;

ReentrantReadWriteLock特点
公平性
当创建ReentrantReadWriteLock类的实例时，我们可以选择锁的获取顺序是否要设为公平的。如果创建的实例是公平的，那么等待时间久的线程可以优先获取锁。

可重入性
ReentrantReadWriteLock类的锁是可重入的。也就是说，Reader角色的线程可以获取“用于写入的锁”，Writer角色的线程也可以获取“用于读取的锁”。

锁降级
ReentrantReadwriteLock类可以按如下顺序将“用于写入的锁”降级为“用于读取的锁”。

获取用于写入的锁

获取用于读取的锁

释放用于写入的锁


但是，“用于读取的锁”不可以升级为“用户写入的锁”。

便携方法
ReentrantReadWriteLock类提供了获取等待中的线程的个数的方法getQueueLength，以及检查是否获取了用于写入的锁的方法isWriteLocked等便携方法。


Thread-per-Message模式定义Thread-Per-Message模式是说为每个请求都分配一个线程，由这个线程来执行处理，使得消息能够并发（但是注意：线程的创建是有限的，可以使用线程池来处理，超过数量则加入等待队列），这里包含两个角色，请求的提交线程和请求的执行线程。
模式详解
Client（委托人）Client角色会向Host角色发出请求（request），但是并不知道Host角色是如何实现该请求的。
HostHost角色收到Client角色的请求（request）之后，会新创建并启动一个线程。新创建的线程将使用Helper角色来 “处理”（handle）请求。
Helper（助手）Helper角色为Host角色提供请求处理的功能。Host角色创建的新线程会利用Helper角色。





优点
提高响应性，缩短延迟时间Thread-Per-Message模式能够提高与Client角色对应的Host角色的响应性，降低延迟时间。尤其是当handle操作非常耗时，或者handle操作需要等待输入&#x2F;输出时，效果非常明显。在Thread-Per-Message模式下，Host角色会启动新的线程。由于启动线程也会花费时间，所以想要提高响应性时，是否使用Thread-Per-Message模式取决于 “handle操作花费的时间” 和 “线程启动花费的时间” 之间的均衡。
适用于操作顺序没有要求时在Thread-Per-Message模式中，handle方法并不一定是按request方法的调用顺序来执行的。因此，当操作要按某种顺序执行时，Thread-Per-Message模式并不适用。
适用于不需要返回值时在Thread-Per-Message模式中，request方法并不会等待handle方法执行结束。所以request得不到handle的运行结果。因此，Thread-Per-Message模式适用于不需要获取返回值的情况。例如通知某个事件时。
应用于服务器为了使服务器可以处理多个请求，我们可以使用Thread-Per-Message模式。服务器本身的线程接收客户端的请求，而这些请求的实际处理则交由其他线程来执行，服务器本身的线程则返回，去等待客户端的其他请求。

Factory Method模式使用new创建Thread实例时，代码依赖于java.lang.Thread类。这时，我们无法控制创建线程的部分，可复用性较低。假如我们用字段threadFactory来保存ThreadFactory对象，用threadFactory.newThread(…)来替代new Thread(…)。这样一来，只要替换赋给threadFactory的ThreadFactory对象，我们便可以控制线程创建了。这就是Factory Method模式。
示例代码
public class Helper &#123;    public void handle(int count, char c) &#123;        System.out.println(&quot;handle begin&quot;);        for (int i = 0; i &lt; count; i++) &#123;            slowly();            System.out.print(c);        &#125;        System.out.println(&quot;&quot;);        System.out.println(&quot;handle end&quot;);    &#125;    private void slowly() &#123;        try &#123;            Thread.sleep(100);        &#125; catch (InterruptedException e) &#123;            // TODO Auto-generated catch block            e.printStackTrace();        &#125;    &#125;&#125;public class Host &#123;    private final Helper helper = new Helper();    private final ThreadFactory threadFactory;    public Host() &#123;        threadFactory = null;    &#125;    public Host(ThreadFactory threadFactory) &#123;        this.threadFactory = threadFactory;    &#125;    public void request(final int count, final char c) &#123;        System.out.println(&quot;request begin [&quot; + count + &quot;, &quot; + c + &quot;] begin&quot;);        threadFactory.newThread(new Runnable() &#123;            @Override            public void run() &#123;                helper.handle(count, c);            &#125;        &#125;).start();        System.out.println(&quot;request begin [&quot; + count + &quot;, &quot; + c + &quot;] end&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main begin&quot;);        ThreadFactory threadFactory = new ThreadFactory() &#123;            @Override            public Thread newThread(Runnable r) &#123;                return new Thread(r);            &#125;        &#125;;        Host host = new Host(threadFactory);        host.request(10, &#x27;A&#x27;);        host.request(20, &#x27;B&#x27;);        host.request(30, &#x27;C&#x27;);        System.out.println(&quot;main End&quot;);    &#125;&#125;

java.util.concurrent.Executor接口Executor接口将某些“处理的执行”抽象化了，参数传入的Runnable对象表示“执行的处理”的内容。
public class Helper &#123;    public void handle(int count, char c) &#123;        System.out.println(&quot;handle begin&quot;);        for (int i = 0; i &lt; count; i++) &#123;            slowly();            System.out.print(c);        &#125;        System.out.println(&quot;&quot;);        System.out.println(&quot;handle end&quot;);    &#125;    private void slowly() &#123;        try &#123;            Thread.sleep(100);        &#125; catch (InterruptedException e) &#123;            // TODO Auto-generated catch block            e.printStackTrace();        &#125;    &#125;&#125;public class Host &#123;    private final Helper helper = new Helper();    private final Executor executor;    public Host(Executor executor) &#123;        this.executor = executor;    &#125;    public void request(final int count, final char c) &#123;        System.out.println(&quot;request begin [&quot; + count + &quot;, &quot; + c + &quot;] begin&quot;);        executor.execute(new Runnable() &#123;            @Override            public void run() &#123;                helper.handle(count, c);            &#125;        &#125;);        System.out.println(&quot;request begin [&quot; + count + &quot;, &quot; + c + &quot;] end&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main begin&quot;);        Executor executor = new Executor() &#123;            @Override            public void execute(Runnable r) &#123;                new Thread(r).start();            &#125;        &#125;;        Host host = new Host(executor);        host.request(10, &#x27;A&#x27;);        host.request(20, &#x27;B&#x27;);        host.request(30, &#x27;C&#x27;);        System.out.println(&quot;main End&quot;);    &#125;&#125;

java.util.concurrent.ExecutorService接口ExecutorService接口对可以反复execute的服务进行了抽象化。线程一直在后台运行着，每当调用execute方式时，在ExecutorService接口后面，线程是一直在运行着，所以ExecutorService接口提供了shutdown方法来结束服务。
示例代码
public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main begin&quot;);        ExecutorService executorService = Executors.newCachedThreadPool();        Host host = new Host(executorService);        try &#123;            host.request(10, &#x27;A&#x27;);            host.request(20, &#x27;B&#x27;);            host.request(30, &#x27;C&#x27;);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            executorService.shutdown();            System.out.println(&quot;main End&quot;);        &#125;    &#125;&#125;

java.util.concurrent.ScheduledExecutorService类
java.util.concurrent.ScheduledExecutorService接口是ExecutorService的子接口，用于推迟操作的执行。
public class Helper &#123;    public void handle(int count, char c) &#123;        System.out.println(&quot;handle begin&quot;);        for (int i = 0; i &lt; count; i++) &#123;            slowly();            System.out.print(c);        &#125;        System.out.println(&quot;&quot;);        System.out.println(&quot;handle end&quot;);    &#125;    private void slowly() &#123;        try &#123;            Thread.sleep(100);        &#125; catch (InterruptedException e) &#123;            // TODO Auto-generated catch block            e.printStackTrace();        &#125;    &#125;&#125;public class Host &#123;    private final Helper helper = new Helper();    private final ScheduledExecutorService scheduledExecutorService;    public Host(ScheduledExecutorService scheduledExecutorService) &#123;        this.scheduledExecutorService = scheduledExecutorService;    &#125;    public void request(final int count, final char c) &#123;        System.out.println(&quot;request begin [&quot; + count + &quot;, &quot; + c + &quot;] begin&quot;);        scheduledExecutorService.schedule(new Runnable() &#123;            @Override            public void run() &#123;                helper.handle(count, c);            &#125;        &#125;, 3L, TimeUnit.SECONDS);        System.out.println(&quot;request begin [&quot; + count + &quot;, &quot; + c + &quot;] end&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main begin&quot;);        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5);        Host host = new Host(scheduledExecutorService);        try &#123;            host.request(10, &#x27;A&#x27;);            host.request(20, &#x27;B&#x27;);            host.request(30, &#x27;C&#x27;);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            scheduledExecutorService.shutdown();            System.out.println(&quot;main End&quot;);        &#125;    &#125;&#125;



总结Client 角色调用Host角色的request方法发来的请求，该请求的实际处理则交给Helper的handle去执行，然而，如果Client直接从request中调用handle方法，那么直到实际操作结束之前，都无法从handle方法返回（request返回），这样一来request的响应性能就下降了，因此，Host角色会启动用于处理来自Client角色请求的新线程，并让该线程来调用handle，这样一来发出请求的线程便可以立即从handle中返回。这就是Thread-Per-Message模式。
Worker Thread模式定义Worker的意思是工作的人、劳动者。在Worker Thread模式中，工人线程会逐个取回工作并进行处理。当所有工作全部完成后，工人线程会等待新的工作到来。
Worker Thread模式也被称为Background Thread（背景线程）模式。另外，如果从“保存多个工人线程的场所”这一点来看，我们也可以称这种模式为Thread Pool（线程池）模式。
模式详解





角色

Client（委托者）
Client角色创建表示工作请求的Request角色并将其传递给Channel角色。在示例程序中，由ClientThread类扮演此角色。

Channel（通信线路）
Channel角色接受来自于Client角色的Request角色，并将其传递给Worker角色。在示例程序中，由Channel类扮演此角色。

Worker（工人）
Worker角色从Channel角色中获取Request角色，并进行工作。当一项工作完成后，它会继续去获取另外的Channel角色。在示例程序中，由WorkerThread类扮演此角色。

Request（请求）
Request角色是表示工作的角色。Request角色中保存了进行工作所必需的信息。在示例程序中，由Request角色扮演此角色。




优点
提高响应速度
调用和执行分离。执行完调用处理的一方可以先继续执行其他处理，这样就可以提高响应速度。

控制执行顺序（调度）
如果调用和执行不可分离，那么在调用后就必须开始执行。
但是如果将调用和执行分离，执行就可以不再受调用调用顺序的制约。我们可以通过设置Request角色的优先级，并控制Channel角色将Request角色传递给Worker角色的顺序来实现上述处理。这种处理称为请求调度（scheduling）。

可以取消和反复执行
将调用和执行分离后，还可以实现“即使调用了也可以被取消执行”这种功能。
由于调用的是Request对象，所以既可以将Request角色保存，又可以反复的执行。

通往分布式之路
将调用和执行分离后，可以将负责调用的计算机与负责执行的计算机分离开来，然后通过网络将扮演Request角色的对象从一台计算机传递至另外一台计算机。


Future模式定义Future模式是多线程开发中非常常见的一种设计模式。它的核心思想是异步调用。当我们需要调用一个函数方法时。如果这个函数执行很慢,那么我们就要进行等待。但有时候,我们可能并不急着要结果。因此,我们可以让被调用者立即返回,让他在后台慢慢处理这个请求。对于调用者来说,则可以先处理一些其他任务,在真正需要数据的场合再去尝试获取需要的数据。

由于Future角色是”只能被赋值一次的变量“，所以可以把它看作一种闭锁（latch）。

模式详解


名字
说明



Main
向Host发出请求并获取数据的类


Host
向请求返回FutureData的实例的类


Data
表示访问数据的方法的接口。由FutureData和RealData实现该接口


FutureData
表示RealData的“提货单”的类。其他线程会创建RealData的实例。


RealData
表示实际数据的类。构造函数的处理会花费很长时间


类图


时序图


角色

Client（请求者）
Client角色向Host角色发出，并会立即接收到请求的处理结果——VirtualData角色。

Host
Host角色会创建新的线程，并开始在新线程中创建RealData角色。同时，它会将Future角色（当做VirtualData角色）返回给Client角色。

VirtualData
VirtualData角色是让Future角色和RealData角色具有一致性的角色。

RealData
RealData角色是表示真实数据的角色。

Future
Future角色是RealData角色的”提货单“，由Host角色传递给Client角色。


示例代码public interface Data &#123;    String getContent();&#125;public class FutureData implements Data &#123;    private RealData realData = null;    private boolean ready = false;    public synchronized void setRealData(RealData realData) &#123;        if (ready) &#123;            return; // balk        &#125;        System.out.println(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;setting content = &quot;+ realData.getContent());        this.realData = realData;        this.ready = true;        notifyAll();    &#125;    @Override    public String getContent() &#123;        while (!ready) &#123;            try &#123;                wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        return realData.getContent();    &#125;&#125;public class RealData implements Data &#123;    private final String content;    public RealData(int count, char c) &#123;        System.out.println(&quot;    making RealData(&quot; + count + &quot;, &quot; + c + &quot;) BEGIN&quot;);        char[] buffer = new char[count];        for (int i = 0; i &lt; count; i++) &#123;            buffer[i] = c;            try &#123;                Thread.sleep(100);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        System.out.println(&quot;    making RealData(&quot; + count + &quot;, &quot; + c + &quot;) END&quot;);        this.content = new String(buffer);    &#125;    @Override    public String getContent() &#123;        return content;    &#125;&#125;public class Host &#123;    public Data request(final int count, final char c) &#123;        System.out.println(&quot;    request(&quot; + count + &quot;, &quot; + c + &quot;) BEGIN&quot;);        final FutureData future = new FutureData();        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                RealData realData = new RealData(count, c);                future.setRealData(realData);            &#125;        &#125;).start();        System.out.println(&quot;    request(&quot; + count + &quot;, &quot; + c + &quot;) END&quot;);        return future;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main BEGIN&quot;);        Host host = new Host();        Data data1 = host.request(10, &#x27;A&#x27;);        Data data2 = host.request(20, &#x27;B&#x27;);        Data data3 = host.request(30, &#x27;C&#x27;);        System.out.println(&quot;main otherJob BEGIN&quot;);        try &#123;            Thread.sleep(5000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;main otherJob END&quot;);        System.out.println(&quot;data1 = &quot; + data1.getContent());        System.out.println(&quot;data2 = &quot; + data2.getContent());        System.out.println(&quot;data3 = &quot; + data3.getContent());        System.out.println(&quot;main END&quot;);    &#125;&#125;

java.util.concurrent 示例程序Callable、Future、FutureTask的类图


示例程序时序图


public interface Data &#123;    String getContent();&#125;public class FutureData extends FutureTask&lt;RealData&gt; implements Data &#123;    public FutureData(Callable&lt;RealData&gt; callable) &#123;        super(callable);    &#125;    @Override    public String getContent() &#123;        String string = null;        try &#123;            get().getContent();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; catch (ExecutionException e) &#123;            e.printStackTrace();        &#125;        return string;    &#125;&#125;public class RealData implements Data &#123;    private final String content;    public RealData(int count, char c) &#123;        System.out.println(&quot;    making RealData(&quot; + count + &quot;, &quot; + c + &quot;) BEGIN&quot;);        char[] buffer = new char[count];        for (int i = 0; i &lt; count; i++) &#123;            buffer[i] = c;            try &#123;                Thread.sleep(100);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        System.out.println(&quot;    making RealData(&quot; + count + &quot;, &quot; + c + &quot;) END&quot;);        this.content = new String(buffer);    &#125;    @Override    public String getContent() &#123;        return content;    &#125;&#125;public class Host &#123;    public FutureData request(final int count, final char c) &#123;        System.out.println(&quot;    request(&quot; + count + &quot;, &quot; + c + &quot;) BEGIN&quot;);        FutureData future = new FutureData(new Callable&lt;RealData&gt;() &#123;            @Override            public RealData call() throws Exception &#123;                return new RealData(count, c);            &#125;        &#125;);        // 启动一个新线程，用于创建RealData的实例。        new Thread(future).start();        System.out.println(&quot;    request(&quot; + count + &quot;, &quot; + c + &quot;) END&quot;);        return future;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main BEGIN&quot;);        Host host = new Host();        FutureData data1 = host.request(10, &#x27;A&#x27;);        FutureData data2 = host.request(20, &#x27;B&#x27;);        FutureData data3 = host.request(30, &#x27;C&#x27;);        System.out.println(&quot;main otherJob BEGIN&quot;);        try &#123;            Thread.sleep(5000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;main otherJob END&quot;);        try &#123;            System.out.println(&quot;data1 = &quot; + data1.get().getContent());            System.out.println(&quot;data2 = &quot; + data2.get().getContent());            System.out.println(&quot;data3 = &quot; + data3.get().getContent());        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; catch (ExecutionException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;main END&quot;);    &#125;&#125;

Two-Phase Termination模式定义该模式的名字直译是“分两阶段终止”的意思，它是一种先执行完终止处理再终止线程的模式。


我们称线程在进行正常处理时的状态为“操作中”，在要停止该线程时，会发出“终止请求”，这样，线程不会突然终止，而是会先开始进行“打扫工作”，称为“终止处理中”，是线程终止的第一阶段。
在“终止处理中”状态下，线程不会在进行正常操作，它虽然仍在运行，但是只会进行终止处理，终止处理完成后，就会真正地终止线程，是线程终止的第二阶段。
该模式的要点如下。

安全的终止线程。
必定会进行终止处理。
发出终止请求后尽快进行终止处理。

模式详解
TerminationRequester（终止请求发出者）TerminationRequester角色负责向Terminator角色发出终止请求，是示例程序中的Main类。

Terminator（终止者）Terminator负责接收终止请求，并实际执行终止处理，提供了表示终止请求的shutdownRequest方法。
当shutdownRequest方法被调用后，Terminator角色会在考虑了安全性的基础上，进入“终止处理中”状态，接着，当终止处理结束后，Terminator角色就会终止自己。


Two-Phase Termination模式的类图



NIO与多线程
java.nio.channels.Channel接口以及实现了该接口的类群的设计中考虑了多线程的问题。
例如，当一个线程在Channel上发生I&#x2F;O阻塞的时候，其他线程可以close该Channel。这时，发生I&#x2F;O阻塞的线程会接收到AsynchronousCloseException异常。
另外，当一个线程在Channel上发生I&#x2F;O阻塞的时候，其他线程还可以interrupt该线程。这时，发生I&#x2F;O阻塞的线程会接收到ClosedByInterruptException异常。

示例代码类图


时序图


public class CountupThread extends Thread &#123;    /**     * counter字段表示当前的计数器     * shutdownRequested字段是表示是否已经发出终止请求的标志，该字段的值用于判断线程是否进入“终止处理中”状态     * shutdownRequest方法是表示线程终止请求的方法，当要终止CountupThread的线程时，程序会调用该方法     * 注意，shutdownRequest还调用了interrupt方法，这是为了确保程序在sleep和wait时也会被终止     */    //计数值    private long counter = 0;    //发出终止请求后变为ture    private volatile boolean shutdownRequested = false;    //终止请求    public void shutdownRequest() &#123;        shutdownRequested = true;        interrupt();    &#125;    //检查是否发出了终止请求    public boolean isShutdownRequested() &#123;        return shutdownRequested;    &#125;    //线程体    public final void run() &#123;        try &#123;            while (!isShutdownRequested()) &#123;                doWork();            &#125;        &#125; catch (InterruptedException e) &#123;        &#125; finally &#123;            doShutdown();        &#125;    &#125;    //操作    private void doWork() throws InterruptedException &#123;        counter++;        System.out.println(&quot;doWork: counter = &quot; + counter);        Thread.sleep(500);    &#125;    //终止处理    private void doShutdown() &#123;        System.out.println(&quot;doShutdown: counter = &quot; + counter);    &#125;&#125;public class Main &#123;    /**     * 启动CountupThread的线程，大约10s后终止该线程     * Thread类的join方法是用户等待线程终止的方法，在指定的线程终止前，join方法不会返回。     *     * @param args     */    public static void main(String[] args) &#123;        System.out.println(&quot;main: Begin&quot;);        try &#123;            //启动线程            CountupThread t = new CountupThread();            t.start();            //稍微间隔一段时间            Thread.sleep(10000);            //线程的终止请求            System.out.println(&quot;main: shutdownRequest&quot;);            t.shutdownRequest();            System.out.println(&quot;main: join&quot;);            //等待线程终止            t.join();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;main: End&quot;);    &#125;&#125;

java.util.concurrent.ExecutorService接口与Two-phase Termination模式
ExecutorService使用了Two-phase Termination模式




isShutdown方法
isTerminated方法



【操作中】
false
false


【终止处理中】
true
false


【终止】
true
true


捕获程序整体的终止退出钩子退出钩子是指在Java虚拟机退出时启动的线程。”java虚拟机退出时“指的是System.exit()被调用或是全部非守护线程终止时。这时，我们可以使用退出钩子来编写程序完全终止时的终止处理。
示例程序执行了以下处理：

设置未捕获的异常的处理器
设置退出钩子
大约3秒后启动执行”整数除零计算“的线程

执行整数除零计算后，程序会抛出java.lang.ArithmeticException异常。由于在示例程序中我们并没有捕获ArithmeticExeception，所以程序会终止。在终止前，”为捕获的异常的处理器“和”退出钩子“会被依次调用。
未捕获的异常的处理器示例代码public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;main:BEGIN&quot;);        // 设置未捕获的异常的处理器        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() &#123;            @Override            public void uncaughtException(Thread t, Throwable e) &#123;                System.out.println(&quot;\n***********&quot;);                System.out.println(&quot;UncaughtExceptionHandler:BEGIN&quot;);                System.out.println(&quot;currentThread = &quot; + Thread.currentThread());                System.out.println(&quot;thread = &quot; + t);                System.out.println(&quot;exception = &quot; + e);                System.out.println(&quot;UncaughtExceptionHandler:END&quot;);            &#125;        &#125;);        // 设置退出钩子        Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;\n*************&quot;);                System.out.println(&quot;shutdown hook:BEGIN&quot;);                System.out.println(&quot;currentThread = &quot; + Thread.currentThread());                System.out.println(&quot;shutdown hook:END&quot;);            &#125;        &#125;));        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;MyThread:BEGIN&quot;);                System.out.println(&quot;MyThread:SLEEP...&quot;);                try &#123;                    Thread.sleep(3000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                int i = 1 / 0;            //    不会来到这里                System.out.println(&quot;MyThread:END&quot;);            &#125;        &#125;, &quot;MyThread&quot;).start();        System.out.println(&quot;main:END&quot;);    &#125;&#125;



Multiphase Cancellation 模式
使用Multiphase Cancellation模式停止线程时，如果在一定时间内线程没有停止，那么程序会逐渐发出更加强硬的终止请求。

Multi-Phase StartUp 模式
使用Two-Phase Termination模式时，在接收到终止请求后，程序并不立即终止线程，而是先进入”终止处理中“阶段，然后安全的终止线程。
而使用Multi-Phase StartUp模式时，如果存在多个子系统，则程序会经过多个阶段启动全部系统。在该模式下，系统会定义一个整数值的运行级锁，用来表示当前哪个运行级别正处于启动中状态。
Java的Applet也使用了该模式，不过它将Multi-Phase StartUp模式缩减至了三步（即创建实例 → 调用init方法 → 调用start方法）。



java.util.concurrent.CountDownLatch类当我们想让某个线程等待指定的线程终止时，可以使用java.lang.Thread类的join方法。但是，由于join方法可以等待的只是”线程终止“这个一次性的操作，所以我们无法使用它实现”等待指定次数的某种操作发生“。
使用java.util.concurrent.CountDownLatch类可以实现”等待指定次数的CountDown方法被调用“这一功能。
示例代码
准备一个进行工作的ExecutorService对象（service）
创建一个CountDownLatch类的实例（doneLatch）。在创建时将初始值TASKS传入CountDownLatch类的构造函数
调用execute方法执行（在内部启动线程）TASKS 个 MyTask
调用await方法等待doneLatch的计数值变为0
调用shutdown方法终止service

public class MyTask implements Runnable &#123;    private final CountDownLatch doneLatch;    private final int context;    private static final Random random = new Random(321234);    public MyTask(CountDownLatch doneLatch, int context) &#123;        this.doneLatch = doneLatch;        this.context = context;    &#125;    @Override    public void run() &#123;        doTask();        doneLatch.countDown();    &#125;    protected void doTask() &#123;        String name = Thread.currentThread().getName();        System.out.println(name + &quot;:MyTask:BEGIN:context = &quot; + context);        try &#123;            Thread.sleep(random.nextInt(3000));        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(name + &quot;:MyTask:END:context = &quot; + context);    &#125;&#125;public class Main &#123;    private static final int TASKS = 10; // 工作的个数    public static void main(String[] args) &#123;        System.out.println(&quot;BEGIN&quot;);        ExecutorService service = Executors.newFixedThreadPool(5);        CountDownLatch doneLatch = new CountDownLatch(TASKS);        try &#123;            // 开始工作            for (int i = 0; i &lt; TASKS; i++) &#123;                service.execute(new MyTask(doneLatch, i));            &#125;            System.out.println(&quot;AWAIT&quot;);            // 等待工作结束            doneLatch.await();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            service.shutdown();            System.out.println(&quot;END&quot;);        &#125;    &#125;&#125;

时序图

java.util.concurrent.CyclicBarrier类CyclicBarrier可以周期性的创建出屏障。在屏障解除之前，碰到屏障的线程是无法继续前进的。屏障的解除条件是到达屏障处的线程个数达到了构造函数指定的个数。也就是说，当指定个数的线程到达屏障处后，屏障就会被解除，然后这些线程就会像听到了”预备，走“一样一起冲出去。
在创建CyclicBarrier的实例时，可以指定Runnable对象。这个对象被称作”屏障操作“。每次屏障被解除后，该屏障操作都会被执行。
示例代码
调用doPhase(phase)方法进行第phase阶段的工作
调用await方法表示自己已经完成了第phase阶段的工作
当其他所有线程都完成了”第phase阶段的工作“后，run方法从await方法中返回并进入下个阶段的工作
当所有阶段的工作都完成后，使用doneLatch向主线程发送”工作结束“的消息。

public class MyTask implements Runnable &#123;    private static final int PHASE = 5;    private final CyclicBarrier phaseBarrier;    private final CountDownLatch doneLatch;    private final int context;    private static final Random random = new Random(32143);    public MyTask(CyclicBarrier phaseBarrier, CountDownLatch doneLatch, int context) &#123;        this.phaseBarrier = phaseBarrier;        this.doneLatch = doneLatch;        this.context = context;    &#125;    @Override    public void run() &#123;        for (int phase = 0; phase &lt; PHASE; phase++) &#123;            doPhase(phase);            try &#123;                phaseBarrier.await();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; catch (BrokenBarrierException e) &#123;                e.printStackTrace();            &#125; finally &#123;                doneLatch.countDown();            &#125;        &#125;    &#125;    protected void doPhase(int phase) &#123;        String name = Thread.currentThread().getName();        System.out.println(name + &quot;:MyTask:BEGIN:context = &quot; + context + &quot;, phase = &quot; + phase);        try &#123;            Thread.sleep(random.nextInt(3000));        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(name + &quot;:MyTask:END:context = &quot; + context + &quot;, phase = &quot; + phase);    &#125;&#125;public class Main &#123;    private static final int THREADS = 3; // 线程的个数    public static void main(String[] args) &#123;        System.out.println(&quot;BEGIN&quot;);        ExecutorService service = Executors.newFixedThreadPool(THREADS);        // 屏障被解除时的操作        Runnable barrierAction = new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;Barrier Action!&quot;);            &#125;        &#125;;        // CyclicBarrier用于使线程步骤一致        CyclicBarrier phaseBarrier = new CyclicBarrier(THREADS, barrierAction);        // CountDownLatch用于确认工作是否结束        CountDownLatch doneLatch = new CountDownLatch(THREADS);        try &#123;            for (int i = 0; i &lt; THREADS; i++) &#123;                service.execute(new MyTask(phaseBarrier, doneLatch, i));            &#125;            // 等待工作结束            System.out.println(&quot;AWAIT&quot;);            doneLatch.await();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            service.shutdown();            System.out.println(&quot;END&quot;);        &#125;    &#125;&#125;

时序图

Thread-Specific Storage定义Thread-Specific Storage就是“线程独有的存储库”，该模式会对每个线程提供独有的内存空间。java.lang.ThreadLocal类提供了该模式的实现，ThreadLocal的实例是一种集合（collection）架构，该实例管理了很多对象，可以想象成一个保管有大量保险箱的房间。
java.lang.ThreadLocal类的方法：

public void set()该方法会检查当前调用线程，默认以该线程的Thread.currentThread()值作为键，来保存指定的值。

public Object get()该方法会检查当前调用线程，默认以该线程的Thread.currentThread()值作为键，获取保存指定的值。


Thread-Specific Storage模式还有以下名称。

Per-Thread Attribute（线程各自的属性）
Thread-Specific Data（线程特有的数据）
Thread-Specific Field（线程特有的字段）
Thread-Local Storage（线程中的局部存储空间）

模式详解java.lang.ThreadLocal是一个泛型类，可以通过参数的类型来指定要存储的对象的类型。ThreadLocal类的声明大致如下：
public class ThreadLocal&lt;T&gt; &#123;	// 存储	public void set(T value) &#123;		...	&#125;		// 获取	public T get() &#123;		...	&#125;	...&#125;




名字
说明



TSLog
创建日志的类（实例属于各个线程所有）


Log
创建日志的类（分配各个线程）


java.lang.ThreadLocal
分配线程持有的存储空间的类


ClientThread
表示调用Log的线程的类


Main
测试程序行为的类


角色

Client（委托者）
Client角色将处理委托给TSObjectProxy角色。一个TSObjectProxy角色会被多个Client角色使用。

TSObjectProxy（线程特有的对象的代理人）
TSObjectProxy角色使用TSObjectCollection角色获取与Client角色对应的TSObject角色。接着，它将处理委托给TSObject角色。

TSObjectCollection（线程持有的对象的集合）
TSObjectCollection角色有一张Client角色与TSObject角色之间的对应表。

TSObject（线程特有的对象）
TSObject角色中保存着线程特有的信息。
TSObject角色有TSObjectCollection角色管理。TSObject角色的方法只会被单线程调用。


类图

时序图新创建TSObject角色


多个client角色访问各自的TSObject角色


示例程序类图


示例程序TimeThreads图


示例代码public class TSLog &#123;    private PrintWriter writer = null;    // 初始化writer字段    public TSLog(String filename) &#123;        try &#123;            writer = new PrintWriter(new FileWriter(filename));        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;    // 写日志    public void println(String s) &#123;        writer.println(s);    &#125;    // 关闭日志    public void close () &#123;        writer.println(&quot;=== Enf of log ===&quot;);        writer.close();    &#125;&#125;public class Log &#123;    private static final ThreadLocal&lt;TSLog&gt; tsLogCollection = new ThreadLocal&lt;&gt;();    // 写日志    public static void println(String s) &#123;        getTsLog().println(s);    &#125;    // 关闭日志    public static void close() &#123;        getTsLog().close();    &#125;    // 获取线程持有的日志    private static TSLog getTsLog() &#123;        TSLog tsLog = tsLogCollection.get();        if (tsLog == null) &#123;            tsLog = new TSLog(Thread.currentThread().getName() + &quot;-log.txt&quot;);            tsLogCollection.set(tsLog);        &#125;        return tsLog;    &#125;&#125;public class ClientThread extends Thread &#123;    public ClientThread(String name) &#123;        super(name);    &#125;    @Override    public void run() &#123;        System.out.println(getName() + &quot; BEGIN&quot;);        for (int i = 0; i &lt; 10; i++) &#123;            Log.println(&quot;i= &quot; + i);            try &#123;                Thread.sleep(100);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Log.close();        &#125;        System.out.println(getName() + &quot; END&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        new ClientThread(&quot;Alice&quot;).start();        new ClientThread(&quot;Bobby&quot;).start();        new ClientThread(&quot;Chris&quot;).start();    &#125;&#125;


保存线程特有信息的位置
线程特有的信息”保存位置“有以下两种：

线程外
类似于ThreadLocal这种将线程特有的信息保存在线程外部的方法称为”线程外“。

线程内
如果在线程中声明字段，该字段就是线程特有的信息。这就是在线程内保存线程特有的信息。



优点与强调吞吐量相比，Thread-Specific Storage模式更看重如下所示的可复用性。

不改变结构即可实现程序
没有显式地执行互斥处理，所以编程时犯错的可能性较小


Thread-Specific Storage与Worker Thread模式不能结合使用。
如果不能确保所有的任务都由不同的线程执行，Thread-Specific Storage模式可能就无法正确工作。这是使用java.lang.ThreadLocal时的一个重要制约条件。


在设计多线程角色时，根据以 [ 主体 ] 为主还是以 [ 客体 ] 为主的不同产生了以下两种方式。

基于角色：以主体为主
所谓基于角色，一言以蔽之即”线程最伟大“的方式。
基于角色的方式即在表示线程的实例中保存进行工作所必需的信息（上下文、状态）。这样可以减少和减轻线程之间的交互信息量。一个线程会使用从其他线程接收到的信息来执行处理，改变自己的内部状态。通常，我们称这样的线程为角色。
class Actor extends Thread &#123;	角色的内部状态	public void run() &#123;		循环地从外部接收并执行任务，改变内部状态	&#125;&#125;

基于任务：以客体为主
所谓基于任务，一言以蔽之即”任务最伟大“的方式。
基于任务的方式不在线程中保存信息（上下文、状态）。在这种方式下，这些信息不保存在线程中，而是保存在线程交互的实例中。而且，不仅是数据，连用于执行请求的方法都定义在其中。像这样在线程之交互的实例可以称为消息、请求或是命令。这里我们暂且称其为任务。由于任务中保存了足够的信息，所以任何线程执行该任务都没有问题。可以说，这是一种富任务往来于轻线程之间的方式。
使用该方式的一个典型的模式是Worker Thread模式。
class Task implements Runnable &#123;	进行工作所必需的信息	public void run() &#123;		工作的处理内容	&#125;&#125;

基于任务的示例
java.util.TimerTask是一个基于任务的类。该类实现了java.lang.Runnable，它会被java.util.Timer类调用。如果要定义一项在一定时间后进行的工作或者定期进行的工作，可以使用java.util.TimerTask类。
java.util.concurrent.FutureTask类也是一个基于任务的类。该类是Future模式的组成部分，它也实现了java.lang.Runnable。

Active Object模式定义Active是主动的意思，因此ActiveObject就是主动对象的意思。所谓主动一般指有自己特有的线程，举例来说，java.lang.Thread类的实例就是一种主动对象。
不过，在Active Object模式中出厂的主动对象可不仅仅有自己特有的线程，它同时还具备可以从外部接收和处理异步消息并根据需要返回处理结果的特征。Active Object模式中的主动对象会通过自己特有的线程在合适的时机处理从外部接收到的异步消息。
在Active Object中，组成主动对象与许多自然人组成法人类似，即使是java语言这样没有异步消息的编程语言，也可以使用Active Object模式组成实际上能够处理异步消息的主动对象。

在Java中，有一种与Active Object模式相关的技术叫做Remote Method Invocation（远程方法调用，RMI）。RMI是一种可以在本地调用方法，然后网络远端的计算机上执行方法的技术。为了能够在网络间传输对象，RMI使用了Java的序列化（serialization）技术。

模式详解成员一览（粗体字为activeObject包中的public的类和接口）



包
名字
说明



无名
Main
测试程序行为的类


无名
MakeClientThread
发出”生成字符串“请求的线程


无名
DisplayClientThread
发出”显示字符串“请求的线程


activeObject
ActiveObject
定义”主动对象“的接口（API）的接口


activeObject
ActiveObjectFactory
创建”主动对象“的类


activeObject
Proxy
将方法调用转换为MethodRequest对象的类（实现了ActiveObject）的接口


activeObject
SchedulerThread
调用execute方法处理MethodRequest对象的类


activeObject
ActivationQueue
按顺序保存MethodRequest对象的类


activeObject
MethodRequest
表示请求的抽象类


activeObject
MakeStringRequest
makeString方法（生成字符串）对应的类。MethodRequest类的子类


activeObject
DisplayStringRequest
displayString方法（显示字符串）对应的类。MethodRequest类的子类


activeObject
Result
表示执行结果的抽象类


activeObject
FutureResult
在Future模式中表示执行结果的类


activeObject
RealResult
表示实际的执行结果的类


activeObject
Servant
执行实际处理的类（实现了ActiveObject接口）


角色
Client（委托者）
Client角色调用ActiveObject角色的方法来委托处理，它能调用的只有ActiveObject角色提供的方法。调用这些方法后，（如果ActivationQueue角色没有满）程序控制权会立即返回。
虽然client只知道ActiveObject角色，但它实际上调用的是Proxy角色。
Client角色在获取处理结果时，会调用VirtualResult角色的getResultValue方法。这里使用了Future模式模式。
在示例程序1中，由MakerClientThread类和DisplayClientThread类扮演此角色。

ActiveObject角色
ActiveObject角色定义了主动对象向Client角色提供的接口。
在示例1程序中，由ActiveObject接口扮演此角色。

Proxy（代理人）
Proxy角色负责将方法调用转换为MethodRequest角色的对象。转换后的MethodRequest角色会被传递给Scheduler角色。
Proxy角色实现了ActiveObject角色提供的接口。
调用Proxy角色的方法的是Client角色。将方法调用转换为MethodRequest角色，并传递给Scheduler角色的操作都是使用Client角色的线程进行的。
在示例1程序中，由Proxy类扮演此角色。

Scheduler
Scheduler角色负责将Proxy角色传递过来的MethodRequest角色传递给ActivationQueue角色，以及从ActivationQueue角色去除并执行MethodRequest角色这两项工作。
Client角色负责将MethodRequest角色传递给ActivationQueue角色。
而从ActivationQueue角色中取出并执行MethodRequest角色这项工作则是使用Scheduler角色自己的线程进行的。在ActiveObject模式中，只有使用Client角色和Scheduler角色时才会启动新线程。
Scheduler角色会把MethodRequest角色放入ActivationQueue角色或者从ActivationQueue角色取出MethodRequest角色。因此，Scheduler角色可以判断下次要执行哪个请求。如果想实现请求调度的判断逻辑，可以将它们实现在Scheduler角色中。也正是因为如此，我们才将其命名为Scheduler。
在示例程序1中，由SchedulerThread类扮演此角色。SchedulerThread并没有进行特殊的调度，而只是执行FIFO（First In First Out）处理。

MethodRequest
MethodRequest角色是来自Client角色的请求对应的角色。MethodRequest定义了负责执行处理的Servant角色，以及负责设置返回值的Future角色和负责执行请求的方法（execute）。
MethodRequest角色为主动对象的接口赋予了对象的表象形式。
在示例程序1中，由MethodRequest类扮演此角色。

ConcreteMethodRequest
ConcreteMethodRequest角色是使MethodRequest角色与具体的方法相对应的角色。对于ActiveObject角色中定义的每个方法，会有各个类与之对应。比如MethodAlphaRequest、MethodBetaRequest…。
在示例程序1中，由MakeStringRequest类和DisplayStringRequest类扮演此角色。其中，MakeStringRequest类对应makeString方法，DisplayStringRequest类对应displayString方法。

Servant（仆人）
Servant角色负责实际地处理请求。
调用Servant角色的是Scheduler角色的线程。Scheduler角色会从ActivationQueue角色取出一个MethodRequest角色（实际上是ConcreteMethodRequest角色）并执行它。此时，Scheduler角色调用的就是Servant角色的方法。
Servant角色实现了ActiveObject角色定义的接口。
Proxy角色会将请求转换为MethodRequest角色，而Servant角色则会实际地执行该请求。Scheduler角色介于Proxy角色和Servant角色之间，负责管理按照什么顺序执行请求。
在示例程序1中，由Servant类扮演此角色。

ActivationQueue（主动队列）
ActivationQueue角色是保存MethodRequest角色的类。
调用putRequest方法的是Client角色的线程，而调用takeRequest方法的是Scheduler角色的线程。这里使用了Producer-Consumer模式。

VirtualResult（虚拟结果）
VirtualResult角色与Future角色、RealResult角色共同构成了Future模式。
Client角色在获取处理结果时会调用VirtualResult角色（实际上是Future角色）的getResultValue方法。
在示例程序1中，由Result类扮演此角色。

Future（期货）
Future角色是Client角色在获取处理时实际调用的角色。当处理结果还没有出来的时候，它会使用Guarded Suspension模式让Client角色的线程等待结果出来。
在示例程序1中，由FutureResult类扮演此角色。

RealResult（真实结果）
RealResult角色是表示处理结果的角色。Servant角色会创建一个RealResult角色作为处理结果，然后调用Future角色的setRealResult方法将其设置到Future角色中。
在示例程序1中，由RealResult类扮演此角色


示例程序1类图

示例程序1时序图

示例1代码public class ActivationQueue &#123;    private static final int MAX_METHOD_REQUEST = 100;    private final MethodRequest[] requestQueue;    private int tail; // 下次putRequest的位置    private int head; // 下次taskRequest的位置    private int count; // MethodRequest的数量    public ActivationQueue() &#123;        this.requestQueue = new MethodRequest[MAX_METHOD_REQUEST];        this.tail = tail;        this.head = head;        this.count = count;    &#125;    public synchronized void putRequest(MethodRequest request) &#123;        while (count &gt;= requestQueue.length) &#123;            try &#123;                wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        requestQueue[tail] = request;        tail = (tail + 1) % requestQueue.length;        count++;        notifyAll();    &#125;    public synchronized MethodRequest takeRequest() &#123;        while (count &lt;= 0) &#123;            try &#123;                wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        MethodRequest request = requestQueue[head];        head = (head + 1) % requestQueue.length;        count --;        notifyAll();        return request;    &#125;&#125;public interface ActiveObject &#123;    Result&lt;String&gt; makeString(int count, char fillchar);    void displayString(String string);&#125;public class ActiveObjectFactory &#123;    public static ActiveObject createActiveObject() &#123;        Servant servant = new Servant();        ActivationQueue queue = new ActivationQueue();        SchedulerThread scheduler = new SchedulerThread(queue);        Proxy proxy = new Proxy(scheduler, servant);        scheduler.start();        return proxy;    &#125;&#125;public class DisplayClientThread extends Thread &#123;    private final ActiveObject activeObject;    public DisplayClientThread(String name, ActiveObject activeObject) &#123;        super(name);        this.activeObject = activeObject;    &#125;    @Override    public void run() &#123;        try &#123;            for (int i = 0; true; i++) &#123;                String string = Thread.currentThread().getName() + &quot; &quot; + i;                activeObject.displayString(string);                Thread.sleep(200);            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;public class DisplayStringRequest extends MethodRequest&lt;Object&gt; &#123;    private final String string;    public DisplayStringRequest(Servant servant, String string) &#123;        super(servant, null);        this.string = string;    &#125;    @Override    public void execute() &#123;        servant.displayString(string);    &#125;&#125;public class FutureResult&lt;T&gt; extends Result&lt;T&gt; &#123;    private Result&lt;T&gt; result;    private boolean ready = false;    public synchronized void setResult(Result&lt;T&gt; result) &#123;        this.result = result;        this.ready = true;        notifyAll();    &#125;    @Override    public synchronized T getResultValue() &#123;        while (!ready) &#123;            try &#123;                wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        return result.getResultValue();    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        ActiveObject activeObject = ActiveObjectFactory.createActiveObject();        new MakeClientThread(&quot;Alice&quot;, activeObject).start();;        new MakeClientThread(&quot;Bobby&quot;, activeObject).start();;        new DisplayClientThread(&quot;Chris&quot;, activeObject).start();;    &#125;&#125;public class MakeClientThread extends Thread &#123;    private final ActiveObject activeObject;    private final char fillchar;    public MakeClientThread(String name, ActiveObject activeObject) &#123;        super(name);        this.activeObject = activeObject;        this.fillchar = name.charAt(0);    &#125;    @Override    public void run() &#123;        try &#123;            for (int i = 0; true; i++) &#123;                Result&lt;String&gt; result = activeObject.makeString(i, fillchar);                Thread.sleep(10);                String value = result.getResultValue();                System.out.println(Thread.currentThread().getName() + &quot;: value = &quot; + value);            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;public class MakeStringRequest extends MethodRequest&lt;String&gt; &#123;    private final int count;    private final char fillchar;    public MakeStringRequest(Servant servant, FutureResult&lt;String&gt; future, int count, char fillchar) &#123;        super(servant, future);        this.count = count;        this.fillchar = fillchar;    &#125;    @Override    public void execute() &#123;        Result&lt;String&gt; result = servant.makeString(count, fillchar);        future.setResult(result);    &#125;&#125;public abstract class MethodRequest&lt;T&gt; &#123;    protected final Servant servant;    protected final FutureResult&lt;T&gt; future;    protected MethodRequest(Servant servant, FutureResult&lt;T&gt; future) &#123;        this.servant = servant;        this.future = future;    &#125;    public abstract void execute();&#125;public class Proxy implements ActiveObject &#123;    private final SchedulerThread scheduler;    private final Servant servant;    public Proxy(SchedulerThread scheduler, Servant servant) &#123;        this.scheduler = scheduler;        this.servant = servant;    &#125;    @Override    public Result&lt;String&gt; makeString(int count, char fillchar) &#123;        FutureResult&lt;String&gt; future = new FutureResult&lt;&gt;();        scheduler.invoke(new MakeStringRequest(servant, future, count, fillchar));        return future;    &#125;    @Override    public void displayString(String string) &#123;        scheduler.invoke(new DisplayStringRequest(servant, string));    &#125;&#125;public class RealResult&lt;T&gt; extends Result&lt;T&gt; &#123;    private final T resultValue;    public RealResult(T result) &#123;        this.resultValue = result;    &#125;    @Override    public T getResultValue() &#123;        return resultValue;    &#125;&#125;public abstract class Result&lt;T&gt; &#123;    public abstract T getResultValue();&#125;public class SchedulerThread extends Thread &#123;    private final ActivationQueue queue;    public SchedulerThread(ActivationQueue queue) &#123;        this.queue = queue;    &#125;    public void invoke(MethodRequest request) &#123;        queue.putRequest(request);    &#125;    @Override    public void run() &#123;        while (true) &#123;            MethodRequest request = queue.takeRequest();            request.execute();        &#125;    &#125;&#125;public class Servant implements ActiveObject &#123;    @Override    public Result&lt;String&gt; makeString(int count, char fillchar) &#123;        char[] buffer = new char[count];        for (int i = 0; i &lt; count; i++) &#123;            buffer[i] = fillchar;            try &#123;                Thread.sleep(100);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        System.out.println(Thread.currentThread().getName() + &quot; make count = &quot; + count + &quot;, fillchar = &quot; + fillchar + &quot; complete&quot;);        return new RealResult&lt;&gt;(new String(buffer));    &#125;    @Override    public void displayString(String string) &#123;        try &#123;            System.out.println(&quot;displayString: &quot; + string);            Thread.sleep(100);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;



类图

时序图

TimeThreads图

java.uti.concurrent包于Active Object模式类和接口一览



包
类和接口
内容



无名
Main
测试程序行为的类


无名
MakerClientThread
委托ActiveObject来生成字符串的线程


无名
DisplayClientThread
委托ACtiveObject来显示字符串的线程


activeObject
ActiveObject
定义主动对象的接口的接口


activeObject
ActiveObjectFactory
创建主动对象的类


activeObject
ActiveObjectImpl
实现了ActiveObject接口的类


activeObject
MakeStringRequest
对应makeString方法（生成字符串）的类


activeObject
DisplayStringRequest
对应DisplayString方法（显示字符串）的类


使用到的标准类库



类和接口
内容



java.util.concurrent.Executors
用于获取ExecutorService的工具类


java.util.concurrent.ExecutorService
用于提交（submit）请求的接口（替换示例程序中1中的SchedulerThread、ActivationQueue）


java.util.concurrent.Callable
将获取返回值的调用（call）抽象化后的接口（替代示例程序1中的MethodRequest）


java.util.Runnable
将不获取返回值的调用（run）抽象化后的接口（替代示例程序1中的MethodRequest）


java.util.concurrent.Future
表示返回值的接口（替代示例程序1中的Result、FutureResult、RealResult）


示例程序2的类图

角色
Main类
用于测试程序行为的类。与示例1不同的是可以通过shutdown方法终止。

MakerClientThread类MakeClientThread类是调用ActiveObject对象的makeString方法（生成字符串）的线程。于示例程序1不同时，makeString方法的返回值类型是Future&lt;String&gt;。

DisplayClientThread类DisplayClientThread类与MakerClientThread类一样，也是表示调用ActiveObject对象的线程的类。

ActiveObject接口ActiveObject接口定义了主动对象的接口。与示例程序1不同的是，makeString的返回值类行为Future&lt;String&gt;，而且也增加了shutdown方法。

ActiveObjectFactory类ActiveObjectFactory类是用于构成ACtiveObject对象的类。
于示例程序1不同的是，这里不会组建多个对象，而是仅仅返回ActiveObjectImpl类的实例。这是因为，使用java.util.concurrent包后，类的结构变简单了。

ActiveObjectImpl类
ActiveObjectImpl类是实现了ActiveObject接口的类，它可以进行很多工作。该类与示例程序1中的Proxy和Servant相对应。
servant字段中保存的是通过Executors.newSingleThreadExecutor方法获取的ExecutorService对象。这样可以确保在这个ExecutorService对象中的背后只有一个线程（通过newSingleThreadExecutor则个名字我们也可以看出来）。
ExecutorService对象相当于示例程序1中的SchedulerThread类的实例。另外，虽然从表面上看不出来，但是ExecutorService对象的内部保存着一个线程安全的队列，该队列相当于示例程序1中的ActivationQueue类的实例。
shutdown方法是用于关闭service字段中保存的ExecutorService对象的方法。这样一来，ExecutorService对象就不会再接受新的请求了。
makeString方法会创建MakeStringRequest类的实例，并submit给ExecutorService对象。
displayString方法会创建DisplayStringRequest类的实例，并在ExecutorService中execute。
可以submit和execute的是Callable对象和Runnable对象。MakeStringRequest类实现了Callable接口，而DisplayStringRequest类实现了Runnable接口。
示例2代码public interface ActiveObject &#123;    Future&lt;String&gt; makeString(int count, char fillchar);    void displayString(String string);    void shutdown();&#125;public class ActiveObjectFactory &#123;    public static ActiveObject createActiveObject() &#123;        return new ActiveObjectImpl();    &#125;&#125;public class ActiveObjectImpl implements ActiveObject &#123;    private final ExecutorService service = Executors.newSingleThreadExecutor();    // 有返回值的调用    @Override    public Future&lt;String&gt; makeString(int count, char fillchar) &#123;        class MakeStringRequest implements Callable&lt;String&gt; &#123;            @Override            public String call() &#123;                char[] buffer = new char[count];                try &#123;                    for (int i = 0; i &lt; count; i++) &#123;                        buffer[i] = fillchar;                        Thread.sleep(100);                    &#125;                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                return new String(buffer);            &#125;        &#125;        // 发出请求        return service.submit(new MakeStringRequest());    &#125;    // 没有返回值的调用    @Override    public void displayString(String string) &#123;        class DisplayStringRequest implements Runnable &#123;            @Override            public void run() &#123;                try &#123;                    System.out.println(&quot;displayString: &quot; + string);                    Thread.sleep(10);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;        // 发出请求        service.execute(new DisplayStringRequest());    &#125;    // 终止服务    @Override    public void shutdown() &#123;        service.shutdown();    &#125;&#125;public class DisplayClientThread extends Thread &#123;    private final ActiveObject activeObject;    public DisplayClientThread(String name, ActiveObject activeObject) &#123;        super(name);        this.activeObject = activeObject;    &#125;    @Override    public void run() &#123;        try &#123;            for (int i = 0; true; i++) &#123;                String string = Thread.currentThread().getName() + &quot; &quot; + i;                activeObject.displayString(string);                Thread.sleep(200);            &#125;        &#125; catch (RejectedExecutionException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125; catch (CancellationException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125; catch (InterruptedException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125;    &#125;&#125;public class MakerClientThread extends Thread &#123;    private final ActiveObject activeObject;    private final char fillchar;    public MakerClientThread(String name, ActiveObject activeObject) &#123;        super(name);        this.activeObject = activeObject;        this.fillchar = name.charAt(0);    &#125;    @Override    public void run() &#123;        try &#123;            for (int i = 0; true; i++) &#123;                Future&lt;String&gt; future = activeObject.makeString(i, fillchar);                Thread.sleep(10);                String value = future.get();                System.out.println(Thread.currentThread().getName() + &quot;: value = &quot; + value);            &#125;        &#125; catch (RejectedExecutionException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125; catch (CancellationException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125; catch (InterruptedException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125; catch (ExecutionException e) &#123;            System.out.println(Thread.currentThread().getName() + &quot;:&quot; + e);        &#125;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        ActiveObject activeObject = ActiveObjectFactory.createActiveObject();        try &#123;            new MakerClientThread(&quot;Alice&quot;, activeObject).start();            new MakerClientThread(&quot;Bobby&quot;, activeObject).start();            new DisplayClientThread(&quot;Chris&quot;, activeObject).start();            Thread.sleep(10000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            System.out.println(&quot;**** shutdown ****&quot;);            activeObject.shutdown();        &#125;    &#125;&#125;

]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>设计</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 多线程基础集合体系概述</title>
    <url>/posts/ff94c717/</url>
    <content><![CDATA[线程集合体系概述



List 集合

CopyOnWriteArrayList

Set 集合

CopyOnWriteArraySet
ConcurrentSkipListSet

Map 集合

ConcurrentMap
ConcurrentHashMap
ConcurrentSkipListMap
ConcurrentNavigableMap

Queue 队列

queue
ConcurrentLinkedQueue
ArrayBlockingQueue
PriorityBlockingQueue
LinkedBlockingQueue


deque
ConcurrentLinkedDeque
ForwardingBlockingDeque



]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 线程池详解</title>
    <url>/posts/cf2a801/</url>
    <content><![CDATA[线程池详解自定义线程池步骤：

线程池本身就是一个生产者、消费者的模型

定义一个双向队列

使用ReetrantLock一把锁对队列中的进行存取操作

同时定义一个Set存储线程集合，消费请求过来的任务，处理不过来的任务就放在双向队列里面

线程池可以设置成如下策略

死等
带超时等待
让调用者放弃任务执行
让调用者抛出异常
让调用者自己执行任务



take putpoll offer
@FunctionalInterfaceinterface RejectPolicy&lt;T&gt; &#123;    void reject(BlockingQueue&lt;T&gt; queue, T task);&#125;@Slf4j(topic = &quot;c.ThreadPool&quot;)class ThreadPool &#123;    // 任务队列    private BlockingQueue&lt;Runnable&gt; taskQueue;    // 线程集合    private HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;();    // 核心线程数    private int coreSize;    // 获取任务时的超时时间    private long timeout;    private TimeUnit timeUnit;    private RejectPolicy&lt;Runnable&gt; rejectPolicy;    // 执行任务    public void execute(Runnable task) &#123;        // 当任务数没有超过 coreSize 时，直接交给 worker 对象执行        // 如果任务数超过 coreSize 时，加入任务队列暂存        synchronized (workers) &#123;            if(workers.size() &lt; coreSize) &#123;                Worker worker = new Worker(task);                log.debug(&quot;新增 worker&#123;&#125;, &#123;&#125;&quot;, worker, task);                workers.add(worker);                worker.start();            &#125; else &#123;                taskQueue.tryPut(task, rejectPolicy);            &#125;        &#125;    &#125;    public ThreadPool(int coreSize, long timeout, TimeUnit timeUnit, int queueCapcity, RejectPolicy&lt;Runnable&gt; rejectPolicy) &#123;        this.coreSize = coreSize;        this.timeout = timeout;        this.timeUnit = timeUnit;        this.taskQueue = new BlockingQueue&lt;&gt;(queueCapcity);        this.rejectPolicy = rejectPolicy;    &#125;    class Worker extends Thread&#123;        private Runnable task;        public Worker(Runnable task) &#123;            this.task = task;        &#125;        @Override        public void run() &#123;            // 执行任务            // 1) 当 task 不为空，执行任务            // 2) 当 task 执行完毕，再接着从任务队列获取任务并执行//            while(task != null || (task = taskQueue.take()) != null) &#123;            while(task != null || (task = taskQueue.poll(timeout, timeUnit)) != null) &#123;                try &#123;                    log.debug(&quot;正在执行...&#123;&#125;&quot;, task);                    task.run();                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    task = null;                &#125;            &#125;            synchronized (workers) &#123;                log.debug(&quot;worker 被移除&#123;&#125;&quot;, this);                workers.remove(this);            &#125;        &#125;    &#125;&#125;@Slf4j(topic = &quot;c.BlockingQueue&quot;)class BlockingQueue&lt;T&gt; &#123;    // 1. 任务队列    private Deque&lt;T&gt; queue = new ArrayDeque&lt;&gt;();    // 2. 锁    private ReentrantLock lock = new ReentrantLock();    // 3. 生产者条件变量    private Condition fullWaitSet = lock.newCondition();    // 4. 消费者条件变量    private Condition emptyWaitSet = lock.newCondition();    // 5. 容量    private int capcity;    public BlockingQueue(int capcity) &#123;        this.capcity = capcity;    &#125;    // 带超时阻塞获取    public T poll(long timeout, TimeUnit unit) &#123;        lock.lock();        try &#123;            // 将 timeout 统一转换为 纳秒            long nanos = unit.toNanos(timeout);            while (queue.isEmpty()) &#123;                try &#123;                    // 返回值是剩余时间                    if (nanos &lt;= 0) &#123;                        return null;                    &#125;                    nanos = emptyWaitSet.awaitNanos(nanos);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;            T t = queue.removeFirst();            fullWaitSet.signal();            return t;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    // 阻塞获取    public T take() &#123;        lock.lock();        try &#123;            while (queue.isEmpty()) &#123;                try &#123;                    emptyWaitSet.await();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;            T t = queue.removeFirst();            fullWaitSet.signal();            return t;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    // 阻塞添加    public void put(T task) &#123;        lock.lock();        try &#123;            while (queue.size() == capcity) &#123;                try &#123;                    log.debug(&quot;等待加入任务队列 &#123;&#125; ...&quot;, task);                    fullWaitSet.await();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;            log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task);            queue.addLast(task);            emptyWaitSet.signal();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    // 带超时时间阻塞添加    public boolean offer(T task, long timeout, TimeUnit timeUnit) &#123;        lock.lock();        try &#123;            long nanos = timeUnit.toNanos(timeout);            while (queue.size() == capcity) &#123;                try &#123;                    if(nanos &lt;= 0) &#123;                        return false;                    &#125;                    log.debug(&quot;等待加入任务队列 &#123;&#125; ...&quot;, task);                    nanos = fullWaitSet.awaitNanos(nanos);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;            log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task);            queue.addLast(task);            emptyWaitSet.signal();            return true;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    public int size() &#123;        lock.lock();        try &#123;            return queue.size();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    public void tryPut(T task, RejectPolicy rejectPolicy) &#123;        lock.lock();        try &#123;            if(queue.size() == capcity) &#123;                rejectPolicy.reject(this, task);            &#125; else &#123;                log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task);                queue.addLast(task);                emptyWaitSet.signal();            &#125;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;

线程池状态



构造方法

newFixedThreadPool





自定义线程池名称

newCachedThreadPool



newSingleThreadExecutor

newScheduledThreadPoolpublic ScheduledFuture&lt;?&gt; schedule(Runnable command,                                   long delay, TimeUnit unit);public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable,                                       long delay, TimeUnit unit);// 延迟一定时间固定周期执行，周期以【任务本身的耗时时间】为准public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,                                              long initialDelay,                                              long period,                                              TimeUnit unit);// 延迟一定时间固定周期执行，周期以【任务本身的耗时时间 + dealy时间】为准public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command,                                                 long initialDelay,                                                 long delay,                                                 TimeUnit unit);

异常处理方式要么在线程池处理逻辑里面使用 try catch 代码块主动捕捉进行
要么使用有返回值的 Callable 接口而不是使用 Runnable 接口
提交任务关闭线程池

shutdownNow() 的话会返回没有执行完的任务


工作线程模式





异步模式之工作线程





任务调度线程池

Tomcat线程池











Fork&#x2F;Join概念

使用

@Slf4j(topic = &quot;c.TestForkJoin2&quot;)public class TestForkJoin2 &#123;    public static void main(String[] args) &#123;        ForkJoinPool pool = new ForkJoinPool(4);        System.out.println(pool.invoke(new MyTask(5)));        // new MyTask(5)  5+ new MyTask(4)  4 + new MyTask(3)  3 + new MyTask(2)  2 + new MyTask(1)    &#125;&#125;// 1~n 之间整数的和@Slf4j(topic = &quot;c.MyTask&quot;)class MyTask extends RecursiveTask&lt;Integer&gt; &#123;    private int n;    public MyTask(int n) &#123;        this.n = n;    &#125;    @Override    public String toString() &#123;        return &quot;&#123;&quot; + n + &#x27;&#125;&#x27;;    &#125;    @Override    protected Integer compute() &#123;        // 如果 n 已经为 1，可以求得结果了        if (n == 1) &#123;            log.debug(&quot;join() &#123;&#125;&quot;, n);            return n;        &#125;        // 将任务进行拆分(fork)        AddTask1 t1 = new AddTask1(n - 1);        t1.fork();        log.debug(&quot;fork() &#123;&#125; + &#123;&#125;&quot;, n, t1);        // 合并(join)结果        int result = n + t1.join();        log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, n, t1, result);        return result;    &#125;&#125;

执行结果
17:16:11.291 c.MyTask [ForkJoinPool-1-worker-1] - fork() 5 + &#123;4&#125;17:16:11.291 c.AddTask [ForkJoinPool-1-worker-0] - fork() 2 + &#123;1&#125;17:16:11.291 c.AddTask [ForkJoinPool-1-worker-2] - fork() 4 + &#123;3&#125;17:16:11.294 c.AddTask [ForkJoinPool-1-worker-0] - join() 117:16:11.291 c.AddTask [ForkJoinPool-1-worker-3] - fork() 3 + &#123;2&#125;17:16:11.294 c.AddTask [ForkJoinPool-1-worker-0] - join() 2 + &#123;1&#125; = 317:16:11.294 c.AddTask [ForkJoinPool-1-worker-3] - join() 3 + &#123;2&#125; = 617:16:11.295 c.AddTask [ForkJoinPool-1-worker-2] - join() 4 + &#123;3&#125; = 1017:16:11.295 c.MyTask [ForkJoinPool-1-worker-1] - join() 5 + &#123;4&#125; = 1515



改进
@Slf4j(topic = &quot;c.AddTask&quot;)class AddTask3 extends RecursiveTask&lt;Integer&gt; &#123;    int begin;    int end;    public AddTask3(int begin, int end) &#123;        this.begin = begin;        this.end = end;    &#125;    @Override    public String toString() &#123;        return &quot;&#123;&quot; + begin + &quot;,&quot; + end + &#x27;&#125;&#x27;;    &#125;    @Override    protected Integer compute() &#123;        if (begin == end) &#123;            log.debug(&quot;join() &#123;&#125;&quot;, begin);            return begin;        &#125;        if (end - begin == 1) &#123;            log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, begin, end, end + begin);            return end + begin;        &#125;        int mid = (end + begin) / 2;        AddTask3 t1 = new AddTask3(begin, mid);        t1.fork();        AddTask3 t2 = new AddTask3(mid + 1, end);        t2.fork();        log.debug(&quot;fork() &#123;&#125; + &#123;&#125; = ?&quot;, t1, t2);        int result = t1.join() + t2.join();        log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, t1, t2, result);        return result;    &#125;&#125;

执行结果
17:26:23.768 c.AddTask [ForkJoinPool-1-worker-3] - join() 4 + 5 = 917:26:23.768 c.AddTask [ForkJoinPool-1-worker-1] - fork() &#123;1,3&#125; + &#123;4,5&#125; = ?17:26:23.772 c.AddTask [ForkJoinPool-1-worker-3] - join() 317:26:23.768 c.AddTask [ForkJoinPool-1-worker-0] - join() 1 + 2 = 317:26:23.768 c.AddTask [ForkJoinPool-1-worker-2] - fork() &#123;1,2&#125; + &#123;3,3&#125; = ?17:26:23.772 c.AddTask [ForkJoinPool-1-worker-2] - join() &#123;1,2&#125; + &#123;3,3&#125; = 617:26:23.772 c.AddTask [ForkJoinPool-1-worker-1] - join() &#123;1,3&#125; + &#123;4,5&#125; = 1515

]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap 详解</title>
    <url>/posts/e344884c/</url>
    <content><![CDATA[目录HahsMap存值过程
根据key计算一个hash值
在put的时候计算数组是否存在 如果不存在调用resize方法创建默认容量为16的数组
确定node在数组中的位置 根据hash值与数组最大索引值进行与运算得到索引位置
获取该位置是否有元素 如果没有元素 直接新建一个Node放在该位置
如果有元素 判断key是否完全相同 如果相同把原来的node赋值给一个变量
此时再去判断 该位置是红黑树还是链表
如果是红黑树 以红黑树的方式将node放在红黑树上
如果是链表 此时遍历链表 然后将node放在最后一位放完以后需要去判断链表的长度 是否超过8 如果超过需要判断是否将链表转换为红黑树（当数组容量小于64的时候 只会进行数组的扩容 如果大于64才会进行链表转换红黑树）
返回被覆盖的值
判断整个数组是否需要扩容

]]></content>
      <categories>
        <category>Java</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 数据结构基础</title>
    <url>/posts/c9844e82/</url>
    <content><![CDATA[链表1、什么是链表？链表 [Linked List]：链表是由一组不必相连【不必相连：可以连续也可以不连续】的内存结构 【节点】，按特定的顺序链接在一起的抽象数据类型。

补充：抽象数据类型（Abstract Data Type [ADT]）：表示数学中抽象出来的一些操作的集合。内存结构：内存中的结构，如：struct、特殊内存块…等等之类；

2、链表共分几类？链表常用的有 3 类： 单链表、双向链表、循环链表。
链表的核心操作集有 3 种：插入、删除、查找【遍历】
单链表单链表  [Linked List]：由各个内存结构通过一个 Next 指针链接在一起组成，每一个内存结构都存在后继内存结构【链尾除外】，内存结构由数据域和 Next 指针域组成。
单链表实现图示：


文字解析：

Data 数据 + Next 指针，组成一个单链表的内存结构 ；
第一个内存结构称为 链头，最后一个内存结构称为 链尾；
链尾的 Next 指针设置为 NULL [指向空]；
单链表的遍历方向单一【只能从链头一直遍历到链尾】

双向链表双向链表 [Double Linked List]：由各个内存结构通过指针 Next 和指针 Prev 链接在一起组成，每一个内存结构都存在前驱内存结构和后继内存结构【链头没有前驱，链尾没有后继】，内存结构由数据域、Prev 指针域和 Next 指针域组成。
双向链表实现图示：


文字解析：

Data 数据 + Next 指针 + Prev 指针，组成一个双向链表的内存结构；
第一个内存结构称为 链头，最后一个内存结构称为 链尾；
链头的 Prev 指针设置为 NULL， 链尾的 Next 指针设置为 NULL；
Prev 指向的内存结构称为 前驱， Next 指向的内存结构称为 后继；
双向链表的遍历是双向的，即如果把从链头的 Next 一直到链尾的[NULL] 遍历方向定义为正向，那么从链尾的 Prev 一直到链头 [NULL ]遍历方向就是反向；

循环链表单向循环链表 [Circular Linked List] : 由各个内存结构通过一个指针 Next 链接在一起组成，每一个内存结构都存在后继内存结构，内存结构由数据域和 Next 指针域组成。
双向循环链表 [Double Circular Linked List] : 由各个内存结构通过指针 Next 和指针 Prev 链接在一起组成，每一个内存结构都存在前驱内存结构和后继内存结构，内存结构由数据域、Prev 指针域和 Next 指针域组成。
循环链表的单向与双向实现图示：


文字解析：

循环链表分为单向、双向两种；
单向的实现就是在单链表的基础上，把链尾的 Next 指针直接指向链头，形成一个闭环；
双向的实现就是在双向链表的基础上，把链尾的 Next 指针指向链头，再把链头的 Prev 指针指向链尾，形成一个闭环；
循环链表没有链头和链尾的说法，因为是闭环的，所以每一个内存结构都可以充当链头和链尾；

集合ArrayList实现原理默认初始容量为10数组数据和容量统计是分开的是通过下标访问数组的如果添加元素的时候超过数组本身的容量，则扩展为原来的1.5倍数加减元素挪动原有数据通过System.arraycopy(Object src, int srcPos, Object dest, int destPos, int length)来操作实现
LinkedList实现原理链表的数据不一定是连续存储的LinkedList通过分半的方式查找的默认是添加到链表尾部
ConcurrentLinkedQueue

LinkedBlockingQueue
put  take 阻塞add remove 异常offer poll true&#x2F;false

入队操作

出队操作private E dequeue() &#123;    // assert takeLock.isHeldByCurrentThread();    // assert head.item == null;    Node&lt;E&gt; h = head;    Node&lt;E&gt; first = h.next;    h.next = h; // help GC    head = first;    E x = first.item;    first.item = null;    return x;&#125;

解析：
h = head
first = h.next
h.next = h (help gc)


head = first
E x = first.item;first.item = null;return x;

ArrayBlockingQueueConcurrentLinkedQueue

CopyOnWriteArrayList
采用空间换取时间安全的做法
适合读多写少的场景

CopyOnWriteArraySet]]></content>
      <categories>
        <category>Java</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>ConcurrentHashMap 详解</title>
    <url>/posts/39a12d12/</url>
    <content><![CDATA[concurrentHashMap 详解初始化数组private final Node&lt;K,V&gt;[] initTable() &#123;    Node&lt;K,V&gt;[] tab; int sc;    while ((tab = table) == null || tab.length == 0) &#123;        if ((sc = sizeCtl) &lt; 0)            Thread.yield(); // lost initialization race; just spin        else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) &#123;            try &#123;                if ((tab = table) == null || tab.length == 0) &#123;                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;                    @SuppressWarnings(&quot;unchecked&quot;)                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];                    table = tab = nt;                    sc = n - (n &gt;&gt;&gt; 2);                &#125;            &#125; finally &#123;                sizeCtl = sc;            &#125;            break;        &#125;    &#125;    return tab;&#125;

分片统计总和final long sumCount() &#123;    CounterCell[] cs = counterCells;    long sum = baseCount;    if (cs != null) &#123;        for (CounterCell c : cs)            if (c != null)                sum += c.value;    &#125;    return sum;&#125;

线程抢占CounterCell// cellsBusy == 1 代表有其他线程正在扩容 else if (cellsBusy == 0 &amp;&amp; counterCells == cs &amp;&amp;         U.compareAndSetInt(this, CELLSBUSY, 0, 1)) &#123;    boolean init = false;    try &#123;                           // Initialize table        if (counterCells == cs) &#123;            CounterCell[] rs = new CounterCell[2];            rs[h &amp; 1] = new CounterCell(x);            counterCells = rs;            init = true;        &#125;    &#125; finally &#123;        cellsBusy = 0;    &#125;    if (init)        break;&#125;

初始化tab
tab 代指 Node&lt;K,V&gt;[] 数组

sizeCtl
-1 表示一个占位符，如果sizeCtl &#x3D; -1，表示当前已经有线程抢到了初始化的权限
&gt; 0的数字 sizeCtl &#x3D; sc &#x3D; n*0.75 &#x3D; 12 表示下一次扩容的大小
负数（非 -1）代表有几个线程正在扩容 （-2）有一个线程正在扩容

binCount
链表长度

CounterCell
分片计数器数组

else if (cellsBusy == 0 &amp;&amp; counterCells == cs &amp;&amp;         U.compareAndSetInt(this, CELLSBUSY, 0, 1)) &#123;    boolean init = false;    try &#123;                           // Initialize table        if (counterCells == cs) &#123;            CounterCell[] rs = new CounterCell[2];            rs[h &amp; 1] = new CounterCell(x);            counterCells = rs;            init = true;        &#125;    &#125; finally &#123;        cellsBusy = 0;    &#125;    if (init)        break;&#125;

CHM的扩容，是可以多个线程并行扩容的
static final int resizeStamp(int n) &#123;    return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));&#125;

resizeStamp(16) &#x3D; 32795
0000 0000 0000 0000 1000 0000 0001 1011 左移16位
1000 0000 0001 1011 0000 0000 0000 0000 + 2
1000 0000 0001 1011 0000 0000 0000 0010 -&gt; 表示当前有一个线程在扩容
扩容的戳
高16位代表扩容的标记
低16位代表扩容的线程数 -&gt; 有一个线程参与扩容了

需要保证每次扩容的扩容戳都是唯一的
可以支持并发扩容

占位节点
MOVED状态，即为 -1

ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);

transfer
数组扩容



else if (U.compareAndSetInt         (this, TRANSFERINDEX, nextIndex,          nextBound = (nextIndex &gt; stride ?                       nextIndex - stride : 0))) &#123;    bound = nextBound;    i = nextIndex - 1;    advance = false;&#125;

链路拆分if (fh &gt;= 0) &#123;    int runBit = fh &amp; n;    Node&lt;K,V&gt; lastRun = f;    for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123;        int b = p.hash &amp; n;        if (b != runBit) &#123;            runBit = b;            lastRun = p;        &#125;    &#125;    // 低位链    if (runBit == 0) &#123;        ln = lastRun;        hn = null;    &#125;    // 高位链    else &#123;        hn = lastRun;        ln = null;    &#125;    for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123;        int ph = p.hash; K pk = p.key; V pv = p.val;        if ((ph &amp; n) == 0)            ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);        else            hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);    &#125;    setTabAt(nextTab, i, ln); // 低位链路，位置保持不动    setTabAt(nextTab, i + n, hn); // 高位链，需要增加n长度位置 14+16=30    setTabAt(tab, i, fwd)    advance = true;&#125;



(f = tabAt(tab, i = (n - 1) &amp; hash)) == null

总结
通过数组的方式来实现并发增加元素的个数
并发扩容，可以通过多个线程来并行实现数据的迁移
采用高低链的方式来解决多次hash计算的问题，提升了效率
sizeCtl的设计，三种表示状态
resizeStamp的设计，高低位的设计来实现唯一性以及多个线程的协助扩容记录


如果连链表的长度大于8，并且node数组的长度 &gt; 64 的时候，如果再添加数据到当前链表中，会把当前链表转换为红黑树。
当出现扩容的时候，如果链表的长度小于8，把红黑树转换为链表


其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。
1.数据结构：取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。
2.保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。
3.锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。
4.链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。
5.查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。                      

]]></content>
      <categories>
        <category>Java</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>picgo</title>
    <url>/posts/c4fe5b8b/</url>
    <content><![CDATA[picGo密钥
75db282dc87afa16cf26ceff14d51491ea494175

]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 基础</title>
    <url>/posts/47eac6e4/</url>
    <content><![CDATA[explain解析+—-+————-+——-+————+——+—————+——+———+——+——–+———-+——-+ | id   | select_type  | table  | partitions   |  type | possible_keys | key    | key_len  | ref    | rows     | filtered    | Extra  |+—-+————-+——-+————+——+—————+——+———+——+——–+———-+——-+
1、idid用来标识整个查询中SELELCT语句的顺序，在嵌套查询中id越大的语句越先执行，该值可能为NULL
id如果相同，从上往下依次执行。id不同，id值越大，执行优先级越高，如果行引用其他行的并集结果，则该值可以为NU
2、select_typesimple
primary
union
dependent union
subquery
dependent subquery
derived
3、tabletable用来表示输出行所引用的表名
4、type（重要）system
const
eq_ref
ref
ref_or_null
index_merge
range
index
all
6、key（重要）key列显示的是当前表实际使用的索引，如果没有选择索引，则此列为null，要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX
7、key_lenkey_len列显示MySQL决定使用的键长度。如果KEY键是NULL，则长度为NULL。在不损失精确性的情况下，长度越短越好
key len的长度还和字符集有关,latin1一个字符占用1个字节,gbk一个字符占用2个字节,utf8一个字符占用3个字节。key_len的计算法方法：
8、refref列用来显示使用哪个列或常数与key一起从表中选择相应的行。它显示的列的名字（或const），此列多数时候为null
9、rowsrows列显示的是mysql解析器认为执行此SQL时必须扫描的行数。此数值为一个预估值，不是具体值，通常比实际值小
10、filtered此参数为mysql 5.7 新加参数，指的是返回结果的行数所占需要读到的行（rows的值）的比例 对于使用join时，前一个表的结果集大小直接影响了循环的行数
11、extra（重要）using index
using where
using temporary
using filesort
using join buffer
impossible where
using index condition
varchar（100）可以存多少中文字符4.0版本以下，varchar(100)，指的是100字节，如果存放UTF8汉字时，只能存33个（每个汉字3字节）
5.0版本以上，varchar(100)，指的是100字符，无论存放的是数字、字母还是UTF8汉字（每个汉字3字节），都可以存放100个。                      
]]></content>
      <categories>
        <category>中间件</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 设计模式</title>
    <url>/posts/fa3d1251/</url>
    <content><![CDATA[Initialization On Demand Holder模式
在Java规范中，类的初始化时线程安全的。所以可以采用嵌套类延迟初始化来保证实例访问的安全性。

示例代码
public class MySystem &#123;    private static class Holder &#123;        public static MySystem instance = new MySystem();    &#125;        private Date date = null;    private MySystem() &#123;    &#125;        public Date getDate() &#123;        return date;    &#125;        public static MySystem getInstance() &#123;        return Holder.instance;    &#125;&#125;

Iterator模式定义for循环将循环变量i的作用抽象化，通用化后形成的模式，在设计模式中称为iterator模式。
Iterator模式用于在数据集合中按照顺序遍历集合。
示例模式详解类和接口一览

示例代码public interface Aggregate &#123;    public abstract Iterator iterator();&#125;public interface Iterator &#123;    public abstract boolean hasNext();    public abstract Object next();&#125;public class BookShelfIterator implements Iterator &#123;    private BookShelf bookShelf;    private int index;    public BookShelfIterator(BookShelf bookShelf) &#123;        this.bookShelf = bookShelf;        this.index = 0;    &#125;    @Override    public boolean hasNext() &#123;        if (index &lt; bookShelf.getLength()) &#123;            return true;        &#125; else &#123;            return false;        &#125;    &#125;    @Override    public Object next() &#123;        Book book = bookShelf.getBookAt(index);        index++;        return book;    &#125;&#125;public class BookShelf implements Aggregate &#123;    private Book[] books;    private int last;    public BookShelf(int maxSize) &#123;        this.books = new Book[maxSize];    &#125;    public Book getBookAt(int index) &#123;        return books[index];    &#125;    public void appendBook(Book book) &#123;        this.books[last] = book;        last++;    &#125;    public int getLength() &#123;        return last;    &#125;    @Override    public Iterator iterator() &#123;        return new BookShelfIterator(this);    &#125;&#125;public class Book &#123;    private String name;    public Book(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return name;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        BookShelf bookShelf = new BookShelf(4);        bookShelf.appendBook(new Book(&quot;Arround the world in 80 days&quot;));        bookShelf.appendBook(new Book(&quot;Bible&quot;));        bookShelf.appendBook(new Book(&quot;Cinderella&quot;));        bookShelf.appendBook(new Book(&quot;Daddy-Long-Legs&quot;));        Iterator it = bookShelf.iterator();        while (it.hasNext()) &#123;            Book book = (Book) it.next();            System.out.println(book.getName());        &#125;    &#125;&#125;

模式详解角色
Iterator（迭代器）
ConcreteIterator（具体的迭代器）
Aggregate（集合）
ConcreteAggregate（具体的集合）

类图


在Iterator模式的实现中，很容易在next方法上出错。该方法的返回值到底是应该指向当前元素还是当前元素的下一个元素呢？更详细的讲，next方法的名字应该是下面这样的。
returnCurrentElementAndAdvancedToNextPosition
也就是说，next方法是“返回当前的元素，并指向下一个元素”。

Adaptor模式定义在程序世界中，经常会存在现有的程序无法直接使用，需要做适当的变换之后才能使用的情况。这种用于填补“现有的程序”和”所需的程序“之间差异的设计模式就是Adaptor模式。
Adaptor模式有以下两种：

类适配器模式（使用继承的适配器）
对象适配器模式（使用委托的适配器）

类适配器模式详解类图

示例代码public class Banner &#123;    private String string;    public Banner(String string) &#123;        this.string = string;    &#125;    public void showWithParen() &#123;        System.out.println(&quot;(&quot; + string + &quot;)&quot;);    &#125;    public void showWithAster() &#123;        System.out.println(&quot;*&quot; + string + &quot;*&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        PrintBanner p = new PrintBanner(&quot;Hello&quot;);        p.printWeak();        p.printStrong();    &#125;&#125;public interface Print &#123;    public abstract void printWeak();    public abstract void printStrong();&#125;public class PrintBanner extends Banner implements Print &#123;    public PrintBanner(String string) &#123;        super(string);    &#125;    @Override    public void printWeak() &#123;        showWithParen();    &#125;    @Override    public void printStrong() &#123;        showWithAster();    &#125;&#125;

对象适配器模式详解类图

示例代码public class Banner &#123;    private String string;    public Banner(String string) &#123;        this.string = string;    &#125;    public void showWithParen() &#123;        System.out.println(&quot;(&quot; + string + &quot;)&quot;);    &#125;    public void showWithAster() &#123;        System.out.println(&quot;*&quot; + string + &quot;*&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        PrintBanner p = new PrintBanner(&quot;Hello&quot;);        p.printWeak();        p.printStrong();    &#125;&#125;public abstract class Print &#123;    public abstract void printWeak();    public abstract void printStrong();&#125;public class PrintBanner extends Print &#123;    private Banner banner;    public PrintBanner(String string) &#123;        this.banner = new Banner(string);    &#125;    @Override    public void printWeak() &#123;        banner.showWithParen();    &#125;    @Override    public void printStrong() &#123;        banner.showWithAster();    &#125;&#125;

模式详解角色
Target（对象）
Client（请求者）
Adaptee（被适配）
Adapter（适配）

类图

用途可以使用Adapter模式使新旧版本兼容，帮助我们轻松地同时维护新版本和旧版本。
例如，假设我们今后只想维护新版本。这时可以让新版本扮演Adaptee角色，旧版本扮演Target角色。接着编写一个扮演Adapter角色的类，让它使用新版本的类来实现旧版本的类中的方法。
Template Method模式定义在父类中定义处理流程的框架，在子类中实现具体处理的模式就称为Template Method模式。
示例模式详解类和接口一览

示例代码public abstract class AbstractDisplay &#123;    public abstract void open();    public abstract void print();    public abstract void close();    public final void display() &#123;        open();        for (int i = 0; i &lt; 5; i++) &#123;            print();        &#125;        close();    &#125;&#125;public class CharDisplay extends AbstractDisplay &#123;    private char ch;    public CharDisplay(char ch) &#123;        this.ch = ch;    &#125;    @Override    public void open() &#123;        System.out.print(&quot;&lt;&lt;&quot;);    &#125;    @Override    public void print() &#123;        System.out.print(ch);    &#125;    @Override    public void close() &#123;        System.out.println(&quot;&gt;&gt;&quot;);    &#125;&#125;public class StringDisplay extends AbstractDisplay &#123;    private String string;    private int width;    public StringDisplay(String string) &#123;        this.string = string;        this.width = string.getBytes().length;    &#125;    @Override    public void open() &#123;        printLine();    &#125;    @Override    public void print() &#123;        System.out.println(&quot;|&quot; + string + &quot;|&quot;);    &#125;    @Override    public void close() &#123;        printLine();    &#125;    private void printLine() &#123;        System.out.print(&quot;+&quot;);        for (int i = 0; i &lt; width; i++) &#123;            System.out.print(&quot;-&quot;);        &#125;        System.out.println(&quot;+&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        AbstractDisplay d1 = new CharDisplay(&#x27;H&#x27;);        StringDisplay d2 = new StringDisplay(&quot;Hello, world&quot;);        StringDisplay d3 = new StringDisplay(&quot;你好，世界&quot;);        d1.display();        d2.display();        d3.display();    &#125;&#125;

模式详解角色
AbstractClass（抽象类）
ConcreteClass（具体类）

类图

用途可以使逻辑处理通用化。
无论在父类类型的变量中保存哪个子类的实例，程度都可以正常工作，这种原则称为里氏替换原则（LSP）。
子类具有实现在父类中所声明的抽象方法的责任。因此，这种责任被称为”子类责任“。
Factory Method模式定义Factory有”工厂“的意思。用Template Mehod模式来构建生成实例的工厂，这就是Factory Method模式。
在Factory Method模式中，父类决定实例的生成方式，但并不决定所要生成的具体的类。
示例模式详解类和接口一览



示例代码public abstract class Factory &#123;    public final Product create(String owner) &#123;        Product p = createProduct(owner);        registerProduct(p);        return p;    &#125;    protected abstract Product createProduct(String owner);    protected abstract void registerProduct(Product product);&#125;public abstract class Product &#123;    public abstract void use();&#125;public class IDCard extends Product &#123;    private String owner;    public IDCard(String owner) &#123;        System.out.println(&quot;制作&quot; + owner + &quot;的ID卡&quot;);        this.owner = owner;    &#125;    @Override    public void use() &#123;        System.out.println(&quot;使用&quot; + owner + &quot;的ID卡&quot;);    &#125;    public String getOwner() &#123;        return owner;    &#125;&#125;public class IDCardFactory extends Factory &#123;    private List owners = new ArrayList();    @Override    protected Product createProduct(String owner) &#123;        return new IDCard(owner);    &#125;    @Override    protected void registerProduct(Product product) &#123;        owners.add(((IDCard)product).getOwner());    &#125;    public List getOwners() &#123;        return owners;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        IDCardFactory factory = new IDCardFactory();        Product card1 = factory.create(&quot;小明&quot;);        Product card2 = factory.create(&quot;小红&quot;);        Product card3 = factory.create(&quot;小刚&quot;);        card1.use();        card2.use();        card3.use();    &#125;&#125;

模式详解角色
Product（产品）
Creator（创建者）
ConcreteProduct（具体的产品）
ConcreteCreator（具体的创建者）

类图

Singleton模式定义确保只生成一个实例的模式被称作Singleton模式。

想确保任何情况下都绝对只有1个实例
想在程序上表现出”只存在一个实例“

示例模式详解角色

类图

示例代码public class Singleton &#123;    private static Singleton singleton = new Singleton();    private Singleton() &#123;        System.out.println(&quot;生成了一个实例&quot;);    &#125;    public static Singleton getInstance() &#123;        return singleton;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;Start.&quot;);        Singleton obj1 = Singleton.getInstance();        Singleton obj2 = Singleton.getInstance();        if (obj1 == obj2) &#123;            System.out.println(&quot;obj1 和 obj2 是相同的实例&quot;);        &#125; else &#123;            System.out.println(&quot;obj1 和 obj2 是不同的实例&quot;);        &#125;        System.out.println(&quot;End.&quot;);    &#125;&#125;

模式详解角色
Singleton
在Singleton模式总，只有Singleton这一个角色。Singleton角色中有一个返回唯一实例的static方法。该方法总是会返回同一个实例。


类图


何时生成这个唯一的实例？
程序运行后，在第一次调用getIntance方法时，Singleton类会被初始化，也就是在这个时候，static字段singleton被初始化，生成了唯一的一个实例。

Prototype模式定义通过复制生成实例。
示例模式详解类和接口一览

示例代码public class Manager &#123;    private HashMap showCase = new HashMap();    public void register(String name, Product proto) &#123;        showCase.put(name, proto);    &#125;    public Product create(String protoName) &#123;        Product p = (Product) showCase.get(protoName);        return p.createClone();    &#125;&#125;public class MessageBox implements Product &#123;    private char decoChar;    public MessageBox(char decoChar) &#123;        this.decoChar = decoChar;    &#125;    @Override    public void use(String s) &#123;        int length = s.getBytes().length;        for (int i = 0; i &lt; length + 4; i++) &#123;            System.out.print(decoChar);        &#125;        System.out.println(&quot;&quot;);        System.out.println(decoChar + &quot; &quot; + s + &quot; &quot; + decoChar);        for (int i = 0; i &lt; length + 4; i++) &#123;            System.out.print(decoChar);        &#125;        System.out.println(&quot;&quot;);    &#125;    @Override    public Product createClone() &#123;        Product p = null;        try &#123;            p = (Product) clone();        &#125; catch (CloneNotSupportedException e) &#123;            e.printStackTrace();        &#125;        return p;    &#125;&#125;public interface Product extends Cloneable &#123;    public abstract void use(String s);    public abstract Product createClone();&#125;public class UnderlinePen implements Product &#123;    private char ulchar;    public UnderlinePen(char ulchar) &#123;        this.ulchar = ulchar;    &#125;    @Override    public void use(String s) &#123;        int length = s.getBytes().length;        System.out.println(&quot;\&quot;&quot; + s + &quot;\&quot;&quot;);        System.out.println(&quot; &quot;);        for (int i = 0; i &lt; length; i++) &#123;            System.out.print(ulchar);        &#125;        System.out.println(&quot;&quot;);    &#125;    @Override    public Product createClone() &#123;        Product p = null;        try &#123;            p = (Product) clone();        &#125; catch (CloneNotSupportedException e) &#123;            e.printStackTrace();        &#125;        return p;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        // 准备        Manager manager = new Manager();        UnderlinePen upen = new UnderlinePen(&#x27;~&#x27;);        MessageBox mbox = new MessageBox(&#x27;*&#x27;);        MessageBox sbox = new MessageBox(&#x27;/&#x27;);        manager.register(&quot;strong message&quot;, upen);        manager.register(&quot;warning box&quot;, mbox);        manager.register(&quot;slash box&quot;, sbox);        // 生成        Product p1 = manager.create(&quot;strong message&quot;);        p1.use(&quot;Hello, world&quot;);        Product p2 = manager.create(&quot;warning box&quot;);        p2.use(&quot;Hello, world&quot;);        Product p3 = manager.create(&quot;slash box&quot;);        p3.use(&quot;Hello, world&quot;);    &#125;&#125;

模式详解角色
Prototype（原型）Product角色负责定义用于复制现有实例来生成新实例的方法。

ConcretePrototype（具体的原型）
ConcretePrototype角色负责实现复制现有实例并生成新实例的方法。

Client（使用者）Client角色负责使用复制实例的方法生成新的实例。


类图


需要实现Cloneable的哪些方法提到Cloneable接口，很容易让人误以为Clonable接口中声明了close方法。其实这是错误的。在Cloneable接口并没有声明任何方法。它只是用来标记”可以使用clone方法进行复制“的。这样的接口被称为标记接口（marker interface）。
clone方法进行的是浅复制clone方法所进行的复制只是将被复制实例的字段值直接复制到新的实例中。换言之，它并没有考虑字段所保存的实例的内容。例如，当字段中保存的是数组时，如果使用clone方法进行复制，则只会复制该数据的引用，并不会一一复制数据中的元素。
像这样的字段对字段的复制（field-to-field-copy）被称为浅复制（shallow copy）。clone方法所进行的复制就是浅复制。
当使用clone方法进行浅复制无法满足需求时，类的设计者可以实现重写clone方法，实现自己需要的复制功能（重写clone方法时，别忘了使用super.clone()来调用父类的clone方法）。
clone方法只会进行复制，并不会调用被复制实例的构造函数。

Builder模式定义Builder模式用于组装具有复杂结构的实例。
示例模式详解类和接口一览



示例代码public abstract class Builder &#123;    public abstract void makeTitle(String title);    public abstract void makeString(String str);    public abstract void makeItems(String[] items);    public abstract void close();&#125;public class Director &#123;    private Builder builder;    public Director(Builder builder) &#123;        this.builder = builder;    &#125;    public void construct() &#123;        builder.makeTitle(&quot;Greeting&quot;);        builder.makeString(&quot;从早上至下午&quot;);        builder.makeItems(new String[]&#123;&quot;晚上好。&quot;, &quot;晚安&quot;, &quot;再见&quot;&#125;);        builder.close();    &#125;&#125;public class HTMLBuilder extends Builder &#123;    private String fileName;    private PrintWriter writer;    @Override    public void makeTitle(String title) &#123;        fileName = title + &quot;.html&quot;;        try &#123;            writer = new PrintWriter(new FileWriter(fileName));        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;        writer.println(&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;&quot; + title + &quot;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&quot;);        writer.println(&quot;&lt;h1&gt;&quot; + title + &quot;&lt;/h1&gt;&quot;);    &#125;    @Override    public void makeString(String str) &#123;        writer.println(&quot;&lt;p&gt;&quot; + str + &quot;&lt;/p&gt;&quot;);    &#125;    @Override    public void makeItems(String[] items) &#123;        writer.println(&quot;&lt;ul&gt;&quot;);        for (int i = 0; i &lt; items.length; i++) &#123;            writer.println(&quot;&lt;li&gt;&quot; + items[i] + &quot;&lt;/li&gt;&quot;);        &#125;        writer.println(&quot;&lt;/ul&gt;&quot;);    &#125;    @Override    public void close() &#123;        writer.println(&quot;&lt;/body&gt;&lt;/html&gt;&quot;);        writer.close();    &#125;    public String getResult() &#123;        return fileName;    &#125;&#125;public class TextBuilder extends Builder &#123;    private StringBuffer buffer = new StringBuffer();    @Override    public void makeTitle(String title) &#123;        buffer.append(&quot;===================================\n&quot;);        buffer.append(&quot;[&quot; + title + &quot;]\n&quot;);        buffer.append(&quot;\n&quot;);    &#125;    @Override    public void makeString(String str) &#123;        buffer.append(&#x27;◆&#x27; + str + &quot;\n&quot;);        buffer.append(&quot;\n&quot;);    &#125;    @Override    public void makeItems(String[] items) &#123;        for (int i = 0; i &lt; items.length; i++) &#123;            buffer.append(&quot; .&quot; + items[i] + &quot;\n&quot;);        &#125;        buffer.append(&quot;\n&quot;);    &#125;    @Override    public void close() &#123;        buffer.append(&quot;===================================\n&quot;);    &#125;    public String getResult() &#123;        return buffer.toString();    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));        try &#123;            usage();            String str = br.readLine();            if (str.equals(&quot;plain&quot;)) &#123;                TextBuilder textBuilder = new TextBuilder();                Director director = new Director(textBuilder);                director.construct();                String result = textBuilder.getResult();                System.out.println(result);            &#125; else if (str.equals(&quot;html&quot;)) &#123;                HTMLBuilder htmlBuilder = new HTMLBuilder();                Director director = new Director(htmlBuilder);                director.construct();                String fileName = htmlBuilder.getResult();                System.out.println(fileName + &quot; 文件编写完成&quot;);            &#125; else &#123;                System.exit(0);            &#125;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; finally &#123;            try &#123;                br.close();            &#125; catch (IOException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    public static void usage() &#123;        System.out.println(&quot;Usage: java Main plain      编写纯文本文档&quot;);        System.out.println(&quot;Usage: java Main html       编写HTML文档&quot;);    &#125;&#125;

模式详解角色
Builder（建造者）
ConcreteBuilder（具体的建造者）
Director（监工）
Client（使用者）

类图

时序图

Abstract Factory模式示例模式详解类和接口一览



模式详解角色
AbstractProduct（抽象产品）
AbstractFactory（抽象工厂）
Client（委托者）
ConcreteProduct（具体产品）
ConcreteFactory（具体工厂）

类图

特点
易于增加的工厂
难以增加的零件

Bridge模式定义Bridge的意思是”桥梁“。就像在现实世界中，桥梁的功能是将河流的两侧连接起来一样，Brige模式的作用也是讲两样东西连接起来，它们分别是类的功能层次结构和类的实现层次结构。
类的层次结构的两个作用希望增加新功能时

当要增加新的功能时，我们可以从各个层次的类中找出最适合自己需求的类，然后以它为父类编写子类，并在子类中增加新的功能。这就是”类的功能层次结构“。
希望增加新的实现时

当子类的ConcreteClass实现了父类AbstractClass类的抽象方法时，它们之间就构成了一个小小的层次结构。
但是，这里的类的层次结构并非用于增加功能，也就是说，这种层次结构并非用于方便我们增加新的方法。它的真正作用是帮助我们实现下面这样的任务分组。

父类通过声明抽象方法来定义接口（API）
子类通过实现具体方法来实现接口（API）

这种层次结构被称为”类的实现层次结构“。
示例模式详解类和接口一览

示例代码public class CountDisplay extends Display &#123;    public CountDisplay(DisplayImpl impl) &#123;        super(impl);    &#125;    public void multiDisplay(int times) &#123;        open();        for (int i = 0; i &lt; times; i++) &#123;            print();        &#125;        close();    &#125;&#125;public class Display &#123;    private DisplayImpl impl;    public Display(DisplayImpl impl) &#123;        this.impl = impl;    &#125;    public void open() &#123;        impl.rawOpen();    &#125;    public void print() &#123;        impl.rawPrint();    &#125;    public void close() &#123;        impl.rawClose();    &#125;    public final void display() &#123;        open();        print();        close();    &#125;&#125;public class Display &#123;    private DisplayImpl impl;    public Display(DisplayImpl impl) &#123;        this.impl = impl;    &#125;    public void open() &#123;        impl.rawOpen();    &#125;    public void print() &#123;        impl.rawPrint();    &#125;    public void close() &#123;        impl.rawClose();    &#125;    public final void display() &#123;        open();        print();        close();    &#125;&#125;public class StringDisplayImpl extends DisplayImpl &#123;    private String string;    private int width;    public StringDisplayImpl(String string) &#123;        this.string = string;        this.width = string.getBytes().length;    &#125;    @Override    public void rawOpen() &#123;        printLine();    &#125;    @Override    public void rawPrint() &#123;        System.out.println(&quot;|&quot; + string + &quot;|&quot;);    &#125;    @Override    public void rawClose() &#123;        printLine();    &#125;    private void printLine() &#123;        System.out.print(&quot;+&quot;);        for (int i = 0; i &lt; width; i++) &#123;            System.out.print(&quot;-&quot;);        &#125;        System.out.println(&quot;+&quot;);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Display d1 = new Display(new StringDisplayImpl(&quot;Hello, China&quot;));        Display d2 = new CountDisplay(new StringDisplayImpl(&quot;Hello, World&quot;));        CountDisplay d3 = new CountDisplay(new StringDisplayImpl(&quot;Hello, Universe&quot;));        d1.display();        d2.display();        d3.display();        d3.multiDisplay(5);    &#125;&#125;

模式详解角色
Abstraction（抽象化）
RefinedAbstraction（改善后的抽象化）
Implementor（实现者）
ConcreteImplementor（具体实现者）

类图

用途
分开后更容易扩展
Bridge模式的特征是将”类的功能层次结构“与”类的实现层次结构“分离开了。
当想要增加功能时，只需要在”类的功能层次结构“一侧增加类即可，不必对”类的实现层次结构“做任何修改。而且，增加后的功能可以被”所有的实现使用“。

继承是强关联，委托是弱关联


Strategy模式定义使用Strategy模式可以整体地替换算法的实现部分。能够整体的替换算法，能让我们轻松地以不同的算法去解决同一个问题，这种模式就是Strategy模式。
示例模式详解类和接口一览

示例代码public class Hand &#123;    public static final int HANDVALUE_GUU = 0;  // 表示石头的值    public static final int HANDVALUE_CHO = 1;  // 表示剪刀的值    public static final int HANDVALUE_PAA = 2;  // 表示布的值    public static final Hand[] hand = &#123;            new Hand(HANDVALUE_GUU),            new Hand(HANDVALUE_CHO),            new Hand(HANDVALUE_PAA)    &#125;;    private static final String[] name = &#123;            &quot;石头&quot;, &quot;剪刀&quot;, &quot;布&quot;,    &#125;;    private int handValue;    public Hand(int handValue) &#123;        this.handValue = handValue;    &#125;    public static Hand getHand(int handValue) &#123;        return hand[handValue];    &#125;    public boolean isStrongerThan(Hand h) &#123;        return fight(h) == 1;    &#125;    public boolean isWeakerThan(Hand h) &#123;        return fight(h) == -1;    &#125;    private int fight(Hand h) &#123;        if (this == h) &#123;            return 0;        &#125; else if ((this.handValue + 1) % 3 == h.handValue) &#123;            return 1;        &#125; else &#123;            return -1;        &#125;    &#125;    @Override    public String toString() &#123;        return name[handValue];    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));        try &#123;            int seed1 = Integer.parseInt(br.readLine());            int seed2 = Integer.parseInt(br.readLine());            Player player1 = new Player(&quot;Taro&quot;, new WinningStragery(seed1));            Player player2 = new Player(&quot;Hana&quot;, new ProbStrategy(seed2));            for (int i = 0; i &lt; 10000; i++) &#123;                Hand nextHand1 = player1.nextHand();                Hand nextHand2 = player2.nextHand();                if (nextHand1.isStrongerThan(nextHand2)) &#123;                    System.out.println(&quot;Winner: &quot; + player1);                    player1.win();                    player2.lose();                &#125; else if (nextHand2.isStrongerThan(nextHand1)) &#123;                    System.out.println(&quot;Winner: &quot; + player2);                    player1.lose();                    player2.win();                &#125; else &#123;                    System.out.println(&quot;Even...&quot;);                    player1.even();                    player2.even();                &#125;            &#125;            System.out.println(&quot;Total result:&quot;);            System.out.println(player1.toString());            System.out.println(player2.toString());        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;public class Player &#123;    private String name;    private Strategy strategy;    private int winCount;    private int lostCount;    private int gameCount;    public Player(String name, Strategy strategy) &#123;        this.name = name;        this.strategy = strategy;    &#125;    public Hand nextHand() &#123;        return strategy.nextHand();    &#125;    public void win() &#123;        strategy.study(true);        winCount++;        gameCount++;    &#125;    public void lose() &#123;        strategy.study(false);        lostCount++;        gameCount++;    &#125;    public void even() &#123;        gameCount++;    &#125;    @Override    public String toString() &#123;        return &quot;Player&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\&#x27;&#x27; +                &quot;, winCount=&quot; + winCount +                &quot;, lostCount=&quot; + lostCount +                &quot;, gameCount=&quot; + gameCount +                &#x27;&#125;&#x27;;    &#125;&#125;public class ProbStrategy implements Strategy &#123;    private Random random;    private int prevHandValue = 0;    private int currentHandValue = 0;    private int[][] history = &#123;            &#123;1, 1, 1&#125;,            &#123;1, 1, 1&#125;,            &#123;1, 1, 1&#125;    &#125;;    public ProbStrategy(int seed) &#123;        random = new Random(seed);    &#125;    @Override    public Hand nextHand() &#123;        int bet = random.nextInt(getSum(currentHandValue));        int handValue = 0;        //    如果石头，剪刀，布的比率为3:5:7        //    如果该随机数 0 &lt;= X &lt; 3，那么出石头        //    如果该随机数 3 &lt;= X &lt; 8，那么出剪刀        //    如果该随机数 8 &lt;= X &lt; 15，那么出布        if (bet &lt; history[currentHandValue][0]) &#123;            handValue = 0;        &#125; else if (bet &lt; history[currentHandValue][0] + history[currentHandValue][1]) &#123;            handValue = 1;        &#125; else &#123;            handValue = 2;        &#125;        prevHandValue = currentHandValue;        currentHandValue = handValue;        return Hand.getHand(handValue);    &#125;    private int getSum(int hv) &#123;        int sum = 0;        for (int i = 0; i &lt; 3; i++) &#123;            sum += history[hv][i];        &#125;        return sum;    &#125;    @Override    public void study(boolean win) &#123;        if (win) &#123;            history[prevHandValue][currentHandValue]++;        &#125; else &#123;            history[prevHandValue][(currentHandValue + 1) % 3]++;            history[prevHandValue][(currentHandValue + 2) % 3]++;        &#125;    &#125;&#125;public interface Strategy &#123;    public abstract Hand nextHand();    public abstract void study(boolean win);&#125;public class WinningStragery implements Strategy &#123;    private Random random;    private boolean won = false;    private Hand preHand;    public WinningStragery(int seed) &#123;        random = new Random(seed);    &#125;    @Override    public Hand nextHand() &#123;        if (!won) &#123;            preHand = Hand.getHand(random.nextInt(3));        &#125;        return preHand;    &#125;    @Override    public void study(boolean win) &#123;        won = win;    &#125;&#125;

模式详解角色
Strategy（策略）
ConcreteStrategy（具体的策略）
Context（上下文）负责使用Strategy角色。

类图

Composite模式定义能够使容器与内容具有一致性，创造出递归结构的模式就是Composite模式。
示例模式详解类和接口一览



示例代码public class Directory extends Entry &#123;    private String name;    private ArrayList directory = new ArrayList();    public Directory(String name) &#123;        this.name = name;    &#125;    @Override    public String getName() &#123;        return name;    &#125;    @Override    public int getSize() &#123;        int size = 0;        Iterator it = directory.iterator();        while (it.hasNext()) &#123;            Entry entry = (Entry) it.next();            size += entry.getSize();        &#125;        return size;    &#125;    public Entry add(Entry entry) &#123;        directory.add(entry);        return this;    &#125;    @Override    protected void printList(String prefix) &#123;        System.out.println(prefix + &quot;/&quot; + this);        Iterator it = directory.iterator();        while (it.hasNext()) &#123;            Entry entry = (Entry) it.next();            entry.printList(prefix + &quot;/&quot; + name);        &#125;    &#125;&#125;public abstract class Entry &#123;    public abstract String getName();    public abstract int getSize();    public Entry add(Entry entry) throws FileTreatmentException &#123;        throw new FileTreatmentException();    &#125;    public void printList() &#123;        printList(&quot;&quot;);    &#125;    protected abstract void printList(String prefix);    @Override    public String toString() &#123;        return getName() + &quot; (&quot; + getSize() + &quot;)&quot;;    &#125;&#125;public class File extends Entry &#123;    private String name;    private int size;    public File(String name, int size) &#123;        this.name = name;        this.size = size;    &#125;    @Override    public String getName() &#123;        return name;    &#125;    @Override    public int getSize() &#123;        return size;    &#125;    @Override    protected void printList(String prefix) &#123;        System.out.println(prefix + &quot;/&quot; + this);    &#125;&#125;public class FileTreatmentException extends RuntimeException &#123;    public FileTreatmentException() &#123;    &#125;    public FileTreatmentException(String message) &#123;        super(message);    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;Making root entries ...&quot;);        Directory rootDir = new Directory(&quot;root&quot;);        Directory binDir = new Directory(&quot;bin&quot;);        Directory tmpDir = new Directory(&quot;tmp&quot;);        Directory usrDir = new Directory(&quot;usr&quot;);        rootDir.add(binDir);        rootDir.add(tmpDir);        rootDir.add(usrDir);        binDir.add(new File(&quot;vi&quot;, 10000));        binDir.add(new File(&quot;latex&quot;, 20000));        rootDir.printList();        System.out.println(&quot;&quot;);        System.out.println(&quot;Making user entries&quot;);        Directory yuki = new Directory(&quot;yuki&quot;);        Directory hanako = new Directory(&quot;hanako&quot;);        Directory tomura = new Directory(&quot;tomura&quot;);        usrDir.add(yuki);        usrDir.add(hanako);        usrDir.add(tomura);        yuki.add(new File(&quot;diary.html&quot;, 100));        yuki.add(new File(&quot;Composite.java&quot;, 200));        hanako.add(new File(&quot;memo.tex&quot;, 300));        tomura.add(new File(&quot;game.doc&quot;, 400));        tomura.add(new File(&quot;junk.mail&quot;, 500));        rootDir.printList();    &#125;&#125;

模式详解角色
Leaf（树叶）表示内容的角色。

Composite（复合物）表示容器的角色。

Component
使Leaf角色和Composite角色具有一致性的角色。

Client使用Composite模式的角色。


类图

用途使用Composite模式可以使容器与内容具有一致性，也可以称为多个和单个的一致性。
Decorator模式定义像蛋糕一样不断为对象添加装饰的设计模式被称为Decorator模式。
示例模式详解类图

示例代码public abstract class Border extends Display &#123;    protected Display display;    protected Border(Display display) &#123;        this.display = display;    &#125;&#125;public abstract class Display &#123;    public abstract int getColumns();    public abstract int getRows();    public abstract String getRowText(int row);    public final void show() &#123;        for (int i = 0; i &lt; getRows(); i++) &#123;            System.out.println(getRowText(i));        &#125;    &#125;&#125;public class FullBorder extends Border &#123;    public FullBorder(Display display) &#123;        super(display);    &#125;    @Override    public int getColumns() &#123;        return 1 + display.getColumns() + 1;    &#125;    @Override    public int getRows() &#123;        return 1 + display.getRows() + 1;    &#125;    @Override    public String getRowText(int row) &#123;        if (row == 0) &#123;            return &quot;+&quot; + makeLine(&#x27;-&#x27;, display.getColumns()) + &quot;+&quot;;        &#125; else if (row == display.getRows() + 1) &#123;            return &quot;+&quot; + makeLine(&#x27;-&#x27;, display.getColumns()) + &quot;+&quot;;        &#125; else &#123;            return &quot;|&quot; + display.getRowText(row - 1) + &quot;|&quot;;        &#125;    &#125;    private String makeLine(char ch, int count) &#123;        StringBuffer buf = new StringBuffer();        for (int i = 0; i &lt; count; i++) &#123;            buf.append(ch);        &#125;        return buf.toString();    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Display b1 = new StringDisplay(&quot;Hello, world&quot;);        Display b2 = new SideBorder(b1, &#x27;#&#x27;);        Display b3 = new FullBorder(b2);        b1.show();        b2.show();        b3.show();        Display d4 = new SideBorder(new FullBorder(new SideBorder(new FullBorder(new StringDisplay(&quot;你好，世界。&quot;)), &#x27;*&#x27;)), &#x27;/&#x27;);        d4.show();    &#125;&#125;public class SideBorder extends Border &#123;    private char borderChar;    public SideBorder(Display display, char borderChar) &#123;        super(display);        this.borderChar = borderChar;    &#125;    @Override    public int getColumns() &#123;        return 1 + display.getColumns() + 1;    &#125;    @Override    public int getRows() &#123;        return display.getRows();    &#125;    @Override    public String getRowText(int row) &#123;        return borderChar + display.getRowText(row) + borderChar;    &#125;&#125;public class StringDisplay extends Display &#123;    private String string;    public StringDisplay(String string) &#123;        this.string = string;    &#125;    @Override    public int getColumns() &#123;        return string.getBytes().length;    &#125;    @Override    public int getRows() &#123;        return 1;    &#125;    @Override    public String getRowText(int row) &#123;        if (row == 0) &#123;            return string;        &#125; else &#123;            return null;        &#125;    &#125;&#125;

模式详解角色
Component增加功能时的核心角色。
ConcreteComponent
Decorator（装饰物）
ConcreteDecorator（具体的装饰物）

类图

用途在不改变被装饰物的前提下增加功能。

继承和委托的一致性继承——父类和子类的一致性
委托——自己和被委托对象的一致性

Visitor模式定义在Visitor模式中，数据结构与处理被分离开来。我们编写一个表示“访问者”的类来访问数据结构中的元素，并把对各元素的处理交给访问者类。这样，当需要增加新的处理时，我们只需要编写新的访问者，然后让数据可以接受访问者的访问即可。
示例模式详解类和接口一览



示例代码public abstract class Entry implements Element &#123;    public abstract String getName();    public abstract int getSize();    public Entry add(Entry entry) throws FileTreatmentException &#123;        throw new FileTreatmentException();    &#125;    public Iterator iterator() throws FileTreatmentException &#123;        throw new FileTreatmentException();    &#125;    @Override    public String toString() &#123;        return getName() + &quot; (&quot; + getSize() + &quot;)&quot;;    &#125;&#125;public interface Element &#123;    public abstract void accept(Visitor v);&#125;public class Directory extends Entry &#123;    private String name;    private ArrayList dir = new ArrayList();    public Directory(String name) &#123;        this.name = name;    &#125;    @Override    public String getName() &#123;        return name;    &#125;    @Override    public int getSize() &#123;        int size = 0;        Iterator it = dir.iterator();        while (it.hasNext()) &#123;            Entry entry = (Entry) it.next();            size += entry.getSize();        &#125;        return size;    &#125;    @Override    public Entry add(Entry entry) throws FileTreatmentException &#123;        dir.add(entry);        return this;    &#125;    @Override    public Iterator iterator() throws FileTreatmentException &#123;        return dir.iterator();    &#125;    @Override    public void accept(Visitor v) &#123;        v.visit(this);    &#125;&#125;public class File extends Entry &#123;    private String name;    private int size;    public File(String name, int size) &#123;        this.name = name;        this.size = size;    &#125;    @Override    public String getName() &#123;        return name;    &#125;    @Override    public int getSize() &#123;        return size;    &#125;    @Override    public void accept(Visitor v) &#123;        v.visit(this);    &#125;&#125;public class FileTreatmentException extends RuntimeException &#123;    public FileTreatmentException() &#123;    &#125;    public FileTreatmentException(String message) &#123;        super(message);    &#125;&#125;public class ListVisitor extends Visitor &#123;    private String currentDir = &quot;&quot;;    @Override    public void visit(File file) &#123;        System.out.println(currentDir + &quot;/&quot; + file);    &#125;    @Override    public void visit(Directory directory) &#123;        System.out.println(currentDir + &quot;/&quot; + directory);        String saveDir = currentDir;        currentDir = currentDir + &quot;/&quot; + directory.getName();        Iterator it = directory.iterator();        while (it.hasNext()) &#123;            Entry entry = (Entry) it.next();            entry.accept(this);        &#125;        currentDir = saveDir;    &#125;&#125;public abstract class Visitor &#123;    public abstract void visit(File file);    public abstract void visit(Directory directory);&#125;public class Main &#123;    public static void main(String[] args) &#123;        try &#123;            System.out.println(&quot;Making root entries...&quot;);            Directory rootDir = new Directory(&quot;root&quot;);            Directory binDir = new Directory(&quot;bin&quot;);            Directory tmpDir = new Directory(&quot;tmp&quot;);            Directory usrDir = new Directory(&quot;usr&quot;);            rootDir.add(binDir);            rootDir.add(tmpDir);            rootDir.add(usrDir);            binDir.add(new File(&quot;vi&quot;, 10000));            binDir.add(new File(&quot;latex&quot;, 20000));            rootDir.accept(new ListVisitor());            System.out.println(&quot;&quot;);            System.out.println(&quot;Making user entries&quot;);            Directory yuki = new Directory(&quot;yuki&quot;);            Directory hanako = new Directory(&quot;hanako&quot;);            Directory tomura = new Directory(&quot;tomura&quot;);            usrDir.add(yuki);            usrDir.add(hanako);            usrDir.add(tomura);            yuki.add(new File(&quot;diary.html&quot;, 100));            yuki.add(new File(&quot;Composite.java&quot;, 200));            hanako.add(new File(&quot;memo.tex&quot;, 300));            tomura.add(new File(&quot;game.doc&quot;, 400));            tomura.add(new File(&quot;junk.mail&quot;, 500));            rootDir.accept(new ListVisitor());        &#125; catch (FileTreatmentException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;

模式详解角色
Visitor（访问者）Visitor角色负责对数据结构中每个具体的元素（ConcreteElement角色）声明一个用于访问XXXXX的visit(XXXXX)方法。
ConcreteVisitor（具体的访问者）
Element（元素）Element角色表示Visitor角色的访问对象。
ConcreteElement
ObjectStruture（对象结构）ObjectStructure角色处理Element角色集合。

类图

用途双重分发
element接受visitor，而visitor又访问element。
在Visitor模式中，ConcreteElement和ConcreteVisitor这两个角色共同决定了实际进行的处理。这种消息分发的方式一般被称为双重分发（double dispatch）。
Visitor模式的目的将处理从数据结构中分离出来。数据结构很重要，它能将元素集合和关联在一起。                      
]]></content>
      <categories>
        <category>Java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 常用命令</title>
    <url>/posts/31eec5f6/</url>
    <content><![CDATA[目录死锁问题排查
com.mysql.cj.jdbc.exceptions.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction

死锁数据库记录：
SELECT * from information_schema.INNODB_TRX;SELECT * FROM information_schema.INNODB_LOCKs;SELECT * FROM information_schema.INNODB_LOCK_waits;

解决步骤如下：

information_schema 这张数据表保存了 MySQL 服务器所有数据库的信息

select * from information_schema.INNODB_TRX;

找到对应死锁的任务


kill 7340]]></content>
      <categories>
        <category>中间件</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 三种集群架构</title>
    <url>/posts/17835f44/</url>
    <content><![CDATA[Redis线程模型Redis基于Reactor模式开发了自己的网络事件处理器，被称为文件事件处理器，由套接字、I&#x2F;O多路复用程序、文件事件分派器（dispatcher），事件处理器四部分组成。


redis为什么那么快
redis是纯内存操作：数据存放在内存中，内存的响应时间大约是100纳秒，这是Redis每秒万亿级别访问的重要基础。
非阻塞I&#x2F;O：Redis采用epoll做为I&#x2F;O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接，读写，关闭都转换为了时间，不在I&#x2F;O上浪费过多的时间。
单线程避免了线程切换和竞态产生的消耗。

redis 三种集群模式redis系列之——分布式锁
redis系列之——缓存穿透、缓存击穿、缓存雪崩
redis系列之——Redis为什么这么快？
redis系列之——数据持久化（RDB和AOF）
redis系列之——一致性hash算法
redis系列之——高可用（主从、哨兵、集群）
redis系列之——事物及乐观锁
redis系列之——数据类型geospatial：你隔壁有没有老王？
redis系列之——数据类型bitmaps：今天你签到了吗？
布隆过滤器是个啥！
所谓的高可用，也叫HA（High Availability），是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。
如果在实际生产中，如果redis只部署一个节点，当机器故障时，整改服务都不能提供服务了。这就是我们常说的单点故障。
如果redis部署了多台，当一台或几台故障时，整个系统依然可以对外提供服务，这样就提高了服务的可用性。
今天我们就聊聊redis高可用的三种模式：主从模式，哨兵模式，集群模式。
一、主从模式一般，系统的高可用都是通过部署多台机器实现的。redis为了避免单点故障，也需要部署多台机器。
因为部署了多台机器，所以就会涉及到不同机器的的数据同步问题。
为此，redis提供了Redis提供了复制(replication)功能，当一台redis数据库中的数据发生了变化，这个变化会被自动的同步到其他的redis机器上去。
redis多机器部署时，这些机器节点会被分成两类，一类是主节点（master节点），一类是从节点（slave节点）。一般主节点可以进行读、写操作，而从节点只能进行读操作。同时由于主节点可以写，数据会发生变化，当主节点的数据发生变化时，会将变化的数据同步给从节点，这样从节点的数据就可以和主节点的数据保持一致了。一个主节点可以有多个从节点，但是一个从节点会只会有一个主节点，也就是所谓的一主多从结构。




1.1.机器规划


机器名称
IP
端口



master
192.168.1.10
6379


slave1
192.168.1.11
6379


slave2
192.168.1.12
6379


slave3
192.168.1.13
6379


1.2.配置主节点配置
主节点按照正常的配置配好即可。
从节点配置
使用默认的配置启动机器，机器都是主节点。如果想要让机器变成从节点，需要在conf服务器上配置主从复制的相关参数。

在从节点的配置文件redis.conf中指定主节点的信息（如果需要的话，可以配置主节点的登录密码，主从复制相关的参数）。三台从节点的配置是一样的。

# 配置主节点的ip和端口slaveof 192.168.1.10 6379# 从redis2.6开始，从节点默认是只读的slave-read-only yes# 假设主节点有登录密码，是123456masterauth 123456


也可以不配置上面的文件，使用redis-server命令，在启动从节点时，通过参数–slaveof指定主节点是谁。。

./redis-server --slaveof 192.168.1.10 6379


也可以不配上面的文件，正常启动redis机器，然后通过redis-cli的命令行执行slaveof 192.168.1.10 6379指定主节点是谁。

系统运行时，如果master挂掉了，可以在一个从库（如slave1）上手动执行命令slaveof no one，将slave1变成新的master；在slave2和slave3上分别执行slaveof 192.168.1.11 6379 将这两个机器的主节点指向的这个新的master；同时，挂掉的原master启动后作为新的slave也指向新的master上。
执行命令slaveof no one命令，可以关闭从服务器的复制功能。同时原来同步的所得的数据集都不会被丢弃。
1.3.机器启动首先启动主节点，然后一台一台启动从节点。
1.4.主从复制的机制




从数据库连接主数据库，发送SYNC命令;
主数据库接收到SYNC命令后，可以执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令;
主数据库BGSAVE执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令;
从数据库收到快照文件后丢弃所有旧数据，载入收到的快照;
主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令;
从数据库完成对快照的载入，开始接受命令请求，并执行来自主数据库缓冲区的写命令;(从数据库初始化完成)
主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令(从数据库初始化完成后的操作)
出现断开重连后，2.8之后的版本会将断线期间的命令传给从数据库，增量复制。
主从刚刚连接的时候，进行全量同步;全同步结束后，进行增量同步。当然，如果有需要，slave在任何时候都可以发起全量同步。Redis的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

1.5.主从模式的优缺点优点
支持主从复制，主机会自动将数据同步到从机，可以进行读写分离;
为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务依然必须由Master来完成;
Slave同样可以接受其他Slaves的连接和同步请求，这样可以有效地分载Master的同步压力;
Master是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求;
Slave同样是以阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据。

缺点
Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复;
主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性;
如果多个Slave断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要Slave启动，就会发送sync请求和主机全量同步，当多个Slave重启的时候，可能会导致Master IO剧增从而宕机。
Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂;
redis的主节点和从节点中的数据是一样的，降低的内存的可用性

二、哨兵模式主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这种方式并不推荐，实际生产中，我们优先考虑哨兵模式。这种模式下，master宕机，哨兵会自动选举master并将其他的slave指向新的master。
在主从模式下，redis同时提供了哨兵命令redis-sentinel，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵进程向所有的redis机器发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。
哨兵可以有多个，一般为了便于决策选举，使用奇数个哨兵。哨兵可以和redis机器部署在一起，也可以部署在其他的机器上。多个哨兵构成一个哨兵集群，哨兵直接也会相互通信，检查哨兵是否正常运行，同时发现master宕机哨兵之间会进行决策选举新的master




哨兵模式的作用:

通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器;
当哨兵监测到master宕机，会自动将slave切换到master，然后通过发布订阅模式通过其他的从服务器，修改配置文件，让它们切换主机;
然而一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

哨兵很像kafka集群中的zookeeper的功能。
2.1.机器规划


机器名称
IP
端口



master
192.168.1.10
6379


slave 1
192.168.1.11
6379


slave 2
192.168.1.12
6379


slave 3
192.168.1.13
6379


sentinel 1
192.168.1.14
26379


sentinel 2
192.168.1.15
26379


sentinel 3
192.168.1.16
26379


这里我们将哨兵进程和redis分别部署在不同的机器上，避免因为redis宕机导致sentinel进程不可用。
2.2.配置redis.conf的配置和上面主从模式一样，不用变。这里主要说一下哨兵的配置。
每台机器的哨兵进程都需要一个哨兵的配置文件sentinel.conf，三台机器的哨兵配置是一样的。
# 禁止保护模式protected-mode no# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，#192.168.1.10代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。sentinel monitor mymaster 192.168.1.10 6379 2# sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码sentinel auth-pass mymaster 123456

2.3.机器启动首先启动主节点，然后一台一台启动从节点。
redis集群启动完成后，分别启动哨兵集群所在机器的三个哨兵，使用redis-sentinel /path/to/sentinel.conf命令。
2.4.哨兵模式的工作
每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

假设master宕机，sentinel 1先检测到这个结果，系统并不会马上进行 failover(故障转移)选出新的master，仅仅是sentinel 1主观的认为master不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由sentinel 1发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。
2.5.主从模式的优缺点优点
哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
主从可以自动切换，系统更健壮，可用性更高。

缺点
具有主从模式的缺点，每台机器上的数据是一样的，内存的可用性较低。
Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

三、集群模式先说一个误区：Redis的集群模式本身没有使用一致性hash算法，而是使用slots插槽。这是很多人的一个误区。这里先留个坑，后面我会出一期《 redis系列之——一致性hash算法》。
Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，对数据进行分片，也就是说每台 Redis 节点上存储不同的内容；




这里的6台redis两两之间并不是独立的，每个节点都会通过集群总线(cluster bus)，与其他的节点进行通信。通讯时使用特殊的端口号，即对外服务端口号加10000。例如如果某个node的端口号是6379，那么它与其它nodes通信的端口号是16379。nodes之间的通信采用特殊的二进制协议。
对客户端来说，整个cluster被看做是一个整体，客户端可以连接任意一个node进行操作，就像操作单一Redis实例一样，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node，这有点儿像浏览器页面的302 redirect跳转。
根据官方推荐，集群部署至少要 3 台以上的master节点，最好使用 3 主 3 从六个节点的模式。测试时，也可以在一台机器上部署这六个实例，通过端口区分出来。
3.1.机器规划


机器名称
IP
端口



master 1
192.168.1.11
6379


master 2
192.168.1.12
6379


master 3
192.168.1.13
6379


slave 1
192.168.1.21
6379


slave 2
192.168.1.22
6379


slave 3
192.168.1.23
6379


3.2.配置修改redis.conf 的配置文件:
# 开启redis的集群模式cluster-enabled yes# 配置集群模式下的配置文件名称和位置,redis-cluster.conf这个文件是集群启动后自动生成的，不需要手动配置。cluster-config-file redis-cluster.conf

3.3.机器启动6个 Redis 服务分别启动成功之后，这时虽然配置了集群开启，但是这六台机器还是独立的。使用集群管理命令将这6台机器添加到一个集群中。
借助 redis-tri.rb 工具可以快速的部署集群。
只需要执行redis-trib.rb create --replicas 1 192.168.1.11:6379 192.168.1.21:6379 192.168.1.12:6379 192.168.1.22:6379 192.168.1.13:6379 192.168.1.23:6379就可以成功创建集群。
该命令执行创建完成后会有响应的日志，通过相关的日志就可以看出集群中机器的关系(不一定和上图对应)，执行的日志如下：
&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.1.21:6379 to 192.168.1.11:6379Adding replica 192.168.1.22:6379 to 192.168.1.12:6379Adding replica 192.168.1.23:6379 to 192.168.1.13:6379M: 80c80a3f3e33872c047a8328ad579b9bea001ad8 192.168.1.11:6379   slots:[0-5460] (5461 slots) masterS: b4d3eb411a7355d4767c6c23b4df69fa183ef8bc 192.168.1.21:6379   replicates 6788453ee9a8d7f72b1d45a9093838efd0e501f1M: 4d74ec66e898bf09006dac86d4928f9fad81f373 192.168.1.12:6379   slots:[5461-10922] (5462 slots) masterS: b6331cbc986794237c83ed2d5c30777c1551546e 192.168.1.22:6379   replicates 80c80a3f3e33872c047a8328ad579b9bea001ad8M: 6788453ee9a8d7f72b1d45a9093838efd0e501f1 192.168.1.13:6379   slots:[10923-16383] (5461 slots) masterS: 277daeb8660d5273b7c3e05c263f861ed5f17b92 192.168.1.23:6379   replicates 4d74ec66e898bf09006dac86d4928f9fad81f373Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes                  # 输入yes，接受上面配置&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster

执行完成后自动生成配置的redis-cluster.conf文件。
登录集群：redis-cli -c -h 192.168.1.11 -p 6379 -a 123456 # -c，使用集群方式登录。
查看集群信息：192.168.1.11:6379&gt; CLUSTER INFO #集群状态。
列出节点信息：192.168.1.11:6379&gt; CLUSTER NODES #列出节点信息。
添加数据：
192.168.1.11:6379&gt; set name aaa-&gt; Redirected to slot [13680] located at 192.168.1.13:6379                # 说明最终将数据写到了192.168.1.13:6379上OK

获取数据：
192.168.1.11:6379&gt; get name-&gt; Redirected to slot [13680] located at 192.168.1.13:6379                # 说明最终到192.168.1.13:6379上读数据&quot;aaa&quot;

3.4.运行机制在 Redis 的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383，可以从上面redis-trib.rb执行的结果看到这16383个slot在三个master上的分布。还有一个就是cluster，可以理解为是一个集群管理的插件，类似的哨兵。
当我们的存取的 Key到达的时候，Redis 会根据 crc16的算法对计算后得出一个结果，然后把结果和16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。
当数据写入到对应的master节点后，这个数据会同步给这个master对应的所有slave节点。
为了保证高可用，redis-cluster集群引入了主从模式，一个主节点对应一个或者多个从节点。当其它主节点ping主节点master 1时，如果半数以上的主节点与master 1通信超时，那么认为master 1宕机了，就会启用master 1的从节点slave 1，将slave 1变成主节点继续提供服务。
如果master 1和它的从节点slave 1都宕机了，整个集群就会进入fail状态，因为集群的slot映射不完整。如果集群超过半数以上的master挂掉，无论是否有slave，集群都会进入fail状态。
redis-cluster采用去中心化的思想，没有中心节点的说法，客户端与Redis节点直连，不需要中间代理层，客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。
3.5.集群扩缩容对redis集群的扩容就是向集群中添加机器，缩容就是从集群中删除机器，并重新将16383个slots分配到集群中的节点上（数据迁移）。
扩缩容也是使用集群管理工具 redis-tri.rb。
扩容时，先使用redis-tri.rb add-node将新的机器加到集群中，这是新机器虽然已经在集群中了，但是没有分配slots，依然是不起做用的。在使用 redis-tri.rb reshard进行分片重哈希（数据迁移），将旧节点上的slots分配到新节点上后，新节点才能起作用。
缩容时，先要使用 redis-tri.rb reshard移除的机器上的slots，然后使用redis-tri.rb add-del移除机器。
3.8.集群模式的优缺点优点采用去中心化思想，数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布;
可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除;
高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升;
降低运维成本，提高系统的扩展性和可用性。
缺点1.Redis Cluster是无中心节点的集群架构，依靠Goss协议(谣言传播)协同自动化修复集群的状态
但 GosSIp有消息延时和消息冗余的问题，在集群节点数量过多的时候，节点之间需要不断进行 PING&#x2F;PANG通讯，不必须要的流量占用了大量的网络资源。虽然Reds4.0对此进行了优化，但这个问题仍然存在。
2.数据迁移问题
Redis Cluster可以进行节点的动态扩容缩容，这一过程，在目前实现中，还处于半自动状态，需要人工介入。在扩缩容的时候，需要进行数据迁移。
而 Redis为了保证迁移的一致性，迁移所有操作都是同步操作，执行迁移时，两端的 Redis均会进入时长不等的阻塞状态，对于小Key，该时间可以忽略不计，但如果一旦Key的内存使用过大，严重的时候会接触发集群内的故障转移，造成不必要的切换。
四、总结主从模式：master节点挂掉后，需要手动指定新的master，可用性不高，基本不用。
哨兵模式：master节点挂掉后，哨兵进程会主动选举新的master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。
集群模式：数据量比较大，QPS要求较高的时候使用。 Redis Cluster是Redis 3.0以后才正式推出，时间较晚，目前能证明在大规模生产环境下成功的案例还不是很多，需要时间检验。
完成，收工！
]]></content>
      <categories>
        <category>中间件</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 常用命令</title>
    <url>/posts/99f6ec28/</url>
    <content><![CDATA[查看Redis 连接数查看当前连接数&gt; info clients# Clientsconnected_clients:38client_longest_output_list:0client_biggest_input_buf:0blocked_clients:0

查看最大连接数&gt; CONFIG GET maxclients1) &quot;maxclients&quot;2) &quot;9968&quot;

]]></content>
      <categories>
        <category>中间件</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>nodejs 常用命令</title>
    <url>/posts/63e97dc8/</url>
    <content><![CDATA[目录缓存npm 查看缓存目录npm config get cache

npm 清理缓存
参考链接：http://claude-ray.com/2019/12/06/npm-install-without-cache/

npm cache clean -f

npm 设置代理http 代理npm 原生支持 http 代理，直接设置即可
# 假设本地代理端口为 8080npm config set proxy &quot;http://localhost:8080&quot;npm config set https-proxy &quot;http://localhost:8080&quot;# 有用户密码的代理npm config set proxy &quot;http://username:password@localhost:8080&quot;npm confit set https-proxy &quot;http://username:password@localhost:8080&quot;

socks5 代理npm 不支持 socks 代理，但是我们可以用一个工具将 socks 代理转成 http 代理，然后将 npm 代理地址设置到这个工具的地址。
# 假设本地 socks5 代理端口为 1080# 首先安装转换工具npm install -g http-proxy-to-socks# 然后使用这个工具监听 8081 端口,支持 http 代理，然后所有 1080 的 socks 代理数据都将转换成 http 的代理数据发送到 8081 上hpts -s localhost:8081 -p 1080# 最后设置 npm 代理为 8081npm config set proxy &quot;http://localhost:8081&quot;npm config set https-proxy &quot;http://localhost:8081&quot;

相当于又加了一个中间层，将 socks 转成 http。
删除代理npm config delete proxynpm config delete https-proxy

                      
]]></content>
      <categories>
        <category>前端</category>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/posts/0/</url>
    <content><![CDATA[Hadoop组成部分前言在上一篇文章我们主要讲了大数据的简单概念，什么是大数据，大数据的特点是什么？之后我们又从大数据扩展到Hadoop，讲了三个最主要的问题，Hadoop是什么，Hadoop发展史，Hadoop相较于其他大数据框架而言优势又是什么?
今天呢，我们依然沿着上一篇的脉络，去探索Hadoop的基本组成部分，是哪些技术有机地组合在了一起造就了Hadoop今天在大数据领域的出色表现，在Hadoop2.0之后，Hadoop主要由以下三个部分组成：

Map - Reduce ：负责计算
Yarn ：负责资源调度
HDFS: 负责数据的存储

它们三个相辅相成，互相成就，当然本篇文章今天只是初略地带大家理解一下这三种技术在Hadoop中所起到的作用，具体更加详细的细节，在我们之后关于Map-Reduce和HDFS专题中会做更加详细的概述。
Map-Ruduce 编程模型首先平常看到这种英语概念，第一时间就是打开我们的谷歌翻译，Map的意思我想大家都知道，毕竟java中用的不能再多，Reduce是降低减少归纳的意思，所以Map-Reduce就是一个先分隔（map）再归纳（Reduce)的过程。
我们来看下定义：
MapReduce是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个Hadoop集群上。
MapReduce主要可以概括为map阶段和reduce阶段。
只看定义确实是有点晦涩，那Map-Reduce通俗理解是什么呢？还是我们上一篇文章讲的那个例子：
初中的时候，男生爱看玄幻小说，因为怕被教导主任查到，于是采用分布式存储的方案，把书分成几页几页的，放在不同的同学那边放着，但教导主任不是傻子，所谓道高一尺魔高一丈，最后还是被发现了，而是还放言今天要是不把这本书凑齐交到他办公室，全部都等着叫家长吧。
最后大家都把手里的残本交给了班长小明，小明根据页码排序整理好，交给了教导主任。
教导主任说你这不是闲的吗，天天不好好学习搁那看的这什么，头破苍穹，是英语书不好背了，还是数学书不好看了？这么着，你不是闲得慌吗，就这个萧炎，就他，你下去给我查查，整本书这个名字一共出现了多少次！不查完今天别想吃饭了！
小明想，这不是玩完了，我自己查，我得查到猴年马月才能查完。

重点来了，传统的编程模型要是需要知道一本书中某个单词出现的频率，只能写个程序，遍历整个文件，如果几个字还好说，但是把斗破苍穹遍历一遍，需要的时间绝对够你吃顿饭的。
那不是还有多线程吗？
是有多线程，但是前提是我们得有一台多核或者多处理器的计算机，而且多线程的程序写起来也有点小复杂。

但小明不傻啊，小明心想，mmp，又不是我一个人看的，为啥要我自己数，于是小明心生一计，回到班里，大家有福同享有难同当，老师现在让我数萧炎在书中一共出现了多少次，我自己数到明天也数不完，谁看的谁过来大家一人数几页，然后你们在下面数好了汇总一下交给我。
于是全班男生一人数了几十页，不到一个小时就数完了，小明成功渡过一劫。
这就是 Map - Reduce，我一个人算不过来了，我找十个人并行计算，最后把结果进行汇总，不用说也知道是什么思想了，数据结构中用的最多的分而治之。
当然，Map-Reduce肯定不止我们上面说的那么简单，具体实现细节还是略微有点繁琐的，详细的执行流程，原理到时候我们在Map-Reduce专题再细细分析。
YarnYarn这个东西在Hadoop2.x时代才诞生，在遥远的Hadoop1.x时代，Map-Reduce不仅要负责计算，还要负责资源调度，简直是又当爹又当妈，一两天还好，时间长了Map-Reduce就受不了了，就向Hadoop总部提意见，总部肯定装作没听到啊，一个人干俩人的活儿不能再划算了。于是就不搭理Map-Reduce，后来有一天，Map-Reduce终于忍无可忍了，就甩袖子不干了，因为之前Map-Reduce又干计算又干资源调度，所以Map-Reduce甩袖子不干了，整个Hadoop计算和资源调度系统全都歇菜了。
耦合太严重，于是Hadoop觉得这不行，被Map-Reduce卡脖子可还得了？于是Hadoop又招了一个专门负责资源调度，就是Yarn，这样一来，Map-Reduce只负责计算，Yarn只负责资源调度，Hadoop内部瞬间和谐多了。再也没有出现过一人罢工，全员歇菜的问题了。
Yarn主要干四个事儿，分别是：
ResourceManager（RM）：

处理客户端请求。
监控NodeManager。
启动或监控ApplicationMaster。
资源的分配与调度。

NodeManager（NM）：

管理单个节点上的资源。
处理来自ResourceManager的命令
处理来自ApplicationMaster的命令

ApplicationMaster（AM）：

负责数据的切分。
为应用程序申请资源并分配给内部的任务。
任务的监控与容错。

Container ：
 Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。
HDFSHDFS : Hadoop分布式文件系统（Hadoop Distributed File System),听名字就知道是Hadoop中负责文件存储部分的技术了。
HDFS相对于前面的Map-Reduce和Yarn就比较容易理解了，HDFS架构主要分为三个部分：
NameNode（nn）:
存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。
NameNode主要存储文件的元数据，比如我们去图书馆借书，NameNode存的就是这个图书馆所有书籍的目录，作者，文件属性，以及书的位置等信息。
DataNode(dn) ：
DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。
还是上面那个图书馆的例子，如果NameNode主要存的是目录的话，那么DataNode就是存书的书架，也就是我们实际的数据实际是在DataNode上存放的。
Secondary NameNode(2nn)：
Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照
看名字就知道了，和我们Nginx中讲的万一Nginx挂了是一个性质，你只有一个NameNode，万一不小心NameNode挂了，所有文件的元数据都没法儿访问，找不到文件的实际位置，那不就gg了吗，所以Secondary NameNode(2nn)：主要就起一个辅助备份的作用.
万一NameNode挂了，别怕，有Secondary NameNode(2nn)在，他那有备份，恢复都是小KS。
参考链接写给后端的Hadoop初级入门教程：Hadoop组成部分。
                      
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/posts/0/</url>
    <content><![CDATA[概念篇什么是大数据大数据 (Big Data) : 主要是指无法在一定范围内用常规软件工具进行捕捉，管理和处理的数据集合，是需要新处理模式才能具有更强的决策力，洞察发现力和流程优化能力的海量，高增长率和多样化的信息资产。
一句话解释：大数据就是大量数据，数据多到传统方案无法处理的程度。
当然数据的体量并不是最重要的，重要的是隐藏在这些数据中的信息，这些信息不论是在商业上还是在研究上都有着巨大的价值，电商通过挖掘这些数据中的信息为每个用户画像，并且推荐合适的商品给用户增加购买，当然，也可以顺便调整一下改个价格杀个熟什么。
大数据的单位但我们毕竟是严谨的理科生啊，你说大数据大数据，多大才是大数据？为了解决这个问题，减少撕逼，科学家就制定了一系列的数据单位，从小到大依次是：
bit` `Byte` `KB` `MB` `GB` `TB` `PB` `EB` `ZB` `YB` `BB` `NB(牛逼)` 和 `DB（呆逼）

当然，光讲这些单位有什么意思，我怎么能知道这些单位能存多少数据？为了方便大家更加直接的感受到这些数据单位的威力，我找了一些小栗子：

全世界所产生的印刷材料的数据大概是200PB。
全世界人类总共说过的话大概是5EB。
国外知名网站P站2017年网站产生的总数据量为3732PB 。
一百万个汉字大概所需要的内存是2MB。

刚才好像混入了什么奇怪的东西。
大数据的特点
大量：必须的，不大都不好意思叫大数据。
高速：这么多数据肯定要快速消化掉的，处理几十年也等不起啊，今年双十一的成交额总不能算到明年双十一再公布吧。
多样：不同的场景会产生不同的数据，优酷就是用户浏览数据，视频数据，QQ音乐就是音乐数据。
低价值密度：这个意思是即使数据量很大，但是我们关注的始终的特定的部分，而非整体，就像警察叔叔调监控一样，一年前一个月前的数据通常对他来说是没什么用的，他只要那么几个关键节点的监控数据就可以了。

应用场景就不说了，哪都是应用场景。
Hadoop是什么？知道了什么是大数据，我们就得思考另外一个问题，弄这么多的数据我放哪啊？
杠精：不明摆着的么，当然放硬盘里啊，要不放哪儿，还能写纸上？ 我：硬盘我知道，可是万一这块硬盘坏了，那数据不就没了吗？
路人：你系不系傻，你多放几块硬盘，分别放上去不就行了吗？
这个时候Hadoop来了，弟弟们都往边上靠靠，你们那种办法太笨拙，交给我，轻轻松松地给你搞定，小意思。
Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要用来解决大数据的存储和分析计算问题。
当然，Hadoop和Spring一样，到现在已经没法去仅仅理解为Hadoop这门技术了，就像你跟别人说，我这个新电商项目基于Spring写的，那别人肯定不会觉得你只用了Spring，会觉得你可能用了Spring MVC，boot，JPA等一系列Spring生态的技术。同样地，Hadoop也是如此，不仅仅是代表Hadoop本身这项技术，同时也代表围绕Hadoop的技术生态。
而且大家千万不要把事情想复杂，以为分布式存储什么这些概念都是多么深奥的东西，的确，官方概念确实是有点抽象晦涩了，但是我觉得，任何一项理论都一定来源于生活，因为是生活给予了他们灵感，但是生活并不是十分复杂的，所以任何深奥复杂的理论一定可以在生活中找到一个通俗易懂的解释。
什么是分布式存储，不跟大家吹，我初中的时候就已经在搞这个了，那时候流行看玄幻小说，那种大部头知道吧，特厚，通常一个班就只有那么一本，被教导主任没收了就完蛋了，谁都没得看，于是当时盛行把一本玄幻小说一页一页撕下来，每个同学几页，大家互相换着看，就算老师发现了也就只是没收了一部分，没办法全部歼灭。你看，分布式有了，存储有了，这不就是分布式存储吗？为了防止一本书被老师没收了导致这本书不完整，那就买三本，也这么几页几页分开存，这不就是多备份吗，没那么复杂，别老纠结那些学者写的给学者看的概念。
Hadoop发展史这个也没啥好讲的，我这里就列几个关键的点，感兴趣的朋友下去可以自己搜，网上一搜一大堆。

一个叫Dung Cutting 没事用java写了一个全文搜索的框架 - Lucene
数据量大的时候，Lucene性能跟不上了就。
巧了，Google本身也是做全文搜索的，为啥人家性能就那么顶呢？
通过学习谷歌，搞了个Nutch
后来谷歌公开了部分GFS和MapReduce的细节。
Dung Cutting 一看这答案都给自己了，于是花了两年，注意是业余时间，自己实现了DFS和MapReduce，Nutch性能一下字就提上去了，一个字，牛逼。
后来Hadoop作为Lucene子项目Nutch的一部分被正式引进了Apache基金会。
然后Map-Reduce和NDFS一块被整合进了Hadoop项目里面，Hadoop就这么诞生了。

为啥人家业余时间就能搞出来这么牛逼的东西，我业余时间王者荣耀王者都上不去，难道有中间商赚差价？
Hadoop发行版本和Linux差不多，不同的公司在此基础上分别定制了自己的发行版本，Hadoop发行版本主要有三个，分别是：

Apache版本：最原始（最基础）的版本，对于入门学习最好，毕竟是出生地，血统也是最正的。
Cloudera：在大型互联网企业中用的较多。
Hortonworks：文档比较全。

不用想，我们肯定选Apache，也没啥别的原因，就是因为它基础，简单，不要钱。
Hadoop优势是什么？Hadoop为啥这么牛逼，导致我们现在一说大数据开发，就会想到Hadoop？
毕竟写程序不是谈恋爱，没什么就算你不好我也依然爱你这回事，我们坏得很，哪个好用使哪个。
Hadoop在江湖中能混到今天的地位主要靠以下四点：

高可靠性：Hadoop底层使用多个数据副本，即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失，想想上面讲的分布式存储的例子。
高扩展性：在集群间分配任务数据，可以方便的扩展数以千计的节点。就是，有一天运维早上一上班，卧槽，集群存储不够了，但是问题不大，因为在集群中加入一个新的节点或者去掉一个节点都分分钟的事儿。
高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。
高容错性：能够将失败的任务重新分配。

你说了一堆优点，Hadoop就没啥缺点吗？必须有，但是这个要到后面写到HDFS，MR的时候才能说，要不现在都不知道Hdfs是啥，说缺点的话不形象，就跟说人坏话一样，当着人家面儿说才有效果。
参考链接写给后端的Hadoop初级入门教程：概念篇
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/posts/0/</url>
    <content><![CDATA[一、命令行登录方式进入 hbase bin 目录下，执行以下命令：
hbase shell

二、命名空间1. 查看所有命名空间list_namespace

2. 查看具体的命名空间describe_namespace &#x27;&lt;namespace&gt;&#x27;

3. 查看命名空间下的所有表list_namespace_tables &#x27;&lt;namespace&gt;&#x27;

三、表操作1. 查看所有表list

2. 查看表结构describe &#x27;&lt;table name&gt;&#x27;

3. 扫描表（scan）
scan &#x27;&lt;table name&gt;&#x27;, &#123; options &#125;

HBase支持以下几种附加方式：

COLUMNS：列过滤
LIMIT：限制查询结果行数
STARTROW：ROWKEY起始行。会先根据这个key定位到region，再向后扫描
STOPROW：结束行
TIMERANGE：限定时间戳范围
VERSIONS：版本数
FILTER：按条件过滤行


1. 扫描所有数据scan &#x27;table_name&#x27;

2. 扫描限制数量 2scan &#x27;&lt;table_name&gt;&#x27;, &#123; LIMIT=&gt;2 &#125;scan &#x27;&lt;table_name&gt;&#x27;, &#123; FILTER=&gt;&quot;PageFilter(2)&quot; &#125;

3. 设置扫描起点终点（根据 rowkey）
STARTROW、ENDROW 等需要大写

scan &#x27;table_name&#x27;, &#123; STARTROW =&gt; &#x27;row10&#x27;, ENDROW =&gt; &#x27;row20&#x27; &#125;

4. 扫描整个列簇
列簇名（column family）中间可以有空格。

语法：
scan &#x27;&lt;table name&gt;&#x27;, &#123;COLUMN=&gt;&#x27;&lt;column family:key&gt;&#x27;&#125;

举个栗子：
scan &#x27;dds_eas_AJ:oms_origin_waybill&#x27;, &#123;COLUMN=&gt;&#x27;f:waybillNo&#x27;&#125;

5. 根据时间戳扫描TIMERANGE

6. 添加过滤FITLER

4. 获取行或单元数据（get）
rowkey 为 row_index。

1. 获取指定行语法：
get &#x27;&lt;namespace&gt;:&lt;table_name&gt;&#x27;, &#x27;&lt;row_index&gt;&#x27;

举个栗子：
get &#x27;dds_eas_AJ:oms_origin_waybill&#x27;, &#x27;00AJ15e4571798369&#x27;

2. 获取指定行的指定列簇中列的数据语法：
get &#x27;&lt;namespace&gt;:&lt;table_name&gt;&#x27;, &#x27;&lt;row_index&gt;&#x27;, &#x27;&lt;column_cluster&gt;:&lt;column_name&gt;&#x27;get &#x27;&lt;namespace&gt;:&lt;table_name&gt;&#x27;, &#x27;&lt;row_index&gt;&#x27;, &#123;COLUMN=&gt;&#x27;&lt;column_cluster&gt;:&lt;column_name&gt;&#x27;, TIMESTAMP=&gt;&lt;TIMESTAMP&gt;&#125;

举个栗子：
get &#x27;dds_eas_AJ:oms_origin_waybill&#x27;, &#x27;00AJ1504571798369&#x27;, &#x27;f:waybillNo&#x27;get &#x27;dds_eas_AJ:oms_origin_waybill&#x27;, &#x27;00AJ1504571798369&#x27;, &#123;COLUMN=&gt;&#x27;f:waybillNo&#x27;&#125;

6. 表是否存在exists &#x27;&lt;table name&gt;&#x27;

7. 表是否 enableis_enabled &#x27;&lt;table name&gt;&#x27;is_disabled &#x27;&lt;table name&gt;&#x27;# 如果要启动/禁用表，使用以下命令：enabled &#x27;&lt;table name&gt;&#x27;disabled &#x27;&lt;table name&gt;&#x27;

8. 统计表数据行数count &#x27;&lt;table name&gt;&#x27;

9. 删除（delete，truncate）1. 清空表truncate &#x27;&lt;table name&gt;&#x27;

2. 删除表先要屏蔽该表，才能对该表进行删除，步骤如下：
disable &#x27;&lt;table name&gt;&#x27;drop &#x27;&lt;table name&gt;&#x27;

3. 删除行数据deleteall &#x27;&lt;table name&gt;&#x27;, &#x27;&lt;row&gt;&#x27;

4. 删除列数据delete &#x27;&lt;table name&gt;&#x27;, &#x27;&lt;row&gt;&#x27;, &#x27;&lt;column name&gt;&#x27;, &#x27;&lt;time stamp&gt;&#x27;

10. 过滤 FILTER
FILTER中支持多个过滤条件通过括号、AND和OR的条件组合
scan &#x27;member&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;birth&#x27;) AND ValueFilter(=,&#x27;substring:1988&#x27;)&quot;

查看 shell 中定义了哪些 filter 常量，如果想要使用 shell 中未定义的常量，在使用的时候必须手动 import filter 的全路径。
show_filters

比较器
二进制比较器：如’binary:abc’，按字典排序跟’abc’进行比较
二进制前缀比较器：如’binaryprefix:abc’，按字典顺序只跟’abc’比较前3个字符
正则表达式比较器（重要）：如’regexstring:ab*yz’，按正则表达式匹配以ab开头，以yz结尾的值。这个比较器只能使用&#x3D;、!&#x3D;两个比较运算符。
子串比较器：如’substring:abc123’，匹配以abc123开头的值。这个比较顺也只能使用&#x3D;、!&#x3D;两个比较运算符。

列过滤1. 限制某个列的值等于26scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;ValueFilter(=,&#x27;binary:26&#x27;)&quot;

2. 值包含6这个值
注：substring不能使用小于等于等符号

scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;ValueFilter(=,&#x27;substring:6&#x27;)&quot;

3. 列名中的前缀为E的scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;E&#x27;)&quot;

4. 列簇含f的数据scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;FamilyFilter(=,&#x27;substring:f&#x27;)&quot;

行过滤
PrefixFilter是对 Rowkey 的前缀进行判断，这是一个非常常用的功能。

1. 限制某行的值等于26scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;RowFilter(=,&#x27;binary:26&#x27;)&quot;

2. 值包含6这个值
注：substring不能使用小于等于等符号

scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;RowFilter(=,&#x27;substring:6&#x27;)&quot;

3. 行名中的前缀为E的scan &#x27;&lt;table name&gt;&#x27;, FILTER=&gt;&quot;PrefixFilter(&#x27;E&#x27;)&quot;

11. 插入数据（put）语法：
put &#x27;&lt;table_name&gt;&#x27;, &#x27;&lt;row_id&gt;&#x27;, &#x27;&lt;column_family&gt;:&lt;column_name&gt;&#x27;, &#x27;&lt;value&gt;&#x27;

举个栗子：
put &#x27;member&#x27;, &#x27;debugo&#x27;,&#x27;info:age&#x27;, &#x27;27&#x27;



四、其他命令查看状态status

查看帮助table_helphelp

查看版本version

五、参考链接Hbase shell 命令介绍
漫谈HBase Filter
HBase 使用过滤器
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/posts/0/</url>
    <content><![CDATA[一、前奏Hadoop是目前大数据领域最主流的一套技术体系，包含了多种技术。
包括HDFS（分布式文件系统），YARN（分布式资源调度系统），MapReduce（分布式计算系统），等等。
有些朋友可能听说过Hadoop，但是却不太清楚他到底是个什么东西，这篇文章就用大白话给各位阐述一下。
假如你现在公司里的数据都是放在MySQL里的，那么就全部放在一台数据库服务器上，我们就假设这台服务器的磁盘空间有2T吧，大家先看下面这张图。


现在问题来了，你不停的往这台服务器的MySQL里放数据，结果数据量越来越大了，超过了2T的大小了，现在咋办？
你说，我可以搞多台MySQL数据库服务器，分库分表啊！每台服务器放一部分数据不就得了。如上图所示！
好，没问题，那咱们搞3台数据库服务器，3个MySQL实例，然后每台服务器都可以2T的数据。
现在我问你一个问题，所谓的大数据是在干什么？
我们来说一下大数据最初级的一个使用场景。假设你有一个电商网站，现在要把这个电商网站里所有的用户在页面和APP上的点击、购买、浏览的行为日志都存放起来分析。
你现在把这些数据全都放在了3台MySQL服务器，数据量很大，但还是勉强可以放的下。
某天早上，你的boss来了。要看一张报表，比如要看每天网站的X指标、Y指标、Z指标，等等，二三十个数据指标。
好了，兄弟，现在你尝试去从那些点击、购买、浏览的日志里，通过写一个SQL来分析出那二三十个指标试试看？
我跟你打赌，你绝对会写出来一个几百行起步，甚至上千行的超级复杂大SQL。这个SQL，你觉得他能运行在分库分表后的3台MySQL服务器上么？
如果你觉得可以的话，那你一定是不太了解MySQL分库分表后有多坑，几百行的大SQL跨库join，各种复杂的计算，根本不现实。
所以说，大数据的存储和计算压根儿不是靠MySQL来搞的，因此，Hadoop、Spark等大数据技术体系才应运而生。
本质上，Hadoop、Spark等大数据技术，其实就是一系列的分布式系统。
比如hadoop中的HDFS，就是大数据技术体系中的核心基石，负责分布式存储数据，这是啥意思？别急，继续往下看。
HDFS全称是Hadoop Distributed File System，是Hadoop的分布式文件系统。
它由很多机器组成，每台机器上运行一个DataNode进程，负责管理一部分数据。
然后有一台机器上运行了NameNode进程，NameNode大致可以认为是负责管理整个HDFS集群的这么一个进程，他里面存储了HDFS集群的所有元数据。
然后有很多台机器，每台机器存储一部分数据！好，HDFS现在可以很好的存储和管理大量的数据了。
这时候你肯定会有疑问：MySQL服务器也不是这样的吗？你要是这样想，那就大错特错了。
这个事情不是你想的那么简单的，HDFS天然就是分布式的技术，所以你上传大量数据，存储数据，管理数据，天然就可以用HDFS来做。
如果你硬要基于MySQL分库分表这个事儿，会痛苦很多倍，因为MySQL并不是设计为分布式系统架构的，他在分布式数据存储这块缺乏很多数据保障的机制。
好，你现在用HDFS分布式存储了数据，接着不就是要分布式来计算这些数据了吗？
对于分布式计算：

很多公司用Hive写几百行的大SQL（底层基于MapReduce）
也有很多公司开始慢慢的用Spark写几百行的大SQL（底层是Spark Core引擎）。

总之就是写一个大SQL，人家会拆分为很多的计算任务，放到各个机器上去，每个计算任务就负责计算一小部分数据，这就是所谓的分布式计算。
这个，绝对比你针对分库分表的MySQL来跑几百行大SQL要靠谱的多。
对于上述所说，老规矩，同样给大家来一张图，大伙儿跟着图来仔细捋一下整个过程。
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/posts/0/</url>
    <content><![CDATA[基础操作登录命令./sqlline.py localhost:2181:/hbase-unsecure

退出方法一!quit

方法二!exit

帮助help

表操作
phoenix&#x2F;hbase对表名、字段名都是大小写敏感，如果直接写小写字母，不加双引号，则默认会被转换成大写字母。

创建表create table if not exists ljc.student (id integer primary key, name varchar(20));

查看当前库中存在的表!tables

删除表语法：
drop table &lt;TABLE_NAMESPACE&gt;.&lt;TABLE_NAME&gt;;

举个栗子：
drop table ljc.student;

查看表结构!describe &quot;&lt;TABLE_NAME&gt;&quot;

插入、更新
Phoenix 中不存在 update 的语法关键字，而是 upsert ，功能上替代了 Insert + update。

upsert into ljc.student(id, name) values(1, &#x27;zhangsan&#x27;);

]]></content>
  </entry>
  <entry>
    <title>draw.io 基础教程</title>
    <url>/posts/5e3e9b12/</url>
    <content><![CDATA[1. 网页端使用懒得安装的直接使用下面这个链接直接开始绘图：https://www.draw.io
2. 桌面端下载在github项目右侧有个release，这里是作者打包生成好的安装文件，比如现在最新的版本是14.5.1点击进去后，可以看到如下图所示的下载页面。根据你自己的系统以及硬件平台选择合适的安装文件。



3. 语言设置安装完后第一次打开默认界面是英文的，如果想使用中文，可以点击Language接着选择自己喜欢的语言，如果想提升英语的还是默认吧哈哈。
选择简体中文。
设置完语言后记得重启下软件。

4. 开始绘图打开drawio后，点击创建新绘图：


接着会提示你选择一个模板，这里直接创建一个空白框图（可根据自身情况选择)

创建完后，如图所示：




添加元素
选择你需要的元素拖入画布 (左侧有官方提供的各种类型元素，点击左下角更多图形可以找到更多类别)
选中元素后可使用鼠标点击元素边缘上的点对元素进行放大&#x2F;缩小等操作（元素右上角的旋转标志可以选择元素）
双击元素可以输入文字
选中元素后可在右侧的样式中修改元素的样式（颜色等）
在右侧的文本中可以修改文字的字体、大小以及颜色等等
在右侧的调整图形中可以对元素的位置、大小以及角度等进行更加精细的调整



元素对齐当要对齐多个元素时，选择多个元素（可通过ctrl+鼠标左键选择多个目标），然后点击调整图形 -&gt; 对齐 然后选择你想要的对齐方式。


元素等距分布当要等距摆放多个元素时，选择多个元素（可通过ctrl+鼠标左键选择多个目标），然后点击调整图形 -&gt; 等距分布 然后选择你想要的分布方式。


连接元素当把鼠标放置元素上（注意没有点击，只是放置）会出现如下图所示的标识，四个箭头（用红圈标出的部分），16个小叉叉（用绿色的圈圈标出）。如果点击了元素只会显示四个箭头。


连接的操作有很多种，这里只简单讲一种，在刚刚说的 当把鼠标放置元素上 后在元素周围出现各种标识，你可以自己随便选择一个作为连接线的起始位置，鼠标左键按下（不要松）拖动鼠标移至你想连接的位置。


连接后在右侧的样式中可以修改连接线的样式、连接方式、颜色、粗细、线形等等。


添加文字
在通用里拖一个Text元素放到你想放的位置
双击Text元素编辑文字
在右侧的文本中对文字的颜色、字体、大小等进行编辑



添加公式可参考官方给的文档：https://www.diagrams.net/doc/faq/math-typesetting


在使用公式功能之前需要打开数学排版，在其他 -&gt; 数学排版 在点击后会显示一个勾勾，然后就能用了：


现在官方支持三种格式，比如写博文中常用的LaTeX格式。用起来也非常方便，直接把公式复制到Text元素里就行了。
$$\sqrt&#123;3×-1&#125;+(1+x)^2$$


如果不了解LaTeX公式不了解可以看下下面几个连接：帮助文档： https://www.latexlive.com/help在线公式编辑器： https://www.latexlive.com/
添加图片有时，需要使用一些现成的图片，点击上方的加号，再点击图片按钮。


接着你可以通过打开按钮选择自己本地的图片，或者通过网上图片的url直接载入进来。


添加表格点击上方的表格图标，然后拖动鼠标可以选择自己需要的表格大小（行数和列数）。

选中表格，在右侧的调整图形中可以调整表格的大小、位置等属性。


自由绘图有时一些特殊的图案软件中并没有提供，这时可以使用自由绘图功能自己去绘制。点击上方的加号，再点击自由绘图，会弹出一个自由绘图窗口。

点击开始绘图按钮就可以自己用鼠标随便绘制，绘制完后点击结束绘图按钮，刚刚绘制好的图案就会变成一个元素随意使用。


组合元素同时选中多个元素，在元素上点击鼠标反键，再点击组合即可组合成一个元素。


保存元素模板有时一些元素（可能是你自己组合设计的新元素）经常被用到，我们可以将其保存成一个模板方便下次使用。如下图所示，将需要保存的元素用鼠标拖至左侧的 便筏本 中，这样以后都可以使用到。

点击便筏本的铅笔符号可以编辑管理自己的便筏本。


5. 保存保存文件在左上角点击 文件 -&gt; 保存 将绘图文件保存到指定路径。


导出图片在左上角点击 文件 -&gt; 导出为 将绘图文件导出成指定格式，一般为了方便使用会导出成PNG或者JPEG格式等。


比如我要将图片保存成PNG格式的图片，软件会提示是否要透明背景、阴影、网格等。另外还有个边框宽度参数，这个参数代表输出图像时是否需要在图片边缘增加一些空白边缘。默认是0，如果需要可以自己设置。


大家可以简单对比下设置和不设置边缘宽度的区别。


6. 常用快捷键


快捷键
作用



CTRL + C
复制元素


CTRL + X
剪切元素


CTRL + V
粘贴元素


CTRL + Z
撤销操作


CTRL + S
保存绘图（建议经常保存，养成良好习惯）


CTRL + A
选中全部元素


DELETE
删除选中元素


]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>v2rayN 配置教程</title>
    <url>/posts/4a137bcb/</url>
    <content><![CDATA[4.12 最新 v2rayN windows 进阶版使用教程 | 附PAC模式路由规则 | 多个自定义路由规则在上篇 v2rayN 使用教程中（点击跳转），已经向大家介绍了最新 v2rayN windows 的重大更新内容以及如何快速使用新版 v2rayN 客户端：

比如，删除了常见PAC 模式; 自定义路由规则集和自由切换多个路由规则集；
系统代理把windows系统部分软件流量（比如浏览器）转到v2ray的http入口、VMESS和VLESS协议 增加SNI属性等
新版 v2rayN 下载地址：https://github.com/2dust/v2rayN/releases/

不少小伙伴，也在上期视频教程下方（点击跳转）留言：
需要详细介绍“自定义路由规则的原理”、“分享一些常用的路由规则”、“能不能如何通过路由规则实现旧版客户端的PAC模式”等等。今天我们就来一起学习吧！
新旧版的不同点旧版的PAC模式是由“本地的PAC文件&#x2F;GFW LIST”对流量先进行分流；然后，再通过v2ray.exe去判断是否走代理出站，并配合”v2ray_privoxy.exe”进行流量转发；这也是为什么使用旧版客户端时， win10 UWP应用能正常工作的原因；新版的路由模式则是直接通过v2ray.exe 程序去分流和判断是否走代理的。（个人理解，如有错误，请帮忙留言指正，谢谢！）
旧版客户端：



新版客户端： 



那旧版PAC 模式消耗的内存更多一点（见下图），自定义灵活度也不高；
新版v2rayN 自定义灵活度高、使用的内存更小、有一定的速度提高，但有学习成本！


常说的 Geo文件是什么？与路由规则和路由规则集的关系是什么？Geo文件即路由规则文件：

“geosite.dat”：提供一个预定义好的 「全球域名」 列表，

“geoip.dat” ：提供一个预定义好的 「全球 ip-地区」 列表。



“.dat文件”里面有无数个分类，比如,中国的域名和IP都在 geosite:cn 和 geoip:cn
gfwlist的网址(也就是经典的PAC)在 geosite:gfw | 点击跳转
广告域名在 geosite:category-ads-all
国外域名在 geosite:geolocation-!cn
本地IP在 geoip:private里;
还有一千多种分类细分，比如 geosite:steam geosite:google 等，
以上内容来自于“网友 ycdm ”，谢谢他的分享。

综上:
geo路由规则文件是”全球域名和 全球地区的 IP 数据库”
路由规则可以采用”数据库内任意域名或者IP的分类”或者”添加一个不在数据库的域名或者IP”，并选择“对应的出站标签”；然后 “xray.exe或者 v2ray.exe “（常说的核心） 自带的路由模式，会根据路由规则中”不同的出站标签”，来决定“出站标签”包含的域名和IP是否走代理出站、直连（本地网络访问）还是禁止访问。
那“路由规则集”就是”包含一个或者多个路由规则的集合”

如何添加&#x2F;自定义路由规则集？添加规则集的目的：不同的路由规则集对应不同的代理模式，可以分别对应“PAC 模式”、“绕过大陆”、“全局代理”等等，来满足自己不同的“科学上网”或者“其他特殊的需求”。
1、下载 Geo 路由规则文件（推荐 V2ray路由加强版）：点击跳转2、普通用户： 直接启用“默认的基础路由规则”，并按照自己的需求和格式要求，在对应的对话框输入内容。

3. 路由规则输入的格式默认的“基础功能”—“一键导入基础规则”
可以在对应的对话框，输入单个网址或者 IP，多个选项，用英文输入方法下的逗号”,” 隔开。比如，在”阻止的Domian或 IP” 输入“domian:jamesdailylife.com”；此时，就不能访问该网址。
启用 “geoip.data” 和 “geosite.data”中，已经包含常用的域名和IP。使用方式：geosite:filename，如 geosite:google 表示对文件内符合 google 内包含的域名，按照自身需求录入到“代理、直连、阻止” ，就行了。

“代理的Domian或 IP”：此对话框的域名或者IP 走代理

“直连的Domian或 IP”：此对话框的域名或者IP 不走代理

“阻止的Domian或 IP”：此对话框的域名或者IP 不能访问




相关域名和IP分类名的解释

category-ads：包含了常见的广告域名。category-ads-all：包含了常见的广告域名，以及广告提供商的域名。cn：相当于 geolocation-cn 和 tld-cn 的合集。apple：包含了 Apple 旗下绝大部分域名。google：包含了 Google 旗下绝大部分域名。microsoft：包含了 Microsoft 旗下绝大部分域名。facebook：包含了 Facebook 旗下绝大部分域名。twitter：包含了 Twitter 旗下绝大部分域名。telegram：包含了 Telegram 旗下绝大部分域名。geolocation-cn：包含了常见的大陆站点域名。geolocation-!cn：包含了常见的非大陆站点域名，同时包含了 tld-!cn。tld-cn：包含了 CNNIC 管理的用于中国大陆的顶级域名，如以 .cn、.中国 结尾的域名。tld-!cn：包含了非中国大陆使用的顶级域名，如以 .hk（香港）、.tw（台湾）、.jp（日本）、.sg（新加坡）、.us（美国）.ca（加拿大）等结尾的域名。
category-games： 包含了 steam、ea、blizzard、epicgames 和 nintendo 等常见的游戏厂商。更多域名类别，请查看 data 目录 。

4. “启用路由高级功能”后，自定义路由规则集的方法有点不同。A. 添加已经编写好&#x2F;在使用的路由规则集：
“从文件中导入规则”： 导入本地的”路由规则集文件”
“从剪贴板中导入规则”： 复制“其他人分享的路由规则集范本”（文章末尾有）
“从订阅Url中导入规则”： 粘贴“别人分享的、含有路由规则集的url链接”

订阅url地址，不是机场的订阅地址，而是含规则集的 url 地址。
除了规则以外的请求，都走“代理”就是白名单模式；都走“直连”就是黑名单模式。
B.添加单个或者多个路由规则：
“Proxy” ： 走代理的域名或者IP
“Direct” ：不走代理的域名或者IP
“Block”： 不能访问的域名或者IP
“Port”：目标端口范围，当目标端口落在此范围内时，此规则生效



5. 特别注意：越靠前的规则，优先级越高；简单来说，优先使用“排在前面的路由规则”对产生的流量进行删选！！！使用加强版 v2ray 路由规则文件，一定特别“设置geoip.dat和geosite.dat文件不跟随core更新”

高级用法v2fly&#x2F;domain-list-community 项目 data 目录中某些列表里的规则会被标记诸如 @cn 的 attribute（如下所示），意为该域名在中国大陆有接入点，可直连。
steampowered.com.8686c.com @cnsteamstatic.com.8686c.com @cn

对于玩 Steam 国区游戏，想要直连的用户，可以设置类别 geosite:steam@cn 为直连，意为将 steam 列表内所有被标记了 @cn attribute 的规则（域名）设置为直连。同理，由于 category-games 列表包含了 steam、ea、blizzard、epicgames 和 nintendo 等常见的游戏厂商。设置类别 geosite:category-games@cn 为直连，即可节省大量服务器流量。

 注意：在 Routing 配置中，类别越靠前（上），优先级越高，所以 geosite:category-games@cn 等所有带有 @cn attribute 的规则都要放置在 geosite:geolocation-!cn 前（上）面才能生效。
category-games 列表内的规则（域名）可能会有疏漏，请留意规则命中情况。如发现遗漏，欢迎到项目 v2fly&#x2F;domain-list-community 提 issue 反馈。

路由规则集范本请先“启用高级路由规则”，按照视频教程添加规则：点击跳转谢谢网友“ANGIANAPR”的分享：点击跳转 GitHub
2dust 大佬分享的白名单和黑名单规则集范例
在4.14、4.13 版客户端中，在电脑能“富强&#x2F;科学上网”的前提下，
才能通过黑白名单范例的 URL 添加规则集！（见下图）

白名单范例：https://raw.githubusercontent.com/2dust/v2rayCustomRoutingList/master/custom_routing_rules_whitelist
黑名单范例：https://raw.githubusercontent.com/2dust/v2rayCustomRoutingList/master/custom_routing_rules_blacklist


1. PAC模式&#x2F;GFW 模式，带广告屏蔽的：
[  &#123;    &quot;outboundTag&quot;: &quot;block&quot;,    &quot;domain&quot;: [      &quot;geosite:category-ads-all&quot;,    ]  &#125;,  &#123;     &quot;outboundTag&quot;: &quot;proxy&quot;,     &quot;ip&quot;: [       &quot;geoip:telegram&quot;     ],     &quot;domain&quot;: [       &quot;geosite:gfw&quot;    ]  &#125;,  &#123;    &quot;port&quot;: &quot;0-65535&quot;,    &quot;outboundTag&quot;: &quot;direct&quot;  &#125;]

2. PAC模式&#x2F;GFW 模式，不带广告屏蔽：
[  &#123;     &quot;outboundTag&quot;: &quot;proxy&quot;,     &quot;ip&quot;: [       &quot;geoip:telegram&quot;     ],     &quot;domain&quot;: [       &quot;geosite:gfw&quot;    ]  &#125;,  &#123;    &quot;port&quot;: &quot;0-65535&quot;,    &quot;outboundTag&quot;: &quot;direct&quot;  &#125;]

3. 全局代理：
[  &#123;    &quot;outboundTag&quot;: &quot;proxy&quot;,    &quot;port&quot;: &quot;0-65535&quot;,  &#125;]

4. “解决Mirosoft Store等UWP软件无法访问”：点击跳转
延伸阅读：什么是路由规则？是将入站数据（用户请求）按需求由不同的出站连接发出，以达到按需求进行代理的目的。
常见用法是分流国内外流量，V2Ray 可以通过内部机制判断不同地区的流量，然后将它们发送到不同的出站代理。
简单地说，先设置相关路由规则， 经过 geo文件来判断目标是否命中相关路由规则，从而决定是否走代理出站(局域网也已绕过)。 

怎么在v2rayN 客户端自定义DNS？

参考链接4.12 最新 v2rayN windows 进阶版使用教程 | 附PAC模式路由规则 | 多个自定义路由规则
V2Ray 路由规则文件加强版  
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>postman 常用配置</title>
    <url>/posts/51f0c4fa/</url>
    <content><![CDATA[参考链接
导入 chrome 请求1. 选择 Copy as cURL（bash）

2. 导入 postmanpostman 左上角点击 Import，选择 Paste Raw Text，去除 –compressed 即可成功导入。


Postman Interceptor 使用1. chrome 启用 Interceptor

2. 设置拦截域名

3. postman 启用拦截

即可即时拦截捕获所有异步请求。
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Intellij IDEA maven 配置</title>
    <url>/posts/a3c558a3/</url>
    <content><![CDATA[idea配置maven依赖优先从指定本地仓库获取在设置中搜索 Runner ,在VM Option中设置参数 -DarchetypeCatalog=internal
-DarchetypeCatalog=internal



maven离线模式及设置下载maven依赖通过idea创建maven项目，maven插件会自动将maven依赖下载到本地仓库。
复制本地仓库先要找到maven的本地仓库，可以通过 file-&gt;settings-&gt;maven 流程查看到maven本地仓库的位置，然后直接复制，粘贴到生产环境下。
修改maven配置这里指修改生产环境（即不能联网）下的maven的settings.xml文件
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;          xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;          xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; 	&lt;!-- 这个就是第二步，maven本地仓库粘贴在生产环境下的位置 --&gt;	&lt;localRepository&gt;D:\Apache\apache-maven-3.6.3&lt;/localRepository&gt;	  &lt;mirrors&gt;	 &lt;mirror&gt;            &lt;id&gt;central&lt;/id&gt;            &lt;name&gt;central&lt;/name&gt;					&lt;!-- 这个就是第二步，maven本地仓库粘贴在生产环境下的位置 --&gt;            &lt;url&gt;file://D:\Apache\apache-maven-3.6.3&lt;/url&gt;            &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;        &lt;/mirror&gt;  &lt;/mirrors&gt;&lt;/settings&gt;

步骤四，设置idea通过 file-&gt;settings-&gt;maven 流程，勾选 work offline 选项，并填写上 maven 本地仓库和修改过的 settings.xml 的位置                      
]]></content>
      <categories>
        <category>研发工具</category>
        <category>Intellij IDEA</category>
      </categories>
      <tags>
        <tag>intellij idea</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title>Intellij IDEA 常用插件</title>
    <url>/posts/be77417b/</url>
    <content><![CDATA[目录列表已使用
Key Promoter X
Alibaba Java Coding GuideLines
CamelCase
Convert YAML and Properties File
GenerateAllSetter
GenerateSerialVersionUID
Git Commit Message Helper
Grep Console
GsonFormatPlus
Json Parser
HighlightBracketPair
Java Bean to Json
JRebel and XRebel
JRebel mybatisPlus extension
MybatisPlus
Kafkalytic
Maven Helper
RestfulToolkit-fix
SequenceDiagram
Translation
Convert YAML and Properties File

未使用
String Manipulation
MapStruct support
arthas idea
Statistic
SonarLint
Jump To Line
Rainbow Brackets
jclasslib：字节码查看神器

参考链接看了我常用的IDEA插件，同事也开始悄悄安装了…
IDEA小技巧：Debug拖动跳转任意行
]]></content>
      <categories>
        <category>研发工具</category>
        <category>Intellij IDEA</category>
      </categories>
      <tags>
        <tag>intellij idea</tag>
      </tags>
  </entry>
  <entry>
    <title>Intellij IDEA 常用配置</title>
    <url>/posts/4a9b2d4f/</url>
    <content><![CDATA[目录右键增加 Open Folder as IntelliJ IDEA Project1、先win+R打开运行窗口，输入regedit，进入到注册表编辑器中，然后进入到下面的目录 计算机\HKEY_CLASSES_ROOT\Directory\Background\shell
新建项，取名为 Intellij IDEA，如下图所示：

修改 Intellij IDEA 项下的默认的数值数据为 Open Folder as IntelliJ IDEA Project

新建一个字符串值，名字为 Icon，数值为 idea64.exe 所在目录的绝对路径




然后在左边的 Intellij IDEA 的项上右击，选择新建 &gt; 项,项名为 command，修改默认的数值数据为 “idea64.exe所在目录的绝对路径” + “%V”，如下图所示：


然后重启电脑，就可以看到下面的效果了，如下图所示：


关闭自动弹出 Documentation取消勾选即可。


代码行宽度超出限制时不自动换行打开 Settings &gt; Editor &gt; Code Style &gt; Java
设置 Hard Wrap at 的值，默认为120，或者将 Wrap on typing 设置为 false，如下所示：


IntelliJ IDEA 修改配置文件位置找到 idea.properties 文件的位置，这里找下的位置如下：
C:\Program Files\JetBrains\IntelliJ IDEA 2021.1.3\bin\idea.properties
修改配置文件位置：

注意：不要修改为Idea的安装目录，因为这样会导致自动更新失败。错误示例： 
idea.config.path=C:\Program Files\JetBrains\IntelliJ IDEA 2021.1.3\configidea.system.path=C:\Program Files\JetBrains\IntelliJ IDEA 2021.1.3\system

修改前：
# idea.config.path=$&#123;user.home&#125;/.IntelliJIdea/config# idea.system.path=$&#123;user.home&#125;/.IntelliJIdea/system

修改后：
idea.config.path=D:\IntelliJIdea\configidea.system.path=D:\IntelliJIdea\system


注意：Idea启动时，依旧会从默认位置中的 idea64.exe.vmoptions 中读配置。其他配置会从上面修改后的指定的路径中去读。所以：默认的路径下要保留 idea64.exe.vmoptions，其他可以删除。

最后重启 idea 即可生效。
IntelliJ IDEA 修改内存大小找到 idea64.exe.vmoptions 的位置，默认是位于 C:\Program Files\JetBrains\IntelliJ IDEA 2021.1.3\bin\ 目录下，如果修改配置文件的位置，则在 D:\IntelliJIdea\config 目录下会有一份额外的同名配置文件，配置文件主要调整前三个参数，整体参数配置参考如下：
-Xms1024m # 最小内存-Xmx4096m # 最大内存-XX:ReservedCodeCacheSize=512m # 预留代码缓存的大小-XX:+UseG1GC-XX:SoftRefLRUPolicyMSPerMB=50-XX:CICompilerCount=2-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow-ea-Dsun.io.useCanonCaches=false-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot;-Djdk.attach.allowAttachSelf=true-Djdk.module.illegalAccess.silent=true-Dkotlinx.coroutines.debug=off

控制内存使用显示状态的打开方式参考下图：


最后在 idea 中打开 Edit Custom VM Options 配置：


配置内容和上面的 idea64.exe.vmoptions 保持一致，重启 idea 即可生效。
编译 spring-configuration-metadata.json 文件在idea设置中搜索 Annotation Processors，接下来勾住 Enable annonation processing 就完成了。
我们可以在编译后的文件中看到自动生成的 spring-configuration-metadata.json，配置效果如下：




IDEA 设置 SQL 格式化(关键字大写)设置 settsings(Ctrl+Alt+S) –&gt; Editor –&gt; Code Style –&gt; SQL 将 keywords 设置为大写(To upper)
如下图所示：


设置作者注释File and Code Templates 配置
点击 File -&gt; Settings -&gt; Editor -&gt; File And Code Templates，在右侧的 File Header 中填入以下信息：
/** * @description: $&#123;NAME&#125; * @author: yahya * @email: yahya@sf-express.com * @create: $&#123;YEAR&#125;/$&#123;MONTH&#125;/$&#123;DAY&#125; $&#123;HOUR&#125;:$&#123;MINUTE&#125; */

Live Templates 配置
点击 File -&gt; Settings -&gt; Editor -&gt; Live Templates，点击右侧的 + 号按钮新建一个 Template Group，命名为 Description。
然后在名为 Description 的 Template Group 上面在新建一个 Live Template，内容填充如下：
/** * @description: $description$ * @author: $user$ * @email: $email$ * @create: $date$ $time$ */

整体配置效果图如下所示：


然后再点击 Edit Variables 按钮，为每个变量设置值，效果如下：


常用内置变量定义如下：

${PACKAGE_NAME} - 将在其中创建新类或接口的目标包的名称
${PROJECT_NAME} - 当前项目的名称
${FILE_NAME} - 将要创建的文件的名称
${NAME} - 您在创建文件的过程中，在 “新建文件” 对话框中指定的新文件的名称
${USER} - 当前用户的登录名
${DATE} - 当前系统日期
${TIME} - 当前系统时间
${YEAR} - 本年度
${MONTH} - 本月
${DAY} - 当月的当前日期
${HOUR} - 当前时间
${MINUTE} - 当前分钟。
${PRODUCT_NAME} - 将在其中创建文件的 IDE 的名称。
${MONTH_NAME_SHORT} - 月份名称的前3个字母。示例：1月，2月等。
${MONTH_NAME_FULL} - 一个月的全名。示例：1月，2月等

去除 Usage 提示点击 Settings -&gt; Editor -&gt; Inlay Hints，在 Code vision 栏取消 Usages 的勾选项，如下图所示：


取消 indexingFile -&gt; Settings 中直接搜索 index


然后旁边两个选项都选择 Ask before download
关闭页面显示的浏览器图标依次点击 File -&gt; Settings -&gt; Tools -&gt; Web Browsers and Preview，将多余的勾选项全部取消勾选，最终效果如下：

]]></content>
      <categories>
        <category>研发工具</category>
        <category>Intellij IDEA</category>
      </categories>
      <tags>
        <tag>intellij idea</tag>
      </tags>
  </entry>
  <entry>
    <title>翻墙杂项</title>
    <url>/posts/126dc918/</url>
    <content><![CDATA[目录一级域名yahyav2rayssr.top
namesilo


用户名
邮箱
密码



yahya-yaoyuming
&#x36;&#55;&#50;&#53;&#53;&#52;&#55;&#56;&#x34;&#64;&#113;&#x71;&#46;&#99;&#111;&#x6d;
Yao88219620ko!


cloudflare


邮箱
密码



&#x36;&#55;&#x32;&#x35;&#x35;&#52;&#x37;&#56;&#x34;&#x40;&#113;&#x71;&#46;&#x63;&#111;&#x6d;
Yao88219620ko!


端口说明文档参考链接：https://developers.cloudflare.com/fundamentals/get-started/reference/network-ports/
已开放HTTPS端口有：443, 2053, 2083, 2087, 2096, 8443
全局API KEY:
66f6f58b393232b878e6a855ab40944431724

hosteONS
VPS 服务器信息。
IP付款链接： https://my.hosteons.com/viewinvoice.php?id=107772&amp;paymentsuccess=true




邮箱
密码



&#x36;&#x37;&#x32;&#53;&#x35;&#x34;&#55;&#x38;&#x34;&#x40;&#113;&#x71;&#46;&#99;&#111;&#x6d;
Yao88219620ko!


x-ui 面板信息


访问地址
用户名
密码



https://194.33.38.170:8443/ 或者 https://vless.yahyav2rayssr.top:8443
admin
7613302589


x-ui 安装
这里采用 centos7-minin 系统。

系统安装证书前置命令：
yum -y install crontabsyum -y install openssl openssl-develcurl https://get.acme.sh | shyum update -y          # Debian/Ubuntu 命令yum install -y curl socat    #Debian/Ubuntu 命令

x-ui 面板安装：
bash &lt;(curl -Ls https://raw.githubusercontent.com/vaxilu/x-ui/master/install.sh) 

]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Intellij IDEA 常见错误</title>
    <url>/posts/4211b3cd/</url>
    <content><![CDATA[目录Command line is too long报错内容:
Error running ‘ServiceStarter’: Command line is too long. Shorten command line for ServiceStarter or also for Application default configuration.
解法:
修改项目下 .idea\workspace.xml，找到标签 &lt;component name=&quot;PropertiesComponent&quot;&gt; ， 在标签里加一行 &lt;property name=&quot;dynamic.classpath&quot; value=&quot;true&quot; /&gt;
中文乱码以及(SpringBoot)yml配置文件中文乱码打开设置并搜索File Encodings,全部改成UTF-8，示图如下：


maven 控制台中文乱码打开 File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Build Tools -&gt; Maven -&gt; Runner 菜单，在 VM Options 选项框里添加以下参数（无需重启）：
-Dfile.encoding=GB2312

如图所示：


]]></content>
      <categories>
        <category>研发工具</category>
        <category>Intellij IDEA</category>
      </categories>
      <tags>
        <tag>intell</tag>
      </tags>
  </entry>
  <entry>
    <title>Charles 抓包教程</title>
    <url>/posts/9ad99481/</url>
    <content><![CDATA[目录内容清单
Charles 的简介
安装 Charles
Charles 初始化设置
过滤网络请求
截取HTTP&#x2F;HTTPS数据
模拟弱网环境
修改网络请求
修改服务器返回内容
服务器压力测试
反向代理
解决与翻墙软件的冲突

Charles 的简介Charles 是目前最主流的网络调试工具（Charles、Fiddler、Wireshark…）之一，对于一个开发者来说与网络打交道是日常需求，因此很多时候我们需要调试参数、返回的数据结构、查看网络请求的各种头信息、协议、响应时间等等。所以了解  Charles 并使用它
Charles 通过将自己设置为系统的网络访问代理服务器，这样所有的网络请求都会通过它，从而实现了网路请求的截获和分析。
Chareles 不仅可以分析电脑本机的网络请求（HTTP 和 HTTPS），还可以分析移动端设备的网络请求。
Charles 是收费软件，作者开发出这样一个方便开发者使用的伟大工具，我们鼓励使用正版软件，但是对于一些囊中羞涩或者学生来说，有破解版的更好，别担心，这些我都准备好了，下一个 section 会讲解如何下载安装。
安装 Charles
方式1： Charles 官网地址，根据你的电脑操作系统选择合适的下载方式。此时下载下来的是需要收费的，不差钱的同学当然可以直接购买。购买链接
方式2:按照方式1的方式去官网下载，然后下载相应 **JAR包**。这里以 MAC 为例，打 Finder，选择应用程序，选中 Charles，右击并选择“显示包内容”，看到 Contents 目录，点击进去选择 Java 文件夹，将下载下来的 JAR包 拖进去替换。至此，完成了 Charles 的破解。

Charles 初始化设置Charles 的工作原理是将自身设置为系统的代理服务器来捕获所有的网络请求。所以使用 Charles ，我们必须设置 Charles 为系统的代理服务器。
打开 Charles，当第一次启动的时候如果没有购买或者没有破解，会有倒计时，之后会看到软件的主界面，然后会请求你赋予它为系统代理的权限。点击授权会让你输入当前系统用户的密码。当然你也可以忽略或者拒绝该请求，然后等想要抓包的时候将它设置为系统的代理服务器。步骤：选择菜单中的“Proxy” -&gt; “Mac OS X Proxy”。如下图：




之后你的电脑上的任何网络请求都可以在 Charles 的请求面板中看到
看看 Charles 的主界面







图上红色圈1:这里代表所有网络请求的展示方式。分别名为 “Structure” 和 “Sequence”。
Structure 将所有的网络请求按照域名划分并展示
Sequence 将所有的网络请求按照时间排序并展示


图上红色圈2：一些的网络请求设置比如 HTTPS 以及端口等信息都在这个菜单栏设置
图上红色圈3：证书设置都在这里进行

过滤网络请求由于 Charles 可以将电脑或者设置过的手机的所有网络请求捕获到，而且我们分析网络传输应该是针对某个特定的网络下的抓包分析，为了清楚明显地看到我们感兴趣的网络请求通常会用到 Charles 的“过滤网络请求的功能”。

方法1:在 Charles 主面板的左侧所有网络请求的下方可以看到看到一个 ”Filter“ 输入栏，在这里你可以输入关键词来筛选出自己感兴趣的网络请求。比如我想分析的网络请求来自于”www.baidu.com“ 下，你可以在下面输入”baidu”即可。




方法2:在 Charles 菜单栏的顶部会看到 “Proxy” 的选项，点击菜单栏选择 “Proxy” -&gt; “Recording Settings” 。选择 “include”。看到面板上面有一个 “Add” 按钮，点击后在弹出的面板里面设置好我们需要分析的网络请求的协议、主机名、端口、路径、参数，当然你也可以只设置一些主要的信息，比如协议和主机名的组合。




方法3:一般打开 Charles 并设置好配置信息后（比如电脑本机或者设置过代理的手机）所有的网络请求都将在 Charles 的面板上显示，同时我们感兴趣的网络请求如果也在面板上显示的话，“Structure”模式下可以选中需要分析的网络请求，鼠标右击选择“Focus”。“Sequence”模式下可以在面板的网络请求显示面板的右下角看到一个Focus按钮，点击勾选后 Charles 只会显示你感兴趣的网络请求。










截取HTTP&#x2F;HTTPS数据截取 HTTP 请求Charles 的主要目的是抓取捕获网络请求，这里以 iPhone 的抓包为例讲解。
Charles 的设置要截获 iPhone 的网络请求就需要为 Charles 开启代理功能。在菜单栏选择“Proxy” -&gt;”Proxy Settings”。填写代理的端口号并将“Enable transparent HTTP proxying”勾选上。




iPhone 上的设置在电脑“系统偏好设置”中心打开网络查看本机 IP 地址，打开手机“设置”-&gt;“无线局域网”，进入当前使用的网络，点击进入当前 WIFI 的详情页（可以看到当前 WIFI 的基本信息，包括子网掩码、端口、IP地址、路由器），在最下角可以看到“DNS”和“HTTP代理”2个section。我们点击“配置代理”，设置 HTTP 代理选中“手动”。服务器处填写电脑ip地址，端口写8888。设置好后，我们打开 iPhone 上的任意需要网络请求的应用，就可以看到 Charles 弹出请求的确认菜单，单击”Allow”按钮，即可完成设置。




截取 HTTPS 请求如果你需要捕获 HTTPS 协议的网络请求，那么则需要安装 Charles 的 CA 证书。步骤如下；

首先需要在 MAC 上安装证书。点击 Charles 顶部的菜单栏，选择 **“Help” -&gt; “SSL Proxying” -&gt; “Install Charles Root Certificate”**。




在 keychain 处将新安装的证书设置为永久信任




即使安装了 CA 证书，Charles 默认是不捕获 HTTPS 协议的网络请求，所以我们需要对某个主机下的网络请求抓包分析的话，选中该网络请求右击选中 “SSL Proxying Enabled”。这样就可以看到我们感兴趣的HTTPS 网络请求了。


如果你需要捕获移动设备的 HTTPS 网络请求，则需要在移动设备上安装证书并作简单的设置

选择 Charles 顶部菜单栏选择 **“Help” -&gt;”Install Charles Root Certificate on a Mobile Device or Remote Browser”**。然后就可以看到 Charles 弹出的安装说明了。




在手机设置好 Charles 代理的情况下，在手机浏览器输入 “chls.pro&#x2F;ssl”。安装提示下载好CA证书。

验证刚刚安装的 CA证书




iPhone 打开设置 -&gt; 通用 -&gt; 关于本机 -&gt; 证书信任设置 -&gt; 开启开关




在 Charles 菜单栏 Proxy -&gt; SSL Proxying Setting -&gt; 点击 Add 按钮 -&gt; 在弹出的对对话框设置需要监听的 HTTPS 域（*:代表通配符）




设置完毕，尽情抓取你想要的 HTTPS 网络请求吧。




模拟弱网环境在平时开发的时候我们经常需要模拟弱网环境，并作弱网环境下的适配工作。Charles 为我们提供了这个服务。
在 Charles 菜单栏选择 **“Proxy” -&gt; “Throttle Settings”**。在弹出的面板上设置网络请求的参数（上行，下行带宽、利用率、可靠性等等信息）。如下图所示。




如果你想对指定主机进行弱网环境下的测试，可以点击上图的“Add”按钮，在弹出的面板上设置协议、主机、端口来对指定的主机进行弱网设置。




修改网络请求对于捕获的网络请求，我们经常需要修改网络请求的cookie、Headers、Url等信息。Charles 提供了对网络请求的编辑和重发功能。只需要选中需要修改编辑的网络请求，在对应的右上角看到有一个“钢笔”的按钮，点击后就可以对选中的网络请求进行编辑了，编辑好后可以在右下角看到 Execute 按钮。这样我们编辑后的网络请求就可以被执行了。




修改服务器返回内容很多时候为了方便调试代码，我们会有这种需求，修改接口返回的数据节点或者内容、甚至是状态码。比如数据为空、数据异常、请求失败、多页数据的情况。 Charles 为我们提供了超实用的功能，“Map（Map Local、Map Remote）功能”、Rewrite功能、Breakpoints功能 ，都可以实现修改服务端返回数据的功能。但是有区别和适用场景：

Map 功能适合长期地将某一请求重定向到另一个指定的网络地址或者本地 JSON 文件
Rewrite 功能适合对网络请求进行一些正则替换
Breakpoints 功能适合对网络请求进行一些临时性的修改（类似于我们开发的断点作用）

Map 功能Map 功能分为 Map Local（将某个网络请求重定向到本地 JSON 文件） 和 Map Remote 功能（将网络请求重定向到另一个网络接口）。
在 Charles 菜单栏选择 “Tools” -&gt; “Map Remote” 或 “Map Local” 即可进入相应的功能模块。
Map Remote 功能适合于切换线上到本地、测试服务到正式服务的场景。比如下图从正式服务切换到测试服务




Map Local 功能我们需要填写重定向的原地址信息和本地目标文件。我们可以先将某个接口的响应内容保存下来（选择对应的网络请求，右击点击 Save Response ）成为 data.json 文件。然后我们编辑里面的 status 、message、data 等信息为我们想要的目标映射文件。




如下所示，我将一个网络请求的内容映射到我本地的一个 JSON 文件。之后这个请求的内容都从网络变为返回我本地的数据了。




Map Local 可能会存在一个小缺陷，其返回的 HTTP Response Header 与正常的网络请求不一样，如果程序设置了校验 Header 信息，此时 Map Local 就会失败，解决办法是同时使用 Rewrite功能将相关的HTTP 头部信息 rewrite 成我们需要的信息
Rewrite 功能Rewrite 适合对某个网络请求进行正则替换，以达到修改结果的目的。
假如我的 App 的界面上的显示的功能模块及其点击事件是根据接口来完成的，我想实现替换功能模块的名称的目的。步骤：点击顶部菜单栏的**“Tools” -&gt; “Rewrite”**。在弹出的面板上勾选 “Enable Rewrite”。点击左下角的 Add按钮，在右上角的 Name：处写好本次配置的名称（如果有多个 Rewrite，为了后期容易区分）。

可以针对特定的网络请求进行 Rewrite。可以点击右上角 Location 面板下面的 Add按钮。在弹出的面板上设置网络请求配置信息。注意此时需要同时设置 Protocol、Port、Host、Path信息（我测试加了 Protocol、Host、Port这3个是无效的）






然后对指定的 Type 和 Action 进行 Rewrite。
Type 主要有 Add Header、Modify Header、Remove Header、Host、Path等等。
Where 可以选择 Request 和 Response。指的是下面的修改是针对 Request 还是 Response




完成设置后点击 Apply 按钮，即可生效。下次继续请求该网络，返回的内容就是我们刚刚设置的内容。比如当前的“政策法规”要变成“哈哈哈，我是假的政策法规”。这时候就可以使用 Rewrite 功能


Breakpoints 功能Breakpoints 相比于其他几个修改网络请求的特点是只是针对当前的网络请求，Breakpoints 只存在于设置过的当前的网络请求，Charles 关闭后下次打开 Breakpoints 消失了。想要修改网络请求 Breakpoints 步骤最简单，跟我们调试工具里面设置的断点一样方便。
对于我们设置了 Breakpoints 的网络请求， Charles 会在下次继续访问该请求的时候停止掉，就跟 debug 一样。此时我们可以 Edit Request，修改过 Request 之后点击右下角的 Execute 按钮。然后等到服务端返回的时候继续是断点状态，此时可以 Edit Response。步骤： 选中某个网络请求 -&gt; 右击 -&gt; 点击“Breakpoints”。
如下图：对该接口设置了 Breakpoints。请求网络后 Edit Response，点击 execute 后服务端返回的结果就是我们编辑的内容了。








服务器压力测试我们可以使用 Charles 的 Repeat 功能地对服务器进行并发访问进行压力测试。步骤：选中某个网络请求 -&gt; 右击 -&gt; Repeat Advanced -&gt; 在弹出的面板里面设置总共的迭代次数（Iterations）、并发数（Concurrency） -&gt; 点击“OK” 。开始执行可以看到以设置的并发数的规模，进行总共达设置的总共迭代次数的访问。（专业的压力测试工具：Load Runner）




反向代理Charles 的反向代理功能允许我们将本地指定端口的请求映射到远程的另一个端口上。设置：点击顶部菜单栏 Proxy -&gt; 点击 Reverse Proxies。
如下所示，我将本地的 8080 端口映射到远程的 80 端口上，点击 OK 生效后，当我继续访问本地的 80 端口，实际返回的就是远程 80 端口的提供的内容了。




解决与翻墙软件的冲突Charles 的工作原理是把自己设置为系统的代理服务器，但是我们开发者经常会利用 VPN 翻墙访问谷歌查找资料（这些翻墙软件的工作原理也是把自己设置成为系统的代理服务器），为了2者和平共处。我们可以在 Charles 的 External Proxy Settings 中将翻墙的代理端口等信息填写。同时我们需要关闭翻墙软件的自动设置，更改为“手动模式”。（使其不主动修改系统代理）
总结Charles 功能强大、界面简洁，读完这篇文章并做出练习，相信你能很快掌握它，“工欲善其事，必先利其器” ，掌握了它，相信可以为你大大提高开发中调试网络的效率。
]]></content>
      <categories>
        <category>研发工具</category>
        <category>抓包</category>
      </categories>
      <tags>
        <tag>抓包</tag>
        <tag>charles</tag>
      </tags>
  </entry>
  <entry>
    <title>Visual Studio Code 常用配置</title>
    <url>/posts/6f59c50b/</url>
    <content><![CDATA[显示当前文件完整路径信息
菜单栏：“文件”→“首选项”→“设置”，进入用户配置界面；
在软件默认的配置界面搜索关键字 “window.title”，将这一行配置复制到右边的用户配置界面中，并将 “activeEditorShort” 修改为 “activeEditorLong”；
保存后，再编辑文件时，软件窗口的标题栏上就可以看到当前文件的完整路径了。

]]></content>
      <categories>
        <category>研发工具</category>
        <category>Visual Studio Code</category>
      </categories>
      <tags>
        <tag>intellij idea</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 指令大全</title>
    <url>/posts/7c42c21b/</url>
    <content><![CDATA[JVM 指令大全栈和局部变量操作将常量压入栈的指令
aconst_null 将null对象引用压入栈

iconst_m1 将int类型常量-1压入栈

iconst_0 将int类型常量0压入栈

iconst_1 将int类型常量1压入栈

iconst_2 将int类型常量2压入栈

iconst_3 将int类型常量3压入栈

iconst_4 将int类型常量4压入栈

iconst_5 将int类型常量5压入栈

lconst_0 将long类型常量0压入栈

lconst_1 将long类型常量1压入栈

fconst_0 将float类型常量0压入栈

fconst_1 将float类型常量1压入栈

dconst_0 将double类型常量0压入栈

dconst_1 将double类型常量1压入栈 

bipush 将一个8位带符号整数压入栈

sipush 将16位带符号整数压入栈

ldc 把常量池中的项压入栈

ldc_w 把常量池中的项压入栈（使用宽索引）

ldc2_w 把常量池中long类型或者double类型的项压入栈（使用宽索引）


从栈中的局部变量中装载值的指令
iload 从局部变量中装载int类型值

lload 从局部变量中装载long类型值

fload 从局部变量中装载float类型值

dload 从局部变量中装载double类型值

aload 从局部变量中装载引用类型值（refernce）

iload_0 从局部变量0中装载int类型值

iload_1 从局部变量1中装载int类型值

iload_2 从局部变量2中装载int类型值

iload_3 从局部变量3中装载int类型值

lload_0 从局部变量0中装载long类型值

lload_1 从局部变量1中装载long类型值

lload_2 从局部变量2中装载long类型值

lload_3 从局部变量3中装载long类型值

fload_0 从局部变量0中装载float类型值

fload_1 从局部变量1中装载float类型值

fload_2 从局部变量2中装载float类型值

fload_3 从局部变量3中装载float类型值

dload_0 从局部变量0中装载double类型值

dload_1 从局部变量1中装载double类型值

dload_2 从局部变量2中装载double类型值

dload_3 从局部变量3中装载double类型值

aload_0 从局部变量0中装载引用类型值

aload_1 从局部变量1中装载引用类型值

aload_2 从局部变量2中装载引用类型值

aload_3 从局部变量3中装载引用类型值

iaload 从数组中装载int类型值

laload 从数组中装载long类型值

faload 从数组中装载float类型值

daload 从数组中装载double类型值

aaload 从数组中装载引用类型值

baload 从数组中装载byte类型或boolean类型值

caload 从数组中装载char类型值

saload 从数组中装载short类型值


将栈中的值存入局部变量的指令
istore 将int类型值存入局部变量

lstore 将long类型值存入局部变量

fstore 将float类型值存入局部变量

dstore 将double类型值存入局部变量

astore 将将引用类型或returnAddress类型值存入局部变量

istore_0 将int类型值存入局部变量0

istore_1 将int类型值存入局部变量1

istore_2 将int类型值存入局部变量2

istore_3 将int类型值存入局部变量3

lstore_0 将long类型值存入局部变量0

lstore_1 将long类型值存入局部变量1

lstore_2 将long类型值存入局部变量2

lstore_3 将long类型值存入局部变量3

fstore_0 将float类型值存入局部变量0

fstore_1 将float类型值存入局部变量1

fstore_2 将float类型值存入局部变量2

fstore_3 将float类型值存入局部变量3

dstore_0 将double类型值存入局部变量0

dstore_1 将double类型值存入局部变量1

dstore_2 将double类型值存入局部变量2

dstore_3 将double类型值存入局部变量3

astore_0 将引用类型或returnAddress类型值存入局部变量0

astore_1 将引用类型或returnAddress类型值存入局部变量1

astore_2 将引用类型或returnAddress类型值存入局部变量2

astore_3 将引用类型或returnAddress类型值存入局部变量3

iastore 将int类型值存入数组中

lastore 将long类型值存入数组中

fastore 将float类型值存入数组中

dastore 将double类型值存入数组中

aastore 将引用类型值存入数组中

bastore 将byte类型或者boolean类型值存入数组中

castore 将char类型值存入数组中

sastore 将short类型值存入数组中


wide指令wide 使用附加字节扩展局部变量索引
通用(无类型）栈操作

nop 不做任何操作

pop 弹出栈顶端一个字长的内容

pop2 弹出栈顶端两个字长的内容

dup 复制栈顶部一个字长内容

dup_x1 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的两个字长的内容压入栈

dup_x2 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈

dup2 复制栈顶部两个字长内容

dup2_x1 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈

dup2_x2 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的四个字长的内容压入栈

swap 交换栈顶部两个字长内容


类型转换
i2l 把int类型的数据转化为long类型

i2f 把int类型的数据转化为float类型

i2d 把int类型的数据转化为double类型 

l2i 把long类型的数据转化为int类型

l2f 把long类型的数据转化为float类型

l2d 把long类型的数据转化为double类型 

f2i 把float类的数据转化为int类型

f2l 把float类型的数据转化为long类型

f2d 把float类型的数据转化为double类型

d2i 把double类型的数据转化为int类型

d2l 把double类型的数据转化为long类型

d2f 把double类型的数据转化为float类型

i2b 把int类型的数据转化为byte类型

i2c 把int类型的数据转化为char类型

i2s 把int类型的数据转化为short类型


整数运算
iadd 执行int类型的加法

ladd 执行long类型的加法

isub 执行int类型的减法

lsub 执行long类型的减法

imul 执行int类型的乘法

lmul 执行long类型的乘法

idiv 执行int类型的除法

ldiv 执行long类型的除法

irem 计算int类型除法的余数

lrem 计算long类型除法的余数

ineg 对一个int类型值进行取反操作

lneg 对一个long类型值进行取反操作

iinc 把一个常量值加到一个int类型的局部变量上


逻辑运算移位操作
ishl 执行int类型的向左移位操作

lshl 执行long类型的向左移位操作

ishr 执行int类型的向右移位操作 

lshr 执行long类型的向右移位操作

iushr 执行int类型的向右逻辑移位操作 

lushr 执行long类型的向右逻辑移位操作


按位布尔运算
iand 对int类型值进行“逻辑与”操作

land 对long类型值进行“逻辑与”操作

ior 对int类型值进行“逻辑或”操作

lor 对long类型值进行“逻辑或”操作

ixor 对int类型值进行“逻辑异或”操作

lxor 对long类型值进行“逻辑异或”操作


浮点运算
fadd 执行float类型的加法 

dadd 执行double类型的加法

fsub 执行float类型的减法

dsub 执行double类型的减法 

fmul 执行float类型的乘法

dmul 执行double类型的乘法

fdiv 执行float类型的除法 

ddiv 执行double类型的除法 

frem 计算float类型除法的余数

drem 计算double类型除法的余数 

fneg 将一个float类型的数值取反 

dneg 将一个double类型的数值取反


对象和数组对象操作指令
new 创建一个新对象

checkcast 确定对象为所给定的类型

getfield 从对象中获取字段

putfield 设置对象中字段的值

getstatic 从类中获取静态字段

putstatic 设置类中静态字段的值

instanceof 判断对象是否为给定的类型


数组操作指令
newarray 分配数据成员类型为基本上数据类型的新数组

anewarray 分配数据成员类型为引用类型的新数组

arraylength 获取数组长度

multianewarray 分配新的多维数组


控制流条件分支指令
ifeq 如果等于0，则跳转

ifne 如果不等于0，则跳转

iflt 如果小于0，则跳转

ifge 如果大于等于0，则跳转

ifgt 如果大于0，则跳转

ifle 如果小于等于0，则跳转

if_icmpcq 如果两个int值相等，则跳转 

if_icmpne 如果两个int类型值不相等，则跳转

if_icmplt 如果一个int类型值小于另外一个int类型值，则跳转

if_icmpge 如果一个int类型值大于或者等于另外一个int类型值，则跳转

if_icmpgt 如果一个int类型值大于另外一个int类型值，则跳转

if_icmple 如果一个int类型值小于或者等于另外一个int类型值，则跳转 

ifnull 如果等于null，则跳转

ifnonnull 如果不等于null，则跳转

if_acmpeq 如果两个对象引用相等，则跳转 

if_acmpnc 如果两个对象引用不相等，则跳转


比较指令
lcmp 比较long类型值

fcmpl 比较float类型值（当遇到NaN时，返回-1）

fcmpg 比较float类型值（当遇到NaN时，返回1）

dcmpl 比较double类型值（当遇到NaN时，返回-1）

dcmpg 比较double类型值（当遇到NaN时，返回1）


无条件转移指令
goto 无条件跳转

goto_w 无条件跳转（宽索引）


表跳转指令
tableswitch 通过索引访问跳转表，并跳转

lookupswitch 通过键值匹配访问跳转表，并执行跳转操作


异常
athrow 抛出异常或错误 

finally子句

jsr 跳转到子例程

jsr_w 跳转到子例程（宽索引）

rct 从子例程返回


方法调用与返回方法调用指令
invokcvirtual 运行时按照对象的类来调用实例方法

invokespecial 根据编译时类型来调用实例方法

invokestatic 调用类（静态）方法

invokcinterface 调用接口方法


方法返回指令
ireturn 从方法中返回int类型的数据

lreturn 从方法中返回long类型的数据

freturn 从方法中返回float类型的数据 

dreturn 从方法中返回double类型的数据 

areturn 从方法中返回引用类型的数据

return 从方法中返回，返回值为void


线程同步
montiorenter 进入并获取对象监视器

monitorexit 释放并退出对象监视器


JVM指令助记符
变量到操作数栈：iload,iload_,lload,lload_,fload,fload_,dload,dload_,aload,aload_

操作数栈到变量：istore,istore_,lstore,lstore_,fstore,fstore_,dstore,dstor_,astore,astore_

常数到操作数栈：bipush,sipush,ldc,ldc_w,ldc2_w,aconst_null,iconst_ml,iconst_,lconst_,fconst_,dconst_ 

加：iadd,ladd,fadd,dadd

减：isub,lsub,fsub,dsub

乘：imul,lmul,fmul,dmul

除：idiv,ldiv,fdiv,ddiv

余数：irem,lrem,frem,drem 

取负：ineg,lneg,fneg,dneg

移位：ishl,lshr,iushr,lshl,lshr,lushr

按位或：ior,lor

按位与：iand,land 

按位异或：ixor,lxor

类型转换：i2l,i2f,i2d,l2f,l2d,f2d(放宽数值转换) 

i2b,i2c,i2s,l2i,f2i,f2l,d2i,d2l,d2f(缩窄数值转换)

创建类实便：new

创建新数组：newarray,anewarray,multianwarray 

访问类的域和类实例域：getfield,putfield,getstatic,putstatic 

把数据装载到操作数栈：baload,caload,saload,iaload,laload,faload,daload,aaload

从操作数栈存存储到数组：bastore,castore,sastore,iastore,lastore,fastore,dastore,aastore

获取数组长度：arraylength

检相类实例或数组属性：instanceof,checkcast 

操作数栈管理：pop,pop2,dup,dup2,dup_xl,dup2_xl,dup_x2,dup2_x2,swap

有条件转移：ifeq,iflt,ifle,ifne,ifgt,ifge,ifnull,ifnonnull,if_icmpeq,if_icmpene,if_icmplt,if_icmpgt,if_icmple,if_icmpge,if_acmpeq,if_acmpne,lcmp,fcmpl,fcmpg,dcmpl,dcmpg 

复合条件转移：tableswitch,lookupswitch

无条件转移：goto,goto_w,jsr,jsr_w,ret

调度对象的实便方法：invokevirtual

调用由接口实现的方法：invokeinterface

调用需要特殊处理的实例方法：invokespecial

调用命名类中的静态方法：invokestatic

方法返回：ireturn,lreturn,freturn,dreturn,areturn,return

异常：athrow

finally关键字的实现使用：jsr,jsr_w,ret


]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 杂项</title>
    <url>/posts/1b362162/</url>
    <content><![CDATA[目录类加载过程

JVM执行引擎

类加载器种类

类加载机制]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 垃圾收集器</title>
    <url>/posts/9e0bfe2e/</url>
    <content><![CDATA[垃圾收集器基本概念并发和并行
并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。

Minor GC 和 Full GC
新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。
老年代GC（Major GC &#x2F; Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。

吞吐量吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 &#x3D; 运行用户代码时间 &#x2F;（运行用户代码时间 + 垃圾收集时间）。虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。
参数详解
CMSScavengeBeforeRemark
在CMS GC前启动一次ygc，目的在于减少old gen对ygc gen的引用，降低remark时的开销—–一般CMS的GC耗时 80%都在remark阶段





参数
描述



UseSerialGC
虚拟机运行在Client模式下的默认值，打开此开关后，使用Serial+Serial Old的收集器组合进行内存回收


UseParNewGC
打开此开关后，使用ParNew+Serial Old的收集器组合进行内存回收


UseConcMarkSweepGC
打开此开关后，使用ParNew+CMS+Serial Old的收集器组合进行内存回收。Serial Old收集器将作为CMS收集器出现Concurrent Mode Failure失败后的后备收集器使用


UseParallelGC
虚拟机运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old（PS MarkSweep）的收集器组合进行内存回收


UseParallelOldGC
打开此开关后，使用Parallel Scavenge + Parallel Old的收集器组合进行内存回收


SurvivorRatio
新生代中Eden区域与Survivor区域的容量比值，默认值为8，代表Eden：Survivor&#x3D;8：1


PretenureSizeThreshold
直接晋升到老年代的对象大小，设置这个参数后，大于这个参数的对象将直接在老年代分配


MaxTenuringThreshold
晋升到老年代的对象年龄，每个对象在坚持过一次Minor GC之后，年龄就增加1，当超过这个参数时就进入老年代


UseAdaptiveSizePolicy
动态调整Java堆中各个区域的大小以及进入老年代的年龄


HandlePromotionFailure
是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况


ParallelGCThreads
设置并行GC时进行内存回收的线程数。默认情况下，当 CPU 数量小于8， ParallelGCThreads 的值等于 CPU 数量，当 CPU 数量大于 8 时，则使用公式：3+((5*CPU)&#x2F;8)；同时这个参数只要是并行 GC 都可以使用，不只是 ParNew。


GCTimeRatio
GC时间占总时间的比率，默认值为99，即允许1%的GC时间。仅在使用Parallel Scavenge收集器时生效


MaxGCPauseMillis
设置GC的最大停顿时间，仅在使用Parallel Scavenge收集器时生效


CMSInitingOccupancyFraction
设置CMS收集器在老年代空间被使用多少后触发垃圾收集。默认值为68%，仅在使用CMS收集器时生效


UseCMSCompactAtFullCollection
设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理，仅在使用CMS收集器时生效


CMSFullGCsBeforeCompaction
设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理。仅在使用CMS收集器时生效


记忆集记忆集是一种用户记录从非收集区域指向收集区域的指针集合的抽象数据结构。它其中的每个元素分别对应内存中的一块连续区域是否有跨代引用对象，如果有，该区域会被标记为“脏的”（dirty），否则就是“干净的”（clean）。这样在GC时，只需要扫描记忆集合就可以简单地确定跨代引用的位置，是个典型的空间换时间的思路。
记忆粒度
字长精度：每个记录精确到一个机器字长（就是处理器的寻址位数，如常见的32位或64位，这个 精度决定了机器访问物理内存地址的指针长度），该字包含跨代指针。
对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针。
卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。

卡表与卡页卡表是记忆集的一种具体实现，它定义记忆集的记录精度、与堆内存的映射关系等。在垃圾收集发生时，只要筛选出卡表的数组元素的值为1，称为这个元素变脏，没有则标识为0，借此得出哪些卡页内存块中包含跨代指针。如图所示：


写屏障在JDK 7之前，卡表的写屏障是无条件的。也就是说，不管更新的引用是否为跨代引用，都会出现一次写屏障。虽然这个造成的overhead相当的小，但在大并发情况下，又会造成虚共享（false sharing）问题。
虚共享CPU的缓存体系是以缓存行（cache line）为单位的，一条缓存行包含2的整数次幂个连续字节，一般为64B大。以64B为前提的话，那么一条缓存行就可以放下64个卡表元素，而64个卡页可以映射到32KB（64*512字节）的堆空间。如果同时有多个线程对同一块32KB堆空间内的引用进行更新，就会在同一个缓存行内发生碰撞，造成缓存频繁写回或者失效，影响性能。
下图示出虚共享的例子。核心1上的线程更新X的引用，而核心2上的线程更新Y的引用，它们落到了同一个缓存行内。


为了避免这种开销，在JDK 7及以后，引入了参数-XX:+UseCondCardMark来开启卡标记时有条件的写屏障，也就是先检查卡表中对应的位是不是脏的，如果不是脏的，再进行标记。这个思路非常简单，但有效地避免了虚共享问题。
读屏障指针的自愈能力

在ZGC中，当读取处于重分配集的对象时，会被读屏障拦截，通过转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象。ZGC将这种行为叫做指针的“自愈能力”。
好处是：第一次访问旧对象访问会变慢，但也只会有一次变慢，当“自愈”完成后，后续访问就不会变慢了。
Shenandoah每次访问都慢，对比发现，ZGC的执行负载更低。



虚拟机的标记实现方案
把标记直接记录在对象头上（如Serial收集器）；
把标记记录在与对象相互独立的数据结构上（如G1、Shenandoah使用了一种相当于堆内存的1&#x2F;64大小的，称为BitMap的结构来记录标记信息）；
直接把标记信息记在引用对象的指针上（如ZGC）

垃圾收集器

可以看到垃圾收集器是按对象的分代来划分的，可以用双箭头连接的垃圾收集器表示两者可以配合使用。可以看到新生代垃圾收集器有Serial、ParNew、Parallel Scavenge，G1，属于老年代的垃圾收集器有CMS、Serial Old、Parallel Old和G1.其中的G1是一种既可以对新生代对象也可以对老年代对象进行回收的垃圾收集器。然而，在所有的垃圾收集器中，并没有一种普遍使用的垃圾收集器。在不同的场景下，每种垃圾收集器有各自的优势。
Serial收集器Serial收集器是最基本、发展历史最悠久的收集器。它是一种单线程垃圾收集器，这就意味着在其进行垃圾收集的时候需要暂停其他的线程，也就是之前提到的”Stop the world“。虽然这个过程是在用户不可见的情况下把用户正常的线程全部停掉，听起来有点狠，这点是很难让人接受的。Serial、Serial Old收集器的工作示意图如下：


尽管由以上不能让人接受的地方，但是Serial收集器还是有其优点的：简单而高效，对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得较高的手机效率。到目前为止，Serial收集器依然是Client模式下的默认的新生代垃圾收集器。
ParNew收集器可ParNew收集器是Serial收集器的多线程版本，ParNew收集器的工作示意图如下：


ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器。除去性能因素，很重要的原因是除了Serial收集器外，目前只有它能与CMS收集器配合工作。
但是，在单CPU环境中，ParNew收集器绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。然而，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。
Parallel Scavenge收集器Parallel Scavenge收集器是新生代垃圾收集器，使用复制算法，也是并行的多线程收集器。与ParNew收集器相比，很多相似之处，但是Parallel Scavenge收集器更关注可控制的吞吐量。吞吐量越大，垃圾收集的时间越短，则用户代码则可以充分利用CPU资源，尽快完成程序的运算任务。
Parallel Scavenge收集器使用两个参数控制吞吐量：

XX:MaxGCPauseMillis 控制最大的垃圾收集停顿时间
XX:GCRatio 直接设置吞吐量的大小。

直观上，只要最大的垃圾收集停顿时间越小，吞吐量是越高的，但是GC停顿时间的缩短是以牺牲吞吐量和新生代空间作为代价的。比如原来10秒收集一次，每次停顿100毫秒，现在变成5秒收集一次，每次停顿70毫秒。停顿时间下降的同时，吞吐量也下降了。
除此之外，Parallel Scavenge收集器还可以设置参数-XX:+UseAdaptiveSizePocily来动态调整停顿时间或者最大的吞吐量，这种方式称为GC自适应调节策略，这点是ParNew收集器所没有的。
Serial Old收集器Serial Old收集器是Serial收集器的老年代版本，也是一个单线程收集器，采用“标记-整理算法”进行回收。其运行过程与Serial收集器一样。
Serial Old收集器的主要意义也是在于给Client模式下的虚拟机使用。如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。


Parallel Old收集器Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法进行垃圾回收。其通常与Parallel Scavenge收集器配合使用，“吞吐量优先”收集器是这个组合的特点，在注重吞吐量和CPU资源敏感的场合，都可以使用这个组合。


CMS收集器CMS收集器（Concurrent Mark Sweep）的目标就是获取最短回收停顿时间，是基于标记-清除算法实现的。在注重服务器的响应速度，希望停顿时间最短，则CMS收集器是比较好的选择。
整个执行过程分为以下4个步骤：
初始标记并发标记重新标记并发清除初始标记和重新标记这两个步骤仍然需要暂停Java执行线程，初始标记只是标记GC Roots能够关联到的对象，并发标记就是执行GC Roots Tracing的过程，而重新标记就是为了修正并发标记期间因用户程序执行而导致标记发生变动使得标记错误的记录。其执行过程如下：


由上图可知，整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，因此，总体上CMS收集器的内存回收过程是与用户线程一起并发执行的。
CMS的优点很明显：并发收集、低停顿。由于进行垃圾收集的时间主要耗在并发标记与并发清除这两个过程，虽然初始标记和重新标记仍然需要暂停用户线程，但是从总体上看，这部分占用的时间相比其他两个步骤很小，所以可以认为是低停顿的。
尽管如此，CMS收集器的缺点也是很明显的：
对CPU资源太敏感，这点可以这么理解，虽然在并发标记阶段用户线程没有暂停，但是由于收集器占用了一部分CPU资源，导致程序的响应速度变慢
CMS收集器无法处理浮动垃圾。所谓的“浮动垃圾”，就是在并发标记阶段，由于用户程序在运行，那么自然就会有新的垃圾产生，这部分垃圾被标记过后，CMS无法在当次集中处理它们（为什么？原因在于CMS是以获取最短停顿时间为目标的，自然不可能在一次垃圾处理过程中花费太多时间），只好在下一次GC的时候处理。这部分未处理的垃圾就称为“浮动垃圾”
由于CMS收集器是基于“标记-清除”算法的，前面说过这个算法会导致大量的空间碎片的产生，一旦空间碎片过多，大对象就没办法给其分配内存,那么即使内存还有剩余空间容纳这个大对象，但是却没有连续的足够大的空间放下这个对象，所以虚拟机就会触发一次Full GC（这个后面还会提到）这个问题的解决是通过控制参数-XX:+UseCMSCompactAtFullCollection，用于在CMS垃圾收集器顶不住要进行FullGC的时候开启空间碎片的合并整理过程。
CMS GC要决定是否在full GC时做压缩依赖以下情况：

UseCMSCompactAtFullCollection 与 CMSFullGCsBeforeCompaction 是搭配使用的；前者目前默认就是true了，也就是关键在后者上。
用户调用了System.gc()，而且DisableExplicitGC没有开启。
young gen报告接下来如果做增量收集会失败；简单来说也就是young gen预计old gen没有足够空间来容纳下次young GC晋升的对象。

增量式并发收集器增量式并发收集器是为了缓解CMS收集器CPU资源占用过多而设计出来的CMS收集变种，所做的事情和以前单核处理器年代PC机操作系统靠抢占式多任务来模拟多核并行多任务的思想一样，是在并发标记清理的时候让收集器线程和用户线程交替运行，尽量减少垃圾收集线程的独占资源的时间；由于性能一半已被废弃。
G1收集器G1（Garbage-First）收集器是现今收集器技术的最新成果之一，之前一直处于实验阶段。
衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数据最多，回收收益最大，这就是G1收集器的Mixed GC模式。
与前几个收集器相比，G1收集器有以下特点：

并行与并发
分代收集（仍然保留了分代的概念）
空间整合（整体上属于“标记-整理”算法，不会导致空间碎片）
可预测的停顿（比CMS更先进的地方在于能让使用者明确指定一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒）

此外，G1收集器将Java堆划分为多个大小相等的Region（独立区域），新生代与老年代都是一部分Region的集合，G1的收集范围则是这一个个Region（化整为零）。
G1的工作过程如下：

初始标记（Initial Marking）

并发标记（Concurrent Marking）

最终标记（Final Marking）

筛选回收（Live Data Counting and Evacuation）


初始标记阶段仅仅只是标记一下GC Roots能够直接关联的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段的用户程序并发运行的时候，能在正确可用的Region中创建对象，这个阶段需要暂停线程。
并发标记阶段从GC Roots进行可达性分析，找出存活的对象，这个阶段食欲用户线程并发执行的。
最终标记阶段则是修正在并发标记阶段因为用户程序的并发执行而导致标记产生变动的那一部分记录，这部分记录被保存在Remembered Set Logs中，最终标记阶段再把Logs中的记录合并到Remembered Set中，这个阶段是并行执行的，仍然需要暂停用户线程。
最后在筛选阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间制定回收计划，这个阶段需要暂停线程。整个执行过程如下：


低延迟垃圾收集器
Shenandoah和ZGC为什么被称为低延迟GC，因为它几乎整个工作过程全部都是并发的，只有初始标记、最终标记这些阶段有短暂的停顿，这部分停顿的时间基本上是固定的，与堆的容量、堆中对象的数量没有正比例关系。实际上，它们都可以在任意可管理的（譬如现在ZGC只能管理4TB以内的堆）堆容量下，实现垃圾收集的停顿都不超过十毫秒这种以前听起来是天方夜谭、匪夷所思的目标。这两款目前仍处于实验状态的收集器，被官方命名为“低延迟垃圾收集器”。

衡量垃圾收集器的三项最重要的指标是：内存占用（Footprint）、吞吐量（Throughput）和延迟（Latency），三者共同构成了一个“不可能三角”。
Shenandoah垃圾回收器Shenandoah收集器是通过比较并交换（Compare ANd Swap，CAS）操作来保证并发时对象的访问正确性的。
Shenandoah的内存屏障模型是基于引用访问屏障的实现，只拦截对象中数据类型为引用类型的读写操作。

比起稍后要介绍的有着Oracle正朔血统的ZGC，Shenandoah反而更像是G1的下一代继承者。使用转发指针（Forwarding Pointer，也常被称为Indirection Pointer）来实现对象移动与用户程序并发的一种解决方案。

Shenandoah相比起G1的改进虽然Shenandoah也是使用基于Region的堆内存布局，同样有着用于存放大对象的HumongousRegion，默认的回收策略也同样是优先处理回收价值最大的Region……但在管理堆内存方面，它与G1至少有三个明显的不同之处，最重要的当然是支持并发的整理算法，G1的回收阶段是可以多线程并行的，但却不能与用户线程并发，这点作为Shenandoah最核心的功能稍后笔者会着重讲解。其次，Shenandoah（目前）是默认不使用分代收集的，换言之，不会有专门的新生代Region或者老年代Region的存在，没有实现分代，并不是说分代对Shenandoah没有价值，这更多是出于性价比的权衡，基于工作量上的考虑而将其放到优先级较低的位置上。最后，Shenandoah摒弃了在G1中耗费大量内存和计算资源去维护的记忆集，改用名为“连接矩阵”（Connection Matrix）的全局数据结构来记录跨Region的引用关系，降低了处理跨代指针时的记忆集维护消耗，也降低了伪共享问题。
九个阶段
初始标记 这个阶段仍是“Stop The World”的，但停顿时间与堆大小无关，只与GC Roots的数量相关
并发标记 与G1一样，遍历对象图，标记出全部可达的对象，这个阶段是与用户线程一起并发的，时间长短取决于堆中存活对象的数量以及对象图的结构复杂程度。
最终标记 与G1一样，处理剩余的SATB扫描，并在这个阶段统计出回收价值最高的Region，将这些Region构成一组回收集（Collection Set）。最终标记阶段也会有一小段短暂的停顿。
并发清理 这个阶段用于清理那些整个区域内连一个存活对象都没有找到的Region
并发回收 在这个阶段，Shenandoah要把回收集里面的存活对象先复制一份到其他未被使用的Region之中。复制对象这件事情如果将用户线程冻结起来再做那是相当简单的，但如果两者必须要同时并发进行的话，就变得复杂起来了。其困难点是在移动对象的同时，用户线程仍然可能不停对被移动的对象进行读写访问，移动对象是一次性的行为，但移动之后整个内存中所有指向该对象的引用都还是旧对象的地址，这是很难一瞬间全部改变过来的。对于并发回收阶段遇到的这些困难，Shenandoah将会通过读屏障和被称为“Brooks Pointers”的转发指针来解决。并发回收阶段运行的时间长短取决于回收集的大小
初始引用更新 并发回收阶段复制对象结束后，还需要把堆中所有指向旧对象的引用修正到复制后的新地址，这个操作称为引用更新。
并发引用更新 真正开始进行引用更新操作，这个阶段是与用户线程一起并发的，时间长短取决于内存中涉及的引用数量的多少。并发引用更新与并发标记不同，它不再需要沿着对象图来搜索，只需要按照内存物理地址的顺序，线性地搜索出引用类型，把旧值改为新值即可。
最终引用更新 解决了堆中的引用更新后，还要修正存在于GC Roots中的引用。这个阶段是Shenandoah的最后一次停顿，停顿时间只与GC Roots的数量相关。
并发清理 经过并发回收和引用更新之后，整个回收集中所有的Region已再无存活对象，最后再调用一次并发清理过程来回收这些Region的内存空间，供以后新对象分配使用。

ZGC收集器
ZGC是一款在JDK 11中新加入的具有实验性质[插图]的低延迟垃圾收集器，是由Oracle公司研发的。2018年Oracle创建了JEP 333将ZGC提交给OpenJDK，推动其进入OpenJDK 11的发布清单之中。

ZGC和Shenandoah的目标是高度相似的，都希望在尽可能对吞吐量影响不太大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟。但是ZGC和Shenandoah的实现思路又是差异显著的。
ZGC收集器是一款基于Region内存布局的，（暂时）不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器。
ZGB可分为三种容量：

小型Region（Small Region）：容量固定为2MB，用于放置小于256KB的小对象。
中型Region（Medium Region）：容量固定为32MB，用于放置大于等于256KB但小于4MB的对象。
大型Region（Large Region）：容量不固定，可以动态变化，但必须为2MB的整数倍，用于放置4MB或以上的大对象。每个大型Region中只会存放一个大对象，所以实际容量可能小于中型Region，最小容量可低至4MB。大型Region在ZGC的实现中是不会被重分配的，因为复制一个大对象的代价非常高昂。

并发整理算法的实现
Shenandoah使用转发指针和读屏障来实现并发整理，ZGC虽然同样用到了读屏障，但用的却是一条与Shenandoah完全不同，更加复杂精巧的解题思路。

ZGC收集器有一个标志性的设计是它采用的染色指针技术（Colored Pointer），直接把标记信息记在引用对象的指针上。指针对于计算机来讲，它也是一个信息的载体，但是目前而言，内存中的理论可访问信息是远大于实际需求的，尽管Linux高18位不能用来寻址，但剩余的46位也足以满足需求，所以ZGC团队就将指针信息载体进行染色，将其高4位用来存储四个记号信息，通过这些标志位，虚拟机可以直接从指针中看到其引用对象的三色标记状态、是否进入了重分配集（即被移动过）、是否只能通过finalize()方法才能被访问到。
由于这些标志位进一步压缩了原本就只有46位的地址空间，也直接导致ZGC能够管理的内存不可以超过4TB（2的42次幂）。


染色指针的三大优势：
染色指针可以使得一旦某个Region的存活对象被移走之后，这个Region立即就能够被释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修正后才能清理。
染色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，设置内存屏障，尤其是写屏障的目的通常是为了记录对象引用的变动情况，如果将这些信息直接维护在指针中，显然就可以省去一些专门的记录操作。
染色指针可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。

四个阶段
并发标记（Concurrent Mark）：并发标记是遍历对象图做可达性分析的阶段，与G1、Shenandoah不同的是，ZGC的标记是在指针上而不是在对象上进行的，标记阶段会更新染色指针中的Marked 0、Marked 1标志位。
并发预备重分配（Concurrent Prepare for Relocate）：这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，ZGC划分Region的目的并非为了像G1那样做收益优先的增量回收，而实用范围更大的扫描成本换取省去G1中记忆集的维护成本。此外，在JDK12的ZGC中开始支持的类卸载以及弱引用的处理，也是在这个阶段中完成的。
并发重分配（Concurrent Relocate）：重分配是ZGC执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表（Forward Table），记录从旧对象到新对象的转向关系。得益于染色指针的支持，ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”（Self-Healing）能力。
并发重映射（Concurrent Remap）：重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用。ZGC的并发重映射并不是一个必须要“迫切”去完成的任务，因为前面提到ZGC有”自愈”能力，最坏也就多跳转一层，这时候，一旦所有指针都被修正之后，原来记录新旧对象关系的转发表就可以释放掉了。

现代处理器一般使用请求分页机制+虚拟内存映射技术。
请求分页机制把线性地址空间和物理地址空间分别划分为大小相等的块。这样的块称为页。通过在线性虚拟空间的页和物理地址空间的页建立映射表，分页机制会进行线性地址到物理地址的映射，完成线性地址到物理地址的转换。
Linus&#x2F;x86-64平台上的ZGC使用了多重映射将多个不同的虚拟内存地址映射到同一个物理内存地址上，多对一映射。意味着ZGC在虚拟内存空间中看到的地址空间比实际的堆内存容量更大。

]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>垃圾收集器</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 垃圾收集器与内存分配策略</title>
    <url>/posts/5b44aded/</url>
    <content><![CDATA[垃圾收集器与内存分配策略对象回收处理过程

判断对象是否存活判断一个对象是否存活需要同时满足以下三个条件：

该类所有的实例都已经被回收
加载该类的类加载器已经被回收
该类对应的java.lang.Class对象没有在任何地方被引用

引用计数算法引用计数法的逻辑是：在堆中存储对象时，在对象头处维护一个counter计数器，如果一个对象增加了一个引用与之相连，则将counter++。如果一个引用关系失效则counter–。如果一个对象的counter变为0，则说明该对象已经被废弃，不处于存活状态。


这种方法来标记对象的状态会存在很多问题：

1 jdk从1.2开始增加了多种引用方式：软引用、弱引用、虚引用，且在不同引用情况下程序应进行不同的操作。如果我们只采用一个引用计数法来计数无法准确的区分这么多种引用的情况。

引用计数法无法解决多种类型引用的问题。但这并不是致命的，因为我们可以通过增加逻辑区分四种引用情况，虽然麻烦一些但还算是引用计数法的变体，真正让引用计数法彻底报废的下面的情况；如果一个对象A持有对象B，而对象B也持有一个对象A，那发生了类似操作系统中死锁的循环持有，这种情况下A与B的counter恒大于1，会使得GC永远无法回收这两个对象。



可达性分析算法在主流的商用程序语言中(Java和C#)，都是使用可达性分析算法判断对象是否存活的。这个算法的基本思路就是通过一系列名为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，下图对象object5, object6, object7虽然有互相判断，但它们到GC Roots是不可达的，所以它们将会判定为是可回收对象。


如下情况的对象可以作为GC Roots：

虚拟机栈(栈桢中的本地变量表)中的引用的对象

方法区中的类静态属性引用的对象

方法区中的常量引用的对象

本地方法栈中JNI（Native方法）的引用的对象

所有被同步锁持有的对象

反应Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。


引用类型强引用(StrongReference)强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。
Object strongReference = new Object();



软引用(SoftReference)如果一个对象只具有软引用，则内存空间充足时，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。

软引用可用来实现内存敏感的高速缓存。

// 强引用String strongReference = new String(&quot;abc&quot;);// 软引用String str = new String(&quot;abc&quot;);SoftReference&lt;String&gt; softReference = new SoftReference&lt;String&gt;(str);

弱引用(WeakReference)弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。
   String str = new String(&quot;abc&quot;);   WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);   str = null;   // 复制代码JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收：   str = null;   System.gc();

弱引用再次变为一个强引用
String str = new String(&quot;abc&quot;);WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);// 弱引用转强引用String strongReference = weakReference.get();

虚引用(PhantomReference)虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。
应用场景：
虚引用主要用来跟踪对象被垃圾回收器回收的活动。 虚引用与软引用和弱引用的一个区别在于：

虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。

String str = new String(&quot;abc&quot;);ReferenceQueue queue = new ReferenceQueue();// 创建虚引用，要求必须与一个引用队列关联PhantomReference pr = new PhantomReference(str, queue);

总结：



引用类型
被垃圾回收时间
用途
生存时间



强引用
从来不会
对象的一般状态
JVM停止运行时终止


软引用
当内存不足时
对象缓存
内存不足时终止


弱引用
正常垃圾回收时
对象缓存
垃圾回收后终止


虚引用
正常垃圾回收时
跟踪对象的垃圾回收
垃圾回收后终止



任何一个对象的finallize()方法都只会被系统调用一次。

垃圾收集算法垃圾收集算法可以划分为“引用计数式垃圾收集”和“追踪式垃圾收集”两大类。


分代收集理论
弱分代假说：绝大多数对象都是朝生夕灭的。

强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡。

跨代引用假说：举个例子，如果某个新生代对象存在跨代引用，由于年老代对象难以消亡，该引用会使得新生代对象在收集时同样得以存活，进而在年龄增长之后晋升到年老代中，这时跨代引用也随即被消除了。
根据此引申出一个在新生代的数据结构，俗称记忆集：这个结构把年老代划分成若干小块，当发生新生代收集时，引用的小块内存里的对象才会被加入到GC Roots进行扫描。



GC概念：

部分收集（Partial PC）

新生代收集（Minor GC &#x2F; Young GC）

老年代收集（Major GC &#x2F; Old GC）：目前只有CMS收集器会有单独收集老年代的行为。



整堆收集（Full GC）



标记清除算法该算法用于新生代的处理，标记-清除算法分为标记和清除两个阶段。该算法首先从根集合进行扫描，对存活的对象对象标记，标记完毕后，再扫描整个空间中未被标记的对象并进行回收（也可以反过来标记存活的对象）



效率问题：标记和清除两个过程的效率都不高;
空间碎片化问题：标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，因此标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。



半复制算法复制算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这种算法适用于对象存活率低的场景，比如新生代。


Appel式回收原理Appel式回收是针对标准ML提出的一种自适应分代策略，在ML语言中，一次回收完成通常只有不到2%的对象能够存活，Appel式回收正式针对这一种情况而设计的策略。Appel式回收策略将空间分为三个：老年代、复制保留区、新生代，在HotSpot虚拟机中的实现中新生代收集器将新生代变成Eden空间，将复制保留区变成两块较小的Survivor空间，在程序运行中每次分配内存只使用Eden和其中一块Survivor空间，在发生垃圾收集时，将存活的对象复制到保留的那一块Survivor上，另外两块空间直接清零（在HotSpot虚拟机中Eden和Survivor的比例为8:1）。
可通过JVM参数：-XX:SurvivorRatio配置比例，-XX:SurvivorRatio=8 表示 Eden区大小 / 1块Survivor区大小 = 8。
第一次Young GC


当Eden区满的时候，触发第一次Young GC，把存活对象拷贝到Survivor的from区，清空Eden区。
当Survivor空间不足以容纳一次Minor GC之后，就需要依赖其他内存区域（大部分时候是老年代）进行分配担保，这些没有足够空间存放的对象直接进入其他区域；再次触发Young GC，扫描Eden区和from区，把存活的对象复制到To区，清空Eden区和from区。如果此时Survivor区的空间不够了，就会提前把对象放入老年代。
第二次Young GC


再次触发Young GC，扫描Eden区和from区，把存活的对象复制到To区，清空Eden区和from区。如果此时Survivor区的空间不够了，就会提前把对象放入老年代。

交换次数可以通过JVM参数MaxTenuringThreshold进行设置。

标记-整理算法标记整理算法的标记过程类似标记清除算法，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，类似于磁盘整理的过程，该垃圾回收算法适用于对象存活率高的场景（老年代）。



Hotspot虚拟机里面关注吞吐量的Parallel Scavenge收集是基于标记-整理算法的；
而关注延迟的CMS收集器则是基于标记-清除算法的，辅助以标记-整理算法，两种算法同时使用。

]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>垃圾收集器</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 运行时数据区域</title>
    <url>/posts/703fe08b/</url>
    <content><![CDATA[运行时数据区域

程序计数器程序计数器占用较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器，由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说就是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能够恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器。
虚拟机栈虚拟机栈也是线程私有，而且生命周期与线程相同，每个Java方法在执行的时候都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。

局部变量表：存放了编译器可知的各种基本数据类型（boolean、byte等）、对象引用（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向另一个代表对象的句柄或其他次对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）



本地方法栈本地方法占（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。
堆Java堆（Java Heap）的唯一目的就是存放对象实例，Java世界里“几乎”所有的对象实例都在这里分配内存。
方法区方法区（Method Area）Java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类型信息、常量（final）、静态变量、即时编译器编译后的代码等数据；别名叫做“非堆”（Non-Heap），目的是与Java堆区分开来。

JDK8中完全废弃了永久代的概念，改用在本地内存中实现的元空间（Meta-space）来代替，把JDK7中永久代剩余的内容（主要是类型信息）全部移到元空间中。

方法区的内存回收目标主要是针对常量池的回收和对类型的卸载（此部分比较苛刻）。
运行时常量池运行时常量池（Running Constant Pool）是方法区的一部分；运行时常量池相对于Class文件常量池的另外一个重要特性是动态性，Java语言并不要求常量一定只有编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，这种特性本开发人员用得比较多的便是String类的intern()方法。
JDK1.7之后被移动到堆中了。


intern方法详解String.intern()是一个Native(本地)方法，它的作用是如果字符串常量池已经包含一个等于此String对象的字符串，则返回字符串常量池中这个字符串的引用, 否则将当前String对象的引用地址（堆中）添加到字符串常量池中并返回。

由于intern(）操作每次都需要与常量池中的数据进行比较以查看常量池中是否存在等值数据，同时JVM需要确保常量池中的数据的唯一性，这就涉及到加锁机制，这些操作都是有需要占用CPU时间的，所以如果进行intern操作的是大量不会被重复利用的String的话，则有点得不偿失。由此可见，String.intern()主要 适用于只有有限值，并且这些有限值会被重复利用的场景，如：数据库表中的列名、人的姓氏、编码类型等。

示例代码：
public class StringTest &#123;    public static void main(String[] args) &#123;      	// 1： 首先会在Heap中创建对象，然后在常量池中放入zhagnsan 和 wangwu ，但是并不会放入zhagnsanwangwu        String a = new String(&quot;zhangsan&quot;) + &quot;wangwu&quot;;      	// 2：调用 intern ，因为字符串常量池中没有”zhangsanwangwu”这种拼接后的字符串，所以将堆中String对象的引用地址添加到字符串常量池中。jdk1.7后常量池引入到了Heap中，所以可以直接存储引用        String b = a.intern();      	// 3：因为 a 的地址和 b的地址一致，所以是true        System.out.println(a == b);            	// 4：因常量池中已经存在 zhangsanwangwu 了，所以直接返回引用就是 a 类型 a ==b 锁 a==b==c        String c = &quot;zhangsanwangwu&quot;;        System.out.println(a == c); // true      	System.out.println(b == c); // true            	// 5：首先会在Heap中创建对象，然后会在常量池中存储 zhang 和 san      	String d = new String(&quot;zhang&quot;) + &quot;san&quot;;      	// 6： 返回的是 常量池中的 地址，因在a变量时已经将 zhangsan 放入到了常量池中      	String f = d.intern();      	System.out.println(d == f); // false    &#125;&#125;



Class文件常量池Class文件常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。运行时常量池中主要存放两大类常量：字面量和符号引用。当Class文件常量池加载到方法区时，会把符号引用转换为直接引用，存放到运行时常量池。





除了字符串常量池，8种基本数据类型中除了两种浮点类型剩余的6种基本数据类型的包装类，都使用了缓冲池技术，但是 Byte、Short、Integer、Long、Character 这5种整型的包装类也只是在对应值在 [-128,127] 时才会使用缓冲池，超出此范围仍然会去创建新的对象。

直接内存NIO（New Input&#x2F;Output）类是一种引入了一种基于通道（Channel）与缓冲区（Buffer）的I&#x2F;O方式的操作类，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。
对象的创建当Java虚拟机遇到一条字节码new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程，在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存大小在类加载完成之后便可完全确定，为对象分配内存的任务实际上便等同于把一块确定大小的内存块从Java堆中划分出来。
内存分配方式指针碰撞假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空间的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存仅仅是把那个指针向空闲方向挪动一段与对象大小相等的距离，这种分配方式叫做指针碰撞（Bump the barrier）。
空闲列表但如果Java堆中的内存并不是规整的，虚拟机就必须维护一个列表，记录上那些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新记录上的记录，这种分配方式成为空闲列表。

实际上使用哪种内存分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有空间压缩整理（Compact）的能力决定。因此，当使用Serial，ParNew等带压缩整理过程的收集器时，系统采用的分配算法是指针碰撞，既简单又高效；而当使用CMS这种基于清除（Sweep）算法的收集器时，理论上就只能采用较为复杂的空闲列表来分配内存。
虚拟机是采用CAS配上失败重试的方法保证更新操作的原子性；另外一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区（Thread Local Allocation Buffer，TLAB），哪个线程要分配内存，就在哪个线程的本地缓冲区中分配内存，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。

对象的内存布局





对象在堆内存中的存储布局可以划分为三个部分：对象头（Header），实例数据（Instance Data）和对齐填充（Padding）。
内存布局图：


对象头HotSpot虚拟机的对象头包括两部分信息，第一部分是“Mark Word”，用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等。
Mark WordMark Word记录了对象和锁有关的信息，当这个对象被synchronized关键字当成同步锁时，围绕这个锁的一系列操作都和Mark Word有关。
Mark Word在32位JVM中的长度是32bit，在64位JVM中长度是64bit。
Mark Word在不同的锁状态下存储的内容不同，在32位JVM中是这么存的：





存储内容
标志位
状态



对象哈希码、对象分代年龄
01
未锁定


指向锁记录的指针
00
轻量级锁定


指向重量级锁的指针
10
膨胀（重量级锁定）


空，不需要记录信息
11
GC标记


偏向线程ID、偏向时间戳、对象分代年龄偏向锁线程ID、epoch、对象分代年龄、偏向锁标识
01
可偏向




重量级锁-MonitorMark Word 状态取决于 Monitor 锁，Monitor 锁必须加 synchronized 锁才会生效


例子：

synchronized 通过一个 lock 引用 找到 monitor 对象来操控 Mark Word 头里面的内容。





锁升级偏向锁

偏向状态





撤销-调用对象的 HashCode

撤销-其他线程使用对象撤销-调用wait&#x2F;notify批量重偏向

批量撤销

轻量级锁
信息存储在当前线程的栈帧里的锁记录（Lock Record）里面。

加锁流程



解锁流程

锁膨胀





自旋优化

锁消除@Fork(1)@BenchmarkMode(Mode.AverageTime)// 预热次数@Warmup(iterations=3)// 测试次数@Measurement(iterations=5)@OutputTimeUnit(TimeUnit.NANOSECONDS)public class MyBenchmark &#123;    static int x = 0;    @Benchmark    public void a() throws Exception &#123;        x++;    &#125;    @Benchmark    // JIT  即时编译器    public void b() throws Exception &#123;        Object o = new Object();        synchronized (o) &#123;            x++;        &#125;    &#125;&#125;

结果：
默认开启优化，可用-XX:-EliminateLocks禁用


类型指针对象头的另一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。
实例数据实例数据是对象真正存储的有效信息，即我们在程序代码里面所以定义的各种类型的字段内容。


-XX:FieldsAllocationStyle
实例数据的字段的存储顺序受此参数影响，相同宽度的字段总是被分配到一起存放。
HotSpot虚拟机默认的分配顺序为longs&#x2F;doubles、ints、shorts&#x2F;chars、bytes&#x2F;booleans、oops（Ordinary Object Pointers）

+XX:CompactFields
子类之中较窄的变量也允许插入父类变量的空隙之中，以节省出一点点空间，默认为true即启用。



对齐填充对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。对象头正好是8字节的倍数（1倍或者2倍），因此当对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。
对象的访问定位对象的访问定位主要有句柄和直接指针两种。
句柄
使用句柄访问的最好好处就是reference中存储的是稳定句柄地址，在对象移动时只会改变句柄中的实例数据指针，而reference本身不需要被修改。

如果使用句柄访问的话，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息。


直接指针速度快，节省了一次指针定位的时间开销。HotSpot采用此方式


类加载机制直接引用和符号引用1.符号引用（Symbolic References）：
　　符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。例如，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。符号引用与虚拟机的内存布局无关，引用的目标并不一定加载到内存中。在Java中，一个java类将会编译成一个class文件。在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。
2.直接引用：
 直接引用可以是
（1）直接指向目标的指针（比如，指向“类型”【Class对象】、类变量、类方法的直接引用可能是指向方法区的指针）
（2）相对偏移量（比如，指向实例变量、实例方法的直接引用都是偏移量）
（3）一个能间接定位到目标的句柄
直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。
类加载过程

其中，加载、验证、准备、初始化、卸载的开始顺序是确定的，注意，只是按顺序开始，进行与结束的顺序并不一定。解析阶段可能在初始化之后开始。
一、类的加载
我们平常说的加载大多不是指的类加载机制，只是类加载机制中的第一步加载。在这个阶段，JVM主要完成三件事：
1、通过一个类的全限定名（包名与类名）来获取定义此类的二进制字节流（Class文件）。而获取的方式，可以通过jar包、war包、网络中获取、JSP文件生成等方式。
2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。这里只是转化了数据结构，并未合并数据。（方法区就是用来存放已被加载的类信息，常量，静态变量，编译后的代码的运行时内存区域）
3、在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。这个Class对象并没有规定是在Java堆内存中，它比较特殊，虽为对象，但存放在方法区中。
二、类的连接
类的加载过程后生成了类的 java.lang.Class 对象，接着会进入连接阶段，连接阶段负责将类的二进制数据合并入JRE（Java运行时环境）中。类的连接大致分三个阶段。
1、验证：验证被加载后的类是否有正确的结构，类数据是否会符合虚拟机的要求，确保不会危害虚拟机安全。
2、准备：为类的静态变量（static filed）在方法区分配内存，并赋默认初值（0值或null值）。如static int a &#x3D; 100;
静态变量a就会在准备阶段被赋默认值0。
对于一般的成员变量是在类实例化时候，随对象一起分配在堆内存中。
另外，静态常量（static final filed）会在准备阶段赋程序设定的初值，如static final int a &#x3D; 666;  静态常量a就会在准备阶段被直接赋值为666，对于静态变量，这个操作是在初始化阶段进行的。
3、解析：将类的二进制数据中的符号引用换为直接引用。
三、类的初始化
类初始化是类加载的最后一步，除了加载阶段，用户可以通过自定义的类加载器参与，其他阶段都完全由虚拟机主导和控制。到了初始化阶段才真正执行Java代码。
****类的初始化的主要工作****是为静态变量赋程序设定的初值。
如static int a &#x3D; 100;在准备阶段，a被赋默认值0，在初始化阶段就会被赋值为100。
Java虚拟机规范中严格规定了****有且只有五种情况必须对类进行初始化****：
1、使用new字节码指令创建类的实例，或者使用getstatic、putstatic读取或设置一个静态字段的值（放入常量池中的常量除外），或者调用一个静态方法的时候，对应类必须进行过初始化。
2、通过java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则要首先进行初始化。
3、当初始化一个类的时候，如果发现其父类没有进行过初始化，则首先触发父类初始化。
4、当虚拟机启动时，用户需要指定一个主类（包含main()方法的类），虚拟机会首先初始化这个类。
5、使用jdk1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、RE_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行初始化，则需要先触发其初始化。
]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据安装部署（常规版）</title>
    <url>/posts/f509a887/</url>
    <content><![CDATA[目录环境准备
Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。(这里使用完全分布式模式)。

准备3台虚拟机，最低要求：内存4G，硬盘40G，这里准备的虚拟机是4G，硬盘40G的配置。
机器配置如下：



hostname
ip
内存
cpu
磁盘



node1
192.168.50.246
4G
2c
40G


node2
192.168.50.247
4G
2c
40G


node3
192.168.50.248
4G
2c
40G


环境配置
所有节点都需要配置。

创建hadoop用户
后续操作都使用hadoop用户，不使用root用户进行操作。

useradd hadooppasswd hadoop

然后配置用户具有root权限
vim /etc/sudoers## Allow root to run any commands anywhereroot  ALL=(ALL)     ALLhadoop   ALL=(ALL)     ALL

机器时间同步安装依赖：
sudo yum install -y epel-releasesudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static

时间同步（每台机器都要执行）
systemctl start ntpd

时间同步停止命令（不用执行）
systemctl stop ntpd

修改主机名每台机器设置各自的 hostname
# node1sudo hostnamectl --static set-hostname node1# node2sudo hostnamectl --static set-hostname node2# node3sudo hostnamectl --static set-hostname node3

设置host文件所有机器都设置
sudo vim /etc/hosts192.168.50.246   node1192.168.50.247   node2192.168.50.248   node3

关闭防火墙sudo systemctl stop firewalldsudo systemctl disable firewalld

创建文件夹并授权给hadoop用户sudo mkdir /appsudo chown -R hadoop:hadoop /app

SSH免密登录配置参考文章5
JDK安装
所有节点都要安装。

参考文章2
Hadoop安装
所有节点都要安装。

参考文章3
集群配置机器规划


服务
node1
node2
node3



HDFS
NameNode
-
SecondaryNameNode


HDFS
DataNode
DateNode
DateNode


YARN
-
ResourceManager
-


YARN
NodeManager
NodeManager
NodeManager


WEB 端口信息


服务
类型
访问地址



HDFS
NameNode
http://node1:50070


HDFS
SecondaryNameNode
http://node3:9868


YARN
jobhistory
http://node1:19888


配置文件
参考链接：https://blog.csdn.net/wjt199866/article/details/106473174
更多配置参数信息，请参考官方网址查询

http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/core-default.xml
http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml

通过这些网址，可以了解最新的全部的hadoop 配置信息，而且包括一些过时的定义标识，从而更好地维护您的集群。

所有的配置文件都在 &#x2F;app&#x2F;hadoop-3.2.3&#x2F;etc&#x2F;hadoop 目录下，主要需要修改的配置文件如下：
配置workersvim /app/hadoop-3.2.3/etc/hadoop/workersnode1node2node3

hadoop-env.sh# The java implementation to use. By default, this environment# variable is REQUIRED on ALL platforms except OS X!export JAVA_HOME=/app/jdk1.8.0_212## To prevent accidents, shell commands be (superficially) locked# to only allow certain users to execute certain subcommands.# It uses the format of (command)_(subcommand)_USER.## For example, to limit who can execute the namenode command,export HDFS_NAMENODE_USER=&quot;hadoop&quot;export HDFS_DATANODE_USER=&quot;hadoop&quot;export HDFS_SECONDARYNAMENODE_USER=&quot;hadoop&quot;export YARN_RESOURCEMANAGER_USER=&quot;hadoop&quot;export YARN_NODEMANAGER_USER=&quot;hadoop&quot;export HADOOP_PID_DIR=/app/hadoop-3.2.3/tmp/hadoop-hadoop-datanode.pid

core-site.xml
集群全局参数。
用于定义系统级别的参数，如 HDFS URL、Hadoop 的临时目录等。

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;!-- 配置 hdfs 的地址，统一通信地址 --&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://node1:8020&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hadoop.data.dir&lt;/name&gt;        &lt;value&gt;/app/hadoop-3.2.3/data&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 配置 hadoop 的临时目录 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;/hadoop/tmp&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 配置读写缓存大小 --&gt;    &lt;property&gt;        &lt;name&gt;io.file.buffer.size&lt;/name&gt;        &lt;value&gt;131072&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 代理用户配置 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;        &lt;value&gt;*&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;        &lt;value&gt;*&lt;/value&gt;    &lt;/property&gt;    &lt;!-- hdfs界面设置操作文件 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;        &lt;value&gt;hadoop&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

hdfs-site.xml
HDFS 参数。
如名称节点和数据节点的存放位置、文件副本的个数、文件读取权限等

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;        &lt;value&gt;file://$&#123;hadoop.data.dir&#125;/name&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;        &lt;value&gt;file://$&#123;hadoop.data.dir&#125;/data&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;        &lt;value&gt;file://$&#123;hadoop.data.dir&#125;/namesecondary&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.client.datanode-restart.timeout&lt;/name&gt;        &lt;value&gt;30&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;        &lt;value&gt;node3:9868&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;        &lt;value&gt;node1:50070&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

mapred-site.xml
Mapreduce 参数。
包括 JobHistory Server 和应用程序参数两部分，如 reduce 任务的默认个数、任务所能够使用内存的默认上下限等。

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 历史服务器端地址 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;        &lt;value&gt;node1:10020&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 历史服务器web端地址 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;        &lt;value&gt;node1:19888&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

yarn-site.xml
集群资源管理系统参数。
配置 ResourceManager，NodeManager 的通信端口，web监控端口等。

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;node2&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 日志采集 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.log.server.url&lt;/name&gt;        &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;        &lt;value&gt;604800&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

分发配置文件xsync /app/hadoop-3.2.3/etc/hadoop

HDFS 集群单点启动如果集群是第一次启动，需要格式化 NameNode（node1 执行）
./hdfs namenode -format

在 node1 上启动 NameNode
./hdfs --daemon start namenode

完成后执行jps命令，查看进程。
在 node1、node2、node3 上执行如下命令（三台都要执行）
./hdfs --daemon start datanode

HDFS 集群批量启动（推荐）如果集群是第一次启动，需要在cdh01节点格式化NameNode（注意格式化之前，一定要先停止上次启动的所有 namenode 和 datanode 进程，然后再删除 data 和 log 数据），然后离谱执行如下命令：
hdfs namenode -format

删除 data 和 logs 数据
cd /app/hadoop-3.2.3rm -rf data/*rm -rf logs/*

node1 启动HDFS
cd /app/hadoop-3.2.3./sbin/start-dfs.sh

YARN 批量启动在配置了ResourceManager的节点（node2）启动YARN
cd /app/hadoop-3.2.3./sbin/start-yarn.sh

历史服务器配置主要对应配置文件 mapred-site.xml，增加如下配置
&lt;!-- 历史服务器端地址 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;    &lt;value&gt;node1:10020&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史服务器web端地址 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;    &lt;value&gt;node1:19888&lt;/value&gt;&lt;/property&gt;

启动停止（node1 机器执行）
# 启动./bin/mapred --daemon start historyserver# 停止./bin/mapred --daemon stop historyserver

参考链接Hadoop基础环境搭建完整版
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK 安装</title>
    <url>/posts/f4e001d9/</url>
    <content><![CDATA[CentOS 7 安装 JAVA环境（JDK 1.8）1. 打开url选择jdk1.8下载https://www.oracle.com/java/technologies/downloads/#java8
这里选择的是 jdk-8u341-linux-x64.tar.gz
 

2. 安装创建安装目录
mkdir /usr/local/java

解压至安装目录
tar -zxvf jdk-8u171-linux-x64.tar.gz -C /usr/local/java/

3. 设置环境变量打开 /etc/profile 文件
vim /etc/profile

在末尾添加
export JAVA_HOME=/usr/local/java/jdk1.8.0_212export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH

使环境变量生效
source /etc/profile

添加软链接
ln -s /usr/local/java/jdk1.8.0_212/bin/java /usr/bin/java

检查
java -version



然后使用 xsync 分发到另外两台机器上去，xsync 命令安装详见文章5。
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop 安装</title>
    <url>/posts/dd1d33f7/</url>
    <content><![CDATA[目录安装包下载https://archive.apache.org/dist/hadoop/common/
解压上传hadoop安装包到 &#x2F;opt&#x2F;software&#x2F; 目录
解压到 &#x2F;app 目录下
tar vf hadoop-3.2.3.tar.gz -C /app/

环境变量配置sudo vim /etc/profile# HADOOP_HOMEexport HADOOP_HOME=/app/hadoop-3.2.3export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin

执行source使环境变量生效
sudo source /etc/profile

目录结构一览drwxr-xr-x. 2 hadoop hadoop    203 Mar 19  2022 bindrwxr-xr-x. 4 hadoop hadoop     30 Oct  9 05:32 datadrwxr-xr-x. 3 hadoop hadoop     20 Mar 19  2022 etcdrwxr-xr-x. 2 hadoop hadoop    106 Mar 19  2022 includedrwxr-xr-x. 3 hadoop hadoop     20 Mar 19  2022 libdrwxr-xr-x. 4 hadoop hadoop   4096 Mar 19  2022 libexec-rw-rw-r--. 1 hadoop hadoop 150571 Mar  9  2022 LICENSE.txtdrwxr-xr-x. 3 hadoop hadoop   4096 Oct  9 08:47 logs-rw-rw-r--. 1 hadoop hadoop  21943 Mar  9  2022 NOTICE.txt-rw-rw-r--. 1 hadoop hadoop   1361 Mar  9  2022 README.txtdrwxr-xr-x. 3 hadoop hadoop   4096 Mar 19  2022 sbindrwxr-xr-x. 4 hadoop hadoop     31 Mar 19  2022 sharedrwxr-xr-x. 3 hadoop hadoop     40 Oct  9 06:01 tmp

目录释义：

bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本
etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件
lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）
sbin目录：存放启动或停止Hadoop相关服务的脚本
share目录：存放Hadoop的依赖jar包、文档、和官方案例

]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS 部署</title>
    <url>/posts/beba2c3a/</url>
    <content><![CDATA[目录hdfs界面设置操作文件在Hadoop的配置文件 core-site.xml 中增加如下配置
&lt;property&gt;  &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;  &lt;value&gt;hadoop&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;  &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;

参考链接https://blog.csdn.net/qq_35246620/article/details/88576800
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>SSH 免密登录配置</title>
    <url>/posts/da9c3502/</url>
    <content><![CDATA[目录生成公钥和私钥所有节点都要操作，命令如下：
ssh-keygen -t rsa

然后敲三个回车，就会生成两个文件 id_rsa（私钥）、id_rsa.pub（公钥），公钥里面的内容就是我们所需要的。
将公钥拷贝到要免密登录的目标机器上所有节点都要操作
ssh-copy-id node1ssh-copy-id node2ssh-copy-id node3

其实上面的命令相当于在 ~&#x2F;.ssh&#x2F;authorized_keys 下追加如下内容：
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDOivJfUMuDNggjCIc1ZZrfbneSb7d8DaKTRPhTxwahGkwyhgB2WCmvtbAsGVqddYUOEKdCu7Nr87RwM7cMfoDCuzagaIZtRpk+amaJSwf65A4YF2Ss6D7U4Aj6i6UmKsmqtd9HHPKq0HAxA1Mvy/lp68O2HS1lsMOu9zfvf0i2pAnaGtVJwBUNlJ86sdSerl2NGNZtV5ZpIP3iVe5m2G5M6EftiKYN6z587nxACz8lqJ9yod8b2lD32fG6KN52r/olPI7ZQVMiCV3DHawT5TmJ2AhGM85MvuzY/2IkglxtMpvsrRiubC7QmOdyNnGfUjSfZLXdO0Us5KNBSZ6c7pkP hadoop@node1...

其中的内容刚好为 id_rsa.pub 公钥里面的内容，所以不通过 ssh-copy-id 的命令也是可行的，通过在当前用户下的 .ssh 目录创建 authorized_keys 文件并将所有节点的公钥内容补充到该文件下也能实现集群间两两彼此免密登录。
* 集群分发脚本xsync编辑文件
cd /appvim xsync

脚本内容
#!/bin/bash#1. 判断参数个数if [ $# -lt 1 ]then  echo Not Enough Arguement!  exit;fi#2. 遍历集群所有机器for host in node1 node2 node3do  echo ====================  $host  ====================  #3. 遍历所有目录，挨个发送  for file in $@  do    #4 判断文件是否存在    if [ -e $file ]    then      #5. 获取父目录      pdir=$(cd -P $(dirname $file); pwd)      #6. 获取当前文件的名称      fname=$(basename $file)      ssh $host &quot;mkdir -p $pdir&quot;      rsync -av $pdir/$fname $host:$pdir    else      echo $file does not exists!    fi  donedone

修改脚本 xsync 具有执行权限
chmod +x xsync

将脚本移动到 &#x2F;bin 中，以便全局调用
sudo mv xsync /bin/

测试脚本
将当前机器的 &#x2F;bin&#x2F;xsync 文件 scp 到 node1 node2 node3 的相同目录下，相同目录覆盖传输。
sudo xsync /bin/xsync

然后在其他机器输入 xsync 命令，发现命令均已生效，说明同步脚本已经执行成功。
参考链接多台linux服务器实现ssh免密互连
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper 安装</title>
    <url>/posts/146a1eb6/</url>
    <content><![CDATA[目录zookeeper 集群通常是用来对用户的分布式应用程序提供协调服务的，为了保证数据的一致性，对 zookeeper 集群进行了这样三种角色划分：leader、follower、observer 分别对应着总统、议员和观察者。

总统（leader）：负责进行投票的发起和决议，更新系统状态。
议员（follower）：用于接收客户端请求并向客户端返回结果以及在选举过程中参与投票。
观察者（observer）：也可以接收客户端连接，将写请求转发给leader节点，但是不参与投票过程，只同步leader的状态。通常对查询操作做负载。

机器规划


类型
IP地址
掩码
网关



master
192.168.50.246
255.255.255.0
192.168.50.1


slave1
192.168.50.247
255.255.255.0
192.168.50.1


slave2
192.168.50.248
255.255.255.0
192.168.50.1


官网地址https://zookeeper.apache.org/releases.html
下载地址https://archive.apache.org/dist/zookeeper/
JDK安装
所有节点都要安装。

参考文章2
将zookeeper压缩文件解压后，我们进入到 conf 目录：
文件配置配置 zoo.cfg将zookeeper压缩文件解压后，我们进入到 conf 目录，将 zoo_sample.cfg 文件复制并重命名为 zoo.cfg 文件。


配置文件修改如下：
# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/usr/local/software/zookeeper-3.4.14/data# the port at which the clients will connectclientPort=2181server.1=192.168.50.246:2888:3888server.2=192.168.50.247:2888:3888server.3=192.168.50.248:2888:3888# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1


参考官方文档：https://zookeeper.apache.org/doc/r3.5.8/zookeeperStarted.html

主要是修改 dataDir 所对应的目录和增加server开头的三个节点的配置信息

tickTime：基本事件单元，这个时间是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，每隔tickTime时间就会发送一个心跳；最小 的session过期时间为2倍tickTime
dataDir：存储内存中数据库快照的位置，除非另有说明，否则指向数据库更新的事务日志。注意：应该谨慎的选择日志存放的位置，使用专用的日志存储设备能够大大提高系统的性能，如果将日志存储在比较繁忙的存储设备上，那么将会很大程度上影像系统性能。
client：监听客户端连接的端口。
initLimit：允许follower连接并同步到Leader的初始化连接时间，以tickTime为单位。当初始化连接时间超过该值，则表示连接失败。
syncLimit：表示Leader与Follower之间发送消息时，请求和应答时间长度。如果follower在设置时间内不能与leader通信，那么此follower将会被丢弃。
server.A&#x3D;B:C:D

　　　　A：其中 A 是一个数字，表示这个是服务器的编号；
　　　　B：是这个服务器的 ip 地址；
　　　　C：Zookeeper服务器之间的通信端口；
　　　　D：Leader选举的端口。
我们需要修改的第一个是 dataDir ,在指定的位置处创建好目录。
第二个需要新增的是 server.A&#x3D;B:C:D 配置，其中 A 对应下面我们即将介绍的myid 文件。B是集群的各个IP地址，C:D 是端口配置。
创建 myid 文件在 上一步 dataDir 指定的目录下，创建 myid 文件。


server 节点配置信息：
server.1=192.168.50.246:2888:3888server.2=192.168.50.247:2888:3888server.3=192.168.50.248:2888:3888

在 192.168.50.246 机器的的 &#x2F;usr&#x2F;local&#x2F;software&#x2F;zookeeper-3.3.6&#x2F;data 目录下创建 myid 文件，然后在该文件中写上 1 即可。


后面的机器依次在相应目录创建myid文件，写上相应配置数字即可。
环境变量配置为了能够在任意目录启动zookeeper集群，我们需要配置环境变量。
ps:你也可以不配，这不是搭建集群的必要操作，只不过如果你不配置环境变量，那么每次启动zookeeper需要到安装文件的 bin 目录下去启动。
首先进入到 &#x2F;etc&#x2F;profile 目录，添加相应的配置信息：
# zookeeperexport ZK_HOME=/usr/local/software/zookeeper-3.4.14export PATH=$PATH:$ZK_HOME/bin

然后通过如下命令使得环境变量生效：
source /etc/profle

启动服务启动命令：
zkServer.sh start

停止命令：
zkServer.sh stop

重启命令：
zkServer.sh restart

查看集群节点状态：
zkServer.sh status

我们分别对集群三台机器执行启动命令。执行完毕后，分别查看集群节点状态：
出现如下即是集群搭建成功：






三台机器， node2 成功的通过了选举称为了 leader，而剩下的两台成为了 follower。这时候，如果你将 node2 关掉，会发现剩下两台又会有一台变成了 leader 节点。
集群测试集群搭建完毕，可以使用客户端连接任意一台服务器进行操作，连接服务器2，创建新的节点，连接服务器1，查看新创建的节点
[root@localhost opt]# zkCli.sh -server localhost:2181[zk: localhost:2183(CONNECTED) 1] ls /[zookeeper][zk: localhost:2183(CONNECTED) 2] create /mynode1 mydata1Created /mynode1[root@localhost opt]# zkCli.sh -server localhost:2181[zk: localhost:2181(CONNECTED) 1] ls /[mynode1, zookeeper]

参考链接zookeeper 集群搭建
Zookeeper系列(4)：搭建Zookeeper集群
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据日常运维命令</title>
    <url>/posts/64ca3b01/</url>
    <content><![CDATA[目录集群启动&#x2F;停止方式总结单个HDFSnameNode 启动
hdfs --daemon start namenode


nameNode 停止
hdfs --daemon stop namenode


dataNode 启动
hdfs --daemon start datanode


dataNode 停止
hdfs --daemon stop datanode


secondaryNamenode 启动
hdfs --daemon start secondarynamenode


secondaryNamenode 停止
hdfs --daemon stop secondarynamenode

YARNresourceManager 启动停止
yarn --daemon start resourcemanageryarn --daemon stop resourcemanager


nodeManager 启动停止
yarn --daemon start nodemanageryarn --daemon stop nodemanager

批量（全机器已配置免密）HDFS启动
./sbin/start-dfs.sh

停止
./sbin/stop-dfs.sh

YARN启动
./sbin/start-yarn.sh

停止
./sbin/stop-yarn.sh
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据安装部署（高可用版）</title>
    <url>/posts/3ee3db16/</url>
    <content><![CDATA[目录环境准备
Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。(这里使用完全分布式模式)。

准备3台虚拟机，最低要求：内存4G，硬盘40G，这里准备的虚拟机是4G，硬盘40G的配置。
机器配置如下：



hostname
ip
内存
cpu
磁盘



node1
192.168.50.246
4G
2c
40G


node2
192.168.50.247
4G
2c
40G


node3
192.168.50.248
4G
2c
40G


环境配置所有节点都需要配置。

注意：安装 centos7 的时候如果是最小化安装（默认的选择就是最小化安装），是不安装 psmisc 包，此时 hadoop 的 HA 无法正常切换，需要安装 yum install psmisc -y 包后，重启。
说明一下：psmisc 工具包含了 pstree、killall、fuser

pstree：以树状图显示程序。

killall：用于kill指定名称的进程。

fuser：用来显示所有正在使用着指定的file, file system 或者 sockets的进程信息。



创建hadoop用户
后续操作都使用hadoop用户，不使用root用户进行操作。

useradd hadooppasswd hadoop

然后配置用户具有root权限
vim /etc/sudoers## Allow root to run any commands anywhereroot  ALL=(ALL)     ALLhadoop   ALL=(ALL)     ALL

机器时间同步安装依赖：
sudo yum install -y epel-releasesudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static

时间同步（每台机器都要执行）
systemctl start ntpd

时间同步停止命令（不用执行）
systemctl stop ntpd

修改主机名每台机器设置各自的 hostname
# node1sudo hostnamectl --static set-hostname node1# node2sudo hostnamectl --static set-hostname node2# node3sudo hostnamectl --static set-hostname node3

设置host文件所有机器都设置
sudo vim /etc/hosts192.168.50.246   node1192.168.50.247   node2192.168.50.248   node3

关闭防火墙sudo systemctl stop firewalldsudo systemctl disable firewalld

创建文件夹并授权给hadoop用户sudo mkdir /appsudo chown -R hadoop:hadoop /app

SSH免密登录配置参考文章5
JDK安装
所有节点都要安装。

参考文章2
Zookeeper安装参考文章7
Hadoop安装
所有节点都要安装。

参考文章3
集群配置机器规划


服务
node1
node2
node3



HDFS
NameNode
NameNode（active节点）
NameNode


HDFS
-
-
SecondaryNameNode


HDFS
DataNode
DateNode
DateNode


HDFS
JournalNode
JournalNode
JournalNode


YARN
ResourceManager
ResourceManager
-


YARN
NodeManager
NodeManager
NodeManager


WEB 端口信息


服务
类型
访问地址



HDFS
NameNode
http://node1:9870, http://node2:9870, http://node3:9870


HDFS
SecondaryNameNode
http://node3:9868


YARN
jobhistory
http://node3:19888


YARN
ResourceManager
http://node1:8088, http://node2:8088


配置文件
参考链接：https://blog.csdn.net/wjt199866/article/details/106473174
更多配置参数信息，请参考官方网址查询

http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/core-default.xml
http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml

通过这些网址，可以了解最新的全部的hadoop 配置信息，而且包括一些过时的定义标识，从而更好地维护您的集群。

所有的配置文件都在 &#x2F;app&#x2F;hadoop-3.2.3&#x2F;etc&#x2F;hadoop 目录下，主要需要修改的配置文件如下：
配置workersvim /app/hadoop-3.2.3/etc/hadoop/workersnode1node2node3

hadoop-env.sh# The java implementation to use. By default, this environment# variable is REQUIRED on ALL platforms except OS X!export JAVA_HOME=/app/jdk1.8.0_212## To prevent accidents, shell commands be (superficially) locked# to only allow certain users to execute certain subcommands.# It uses the format of (command)_(subcommand)_USER.## For example, to limit who can execute the namenode command,export HDFS_NAMENODE_USER=&quot;hadoop&quot;export HDFS_SECONDARYNAMENODE_USER=&quot;hadoop&quot;export HDFS_DATANODE_USER=&quot;hadoop&quot;export HDFS_JOURNALNODE_USER=&quot;hadoop&quot;export HDFS_ZKFC_USER=&quot;hadoop&quot;export YARN_RESOURCEMANAGER_USER=&quot;hadoop&quot;export YARN_NODEMANAGER_USER=&quot;hadoop&quot;export HADOOP_PID_DIR=/app/hadoop-3.2.3/tmp/hadoop-hadoop-datanode.pid

core-site.xml
集群全局参数。
用于定义系统级别的参数，如 HDFS URL、Hadoop 的临时目录等。

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;!-- 配置 hdfs 的地址，统一通信地址 --&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://vmcluster&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 整合 Zookeeper --&gt;    &lt;property&gt;        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;        &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 配置 hadoop 的数据目录 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.data.dir&lt;/name&gt;        &lt;value&gt;/app/hadoop-3.2.3/data&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 配置 hadoop 的临时目录 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;/app/hadoop-3.2.3/tmp&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 配置读写缓存大小 --&gt;    &lt;property&gt;        &lt;name&gt;io.file.buffer.size&lt;/name&gt;        &lt;value&gt;131072&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 代理用户配置 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;        &lt;value&gt;*&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;        &lt;value&gt;*&lt;/value&gt;    &lt;/property&gt;    &lt;!-- hdfs界面设置操作文件 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;        &lt;value&gt;hadoop&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

hdfs-site.xml
HDFS 参数。
如名称节点和数据节点的存放位置、文件副本的个数、文件读取权限等

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;        &lt;value&gt;file://$&#123;hadoop.data.dir&#125;/dfs/nn&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;        &lt;value&gt;file://$&#123;hadoop.data.dir&#125;/dfs/dn&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;        &lt;value&gt;file://$&#123;hadoop.data.dir&#125;/namesecondary&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.client.datanode-restart.timeout&lt;/name&gt;        &lt;value&gt;30&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;        &lt;value&gt;node3:9868&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;        &lt;value&gt;node1:50070&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 对照clickhouse，可以理解为给整个集群起的一个识别名字 --&gt;    &lt;property&gt;        &lt;name&gt;dfs.nameservices&lt;/name&gt;        &lt;value&gt;vmcluster&lt;/value&gt;    &lt;/property&gt;    &lt;!-- Currently, only a maximum of two NameNodes may be configured per nameservice. --&gt;    &lt;!-- unique identifiers for each NameNode in the nameservice --&gt;    &lt;!-- 目前为止，一个集群里面只能最多有两个NameNodes 注意了 --&gt;    &lt;property&gt;        &lt;name&gt;dfs.ha.namenodes.vmcluster&lt;/name&gt;        &lt;value&gt;nn1,nn2,nn3&lt;/value&gt;    &lt;/property&gt;    &lt;!-- the fully-qualified RPC address for each NameNode to listen on --&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.rpc-address.vmcluster.nn1&lt;/name&gt;        &lt;value&gt;node1:8020&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.rpc-address.vmcluster.nn2&lt;/name&gt;        &lt;value&gt;node2:8020&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.rpc-address.vmcluster.nn3&lt;/name&gt;        &lt;value&gt;node3:8020&lt;/value&gt;    &lt;/property&gt;    &lt;!-- the fully-qualified HTTP address for each NameNode to listen on --&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.http-address.vmcluster.nn1&lt;/name&gt;        &lt;value&gt;node1:9870&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.http-address.vmcluster.nn2&lt;/name&gt;        &lt;value&gt;node2:9870&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.http-address.vmcluster.nn3&lt;/name&gt;        &lt;value&gt;node3:9870&lt;/value&gt;    &lt;/property&gt;    &lt;!-- the URI which identifies the group of JNs where the NameNodes will write/read edits --&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;        &lt;value&gt;qjournal://node1:8485;node2:8485;node3:8485/vmcluster&lt;/value&gt;    &lt;/property&gt;    &lt;!-- the Java class that HDFS clients use to contact the Active NameNode --&gt;    &lt;property&gt;        &lt;name&gt;dfs.client.failover.proxy.provider.vmcluster&lt;/name&gt;        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;    &lt;/property&gt;        &lt;!-- a list of scripts or Java classes which will be used to fence the Active NameNode during a failover --&gt;    &lt;!-- 为了确保任何时候都只有一个NameNode在工作，failover的时候可能需要强制杀死一个NameNode，有两种方法，ssh或者shell，一般选择ssh --&gt;    &lt;property&gt;        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;        &lt;value&gt;sshfence&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;        &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;        &lt;value&gt;30000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;        &lt;value&gt;100&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.safemode.threshold.pct&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;        &lt;value&gt;/app/hadoop-3.2.3/data/jn&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 启用自动故障转移 --&gt;    &lt;property&gt;        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;3&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.blocksize&lt;/name&gt;        &lt;value&gt;67108864&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

mapred-site.xml
Mapreduce 参数。
包括 JobHistory Server 和应用程序参数两部分，如 reduce 任务的默认个数、任务所能够使用内存的默认上下限等。

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 历史服务器端地址 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;        &lt;value&gt;node3:10020&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 历史服务器web端地址 --&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;        &lt;value&gt;node3:19888&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;        &lt;value&gt;HADOOP_MAPRED_HOME=/app/hadoop-3.2.3&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.map.env&lt;/name&gt;        &lt;value&gt;HADOOP_MAPRED_HOME=/app/hadoop-3.2.3&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;        &lt;value&gt;HADOOP_MAPRED_HOME=/app/hadoop-3.2.3&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;        &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

yarn-site.xml
集群资源管理系统参数。
配置 ResourceManager，NodeManager 的通信端口，web监控端口等。

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;        &lt;value&gt;yarnCluster&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.ha.automatic-failover.enabled&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.ha.automatic-failover.embedded&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.connect.retry-interval.ms&lt;/name&gt;        &lt;value&gt;2000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;        &lt;value&gt;rm1,rm2&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;        &lt;value&gt;node1&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;        &lt;value&gt;node2&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;        &lt;value&gt;node1:8088&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;        &lt;value&gt;node2:8088&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.address.rm1&lt;/name&gt;        &lt;value&gt;node1:8032&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.address.rm2&lt;/name&gt;        &lt;value&gt;node2:8032&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm1&lt;/name&gt;        &lt;value&gt;node1:8030&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm2&lt;/name&gt;        &lt;value&gt;node2:8030&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 整合 Zookeeper --&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;        &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;node2&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 日志采集 --&gt;    &lt;property&gt;        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.log.server.url&lt;/name&gt;        &lt;value&gt;http://node3:19888/jobhistory/logs&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;        &lt;value&gt;604800&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 整合 Zookeeper --&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.zk.state-store.address&lt;/name&gt;        &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt;    &lt;/property&gt;        &lt;property&gt;        &lt;name&gt;yarn.application.classpath&lt;/name&gt;        &lt;value&gt;            $HADOOP_CONF_DIR,            $HADOOP_COMMON_HOME/share/hadoop/common/*,            $HADOOP_COMMON_HOME/share/hadoop/common/lib/*,            $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,            $HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,            $HADOOP_YARN_HOME/share/hadoop/yarn/*,            $HADOOP_YARN_HOME/share/hadoop/yarn/lib/*        &lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;mapred.job.queue.name&lt;/name&gt;        &lt;value&gt;hadoop.myqueue&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;

分发配置文件xsync /app/hadoop-3.2.3/etc/hadoop

初始化zk 初始化在 node1 上格式化 zookeeper，第33行的日志表示创建成功。
hdfs zkfc -formatZK

验证 zkfc 是否格式化成功，如果多了一个 hadoop-ha 包就是成功了，如下所示：


启动 JournalNode 集群依次在 node1, node2, node3 上面执行：
hdfs --daemon start journalnode

NameNode 集群初始化格式化集群的一个NameNode（node1），有两种方法，我使用的是第一种：
hdfs namenode –format

在 node1 上启动刚才格式化的 namenode：
hdfs --daemon start namenode

在 node1 机器上，将 node1 的数据复制到 node2 上来,在 node 2 上执行（node3 同理）：
hdfs namenode –bootstrapStandby

启动 node2 和 node3 的 namenode：
hdfs --daemon start namenode

DataNode 启动启动所有的datanode，在 node1 上执行：
hdfs --daemon start datanode

Yarn 启动启动yarn，在 node1 上执行以下命令：
start-yarn.sh

测试 HDFS 是否可用hdfs dfs -ls /

一键启动在 node1 机器下的 /app/hadoop-3.2.3/sbin 目录下执行一键启动命令（需提前启动好 zookeeper 集群）：
start-all.sh

历史服务器配置主要对应配置文件 mapred-site.xml，增加如下配置
&lt;!-- 历史服务器端地址 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;    &lt;value&gt;node3:10020&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史服务器web端地址 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;    &lt;value&gt;node3:19888&lt;/value&gt;&lt;/property&gt;

启动停止（node3 机器执行）
# 启动./bin/mapred --daemon start historyserver# 停止./bin/mapred --daemon stop historyserver

参考链接YARN &amp;&amp; Hadoop 集群环境准备
Hadoop之4-HDFS HA配置
Hadoop HA 高可用集群搭建
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum 常用命令</title>
    <url>/posts/500bccb4/</url>
    <content><![CDATA[yum 生成缓存yum makecache fast

yum 清除缓存yum clean all

]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>RPM 常用命令</title>
    <url>/posts/7cf61fc4/</url>
    <content><![CDATA[目录安装语法：
rpm -i &lt;需要安装的包文件名&gt;

举个栗子：
# 安装 example.rpm 包rpm -i example.rpm# 安装 example.rpm 包并在安装过程中显示正在安装的文件信息rpm -iv example.rpm# 安装 example.rpm 包并在安装过程中显示正在安装的文件信息及安装进度rpm -ivh example.rpm

查看安装完成的软件语法：
rpm -qa

举个栗子：
[root@jacky zookeeper]# rpm -qa | grep jdkjava-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.i686java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.i686

卸载软件语法：
rpm -e --nodeps &lt;要卸载的软件包&gt;

举个栗子：
root@jacky zookeeper]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.i686

                      
]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 基础知识</title>
    <url>/posts/70711607/</url>
    <content><![CDATA[Linux系统的7个运行级别(runlevel)运行级别分为以下6种：
0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动
1：单用户工作状态，root权限，用于系统维护，禁止远程登陆
2：多用户状态(没有NFS)
3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式
4：系统未使用，保留
5：X11控制台，登陆后进入图形GUI模式
6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动

运行级别的原理：

在目录&#x2F;etc&#x2F;rc.d&#x2F;init.d下有许多服务器脚本程序，一般称为服务(service)
在&#x2F;etc&#x2F;rc.d下有7个名为rcN.d的目录，对应系统的7个运行级别
rcN.d目录下都是一些符号链接文件，这些链接文件都指向init.d目录下的service脚本文件，命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位数字。
系统会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件   对于以K开头的文件，系统将终止对应的服务   对于以S开头的文件，系统将启动对应的服务
另外 init 0 为关机，init 6 为重启系统


查看当前运行级别runlevel

进入其它运行级别init [级别]

]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 修改 root 密码</title>
    <url>/posts/1f71be40/</url>
    <content><![CDATA[目录方式一在启动引导主页上按e进入内核编辑



找到 Linux16 这一段，在末尾处添加 rd.break，按下组合键 CTRL+X 运行内核程序进入紧急救援模式


在这个模式下依次输入以下命令
mount -o remount,rw /sysrootchroot /sysrootpasswd # 注意：到这里的时候会提示输入两次需要重置的密码，输入完成之后回车即可touch /.autorelabel # 如果已经开启了SElinux，则需要输入此命令reboot



重新进入系统输入刚刚重置的密码即可登陆root账户
方式二前面操作和方式一样
在linux16 这一段的最后添加上 init=/bin/sh




进来上图界面后输入以命令1、挂载根目录
mount -o remount, rw /

2、选择要修改密码的用户名，这里选择root用户进行修改，可以更换为你要修改的用户passwd3、输入2次一样的新密码，注意输入密码的时候屏幕上不会有字符出现。如果输入的密码太简单，会提示警告（BAD PASSWORD：The password fails the dictionary check - it is too simplistic&#x2F;systematic），可以无视它，继续输入密码，不过建议还是设置比较复杂一些的密码，以保证安全性4、如果已经开启了SElinux，则需要输入以下命令
touch /.autorelabel

5、最后输入以下命令重启系统即可
exec /sbin/init# 或exec /sbin/reboot

]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 常用命令</title>
    <url>/posts/7fdd7943/</url>
    <content><![CDATA[目录修改时区查看时间各种状态
timedatectl

结果输出如下：
      Local time: 六 2023-01-07 04:41:46 UTC  Universal time: 六 2023-01-07 04:41:46 UTC        RTC time: n/a       Time zone: UTC (UTC, +0000)     NTP enabled: n/aNTP synchronized: yes RTC in local TZ: no      DST active: n/a

列出所有时区
timedatectl list-timezones

将硬件时钟调整为与本地时钟一致, 0 为设置为 UTC 时间
timedatectl set-local-rtc 1

设置系统时区为上海
timedatectl set-timezone Asia/Shanghai

校准时间yum -y install ntp# 通过阿里云时间服务器校准时间ntpdate ntp1.aliyun.com

]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 安装</title>
    <url>/posts/b23a554b/</url>
    <content><![CDATA[运行模式查看当前模式systemctl get-default

修改为图形界面systemctl set-default graphical.target

修改为命令行systemctl set-default multi-user.target



]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 网络篇</title>
    <url>/posts/2004b1f1/</url>
    <content><![CDATA[查看网关&#x2F;路由route -n

]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title>gpedit 常用配置</title>
    <url>/posts/9e487b57/</url>
    <content><![CDATA[关闭 Antimalware Service Executable

Antimalware Service Executable是什么 如何关闭Antimalware Service Executable进程是微软杀毒软件Windows Defender的相关系统进程,是个正常的系统进程，其工作时经常会出现高CPU、高内存与高磁盘的情况。
关闭步骤：1、win键+R，输入“gpedit.msc”，打开“本地组策略编辑器”；2、依次选择“计算机配置”-“管理模板”-“Windows组件”-“Windows Defender防病毒程序”；3、找到“关闭Windows Defender防病毒程序”选项，右键“编辑“，选择“已启用”，确定即可；
]]></content>
      <categories>
        <category>运维</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>gpedit</tag>
      </tags>
  </entry>
  <entry>
    <title>vmware 网络配置</title>
    <url>/posts/da1888d/</url>
    <content><![CDATA[目录网卡配置桥接模式参考链接Mac VMware fusion10 Centos7网络配置
如何使VMware ip与本机ip处于同一网段
CentOS 7 在vmware中的网络设置
]]></content>
      <categories>
        <category>运维</category>
        <category>vmware</category>
      </categories>
      <tags>
        <tag>vmware</tag>
      </tags>
  </entry>
  <entry>
    <title>字体替换</title>
    <url>/posts/7e3491fa/</url>
    <content><![CDATA[字体替换1. 方式一1. 替换系统字体
powershell 命令

覆盖文件move-item [源文件] [目标文件] -force

删除文件
delete-item [文件]



重启电脑，进入安全模式，然后打开 CMD 命令行窗口，将需要替换的字体放到下 c:\fonts 目录下，然后执行以下命令：
xcopy C:\fonts C:\Windows\Fonts

2. 方式二（无须进入安全模式，推荐）1. 替换 CMD 默认字体
如果强制覆盖了 SimSun &amp; NSimSun (TrueType) 和 SimSun-ExtB (TrueType)（原始字体分别对应 simsun.ttc 和 simsunb.ttf），会出现重启之后无法打开 CMD 命令行窗口的情况，所以需要对 CMD 命令行的默认字体做切换。

运行 regedit，然后打开如下的键：HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Console\TrueTypeFont，如下图所示：


鼠标右键，然后新建字符串值：


输入 0 或者 00 或者 000 或者 0000，每增加一个字体，增加一个0，这里增加的 Consolas-with-Yahei 第四个新的字体，因此使用的是0000，然后选中 0000 这一项，修改，在弹出框中输入字体 Consolas-with-Yahei，如下所示：


这样子就修改完成了，我们需要进入到 CMD 下，然后在窗口标题栏上右键 -&gt; Options -&gt; 打开字体面板， 发现没有出现注册表中的字体，我们需要回到 CMD 下，输入以下命令：
chcp 437

然后会切换字体。这时候再来看字体这里，就会出现新的字体，选择我们需要的字体，然后确定就OK了。
这里附带一个永久修改 Active Code Page 的办法：
有时候，我们的 CMD 的 codepage 和字体等会变化，比如突然由中文变成英文的 codepage（因为一些sh程序的干扰）
下面是修正方法：
进入 HKEY_CURRENT_USER\Console\%SystemRoot%_system32_cmd.exe，编辑 CodePage 项，设置为如下的数值：

数值含义如下：

十六进制 000003a8 或十进制 936，表示 936 (ANSI&#x2F;OEM - 简体中文 GBK)。
十六进制 000001b5 或十进制 437，表示 437 (OEM - 美国)。


效果如下图所示：


2. 替换系统字体键盘上 Windows + R，打开运行后输入 regedit。
找到路径：计算机\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Fonts，如下图所示：




点击后面有默认字样的字体，鼠标右键，修改：Microsoft YaHei &amp; Microsoft YaHei UI (TrueType)，这是系统默认的字体。如下图所示。


点击确定后，再找到 Microsoft YaHei Bold &amp; Microsoft YaHei UI Bold (TrueType)，检查是否一致。


重启电脑，字体生效。
]]></content>
      <categories>
        <category>运维</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>字体</tag>
      </tags>
  </entry>
  <entry>
    <title>windows 常用命令</title>
    <url>/posts/7101b844/</url>
    <content><![CDATA[目录转换磁盘convert [driver] /fs:ntfs
查看局域网所有IParp -a
CMD临时代理set http_proxy=http://127.0.0.1:1080set https_proxy=http://127.0.0.1:1080
设置IP、DNS、网关netsh interface ip set address name=&quot;本地连接&quot; source=static addr=192.168.132.5 mask=255.255.255.0netsh interface ip set address name=&quot;本地连接&quot; gateway=192.168.132.1 gwmetric=0netsh interface ip set dns name=&quot;本地连接&quot; source=static addr=192.168.132.1 register=PRIMARYnetsh interface ip set wins name=&quot;本地连接&quot; source=static addr=none
查看IP、DNS、网关netsh interface ip show address
清除DNS缓存ipconfig /flushdns

重置Winsock目录netsh winsock reset

tasklist
&#x2F;S     system           指定连接到的远程系统。  
&#x2F;U     [domain]user    指定使用哪个用户执行这个命令。  
&#x2F;P     [password]       为指定的用户指定密码。  
&#x2F;M     [module]         列出调用指定的 DLL 模块的所有进程。如果没有指定模块名，显示每个进程加载的所有模块。  
&#x2F;SVC                   显示每个进程中的服务。  
&#x2F;V                      指定要显示详述信息。  
&#x2F;FI    filter           显示一系列符合筛选器指定的进程。  
&#x2F;FO    format           指定输出格式，有效值: “TABLE”、”LIST”、”CSV”。  
&#x2F;NH                     指定栏标头不应该在输出中显示。只对 “TABLE” 和 “CSV” 格式有效。

taskkill
TASKKILL [&#x2F;S system [&#x2F;U username [&#x2F;P [password]]]]  
{ [&#x2F;FI filter] [&#x2F;PID processid | &#x2F;IM imagename] } [&#x2F;F] [&#x2F;T]

端口转发# 执行命令netsh interface portproxy add v4tov4 listenaddress=[LOCAL_HOST]  listenport=[LOCAL_PORT]  connectaddress=[TARGET_HOST] connectport=[TARGET_PORT]# 例netsh interface portproxy add v4tov4 listenaddress=100.120.9.96  listenport=2222  connectaddress=10.206.230.177 connectport=22# 查看现有的配置netsh interface portproxy show all# 删除原有的端口转发netsh interface portproxy delete v4tov4 listenaddress=[LOCAL_HOST]  listenport=[LOCAL_PORT]# 例netsh interface portproxy delete v4tov4 listenaddress=100.120.9.96  listenport=2222

Diskpart 手动创建 EFI、MSR 引导分区用傲梅分区助手将磁盘转换为GPT格式创建 EFI 分区diskpartlist diskselect disk x   (选择需要的硬盘)create partition efi size=100assign letter=bformat quick fs=FAT32

创建 msr 分区create partition msr size=16  (Win 10 默认是16M) 

创建 Recovery 分区 (WindowsRE)create partition primary size=450format quick fs=ntfs label=&quot;Recovery&quot;assign letter=&quot;R&quot;set id=&quot;de94bba4-06d1-4d40-a16a-bfd50179d6ac&quot;gpt attributes=0x8000000000000001      ( 8 和 1之间有14个0)

IP释放、更新、以及清除 DNS
在桌面上，按Windows键，然后输入CMD。
右键单击“ 命令提示符”，然后选择“以管理员身份运行”。
在命令提示符下输入ipconfig / release。
等待几秒钟可以得到IP地址已释放。
在命令提示符下输入ipconfig /renew。
等待几秒钟可以得到已重新建立IP地址。
在命令提示符下输入ipconfig / flushdns。
关闭命令窗口并尝试建立连接。

]]></content>
      <categories>
        <category>运维</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>windows 常用配置</title>
    <url>/posts/d741411d/</url>
    <content><![CDATA[目录设置U盘插入电脑后自动打开文件夹播放更改媒体或设备的默认设置


选择需要的选项即可，如下图所示：


修改时区方法一
使用「Windows 设置」自动设置时区


使用 Windows + I 快捷键打开「Windows 设置」
打开「时间和语言」——「日期和时间」
启用「自动设置时区」开关



方法二使用「命令提示符」调整时区，执行以下命令以查看当前时区设置：
tzutil /g

如果要调整时区设置，可使用以下命令：
tzutil /s &quot;China Standard Time&quot;



上述是以中国标准时间为例，如果要列出所有可用时区选项，可用：
tzutil /l



方法三
使用 Powershell 调整时区。

使用 Windows + X 快捷键打开快捷菜单——选择 Windows PowerShell（管理员），执行以下命令查看当前时区设置：
Get-TimeZone

执行以下命令列出可用时区列表：
Get-TimeZone -ListAvailable



使用以下命令调整时区设置：
Set-TimeZone -Name &quot;China Standard Time&quot;

解决Windows 10下蓝牙设备无法删除的故障在更换了一张无线网卡（蓝牙适配器跟无线网卡是集成在一起的）后，蓝牙设备全失联了，想要重新配对，可是原有设备无法删除。


蓝牙设备无法删除，折腾了好久啊，最后突然发现了如下方法，打开“计算机管理”中的“设备管理器”节点，在该节点上右击后点“查看”然后勾选“显示隐藏的设备”如下图：


勾选“显示隐藏的设备”， 在右边蓝节节点，找到要删除的蓝牙设备，在其上点右键，选择“卸载设备”。


卸载设备，依次把要删除的多个设备全卸载，问题就解决了。
删除右键菜单 AMD 选项打开 regedit 菜单，进入到 计算机\HKEY_CLASSES_ROOT\Directory\Background\shellex\ContextMenuHandlers\ace 路径，找到默认值，右键删除即可。

]]></content>
      <categories>
        <category>运维</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>windows 常见错误</title>
    <url>/posts/dfcbdf9f/</url>
    <content><![CDATA[目录dll 注册for %1 in (%windir%\system32\*.dll) do regsvr32.exe /s %1for %1 in (%windir%\system32\*.dll) do regasm.exe /s %1

模块xxx已加载，但找不到入口点DllRegisterServer



使用regasm注册.net com组件出现不是有效的.net程序集的解决办法在电脑上装有VS 2008和VS 2010.使用VS 2010编写了一个C# com组件:MyCom（基于.net framework4.0），然后使用VS 2008的命令提示工具运行命令：regasm MyCom，结果提示错误：RegAsm：error RA0000,“MyCOM”不是有效的.net程序集。开始百思不得其解。后来才醒悟到VS 2008的命令提示工具运行的regasm.exe是vs2008版本，它可能注册不了基于.net framework4.0的C# com组件。后来发现确实是这样的。如果一台机子上装有VS 2008和VS 2010，那么它就有两个版本的regasm.exe，分别存放的位置是C:\Windows\Microsoft.NET\Framework\v2.0.50727和C:\Windows\Microsoft.NET\Framework\v4.0.30319.使用VS 2010版本的regasm能注册vs2008编写的C# com组件，但是使用vs2008版本的regasm不能注册基于.net framework4.0的C# com组件。
程序无法正常启动 0xc0000142 解决方法在命令下执行
for %1 in (%windir%\system32\*.dll) do regsvr32.exe /s %1 
完成后重启如果不能解决，继续以管理员身份运行命令提示符中依次执行以下命令
DISM/Online /Cleanup-image /ScanhealthDISM/Online /Cleanup-image /RestorehealthSfc /scannow]]></content>
      <categories>
        <category>运维</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>运维常用命令-常用篇</title>
    <url>/posts/e9ae7850/</url>
    <content><![CDATA[1. ls 系列
-F：根据文件、目录等信息在文件名或目录名最后给予附加数据结构

*  代表可执行文件；
&#x2F;  代表目录
&#x3D;  代表socket文件
|  代表FIFO文件
@  代表连接文件


1. 只显示文件类型，排除目录方法一：
^[^d] 是一个正则表达式，[^d] 表示字符串含有一个不是 d 的字符， ^d 表示以 d 开头，^[^d] 表示不以 d 开头

ls -l | grep ^[^d]

所以只显示文件夹的写法为：
ls -l | grep ^d

方法二：ls -l | grep -v ^d

如果文件名包含空格，可以用下面命令：
ls -l | grep -v [/$]


2. sed 系列1. 替换字符串sed &#x27;s/old/new/g&#x27;

3. rm 系列1. 删除带有指定字符串的文件方法一：
注意字符串如果含有特殊字符，必须做转义处理，否则默认会删除当前目录下的所有文件。

rm -f *字符串*

方法二：find -type f -name &#x27;*字符串*&#x27; -delete

4. awk 系列1. 获取某一行中指定字符后的内容比如有个xxx.txt文件，里面有很多行内容，其中有行内容为ro.xxx&#x3D;123，要想获取到123这个值，可以如下处理
#!/bin/shNAME=`cat xxx.txt | grep &#x27;ro.xxx&#x27; | awk -F &#x27;=&#x27; &#x27;&#123;print $2&#125;&#x27;`echo $NAME

5. $(cd dirname $0;pwd)cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd 等同于 $(dirname $(readlink -f &quot;$0&quot;))
# 在/home/admin/test/下新建test.sh内容如下：cd `dirname $0`echo `pwd` # 然后返回到/home/admin/执行sh test/test.sh # 运行结果:/home/admin/test

6. basename1. basename打印除上层路径外的基础文件名；当文件名后存在后缀时，除去后面的后缀，如 # basename include&#x2F;stdio.h .h 只会打印出 stdio
2. basename -s-s参数后面指定要去除的后缀字符，即：# basename -s .h include&#x2F;stdio.h 同 # basename include&#x2F;stdio.h .h 一样只会打印出 stdio
3. basename -a-a参数可追加执行多个文件路径，取每一个路径的基础文件名并打印。用法如下图：


7. pwd1. pwd -L打印出环境变量 $PWD 的值，如果 PWD 赋值为当前工作路径，pwd 默认同 pwd -L
2. pwd -P打印真实路径，不打印链接的路径，区别如图：


8. watch命令参数：
-n 或 –interval watch 缺省每2秒运行一下程序，可以用 -n 或 -interval 来指定间隔的时间。
-d 或 –differences 用 -d 或 –differences 选项 watch 会高亮显示变化的区域。 而 -d&#x3D;cumulative 选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。
-t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。
示例：
watch -n 1 -d &quot;&lt;command&gt;&quot;

9. grep


元字符
功能
例子
匹配什么



^
锚定行的开始
&#x2F;^love&#x2F;
匹配所有以love开头的行


$
锚定行的结束
&#x2F;love$&#x2F;
匹配所有以love 结束的行


.
匹配一个字符
&#x2F;l..e&#x2F;
匹配这样的行，这些行包含这样的字符：第一个字符是l,紧跟着两个字符，然后是e


*
代表0个或多个先前字符
&#x2F;*love&#x2F;
匹配所有这样的行，有0个或多个空格，空格后跟着love


[]
匹配字符组中的一个字符
&#x2F;[Ll]ove&#x2F;
匹配所有包含love或者Love的行


[^]
匹配一个不在范围内的字符
&#x2F;[^A-Z]ove&#x2F;



&lt;
锚定单词的开始
&lt;love
匹配所有这样的行，这些行包含以love开头的单词（vi和grep支持这个功能）


&gt;
锚定单词的结束
Love&gt;
匹配所有这样的行，这些行包含以love结束的单词（vi和grep支持这个功能）


(..)
标记后面用到的匹配字符
&#x2F;(love)able1rs&#x2F;
最多可以使用9个标签。第一个标签是模板最左边的部分。在本例子中，模板love保存的标签为1，后面的1指得就是love；本例子搜索的是这样的行，这些行包含这样的字符，在Loveabel后面跟着lovers


x{m}
M次复制字符x




x{m,}
至少m次复制字符x




x{m,n}
至少m次，至多n次复制字x




w
文字和数字字符，[A-Za-z0-9]
Lw*e
匹配一个l字符，紧跟着0个或多个文字或数字字符，然后是e


W
同上




b
单词分界线
bloveb
仅仅匹配单词love


递归查找某个文本内容
R 表示递归，就是在当前目录找不到就去子目录找 
E 表示把文件名也打印出来 
n 打印此行在文件中的位置。

示例：
# 这句可以显示在哪个文件里包含3306grep -Rl &quot;3306&quot;# 可以显现文件名，行数grep -REn &quot;3306&quot;

查找替换内容# sed -i &quot;s/[原字符串]/[新字符串]/g&quot; `grep &#x27;[原字符串]&#x27; -rl /opt/kubernetes`# 示例：替换/opt/kubernetes下所有文件内容为242的换成245sed -i &quot;s/242/245/g&quot; `grep &#x27;242&#x27; -rl /opt/kubernetes`

10. 查看端口占用查看那些程序使用tcp的80端口$fuser -v -n tcp 80$fuser -v 80/tcp  

]]></content>
      <categories>
        <category>运维</category>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title>windows 开启 FTP</title>
    <url>/posts/b7b934f4/</url>
    <content><![CDATA[WIN10开启FTP1.控制面板 –&gt; 程序–&gt; 启用或关闭windows功能

2.左下角搜索栏搜索IIS（iis）3.右键添加FTP站点

4.创建站点名字和目录5.绑定本机IP地址，SSL勾选无SSL

6.身份验证 –&gt;匿名，授权 –&gt; 所有用户，权限 –&gt;读取写入7.控制面板 –&gt; 系统和安全 –&gt; Windows Defender 防火墙 –&gt; 允许应用或功能通过Windows Defender 防火墙 8.更改设置 –&gt; 勾选 FTP 服务器9.设置应用路径（C:\Windows\System32\svchost.exe）10.使用ftp访问（格式为ftp:&#x2F;&#x2F; + 要访问的IP地址）]]></content>
      <categories>
        <category>运维</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title>运维常用命令-常用配置篇</title>
    <url>/posts/c3218428/</url>
    <content><![CDATA[禁止pingLinux默认是允许Ping响应的，系统是否允许Ping由2个因素决定的：A、内核参数，B、防火墙，需要2个因素同时允许才能允许Ping，2个因素有任意一个禁Ping就无法Ping。
内核参数设置允许PING设置
临时允许PING操作的命令为：echo 0 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all

永久允许PING配置方法。
&#x2F;etc&#x2F;sysctl.conf 中增加一行
  net.ipv4.icmp_echo_ignore_all=0

如果已经有net.ipv4.icmp_echo_ignore_all这一行了，直接修改&#x3D;号后面的值即可的（0表示允许，1表示禁止）。
修改完成后执行以下命令，使新配置生效。
sysctl -p

防火墙设置
注：此处的方法的前提是内核配置是默认值，也就是没有禁止Ping。

以Iptables防火墙为例
允许PING设置iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPTiptables -A OUTPUT -p icmp --icmp-type echo-reply -j ACCEPT

或者也可以临时停止防火墙操作的。
service iptables stop

禁止PING设置iptables -A INPUT -p icmp --icmp-type 8 -s 0/0 -j DROP

]]></content>
      <categories>
        <category>运维</category>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>运维配置</tag>
      </tags>
  </entry>
  <entry>
    <title>运维常用命令-时间篇</title>
    <url>/posts/c72fbcb5/</url>
    <content><![CDATA[linux 查看系统当前时间，修改时间，查看文件时间查看时间和日期date

设置时间和日期例如：将系统日期设定成2018年6月8日的命令
date -s 06/08/2018

将系统时间设定成下午10点46分03秒的命令
date -s 10:46:03

查看时区date -R

查询系统当前日期date +&quot;%Y-%m-%d&quot;

查询系统当前时间date +&quot;%H-%M-%S&quot;

查看文件时间ls -l 或者 ll


要显示秒（实际更精确），可以用 --full-time 参数


要显示更多信息，用 stat 命令：
]]></content>
      <categories>
        <category>运维</category>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>运维配置</tag>
      </tags>
  </entry>
  <entry>
    <title>运维常用命令-系统篇</title>
    <url>/posts/85b72ed0/</url>
    <content><![CDATA[设置 hostname
hostname 存放于 /etc/host/hostname

hostnamectl set-hostname [hostname]

查看用户和用户组查看用户列表cat /etc/passwd



查看用户组列表cat /etc/group



查看系统中有哪些用户cut -d : -f 1 /etc/passwd



查看可以登录系统的用户cat /etc/passwd | grep -v /sbin/nologin | cut -d : -f 1



查看用户操作w (root权限)



查看某一用户w &lt;user_name&gt;



查看登录用户who



查看用户登录历史记录last



修改root用户密码passwd



root用户修改其他用户密码passwd &lt;user_name&gt;



重启init 6init 6 基于一系列 /etc/inittab 文件，并且每个应用都会有一个相应 shutdown 脚本。init 6 调用一系列 shutdown 脚本(&#x2F;etc&#x2F;rc0.d&#x2F;K*)来使系统优雅关机。
rebootreboot 并不执行这些过程，reboot更是一个 kernel 级别的命令，不对应用使用 shutdown 脚本。
综上平常推荐使用 init 6 命令，只有在系统出了问题的时候才比较推荐使用 reboot 命令。
]]></content>
      <categories>
        <category>运维</category>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>运维配置</tag>
      </tags>
  </entry>
  <entry>
    <title>gitlab 安装</title>
    <url>/posts/fc8249c5/</url>
    <content><![CDATA[目录安装
gitlab 运行需要较大内存，建议将虚拟机内存设置为 4GB 以上，并保证相关端口不被其他进行占用。

安装相关依赖yum -y install policycoreutils openssh-server openssh-clients postfix

设置 postfix
设置 postfix 为开机自启动，目的：支持 gitlab 邮件发送。

systemctl enable postfix &amp;&amp; systemctl start postfix

rpm 包安装官方参考链接：https://packages.gitlab.com/gitlab/gitlab-ce/install#bash-rpm
使用以下命令进行快速安装：
curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash


EL 是 Red Hat Enterprise Linux 的简写 

EL6 软件包用于在 Red Hat 6.x, CentOS 6.x, and CloudLinux 6.x 的安装。
EL5 软件包用于在 Red Hat 5.x, CentOS 5.x, CloudLinux 5.x 的安装。
EL7 软件包用于在 Red Hat 7.x, CentOS 7.x, and CloudLinux 7.x 的安装。


所以这里我们采用安装 EL7 的模式，安装命令如下：
官方参考链接：https://packages.gitlab.com/gitlab/gitlab-ce/packages/el/7/gitlab-ce-15.8.5-ce.0.el7.x86_64.rpm
sudo yum -y install gitlab-ce-15.8.5-ce.0.el7.x86_64

安装完毕后的主体文件都在 /opt/gitlab/ 目录下，可自行翻阅按需修改。
修改 root 密码官方修改密码：(http://docs.gitlab.com/ce/security/reset_root_password.html)
在root用户下，执行
# 老版命令gitlab-rails console production# 新版命令gitlab-rails console -e production

获得用户数据，修改用户密码
[root@svr34 bin]# gitlab-rails console productionLoading production environment (Rails 4.2.5.2)irb(main):001:0&gt; user = User.where(id: 1).first=&gt; #&lt;User id:1 @root&gt;irb(main):002:0&gt; user.password=&quot;7613302589&quot;=&gt; &quot;12345678&quot;irb(main):003:0&gt; user.password_confirmation=&quot;7613302589&quot;=&gt; &quot;12345678&quot;irb(main):004:0&gt; user.save!=&gt; trueirb(main):005:0&gt; quit

修改访问 URL编辑 gitlab.rb 文件。
# vim /etc/gitlab/gitlab.rbexternal_url &#x27;http://192.168.50.245:8138&#x27;


此处注意别使用已被占用的端口！（如8080）



重置并启动 Gitlab重置：

注：第一次预计需要几分钟

gitlab-ctl reconfigure

启动：
gitlab-ctl restart

端口用途一览




端口号
归类
用途



8060
Nginx
用途不明


8138
Nginx
第二个 nginx 的端口，就是 gitlab 实例的主端口，所有外部访问的 http 均通过 gitlab 内置的 nginx 服务器处理，并使用该端口，当然暴露地址为外网0.0.0.0


9121
Redis
redis_exporter 的 9121，是 gitlab 内置 redis 数据库，只向本机暴露


9090
Prometheus
向本机暴露，用途应该是创建和管理时间序列事件的触发，如通知那些功能


9187
PostgreSQL
postgres_expoter 的9187，是 gitlab 内置的 postegres 数据库，向本机暴露


9093
Ruby
config.ru 的 9093，gitlab 使用 ruby 的 unicorn 作为 app server 运行，管理 worker 等功能，比较重要，默认为 8080，由于 8080 比较受欢迎，这个端口基本上都得改，暴露可自行设定；


9168
Ruby
用途不明


9100
NodeJS
node_exporter 的 9100，一个 nodejs 进程，用于实现测量所在的机器的资源状态比如cpu、内存、硬盘等数据的功能


9229
Go
gitlab-workhors 的 9229，一个是用 go 语言写的组件，是 gitlab 发展途中添加进来的用于优化 git over http 的组件，具体历史可以查看这里了解gitlab-workhors的由来


8082
其他
sidekiq 的 8082，是一种多线程后台处理系统，用于实现 gitlab 异步运行任务


9236
其他
gitaly 的9236，是一个能够提供访问 git 仓库的 RPC 远程调用功能的服务，属于 gitlab 的一个托管组件gitlab 的配置文件位于/etc/gitlab/gitlab/gitlab.rb，使用vim等工具可以直接修改，各种参数配置修改可以参考官方文档


nginx 代理关闭 selinux
什么是selinux ？
SELinux：即安全增强型 Linux（Security-Enhanced Linux）
它是一个 Linux 内核模块，也是 Linux 的一个安全子系统
它主要由美国国家安全局开发，主要作用是最大限度地减小系统中服务进程可访问的资源（最小权限原则）
为什么要关闭 selinux ？
有的软件对于 selinux 的安全规则支持不够好，就会建议在安装前把 selinux 先关闭，例如 k8s，本次在启动 nginx 的过程中发现 gitlab 会报 502 的错误，经由使用 journalctl -xe  命令发现有 selinux 的相关错误信息，所以需要把 selinux 做一次人工的手动禁用。
selinux 常用命令：
# 查看审计日志cat /var/log/audit/audit.log# 分析一个文件sealert -a /var/log/audit/audit.log# 查询系统中的布尔型规则及其状态getsebool -a

selinux的三种运行模式:

enforcing: 强制模式，SELinux 正在运行中，已经在限制 domain&#x2F;type
permissive: 宽容模式：SELinux 正在运行中，但仅发出警告信息,并不会实际限制 domain&#x2F;type 的存取（permissive模式可以用在测试环境中供调试规则时使用）
disabled: 关闭，SELinux 没有实际运行。

sestatus -v # 查看当前信息getenforce # 查看当前运行模式

临时关闭# 0: Permissive# 1: Enforcingsetenforce 0

永久关闭# vim /etc/selinux/configSELINUX=disabled

外部 nginx 安装添加 Nginx 到 YUM 源
sudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm

安装 nginx
sudo yum install -y nginx

启用 nginx
sudo systemctl enable nginx.service &amp;&amp; sudo systemctl start nginx.service

Nginx 常用配置目录如下：
# 资源文件目录/usr/share/nginx/html/├── 50x.html└── index.html# 配置文件主目录/etc/nginx/├── conf.d│   ├── default.conf│   └── gitlab.conf # gitlab 配置文件├── fastcgi_params├── mime.types├── modules├── nginx.conf # nginx 根目录配置文件├── scgi_params└── uwsgi_params

代理 gitlab 内部 nginxgitlab 服务器主体框架如下：


nginx 配置文件gitlab.conf 配置文件内容如下：
# 主访问入口server &#123;  listen 80;  server_name gitlab.yahya.top;  # 入口反向代理  location / &#123;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_redirect off;    # 配置反向代理地址    proxy_pass http://192.168.50.245:8138;    proxy_http_version 1.1;    # 一定记得要配置 body_size    client_max_body_size 1024m;  &#125;&#125;

修改 gitlab.rb 文件

external_url 的配置直接影响到 gitlab 系统中所有 http 入口的地址，比如 git 仓库的 http 地址，gitlab 访问页面的地址，注册回调的地址，邮件验证的地址等。

编辑 gitlab.rb 文件
vim /etc/gitlab/gitlab.rb

配置域名external_url &#x27;http://gitlab.yahya.top&#x27;

修改对外主端口nginx[&#x27;listen_port&#x27;] = 8138

max_body_size 配置gitlab 是可以使用 http 和 ssh 两种方式来进行git操作的，当使用 http 时，是通过post请求发送内容，若 nginx 在代理时没有设置 body_size 时将会收到：413 Request Entity Too Large 的错误，push 不了代码，内外部的 nginx 都需要配置，在 gitlab.rb 中添加：
nginx[&#x27;client_max_body_size&#x27;] = &#x27;1024m&#x27;

认证普通用户
默认情况下注册的用户是需要进行审批，否则在没有审批的情况下登录会报以下的错误：
Your account is pending approval from your GitLab administrator and hence bl

登录 root 用户，点击头像这里


点击 Overview -&gt; Users -&gt; Pending approval，审批需要注册的用户即可。


临时关闭分支保护
git push 报错 pre-receive hook declined，原因为 master 为受保护分支，无法强推代码到 master 分支上。使用 Owner 以及 Admin 角色账号推送都无法成功。

Settings -&gt; Repository -&gt; Protected Branches 临时 Unprotect master 分支(强推成功后一定要重新添加为受保护的分支)


关于 GitLab 访问权限
访问权限 - Visibility Level：
这个是在建立项目时就需要选定的，主要用于决定哪些人可以访问此项目，包含 3 种：

Private - 私有，只有属于该项目成员才有看到
Internal - 内部，用 GitLab 账号的人都看到
Public - 公开，任何人可以看到

开源项目和组设置的是 Internal。
行为权限：
在满足行为权限之前，必须具备访问权限（如果没有访问权限，那就无所谓行为权限了），行为权限是指对该项目进行某些操作，比如提交、创建问题、创建新分支、删除分支、创建标签、删除标签等角色。

官方权限解释文档：https://docs.gitlab.com/ee/user/permissions.html#project-members-permissions


Guest - 访客
可以创建 issue、发表评论，不能读写版本库。

Reporter  - 报告者
可以理解为测试员、产品经理等，一般负责提交 issue 等 可以克隆代码，不能提交，QA、PM 可以赋予这个权限。

Developer - 开发者
可以克隆代码、开发、提交、push，RD 可以赋予这个权限。

Master - 主人
可以创建项目、添加 tag、保护分支、添加项目成员、编辑项目，核心 RD 负责人可以赋予这个权限。

Owner - 拥有者
可以设置项目访问权限 - Visibility Level、删除项目、迁移项目、管理组成员，开发组 Leader 可以赋予这个权限。

Maintainer - 维护者
权限与 Owner 差不多，但无删除项目等权限。


参见错误502 错误：
首先保证Gitlab可用运行内存大于 4G，端口未被占用
再赋予权限：
chmod -R 755 /var/log/gitlab

再重置重启，访问后仍然可能遇到502，不过我刷新2次就一切ok了。
参考文章使用Nginx搭建并代理GitLab服务器
Centos7 搭建Gitlab服务器并配置项目全过程
gitlab配置域名并https访问
linux(centos8):禁用selinux(临时关闭&#x2F;永久关闭)
]]></content>
      <categories>
        <category>运维</category>
        <category>常用安装</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo 安装</title>
    <url>/posts/9d95a809/</url>
    <content><![CDATA[目录yum 源配置将 yun 源设置成阿里云的，可以大大提高安装速度，推荐使用，所需命令如下。
rm -rf /etc/yum.repos.d/*  # 删除本地repo文件curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo  ## 下载阿里云centos7镜像源yum clean all; yum makecache # 清理缓存、建立缓存

如果担心中途出其他问题先考虑先把原有 /etc/yum.repos.d 目录下的文件做一次备份方便还原。
git 安装yum install -y git

nodejs 安装wget https://nodejs.org/dist/v16.14.2/node-v16.14.2-linux-x64.tar.xztar -vxf node-v16.14.2-linux-x64.tar.xz   # 解压node.js软件压缩软件包mv node-v16.14.2-linux-x64 /usr/local/bin # 移动node到/usr/local/bin目录下cd /usr/local/bin/ # 进入/usr/local/binmv node-v16.14.2-linux-x64/ node # 修改node-v16.14.2-linux-x64 名称为 node

然后修改 /etc/profile 文件，增加以下配置：
export N_PREFIX=/usr/local/bin/node  # 设置node软件家目录的环境变量export PATH=$PATH:$N_PREFIX/bin  # 设置node软件到bin目录下环境变量  实现bin目录下命令的全局使用

最后执行 source /etc/profile 使配置生效，用以下命令验证确认 nodejs 已经安装成功。
node -vnpm -v

n 安装使用 n 可以对 nodejs 进行多版本管理，推荐使用 n 来切换管理 nodejs 版本，安装命令如下：
npm install -g n

常用命令如下：
n stable # 安装最新的稳定版n lts # 安装最新的 LTS 版n &lt;version&gt; # 安装指定的 node 版本

hexo 安装hexo 的安装比较简单，直接按照官网的说明步骤安装即可。首先是基础软件 nodejs 以及 git，这两个都是常用基础软件所以就不介绍细节了，官网直接安装即可。 按照使用了 npm 这个 nodejs 库管理软件，由于默认源在国外经常连接超时，所以首先需要修改成国内的镜像源，这里是改成了淘宝的镜像源。
npm config set registry https://registry.npm.taobao.org

接下来就是使用 npm 命令安装 hexo，推荐使用 cnpm
npm install -g cnpm --registry=https://registry.npm.taobao.orgcnpm install -g hexo-cli

关闭防火墙systemctl stop firewalld; systemctl disable firewalld

关闭 selinux临时关闭# 0: Permissive# 1: Enforcingsetenforce 0

永久关闭# vim /etc/selinux/configSELINUX=disabled

hexo 初始化

站点配置文件：站点目录下的_config.yml，路径为&lt;folder&gt;\_config.yml
主题配置文件：站点目录下的themes文件夹下的，主题文件夹下的_config.yml，路径为&lt;folder&gt;\themes\&lt;主题文件夹&gt;\_config.yml


新建一个目录，作为统一存放 markdown 文件的目录，然后进入到该目录下执行以下命令。
hexo init

markdown 菜单目录生成hexo 文件首部加上 toc: true，就可以在文章左侧生成目录，且可以正常跳转。因此你只用简单的加上toc: true即可，任何其他的操作都是不必要的。
如果你装了hexo的toc插件，请你删除它，它会影响你目录的跳转！使用下面的语句删除toc插件
npm remove hexo-toc --save

图片相对路径配置
hexo-renderer-marked 3.1.0 引入了一个新的选项，其允许你无需使用 asset_img 标签插件就可以在 markdown 中嵌入图片，如需启用，编辑 _config.yml，添加以下配置：

post_asset_folder: truemarked:  prependRoot: true  postAsset: true

安装以下依赖：
npm install https://github.com/7ym0n/hexo-asset-image --save # 解决 &lt;img /&gt; 图片标签相对路径问题npm install hexo-simple-image --save # 解决 ![]() 图片标签相对路径问题

最终效果如下：
├── hexo-asset-image@0.0.3 (git+ssh://git@github.com/7ym0n/hexo-asset-image.git#6c88c98214765112d148850a646ddca379fcdcfe)├── hexo-simple-image@1.0.4

这样子以 &lt;img /&gt; 和 ![]() 包裹的相对路径图片都可以正常显示了。
创建自定义 about 页博客是用的hexo，打算增加一个about页。
根据文档，当然非常简单，只需要：
hexo new page &quot;about&quot;

然后修改所用主题目录下的_config.yml文件，将menu中about前的注释去掉。
menu:  home:  / || home  about:  /about/ || user  tags:  /tags/ || tags  ...

然后修改source/about/目录中的index.md文件即可。
但是，我想要在页面中显示表格，而且不用markdown格式的表格。
经谷歌，可以直接在index.md中写html代码，这太好了。
可是，写好代码，hexo g之后，怪异的现象出现了，about页面中，页顶标题下是许多空白行，表格要下拉到页面最底部才可见。
又搜索之后，找到了答案，将 index.md 改名为 index.html，修改之后，马上显示正常了。
主题方案fluid代码高亮主题选择方案：https://highlightjs.org/static/demo/
使用手册：https://hexo.fluid-dev.com/docs/start/#%E4%B8%BB%E9%A2%98%E7%AE%80%E4%BB%8B
隐藏文章
TIP
隐藏会使文章在分类和标签类里都不显示
隐藏后依然可以通过文章链接访问

如果想把某些文章隐藏起来，不在首页和其他分类里展示，可以在文章开头 Front-matter (opens new window) 中配置 hide: true 属性。
---title: 文章标题index_img: /example.jpgdate: 2019-10-10 10:00:00hide: true---以下是文章内容

next
参考配置：https://blog.csdn.net/as480133937/article/details/100138838

本地搜索NexT 主题自带了一个搜索功能 Local Search，即在编译文件时本地生成一个数据库，放在网站根目录下，用户借助此数据库进行搜索查询。 安装：
npm install hexo-generator-searchdb --save

在 NexT 的配置文件中打开：
local_search:  enable: true

图片懒加载# Vanilla JavaScript plugin for lazyloading images.# For more information: https://github.com/ApoorvSaxena/lozad.jslazyload: true

yilia-plus
参考配置：https://gitee.com/nate-lin/yilia-plus

远程发布github免密关联ssh-keygen

然后将生成的 id_rsa.pub 文件内容关联到 github 的 SSH and GPG Keys 菜单的下的 ssh key 列表


新建仓库仓库名称格式 &lt;你的 GitHub 用户名&gt;.github.io ，站点会通过这个名称实现域名访问

注意：仓库的访问权限需要设置为 public，否则无法通过 .github.io 域名的形式进行访问。



github page 暴露
参考链接：https://docs.github.com/en/pages/quickstart

默认情况下新建的仓库在 github page 是不关联任何分支的，即为 None，所以需要调整 Pages 配置为以下图示效果：


cloudflare 加速经实测 githubpage 在国内很容易被墙，所以决定在现有的 cloudflare 网站上做一层 CNAME 域名重定向访问到 github page 上，解决国内无法直接访问 github page 的问题，操作步骤如下：
创建 CNAME DNS 解析记录，最终访问域名为 https://blog.yahyav2rayssr.top，cloudflare 配置如下：


另外还需要在 github 上面设置自定义域名，填写位置如下：


hexo 远程仓库配置安装发布插件cnpm install hexo-deployer-git --save

修改 hexo 配置增加 github 相关配置，内容如下：
# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repo: git@github.com:yaoyuming/yaoyuming.github.io.git  branch: master

文件压缩hexo-neat
hexo-neat 主要用来压缩 html，css 以及 js 文件。

安装 hexo-neat在站点根目录下
npm install hexo-neat --save

添加相关配置在站点配置文件 _config.yml 添加相关配置，直接添加到站点配置文件的末尾就可以。可以安装自己的需求去自定义配置，配置内容如下：
# hexo-neat# 博文压缩neat_enable: true# 压缩htmlneat_html:  enable: true  exclude:# 压缩css  neat_css:  enable: true  exclude:    - &#x27;**/*.min.css&#x27;# 压缩jsneat_js:  enable: true  mangle: true  output:  compress:  exclude:    - &#x27;**/*.min.js&#x27;    - &#x27;**/jquery.fancybox.pack.js&#x27;    - &#x27;**/index.js&#x27;  

hexo-neat 插件注意事项在使用hexo-neat插件时，可以在命令窗口中看到各个文件的压缩率，于是可以通过跳过一些文件让效率更高。
跳过压缩文件的正确配置方式

压缩 html 时不要跳过 .md 文件和 .swig 文件
.md 文件就是 markdown 文件，如果跳过压缩 .md 文件，而又刚好在文章中使用到了 tab 标签，那么当 hexo 在生成静态页面时就会发生解析错误。这会导致使用到了 tab 标签的页面生成失败而无法访问。
.swig 文件是模板引擎文件，也就是 hexo 可以通过这些文件来生成对应的页面。如果跳过这些文件，所有页面完全没有起到压缩的效果，页面源代码里依然存在着一大堆空白。

如果按照官方插件的文档说明来配置exclude，会发现完全不起作用。这是因为配置的文件路径不对，压缩时找不到你配置的文件，自然也就无法跳过了。于是需要给这些文件指定正确的路径，万能的配置方式如下：
neat_css:  enable: true  exclude:    - &#x27;**/*.min.css&#x27;

gulp
gulp 主要用来压缩图片。

安装 gulpgulp 全局安装：
npm install --global gulp-cli

gulp 局部安装：
npm install gulp --savenpm install gulp-babel babel-preset-env babel-preset-mobx --savenpm install -D @babel/core @babel/preset-react @babel/preset-env --save

图片压缩安装：
npm install gulp-imagemin --save

最终生成的 package.json 新增内容如下：
&#123;  &quot;scripts&quot;: &#123;    &quot;compile&quot;: &quot;hexo clean &amp;&amp; hexo generate &amp;&amp; gulp minify-images&quot;  &#125;,  &quot;dependencies&quot;: &#123;    &quot;babel-preset-env&quot;: &quot;^1.7.0&quot;,    &quot;babel-preset-mobx&quot;: &quot;^2.0.0&quot;,    &quot;gulp&quot;: &quot;^4.0.2&quot;,    &quot;gulp-babel&quot;: &quot;^8.0.0&quot;,    &quot;gulp-imagemin&quot;: &quot;^7.1.0&quot;,  &#125;,  &quot;devDependencies&quot;: &#123;    &quot;@babel/core&quot;: &quot;^7.8.4&quot;,    &quot;@babel/preset-env&quot;: &quot;^7.8.4&quot;,    &quot;@babel/preset-react&quot;: &quot;^7.8.3&quot;  &#125;&#125;

gulpfile.js 配置新增 gulpfile.js，内容如下：
// 引入需要的模块var gulp = require(&#x27;gulp&#x27;);var imagemin = require(&#x27;gulp-imagemin&#x27;);// 压缩图片gulp.task(&#x27;minify-images&#x27;, function () &#123;    return gulp.src([&#x27;./public/**/*.png&#x27;, &#x27;./public/**/*.jpg&#x27;, &#x27;./public/**/*.gif&#x27;])        .pipe(imagemin(            [imagemin.gifsicle(&#123; &#x27;optimizationLevel&#x27;: 3 &#125;),            imagemin.mozjpeg(&#123; &#x27;progressive&#x27;: true &#125;),            imagemin.optipng(&#123; &#x27;optimizationLevel&#x27;: 5 &#125;),            imagemin.svgo()],            &#123; &#x27;verbose&#x27;: true &#125;))        .pipe(gulp.dest(&#x27;./public&#x27;))&#125;);

制作永久链接hexo 预设永久连结是依照日期，但是这个很容易改动，又不希望永久连结内使用文章标题（因为是中文也有可能改动），所以有必要对链接路径做自定义配置。
安装 abbrlinknpm install hexo-abbrlink --save

设定预设设定hexo的站点配置文件(_config.yml)中
使用 permalink: :year/:month/:day/:title/ 当作永久连结的设定
也就是说文章的永久连接最后会是 年/月/日/标题 这样的格式，详情可以看 hexo永久连结文档
而稍微底下一点有
permalink_defaults:

这个是可以设定自己的参数的。
自定义设定我使用 hexo-abbrlink 对每篇文章生出一个编号
设定 hexo-abbrlink在主题配置文件加上
abbrlink:  alg: crc32  # support crc16(default) and crc32    rep: hex    # support dec(default) and hex  # crc16/crc32: 差别在于编号个数的极限，crc16可以生出65535个  # dec/hex:     差别在于编号生出来是十进制还是十六进制

自定义永久连结格式我想要以作者名字为主，再加上编号来形成永久连结
permalink_defaults:  author_name: yahya   # 新增一个作者名字的参数permalink: :author_name/:abbrlink/    # 结果是：网域/作者名字/abbrlink生成编号

私人文章隐藏当一篇文章被设置为「隐藏」时，它不会出现在任何列表中（包括首页、存档、分类页面、标签页面、Feed、站点地图等），也不会被搜索引擎索引（前提是搜索引擎遵守 noindex 标签）。
只有知道文章链接的人才可以访问被隐藏的文章。
Github 地址：https://github.com/printempw/hexo-hide-posts
安装在站点根目录下执行
npm install hexo-hide-posts --save

配置在站点目录下的_config.yml中如下配置：
# hexo-hide-postshide_posts:  # 可以改成其他你喜欢的名字  filter: hidden  # 指定你想要传递隐藏文章的位置，比如让所有隐藏文章在存档页面可见  # 常见的位置有：index, tag, category, archive, sitemap, feed, etc.  # 留空则默认全部隐藏  public_generators: []  # 为隐藏的文章添加 noindex meta 标签，阻止搜索引擎收录  noindex: true

举个栗子：设置 filter: secret 之后，你就可以在 front-matter 中使用 secret: true 来隐藏文章了。
使用在文章的属性中定义 hidden: true 即可隐藏文章。
---title: &#x27;Hidden Post&#x27;date: &#x27;2021/03/05 21:45:14&#x27;hidden: true---

虽然首页上被隐藏了，但你仍然可以通过 https://hexo.test/lorem-ipsum/ 链接访问它。
你可以在命令行运行 hexo hidden:list 来获取当前所有的已隐藏文章列表。
插件也在 Local Variables 中添加了 all_posts 和 hidden_posts 变量，供自定义主题使用。
推荐主题hexo-theme-fluid
hexo-theme-next
hexo-theme-pure
hexo-theme-yilia-plus
hexo-theme-3-hexo
参考链接Hexo 博客 NexT 主题的安装使用
centos7系统部署hexo博客新手入门
使用cloudflare免费加速github page
Hexo使用Gulp压缩静态资源
使用Gulp压缩Hexo博客静态资源
node.js版本管理工具n无效的原理和解决方法
]]></content>
      <categories>
        <category>运维</category>
        <category>常用安装</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>zsh 安装</title>
    <url>/posts/a1ba4b4f/</url>
    <content><![CDATA[安装zsh配置oh-my-zsh安装了虚拟机，玩了几天，发现自带的shell不太好用。本着折腾的优良作风，配置了oh-my-zsh，本文记录下安装步骤。
查看当前shellecho $SHELL

返回结果:

bin&#x2F;bash

安装zshyum install -y zsh

静候安装完成…
成功后如下所示


zsh下载完成
设置默认shellchsh -s /bin/zsh

请在root用户下切换shell


更换shell
返回结果如下，表示切换完成（配置完成后需要重启方能生效，我们先下载oh-my-zsh，稍后重启）
安装git自动和手动安装都需要安装git，执行
yum install -y git

静候安装完成,完成后选择一种oh-my-zsh的安装方式。
安装oh-my-zsh（自动）sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;

使用curl来安装，wget命令执行后不起作用，暂时不知道怎么回事。
出现以下界面，显示安装成功。


oh-my-zsh
手动安装下载源码
git clone https://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh

复制配置
cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc

修改主题ZSH_THEME 字段就是主题，可以从资料里的主题找


主题配置
完成后，重启生效默认shellreboot

别名配置首先我们看下git的别名
vi ~/.oh-my-zsh/plugins/git/git.plugin.zsh



git 别名
很强大有木有，我们还可以自定义别名，在~/.zshrc中，最下面直接写即可。


小技巧1、输入d,就会列出你在这个回话中访问的目录，输入前面的序号，就可以直接跳转 2、可以忽略cd命令, 输入..或者...和当前目录名都可以跳转
资料
oh-my-zsh
oh-my-zsh主题一览
oh-my-zsh配置你的zsh提高shell逼格终极选择

主题修改进入themes的目录
cd ~/.oh-my-zsh/themesll #查看主题 默认主题是 ZSH_THEME=&quot;robbyrussell&quot;

在.zshrc中修改主题vi ~&#x2F;.zshrc

推荐主题：jonathan 或者 rkj-repos

vi ~/.zshrc # 找到ZSH_THEME 修改为你想要的主题即可

]]></content>
      <categories>
        <category>运维</category>
        <category>常用安装</category>
      </categories>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title>fastjson 常用 API</title>
    <url>/posts/86e940c9/</url>
    <content><![CDATA[对象和 json 互转Object转JSON对象
JSON 是 JSONObject 的抽象类，JSONObject  共享JSON 类的 toJson 方法。

  public static void main(String[] args) &#123;JSONObject json = (JSONObject) JSON.toJSON(o);      // 或者      JSONObject jsonObject = (JSONObject) JSONObject.toJSON(stu);  &#125;

JAVA对象转JSON对象public static void main(String[] args) &#123;    JSONObject jsonObject = (JSONObject) JSONObject.toJSON(stu);&#125;

转JSON字符串public static void main(String[] args) &#123;    String stuString = JSONObject.toJSONString(stu);&#125;

JSON对象转Java对象public static void main(String[] args) &#123;    Student stu = new Student(&quot;公众号编程大道&quot;, &quot;m&quot;, 2);    //先转成JSON对象    JSONObject jsonObject = (JSONObject) JSONObject.toJSON(stu);    //JSON对象转换成Java对象    Student student = JSONObject.toJavaObject(jsonObject, Student.class);&#125;

JSON字符串转JSON对象public static void main(String[] args) &#123;    String stuString = &quot;&#123;\&quot;age\&quot;:2,\&quot;name\&quot;:\&quot;公众号编程大道\&quot;,\&quot;sex\&quot;:\&quot;m\&quot;&#125;&quot;;        //JSON字符串转换成JSON对象    JSONObject jsonObject1 = JSONObject.parseObject(stuString);&#125;

转Java对象public static void main(String[] args) &#123;    String stuString = &quot;&#123;\&quot;age\&quot;:2,\&quot;name\&quot;:\&quot;公众号编程大道\&quot;,\&quot;sex\&quot;:\&quot;m\&quot;&#125;&quot;;    //JSON字符串转换成Java对象    Student student1 = JSONObject.parseObject(stuString, Student.class);    System.out.println(&quot;JSON字符串转换成Java对象\n&quot; + student1);&#125;

List 和 JSONArray 互转List 转 JSONArrayList&lt;T&gt; list = new ArrayList&lt;T&gt;(); JSONArray array= JSONArray.parseArray(JSON.toJSONString(list))；

JSONArray 转 ListJSONArray array = new JSONArray(); List&lt;Student&gt; list = JSONObject.parseArray(array.toJSONString(), Student.class);

字符串转 ListString str = &quot;&quot;; List&lt;T&gt; list = JSONObject.parseArray(str,T.class);

序列化@JSONField@JSONField(name=&quot;gender&quot;) public String sex;

@JSONType//配置序列化的时候,不序列化id  sex@JSONType(ignores =&#123;&quot;id&quot;, &quot;sex&quot;&#125;) public class Person implements Serializable &#123;&#125;

SerializeFilter通过SerializeFilter可以使用扩展编程的方式实现定制序列化。fastjson提供了多种SerializeFilter：
1. PropertyPreFilter根据PropertyName判断是否序列化。
//定制序列化,只序列化一部分字段,将需要序列化的字段名,配置到数组中 如果什么都不配置,则序列化全部字段SimplePropertyPreFilterfilter = new SimplePropertyPreFilter(User.class, newString[]&#123;&quot;name&quot;&#125;);String jsonString =JSON.toJSONString(user,filter);

2. PropertyFilter根据PropertyName和PropertyValue来判断是否序列化。
PropertyFilter filter2 = new PropertyFilter() &#123;    @Override    public boolean apply(Object object, String key, Object value) &#123;        if (key.equals(&quot;sex&quot;)) &#123;            if ((Integer) value &gt; 1) &#123;                return true;            &#125;        &#125; else if (key.equals(&quot;name&quot;)) &#123;            return true;        &#125;        return false;    &#125;&#125;;String jsonString = JSON.toJSONString(user, filter2);

3. NameFilter修改Key，如果需要修改Key,process返回值则可。
   // 如果需要修改Key,process返回值则可// 返回需要修改后的key值,如果不修改,则返回name,切记不能返回null,否则会报错   NameFilter nameFilter = new NameFilter() &#123;       @Override       public String process(Object object, String name, Object value) &#123;           if (name.equals(&quot;id&quot;)) &#123;               return &quot;ID&quot;;           &#125;           return name;       &#125;   &#125;;

4. ValueFilter修改Value。
ValueFilter valueFilter = new ValueFilter() &#123;    @Override    public Object process(Object object, String name, Object value) &#123;        if (name.equals(&quot;name&quot;)) &#123;            return &quot;张三&quot;;        &#125;        return &quot;&quot;;    &#125;&#125;;

5. BeforeFilter序列化时在最前添加内容。
BeforeFilter beforeFilter = new BeforeFilter() &#123;    @Override    public void writeBefore(Object object) &#123;        writeKeyValue(&quot;start&quot;, &quot;bofore&quot;);    &#125;&#125;;

6. AfterFilter序列化时在最后添加内容。
AfterFilter afterFilter = new AfterFilter() &#123;    @Override    public void writeAfter(Object object) &#123;        writeKeyValue(&quot;end&quot;,&quot;after&quot;);    &#125;&#125;;

                      
]]></content>
      <categories>
        <category>Java</category>
        <category>工具库</category>
      </categories>
      <tags>
        <tag>fastjson</tag>
      </tags>
  </entry>
  <entry>
    <title>常见错误</title>
    <url>/posts/c10f304f/</url>
    <content><![CDATA[目录[解决]&#x2F;bin&#x2F;bash^M: bad interpreter: No such file or directory执行一个脚本full_build.sh 时, 一直是提示我:-bash: .&#x2F;full_build.sh: &#x2F;bin&#x2F;bash^M: bad interpreter: No such file or directory
开始是说我权限不够, 不能执行, 接着我就把权限给改了,  就一直报上面问题.记得几个月前, 就遇到过类似的问题, 当时是在编译Android Framework, 后来打开出错的.xml文件, 很直接的看到很多的^M的标识,  由于负责编译的同事帮忙解决了, 就没有去问为什么, 今天再次遇到, 就上网搜了搜, 才明白了原因.  
出现上面错误的原因之一是脚本文件是DOS格式的, 即每一行的行尾以\r\n来标识, 使用vim编辑器打开脚本, 运行::set ff?可以看到DOS或UNIX的字样. 使用set ff&#x3D;unix把它强制为unix格式的, 然后存盘退出, 即可.
网上也有很多的其他方法, 比如: 执行dos2unix 命令转换编码,  命令为: #dos2unix full_build.sh,  但我没有dos2unix的安装包, 所以就跳过了.  
也有说造成这种问题的原因是在使用vim时不小心按了个: Ctrl+v,  脚本是我从服务器上下的, 不清楚到底怎么会变成了DOS格式的了. 总之解决了就行啦.                      
]]></content>
      <categories>
        <category>运维</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>常见错误</tag>
      </tags>
  </entry>
  <entry>
    <title>杂烩</title>
    <url>/posts/c10d2cc/</url>
    <content><![CDATA[刷新DNS缓存现在很多Linux发行版都没有内置DNS本地缓存，Linux不像Windows那样可以使用ipconfig &#x2F;flushdns来刷新，在Linux下无需刷新，因为本身没有缓存；
当然，如果非要缓存刷新，可以安装nscd，然后刷新这个守护进程。
Ubuntu：
apt-get install -y nscd

CentOS:
yum install -y nscd

使用：
service nscd restart

查看DNS信息[deployer@CBSS-DMZ-19 ~]$ nslookup mall.10010.comServer:         202.106.0.20                                           　　 #这个域名是通过202.106.0.20这个DNS服务器进行解析的.Address:        202.106.0.20#53                                         　　#DNS服务器使用的IP地址和端口号Non-authoritative answer:mall.10010.com  canonical name = mall.10010.com.cdn.dnsv1.com.          　　#mall.10010.com对应的另外的域名mall.10010.com.cdn.dnsv1.commall.10010.com.cdn.dnsv1.com    canonical name = lt.p23.tc.cdntip.com. 　　 #mall.10010.com.cdn.dnsv1.com对应的另外的域名lt.p23.tc.cdntip.comName:   lt.p23.tc.cdntip.comAddress: 123.125.46.202      　　 #域名对应的第1个IP地址Name:   lt.p23.tc.cdntip.comAddress: 121.29.54.199       　　 #域名对应的第2个IP地址Name:   lt.p23.tc.cdntip.comAddress: 121.29.54.195       　　 #域名对应的第3个IP地址[deployer@CBSS-DMZ-19 ~]$ cat /etc/resolv.conf    　　 #LINUX主机在本地配置的域名服务器nameserver 202.106.0.20

防火墙开放端口#查看防火墙某个端口是否开放firewall-cmd --query-port=3306/tcp#开放防火墙端口3306firewall-cmd --zone=public --add-port=3306/tcp --permanent#查看防火墙状态systemctl status firewalld#关闭防火墙systemctl stop firewalld#打开防火墙systemctl start firewalld#开放一段端口firewall-cmd --zone=public --add-port=40000-45000/tcp --permanent#查看开放的端口列表firewall-cmd --zone=public --list-ports

解决SSH连接Linux超时自动断开1. $TMOUT 系统环境变量用以下命令判断是否是否设置了该参数
echo $TMOUT

如果输出空或0表示不超时，大于0的数字n表示n秒没有收入则超时
修改方法：
vi /etc/profile# 将以下900修改为0就是设置不超时export TMOUT=900# 让配置立即生效source /etc/profile

2. sshd 服务配置

ClientAliveInterval指定了服务器端向客户端请求消息的时间间隔, 默认是0, 不发送。设置60表示每分钟发送一次, 然后客户端响应, 这样就保持长连接了。
ClientAliveCountMax表示服务器发出请求后客户端没有响应的次数达到一定值, 就自动断开。正常情况下, 客户端不会不响应，使用默认值3即可。


1. 查看现有配置cd /etc/ssh# 查看sshd_config中关于客户端活动状态的配置grep ClientAlive sshd_config

默认输出如下：
# ----------------------------# ClientAliveInterval 0# ClientAliveCountMax 3# ----------------------------

3. 修改sshd配置# 启用客户端活动检查，每60秒检查一次，3次不活动断开连接sed -i &quot;s/#ClientAliveInterval 0/ClientAliveInterval 60/g&quot; sshd_configsed -i &quot;s/#ClientAliveCountMax 3/ClientAliveCountMax 3/g&quot; sshd_config

4. 重新加载service sshd reload

5. 确认修改情况# 备份原配置文件cp sshd_config sshd_config.bak# 确认修改grep ClientAlive sshd_config# 比较配置文件差异diff sshd_config sshd_config.bak

3. xshell简易配置方式

]]></content>
      <categories>
        <category>运维</category>
        <category>杂烩</category>
      </categories>
      <tags>
        <tag>杂烩</tag>
      </tags>
  </entry>
  <entry>
    <title>研发文档规范</title>
    <url>/posts/c375a1af/</url>
    <content><![CDATA[文档类型在项目开发过程中，应该按要求编写好十三种文档，文档编写要求具有针对性、精确性、清晰性、完整性、灵活性、可追溯性。同时依照项目人员的角色划分，完成不同类型的文档。以下排序并未严格按照时间排序。

类型说明可行性分析报告（产品人员）可行性研究报告的编写目的是：说明该软件开发项目的实现在技术、经济和社会条件方面的可行性；评述为了合理达到开发目标而可能选择的各种方案；实施方案的利弊；说明并论证所选定的方案。
项目开发计划（产品人员）软件项目开发计划即为软件项目实施方案制定出的具体计划。项目开发计划应提前给管理部门，并作为开发阶段评审的基础。编写项目开发计划的目的是用文件的形式，把对于在开发过程中各项工作的负责人员、开发进度、所需经费预算、所需的软硬条件等问题做出的安排记载下来，以便根据本计划开展和检查项目的开发工作。
软件需求说明书（产品人员）软件需求说明书也称为软件规格说明。该说明书对所开发软件的功能、性能、用户界面及运行环境等做出详细的说明。它是用户与开发人员双方对软件需求取得共同理解基础上达成的协议，也是实施开发工作的基础。软件需求说明书的编写目的就是为了使用户和软件开发者双方对该软件的初需求有一个共同的理解，并使之成为整个开发工作的基础。
概要设计说明书 （开发人员）概要设计说明书又可称系统设计说明书，这里所说的系统是指程序系统。编写的目的是说明对程序系统的设计考虑，包括程序系统的基本处理。流程、程序系统的组织结构、模块划分、功能分配、接口设计。运行设计、数据结构设计和出错处理设计等，为程序的详细设计提供基础。
详细设计规格说明书（开发人员）详细设计说明书又可称程序设计说明书。编写目的是说明一个软件系统各个层次中的每一个程序（每人模块或子程序）的设计考虑。如果项目比较简单，层次较少，本文件可以不单独编写，有关内容合并入概要设计说明书。
用户操作手册（产品人员）用户操作手册的编写是要使用非专门术语的语言，充分地描述该软件系统所具有的功能及基本的使用方法，提供该软件每一个运行的具体过程和有关知识，包括操作方法的细节。使用户（或潜在用户）通过本手册能够了解该软件的用途，并且能够确定在什么情况下，如何使用它。
测试计划（测试人员）测试计划是软件项目实施计划中的一项重要的内容，应当在软件开发初期、即需求分析阶段制订。测试计划应当定义被测试对象和测试目标，确定测试阶段和测试周期的划分；制订测试人员、软硬件资源和测试进度等方面的计划，规定软件测试方法，测试标准以及支持环境和测试工具。针对子系统在特定的测试阶段所要进行的测试工作制订详细计划，它详细说明规定了测试小组的各项测试任务，测试策略、任务分配和进度安排等。
测试分析报告（测试人员）测试工作完成以后，应当提交测试计划情况说明书，对测试结果加以分析，并提出测试的结论性意见。
开发进度月报（开发人员）开发进度月报的编写目的是及时向有关部门汇报项目开发的进度和情况，以便及时发现和处理开发过程中出现的问题，一般，开发进度月报是以项目组单位每月编写的。如果被开发的软件系统规模比较大，整个工程项目被划分给若干个分项目驵承担，开发进度月报将以分项目为单位每月编写。
项目开发总结报告（产品人员）软件项目开发完成之后，应当与项目实施计划对照，总结实际执行的情况，如进度、成果、资源利用、成本和投入的人力。此外，还需对开发工作做出评价，总结经验和教训。项目开发总结报告的编写是为了总结本项目开发工作的经验，说明实际取得的开发结果以及对整个开发工作的各个方面的评价。
软件维护手册（开发人员）主要包括软件系统说明、程序模块说明、操作环境、支持软件的说明、维护过程的说明，便于软件的维护。
软件问题报告（测试人员）指出软件问题的登记情况，如日期、发现人、状态、问题所属模块等，为软件修改提供准备文档。
软件修改报告（开发人员）软件产品投入运行以后，发现了需对其进行修正、更改等问题，应将存在的问题、修改的考虑以及修改的影响作出详细的描述，提交审批。
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
        <tag>研发文档</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 时间基本概念</title>
    <url>/posts/8c2abb3e/</url>
    <content><![CDATA[目录前言格林威治时间、世界时、祖鲁时间、GMT、UTC、跨时区、夏令时，这些眼花缭乱的时间术语，我们可能都不陌生，但是真正遇到问题，可能又不那么确定，不得不再去查一查，
处理完可能过段时间又忘记。今天，我们彻底来梳理一下它们。
GMT什么是GMTGMT（Greenwich Mean Time）， 格林威治平时（也称格林威治时间）。
它规定太阳每天经过位于英国伦敦郊区的皇家格林威治天文台的时间为中午12点。
GMT的历史格林威治皇家天文台为了海上霸权的扩张计划，在十七世纪就开始进行天体观测。为了天文观测，选择了穿过英国伦敦格林威治天文台子午仪中心的一条经线作为零度参考线，这
条线，简称格林威治子午线。
1884年10月在美国华盛顿召开了一个国际子午线会议，该会议将格林威治子午线设定为本初子午线，并将格林威治平时 (GMT, Greenwich Mean Time) 作为世界时间标准（UT, 
Universal Time）。由此也确定了全球24小时自然时区的划分，所有时区都以和 GMT 之间的偏移量做为参考。
1972年之前，格林威治时间（GMT）一直是世界时间的标准。1972年之后，GMT 不再是一个时间标准了。
UTC什么是UTCUTC（Coodinated Universal Time），协调世界时，又称世界统一时间、世界标准时间、国际协调时间。由于英文（CUT）和法文（TUC）的缩写不同，作为妥协，简称UTC。
UTC 是现在全球通用的时间标准，全球各地都同意将各自的时间进行同步协调。UTC 时间是经过平均太阳时（以格林威治时间GMT为准）、地轴运动修正后的新时标以及以秒为
单位的国际原子时所综合精算而成。
在军事中，协调世界时会使用“Z”来表示。又由于Z在无线电联络中使用“Zulu”作代称，协调世界时也会被称为”Zulu time”。
UTC 由两部分构成
原子时间（TAI, International Atomic Time）：结合了全球400个所有的原子钟而得到的时间，它决定了我们每个人的钟表中，时间流动的速度。
世界时间（UT, Universal Time）：也称天文时间，或太阳时，他的依据是地球的自转，我们用它来确定多少原子时，对应于一个地球日的时间长度。

UTC的历史1960年，国际无线电咨询委员会规范统一了 UTC 的概念，并在次年投入实际使用。
“Coordinated Universal Time”这个名字则在1967年才被正式采纳。
1967年以前， UTC被数次调整过，原因是要使用闰秒（leap second）来将 UTC 与地球自转时间进行统一。
CST北京时间，China Standard Time，中国标准时间。在时区划分上，属东八区，比协调世界时早8小时，记为UTC+8。
不过这个CST这个缩写比较纠结的是它可以同时代表四个不同的时间，分别如下： 

Central Standard Time (USA) UT-6:00 美国标准时间
Central Standard Time (Australia) UT+9:30 澳大利亚标准时间
China Standard Time UT+8:00 中国标准时间
Cuba Standard Time UT-4:00 古巴标准时间

Java Date 使用 UTC 时间，如 Tue Jan 05 14:28:41 CST 2016 表示 China Standard Time UT+8:00 。
GMT vs UTCGMT 是前世界标准时，UTC 是现世界标准时。
UTC 比 GMT 更精准，以原子时计时，适应现代社会的精确计时。
但在不需要精确到秒的情况下，二者可以视为等同。
每年格林尼治天文台会发调时信息，基于 UTC。
时区随着火车铁路与其他交通和通讯工具的发展，以及全球化贸易的推动，各地使用各自的当地太阳时间带来了时间不统一的问题，在19世纪催生了统一时间标准的需求，时区由此诞生。
时区是如何定义的从格林威治本初子午线起，经度每向东或者向西间隔15°，就划分一个时区，在这个区域内，大家使用同样的标准时间。
但实际上，为了照顾到行政上的方便，常将1个国家或1个省份划在一起。所以时区并不严格按南北直线来划分，而是按自然条件来划分。另外：由于目前，国际上并没有一个批准
各国更改时区的机构。一些国家会由于特定原因改变自己的时区。
全球共分为24个标准时区，相邻时区的时间相差一个小时。
在不同地区，同一个时区往往会有很多个不同的时区名称，因为名称中通常会包含该国该地区的地理信息。在夏令时期间，当地的时区名称及字母缩写会有所变化（通常会包
含“daylight”或“summer”字样）。
例如美国东部标准时间叫：EST，Estern Standard Time；而东部夏令时间叫：EDT，Estern Daylight Time。

想查看世界所有时区的名字可以访问这个网站：
https://www.timeanddate.com/time/zones/

夏令时什么是夏令时DST（Daylight Saving Time），夏令时又称夏季时间，或者夏时制。
它是为节约能源而人为规定地方时间的制度。一般在天亮早的夏季人为将时间提前一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。
全球约40%的国家在夏季使用夏令时，其他国家则全年只使用标准时间。标准时间在有的国家也因此被相应地称为冬季时间。
在施行夏令时的国家，一年里面有一天只有23小时（夏令时开始那一天），有一天有25小时（夏令时结束那一天），其他时间每天都是24小时。
夏令时的历史1784年，美国驻法国大使本杰明·富兰克林（Benjamin Franklin）提出“日光节约时间制”。1908年，英国建筑师威廉·维莱特（William Willett）再次提出，但当时该提案并未被采纳。
1916年，处于一战时期的德国政府下令将时钟推至一个小时后，通过获得额外一小时的日光来节省战争所需的煤炭，成为第一个实行夏时制的国家。随后，英法俄美四个一战参战国纷纷效仿。
美国在一战结束后于1919年取消夏时制，但在1942年二战时，美国重新启动夏令时制，1966年正式立法确定永久使用。1973至1975年石油危机爆发期间，美国连续两年延长夏令时制，以节省石油。
欧洲大部分国家则是从1976年——第四次中东战争导致首次石油危机（1973年）的3年后才开始施行夏令时制。
1986年4月，中国国务院办公厅发出《在全国范围内实行夏时制的通知》，要求全民早睡早起节约能源：每年4月中旬的第一个星期日2时，将时钟拨快一小时；10月中旬第一个星期日的2时，再将时钟拨慢一小时。但此夏令时只实行了6年，在1992年停止施行，主因是中国东西地域广阔却只奉行一个北京时间，实时夏令时制带来很多不切实际的反效果。
夏令时的争议从过去的100多年来看，夏令时往往是在国家发生严重危机（如战争和能源短缺）的情况下才会受到青睐。而在相对和平的近10年里，这种时间制度则变得越来越不受欢迎。
它会使得人们的生物钟被扰乱，常常陷入睡眠不足的情况，不仅对人体健康有害、导致车祸，还会对旅游、航空领域造成极大的混乱。
另外，冬、夏令时究竟能否起到节能的作用，也仍有待商榷。美国一项截至2014年3月的研究表明，这种时间转换制度最多能在3、4月帮助美国减少1%的用电量，而美国国家标准局则认为，夏令时对用电量没有丝毫影响。
在俄罗斯，此前的一份报告也显示，夏令时帮助俄罗斯每年节约的电量，仅相当于两三个火力发电厂的发电量，十分的“鸡肋”。
去年（2019年）3月26日，作为全世界第一个提出并实行夏令时的国家，德国，在欧洲议会上以410比192的赞成票通过了取消冬、夏令时转换制提案，拟定于2021年4月起，所有欧盟国家不再实行冬、夏令时转换。待各成员国形成最终法案后，将选择永久使用夏令时时间或是冬令时时间。
本地时间在日常生活中所使用的时间我们通常称之为本地时间。这个时间等于我们所在（或者所使用）时区内的当地时间，它由与世界标准时间（UTC）之间的偏移量来定义。这个偏移量可以表示为 UTC- 或 UTC+，后面接上偏移的小时和分钟数。
总结以上分别从定义、来源等维度解释和扩展说明了GMT、UTC、时区和夏令时的概念、历史、意义，并在最后列举了这些概念在JS项目中的一个非常实用的应用。
简单地讲， GMT 是以前的世界时间标准；UTC 是现在在使用的世界时间标准；时区是基于格林威治子午线来偏移的，往东为正，往西为负；夏令时是地方时间制度，施行夏令时的地方，每年有2天很特殊（一天只有23个小时，另一天有25个小时）。
从源头上彻底了解了这些概念，将会让我们在处理与时间相关的问题时如虎添翼。
参考文章彻底弄懂GMT、UTC、时区和夏令时
5分钟了解GMT，CST，UTC是什么鬼？
]]></content>
      <categories>
        <category>中间件</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>fastjson 常见问题</title>
    <url>/posts/4e9562ed/</url>
    <content><![CDATA[com.alibaba.fastjson.JSONException: syntax error, expect {, actual string, pos 0 报错解决方案解决方案1用 JSON.parse(String text) 方法，去除转义即可：
把去除转义后的 字符串 传入 
JSONObject.parseObject(String text, Class&lt;T&gt; clazz);

解决方案2利用字符串替换方法，替换掉转义的 \
String replaceText = text.replaceAll(&quot;\\\\&quot;, &quot;&quot;);

如果字符串前后还多了 “
再次切割
String paseText = replaceText.substring(1, replaceText.length() - 1);

切割后，再次传入即可解决。
]]></content>
      <categories>
        <category>Java</category>
        <category>工具库</category>
      </categories>
      <tags>
        <tag>fastjson</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 时间数据类型对照表</title>
    <url>/posts/18ea587c/</url>
    <content><![CDATA[目录Java数据类型和MySql数据类型对应表


类型名称
显示长度
数据库类型
JAVA类型
JDBC类型索引(int)
描述



VARCHAR
L+N
VARCHAR
java.lang.String
12



CHAR
N
CHAR
java.lang.String
1



BLOB
L+N
BLOB
java.lang.byte[]
-4



TEXT
65535
VARCHAR
java.lang.String
-1











INTEGER
4
INTEGER UNSIGNED
java.lang.Long
4



TINYINT
3
TINYINT UNSIGNED
java.lang.Integer
-6



SMALLINT
5
SMALLINT UNSIGNED
java.lang.Integer
5



MEDIUMINT
8
MEDIUMINT UNSIGNED
java.lang.Integer
4



BIT
1
BIT
java.lang.Boolean
-7



BIGINT
20
BIGINT UNSIGNED
java.math.BigInteger
-5



FLOAT
4+8
FLOAT
java.lang.Float
7



DOUBLE
22
DOUBLE
java.lang.Double
8



DECIMAL
11
DECIMAL
java.math.BigDecimal
3



BOOLEAN
1
同TINYINT













ID
11
PK (INTEGER UNSIGNED)
java.lang.Long
4











DATE
10
DATE
java.sql.Date
91



TIME
8
TIME
java.sql.Time
92



DATETIME
19
DATETIME
java.sql.Timestamp
93



TIMESTAMP
19
TIMESTAMP
java.sql.Timestamp
93



YEAR
4
YEAR
java.sql.Date
91



参考文章Java数据类型和MySql数据类型对应表
Java 8日期与数据库日期的映射关系
]]></content>
      <categories>
        <category>中间件</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>时区</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 时区问题</title>
    <url>/posts/3aad583d/</url>
    <content><![CDATA[目录修改时区mysql 数据库可以通过下面两个 sql 查看时区:
SELECT TIMEDIFF(NOW(),CONVERT_TZ(NOW(),@@session.time_zone,&#x27;+00:00&#x27;));

或者:
SELECT TIMEDIFF(NOW(), UTC_TIMESTAMP); 

如果是中国标准时间, 会输出08:00
以下记录修改 mysql 时区的几种方法。
方法一通过 mysql 命令行模式下动态修改。
查看 mysql 当前时间，当前时区：
&gt; select curtime();   # 或select now()也可以+-----------+| curtime() |+-----------+| 15:18:10  |+-----------+&gt; show variables like &quot;%time_zone%&quot;;+------------------+--------+| Variable_name    | Value  |+------------------+--------+| system_time_zone | UTC    || time_zone        | SYSTEM |+------------------+--------+2 rows in set (0.00 sec)# time_zone说明mysql使用system的时区，system_time_zone说明system使用UTC时区

修改时区：
set global time_zone = &#x27;+8:00&#x27;;  # 修改mysql全局时区为北京时间，即我们所在的东8区set time_zone = &#x27;+8:00&#x27;;  # 修改当前会话时区flush privileges;  # 立即生效

方法二使用6.0以下版本的jdbc，降版本，并不推荐。
方法三在 jdbc url 指定默认时区，在jdbc连接的url后面加上serverTimezone=UTC或 GMT 即可，如果指定使用 gmt+8 时区，需要写成 GMT%2B8，否则可能报解析为空的错误。示例如下：
jdbc.url=jdbc:mysql://localhost:3306/demo?serverTimezone=UTC&amp;characterEncoding=utf-8jdbc.url=jdbc:mysql://localhost:3306/demo?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8jdbc.url=jdbc:mysql://localhost:3306/demo?serverTimezone=Asia/Shanghai&amp;characterEncoding=utf-8

方法四通过修改 my.cnf 配置文件来修改时区
# vim /etc/my.cnf  ##在[mysqld]区域中加上default-time_zone = &#x27;+8:00&#x27;# /etc/init.d/mysqld restart  ##重启mysql使新时区生效

关闭SSL在这里有一个地方需要注意，MySQL 在高版本需要指明是否进行 SSL 连接。
SSL 协议提供服务主要：

认证用户服务器，确保数据发送到正确的服务器；
加密数据，防止数据传输途中被窃取使用；
维护数据完整性，验证数据在传输过程中是否丢失；

当前支持 SSL 协议两层：
SSL 记录协议（SSL Record Protocol）：建立靠传输协议（TCP）高层协议提供数据封装、压缩、加密等基本功能支持
SSL 握手协议（SSL Handshake Protocol）：建立SSL记录协议用于实际数据传输始前通讯双进行身份认证、协商加密算法、 交换加密密钥等。
不建议在没有服务器身份验证的情况下建立SSL连接。根据 MySQL 5.5.45+、5.6.26+ 和 5.7.6+ 的要求，如果不设置显式选项，则必须建立默认的SSL连接。需要通过设置useSSL=false
来显式禁用SSL，或者设置useSSL&#x3D;true并为服务器证书验证提供信任存储。
1.true 需要连接
2.false 不需要连接
所以建议设置useSSL为false，有时遇到的问题可以这样来考虑
jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false**

参考文章mysql的timestamp会存在时区问题？
数据库时间慢了14个小时，Mybatis说，这个锅我不背！
java LocalDateTime 和 mysql datetime timestamp时区问题
MySQL 总是差八个小时，如何破？
]]></content>
      <categories>
        <category>中间件</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>时区</tag>
      </tags>
  </entry>
  <entry>
    <title>RabbitMQ 详解</title>
    <url>/posts/8e078847/</url>
    <content><![CDATA[RabbitMQ详解RabbitMQ的优点：

开源, 性能有效, 稳定性好
提供可靠性消息投递模式(confirm), 返回模式(return)等
与Spring完美整合, API丰富
集群模式丰富, 支持表达式配置, 高可用HA模式, 镜像队列模型
可以保证数据不丢失的前提下做到高可靠性, 可用性

RabbitMQ高性能原因：

由Erlang语言开发，继承其天生的并发性，稳定性和安全性有保障

RabbitMQ的协议：
AMQP（Advanced Message Queuing Protocol）高级消息队列协议，是一个异步消息传递所使用应用层协议规范，为面向消息中间件设计，基于此协议的客户端与消息中间件可以无视消息来源传递消息，不受客户端、消息中间件、不同的开发语言环境等条件的限制。


设计概念解释：

Server : 又称Broker, 接受客户端连接, 实现AMQP实体服务
Connection : 连接, 应用程序与Broker的网络连接
Channel : 网络信道, 几乎所有的操作都在Channel中进行, Channel是进行消息读写的通道。客户端可以建立多个Channel, 每个Channel代表一个会话任务。
Message : 消息, 服务器和应用程序之间传送的数据, 有Properties和Body组成。Properties可以对消息进行修饰, 比如消息的优先级, 延迟等高级特性; Body就是消息体内容。
Virtual Host : 虚拟地址, 用于进行逻辑隔离, 最上层的消息路由。一个Virtual Host里面可以有若干个Exchange和Queue, 同一个Virtual Host里面不能有相同名称的Exchange或Queue
Exchange : 交换机, 用于接收消息, 根据路由键转发消息到绑定的队列
Binding : Exchange和Queue之间的虚拟连接, binding中可以包含routing key
Routing Key : 一个路由规则, 虚拟机可用它来确定如何路由一个特定消息
Queue : 也成Message Queue, 消息队列, 用于保存消息并将它们转发给消费者

RabbitMQ整体架构


RabbitMQ成员简介Binding-绑定
Exchange和Exchange, Queue之间的连接关系
绑定中可以包含RoutingKey或者参数

Queue-消息队列
消息队列, 实际存储消息数据
Durability : 是否持久化
Auto delete : 如选yes,代表当最后一个监听被移除之后, 该Queue会自动被删除

Message-消息
服务和应用程序之间传送的数据
本质上就是一段数据, 由Properties和Payload(Body)组成
常用属性 : delivery mode, headers(自定义属性)
其他属性
content_type, content_encoding, priority
correlation_id : 可以认为是消息的唯一id
replay_to : 重回队列设定
expiration : 消息过期时间
message_id : 消息id
timestamp, type, user_id, app_id, cluster_id



Virtual Host-虚拟主机
虚拟地址, 用于进行逻辑隔离, 最上层的消息路由
一个Virtual Host里面可以有若干个Exchange和Queue
同一个Virtual Host里面不能有相同名称的Exchange或Queue

Exchange-交换机接收消息，并根据路由键转发消息到所绑定的队列
注：交换机不会存储消息，如果消息发送到没有绑定消费队列的交换机，消息则丢失。


交换机的属性

Name : 交换机名称
Type : 交换机类型, direct, topic, fanout, headers
Durability : 是否需要持久化, true为持久化
Auto Delete : 当最后一个绑定到Exchange上的队列删除后, 自动删除该Exchange
Internal : 当前Exchange是否用于RabbitMQ内部使用, 默认为False, 这个属性很少会用到
Arguments : 扩展参数, 用于扩展AMQP协议制定化使用

交换机的四种类型

Direct exchange（直连交换机）是根据消息携带的路由键（routing key）将消息投递给对应队列的
注意 : Direct模式可以使用RabbitMQ自带的Exchange(default Exchange), 所以不需要将Exchange进行任何绑定(binding)操作, 消息传递时, RoutingKey必须完全匹配才会被队列接收, 否则该消息会被抛弃






Fanout exchange（扇型交换机）将消息路由给绑定到它身上的所有队列
不处理路由键, 只需要简单的将队列绑定到交换机上
发送到交换机的消息都会被转发到与该交换机绑定的所有队列上
Fanout交换机转发消息是最快的






Topic exchange（主题交换机）队列通过路由键绑定到交换机上，然后，交换机根据消息里的路由值，将消息路由给一个或多个绑定队列（模糊匹配）
“#” : 匹配一个或多个词
“*” : 匹配一个词






Headers exchange（头交换机）类似主题交换机，但是头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。

RabbitMQ常用的5种工作模式1、点对点(简单)的队列




不需要交换机
一个生产者，一个消费者

2、工作队列（公平性）




不需要交换机
一个生产者，多个消费者，但是一个消息只会发送给一个队列（竞争的消费者模式）
默认是轮询，即会将消息轮流发给多个消费者，但这样对消费得比较慢的消费者不公平
可采用公平分配，即能者多劳
channel.basicQos(1); &#x2F;&#x2F; 限定：发送一条信息给消费者A，消费者A未反馈处理结果之前，不会再次发送信息给消费者A
boolean autoAck &#x3D; false; &#x2F;&#x2F; 取消自动反馈 channel.basicConsume(QUEUE_NAME, autoAck, consumer); &#x2F;&#x2F; 接收信息
channel.basicAck(envelope.getDeliveryTag(), false); &#x2F;&#x2F; 反馈消息处理完毕



3、发布&#x2F;订阅




一个生产者，多个消费者
每一个消费者都有自己的一个队列
生产者没有直接发消息到队列中，而是发送到交换机
每个消费者的队列都绑定到交换机上
消息通过交换机到达每个消费者的队列

该模式就是Fanout Exchange（扇型交换机）将消息路由给绑定到它身上的所有队列
4、路由



生产者发送消息到交换机并指定一个路由key，消费者队列绑定到交换机时要制定路由key（key匹配就能接受消息，key不匹配就不能接受消息）
该模式采用Direct exchange（直连交换机）
5、主题（通配符）



此模式实在路由key模式的基础上，使用了通配符来管理消费者接收消息。生产者P发送消息到交换机X，交换机根据绑定队列的routing key的值进行通配符匹配
符号#：匹配一个或者多个词lazy.# 可以匹配lazy.irs或者lazy.irs.cor
符号：只能匹配一个词 lazy. 可以匹配 lazy.irs 或者 lazy.cor
该模式采用Topic exchange（主题交换机）
消息可靠性传递或回退（生产者端）生产者发送消息出去之后，不知道到底有没有发送到RabbitMQ服务器， 默认是不知道的。而且有的时候我们在发送消息之后，后面的逻辑出问题了，我们不想要发送之前的消息了，需要撤回该怎么做。
AMQP 事务机制

txSelect  将当前channel设置为transaction模式
txCommit  提交当前事务
txRollback  事务回滚

Confirm 模式
消息的确认, 是指生产者投递消息后, 如果Broker收到消息, 则会给我们产生一个应答
生产者进行接收应答, 用来确定这条消息是否正常发送到Broker, 这种方式也是消息的可靠性投递的核心保障

在channel上开启确认模式 : channel.confirmSelect()
在channel上添加监听 : addConfirmListener, 监听成功和失败的返回结果, 根据具体的结果对消息进行重新发送, 或记录日志等后续处理

Return消息机制
Return Listener用于处理一些不可路由的消息
正常情况下消息生产者通过指定一个Exchange和RoutingKey, 把消息送到某一个队列中去, 然后消费者监听队列, 进行消费，但在某些情况下, 如果在发送消息的时候, 当前的exchange不存在或者指定的路由key路由不到,这个时候如果我们需要监听这种不可达的消息, 就要使用Return Listener。
在基础API中有一个关键的配置项Mandatory : 如果为true, 则监听器会接收到路由不可达的消息, 然后进行后续处理（补偿或人工处理）, 如果为false, 那么broker端自动删除该消息。
如何保障消息可靠传递

保障消息的成功发出
保障MQ节点的成功接收
发送端收到MQ节点(Broker)的确认应答
完善的消息补偿机制

方案：
1、消息落库, 对消息状态进行标记





step1:消息入库
step2:消息发送
step3:消费端消息确认
step4:更新库中消息状态为已确认
step5:定时任务读取数据库中未确认的消息
step6:未收到确认结果的消息重新发送
step7:如果重试几次之后仍然失败, 则将消息状态更改为投递失败的终态, 后面需要人工介入

2、消息的延迟投递, 做二次确认, 回调检查





step1 : 第一次消息发送, 必须业务数据落库之后才能进行消息发送
step2 : 第二次消息延迟发送, 设定延迟一段时间发送第二次check消息
step3 : 消费端监听Broker, 进行消息消费
step4 : 消费成功之后, 发送确认消息到确认消息队列
step5 : Callback Service监听step4中的确认消息队列, 维护消息状态, 是否消费成功等状态
step6 : Callback Service监听step2发送的Delay Check的消息队列, 检测内部的消息状态, 如果消息是发送成功状态, 则流程结束, 如果消息是失败状态, 或者查不到当前消息状态时, 会通知生产者, 进行消息重发, 重新上述步骤

重试机制和幂等性保障（消费者端）重试机制
消费者在消费消息的时候，如果消费者业务逻辑出现程序异常，会使用消息重试机制。

情况1:  消费者获取到消息后，调用第三方接口，但接口暂时无法访问，是否需要重试?  （需要重试机制）
情况2:  消费者获取到消息后，抛出数据转换异常，是否需要重试?（不需要重试机制）需要发布进行解决。

对于情况2，如果消费者代码抛出异常是需要发布新版本才能解决的问题，那么不需要重试，重试也无济于事。应该采用日志记录+定时任务job健康检查+人工进行补偿
重试机制的实现
在SpringBoot中，@RabbitListener(queue&#x3D;””)用于消费者监听队列。底层使用Aop进行拦截，如果程序没有抛出异常，则自动提交事务。如果抛出异常，该消息会缓存到RabbitMQ服务器，自动实施重试机制，一直到成功为止。可以配置重试间隔时间和重试的次数。
幂等性保障
幂等性：多次执行, 结果保持一致
网络延迟传输中，消费出现异常或者是消费延迟消费，会造成MQ进行重试补偿，在重试过程中，可能会造成重复消费。
解决方案：

唯一ID+指纹码机制
唯一ID + 指纹码机制，利用数据库主键去重
SELECT COUNT(1) FROM T_ORDER WHERE ID &#x3D; 唯一ID +指纹码
好处：实现简单
坏处：高并发下有数据库写入的性能瓶颈
解决方案：跟进ID进行分库分表进行算法路由


利用Redis的原子性去实现
在接收到消息后将消息ID作为key执行 setnx 命令，如果执行成功就表示没有处理过这条消息，可以进行消费了，执行失败表示消息已经被消费了。



自动签收与手动签收（消费端）默认是自动签收
channel.basicConsume(QUEUE_NAME, false, defaultConsumer); //关闭自动签收，变为手动签收channel.basicAck(envelope.getDeliveryTag(), false); // 手工签收, 第二个参数表示是否批量签收

消费端限流消息队列中囤积了大量的消息, 或者某些时刻生产的消息远远大于消费者处理能力的时候, 这个时候如果消费者一次取出大量的消息, 但是客户端又无法处理, 就会出现问题, 甚至可能导致服务崩溃, 所以需要对消费端进行限流
RabbitMQ提供了一种qos(服务质量保证)功能, 即在非自动确认消息的前提下, 如果一定数目的消息(通过consumer或者channel设置qos的值)未被确认前, 不进行消费新的消息

自动签收要设置成false, 建议实际工作中也设置成false
void basicQos(int prefetchSize, int prefetchCount, boolean global) throws IOException;
prefetchSize : 消息大小限制, 一般设置为0, 消费端不做限制
prefetchCount : 会告诉RabbitMQ不要同时给一个消费者推送多于N个消息, 即一旦有N个消息还没有ack, 则该consumer将block(阻塞), 直到有消息ack
global : true&#x2F;false 是否将上面设置应用于channel, 简单来说就是上面的限制是channel级别的还是consumer级别 注意 :



prefetchSize和global这两项，RabbitMQ没有实现，暂且不关注，prefetchCount在autoAck设置false的情况下生效,即在自动确认的情况下这个值是不生效的
限流可实现公平队列。
消费端ACK和重回队列消费端ACK

消费端的手工ACK和NACK, ACK是确认成功消费, NACK表示消息处理失败, 会重发消息
消费端进行消费的时候, 如果由于业务异常我们可以进行日志的记录, 然后进行补偿
如果由于服务器宕机等严重问题, 就需要手工进行ACK保障消费端消费成功

重回队列

消费端重回队列是为了对没有处理成功的消息, 把消息重新回递给Broker
一般在实际应用中, 都会关闭重回队列, 也就是设置为False

TTL队列&#x2F;消息
TTL是Time To Live的缩写, 也就是生存时间
RabbitMQ支持消息的过期时间, 在消息发送时可以进行指定
RabbitMQ支持队列的过期时间, 从消息入队列开始计算, 只要超过了队列的超时时间配置, 那么消息会自动清除

死信队列（DLX）
Dead-Letter-Exchange
利用DLX, 当消息在一个队列中变成死信(dead message)之后, 它能被重新publish到另一个Exchange, 这个Exchange就是DLX
DLX也是一个正常的Exchange, 和一般的Exchange没有区别, 它能在任何队列上被指定, 实际上就是设置某个队列的属性为死信队列
当这个队列中有死信时, RabbitMQ就会自动将这个消息重新发布到设置的Exchange上去, 进而被路由到另一个队列
可以监听这个队列中消息做相应的处理, 这个特性可以弥补RabbitMQ3.0以前支持的immediate参数的功能

消息变成死信有以下几种情况 :

消息被拒绝(basic.reject&#x2F;basic.nack) 并且requeue重回队列设置成false
channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, false); &#x2F;&#x2F;丢弃消息


消息TTL过期
队列达到最大长度

死信队列的设置 :

设置死信队列属性实现


首先要设置死信队列的exchange和queue, 然后进行绑定
Exchange : dlx.exchange
Queue : dlx.queue
RoutingKey : #


然后正常声明交换机, 队列, 绑定, 只不过需要在队列加上一个扩展参数即可 : arguments.put(“x-dead-letter-exchange”, “dlx.exchange”);
这样消息在过期, reject或nack(requeue要设置成false), 队列在达到最大长度时, 消息就可以直接路由到死信队列。


用rabbitmq-delayed-message-exchange插件实现延迟队列

RabbitMQ负载均衡
轮询法

随机法

源地址哈希法

加权轮询法

加权随机法

最小连接数法


RabbitMQ之如何保障数据不丢失1、费者实例宕机的时候，如何保障数据是不会丢失？手动ack机制非常的简单，必须要消费者确保自己处理完毕了一个消息，才能手动发送ack给MQ，MQ收到ack之后才会删除这个消息，如果消费者还没发送ack，消费者自己就宕机了，此时MQ感知到它的宕机，就会重新投递这条消息给其他的消费者实例。通过这种机制保证消费者实例宕机的时候，数据是不会丢失的。
如果采用手动ack机制，实际上消费者服务每次消费了一条消息，处理完毕完成消费之后，就会发送一个ack消息给RabbitMQ服务器，这个ack消息是会带上自己本次消息的delivery tag的。
这里大家必须注意的一点，就是delivery tag仅仅在一个channel内部是唯一标识消息投递的。所以说，你ack一条消息的时候，必须是通过接受这条消息的同一个channel来进行。
channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);//表给示消费者成功消费，返回给MQ

2、分析手动ack和默认自动ack区别？①实际上默认用自动ack，是非常简单的。RabbitMQ只要投递一个消息出去给仓储服务，那么他立马就把这个消息给标记为删除，因为他是不管消费者服务到底接收到没有，或者处理完没有。所以这种情况下，性能很好，但是数据容易丢失。
②如果手动ack，那么就是必须等消费者服务完成消费以后，才会手动发送ack给RabbitMQ，此时RabbitMQ才会认为消息处理完毕，然后才会标记消息为删除。这样在发送ack之前，消费者服务宕机，RabbitMQ会重发消息给另外一个消费者服务实例，保证数据不丢失。
3、如何保证生产者投递到消息中间件(MQ)的消息不丢失？问题：如果投递出去的消息在网络传输过程中丢失，或者在RabbitMQ的内存中还没写入磁盘的时候宕机，都会导致生产端投递到MQ的数据丢失。而且丢失之后，生产者自己还感知不到，同时还没办法来补救。
生产者需要开启confirm模式，投递消息到MQ，如果MQ一旦将消息持久化到磁盘之后，必须也要回传一个confirm消息给生产端。这样的话，如果生产端的服务接收到了这个confirm消息，就知道是已经持久化到磁盘了。如果没有接收到confirm消息，那么就说明这条消息半路可能丢失了，此时你就可以重新投递消息到MQ去，确保消息不要丢失。
而且一旦你开启了confirm模式之后，每次消息投递也同样是有一个delivery tag的，也是起到唯一标识一次消息投递的作用。这样，MQ回传ack给生产端的时候，会带上这个delivery tag。你就知道具体对应着哪一次消息投递了，可以删除这条消息。
此外，如果RabbitMQ接收到一条消息之后，结果内部出错发现无法处理这条消息，那么MQ会回传一个nack消息给生产者。此时生产者就会感知到这条消息可能处理有问题，你可以选择重新再次投递这条消息到MQ去。
或者另一种情况，如果某条消息很长时间都没给你回传ack&#x2F;nack，那可能是极端意外情况发生了，数据也丢了，你也可以自己重新投递消息到MQ去。
4、confirm机制投递消息的高延迟性一旦启用了confirm机制投递消息到MQ之后，MQ是不保证什么时候会给你一个ack或者nack的。
因为RabbitMQ自己内部将消息持久化到磁盘，本身就是通过异步批量的方式来进行的。正常情况下，你投递到RabbitMQ的消息都会先驻留在内存里，然后过了几百毫秒的延迟时间之后，再一次性批量把多条消息持久化到磁盘里去。这样做，是为了兼顾高并发写入的吞吐量和性能的，因为要是你来一条消息就写一次磁盘，那么性能会很差，每次写磁盘都是一次fsync强制刷入磁盘的操作，是很耗时的。
那如何解决呢？
绝对不能以****同步*写消息 + 等待ack的方式来投递消息，用来临时存放未ack消息的存储需要承载高并发写入，而且我们不需要什么复杂的运算操作，这种存储首选绝对不是MySQL之类的关系数据库，而建议采用kv存储*。kv存储承载高并发能力极强，而且kv操作性能很高。
生产者消息投递出去之后并且在kv存储器存储，这个投递的线程其实就可以返回了，至于每个消息的异步回调，是通过在channel注册一个confirm监听器实现的。生产者收到一个消息ack之后，就从kv存储中删除这条临时消息；收到一个消息nack之后，就从kv存储提取这条消息然后重新投递一次即可；也可以自己对kv存储里的消息做监控，如果超过一定时长没收到ack，就主动重发消息。                      
]]></content>
      <categories>
        <category>中间件</category>
        <category>消息队列</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常见错误：Attempting to operate on hdfs namenode as root</title>
    <url>/posts/471a88e0/</url>
    <content><![CDATA[目录Attempting to operate on hdfs namenode as root使用root配置的hadoop并启动会出现报错
错误：
Starting namenodes on [master]ERROR: Attempting to operate on hdfs namenode as rootERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.Starting datanodesERROR: Attempting to operate on hdfs datanode as rootERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.Starting secondary namenodes [slave1]ERROR: Attempting to operate on hdfs secondarynamenode as rootERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.

解决方法：
在 &#x2F;hadoop&#x2F;sbin 路径下：将 start-dfs.sh，stop-dfs.sh 两个文件顶部添加以下参数
HDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root

start-yarn.sh，stop-yarn.sh 顶部也需添加以下
YARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=yarnYARN_NODEMANAGER_USER=root]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常见错误：HDFS报错解决：Operation category JOURNAL is not supported in state standby</title>
    <url>/posts/d8e7a818/</url>
    <content><![CDATA[目录HDFS报错解决：Operation category JOURNAL is not supported in state standby现象org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby. Visit https://s.apache.org/sbnn-error	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:88)	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1954)	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1442)	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4716)	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1293)	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:148)	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:14726)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)	at java.security.AccessController.doPrivileged(Native Method)	at javax.security.auth.Subject.doAs(Subject.java:422)	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)	at org.apache.hadoop.ipc.Client.call(Client.java:1457)	at org.apache.hadoop.ipc.Client.call(Client.java:1367)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)	at com.sun.proxy.$Proxy16.rollEditLog(Unknown Source)	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:152)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:365)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:362)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:504)	at java.util.concurrent.FutureTask.run(FutureTask.java:266)	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)	at java.lang.Thread.run(Thread.java:748)2019-06-28 03:27:27,782 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Exception from remote name node RemoteNameNodeInfo [nnId=nns, ipcAddress=nns/192.168.56.14:8020, httpAddress=http://nns:50070], try next.org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby. Visit https://s.apache.org/sbnn-error	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:88)	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1954)	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1442)	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4716)	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1293)	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:148)	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:14726)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)	at java.security.AccessController.doPrivileged(Native Method)	at javax.security.auth.Subject.doAs(Subject.java:422)	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)	at org.apache.hadoop.ipc.Client.call(Client.java:1457)	at org.apache.hadoop.ipc.Client.call(Client.java:1367)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)	at com.sun.proxy.$Proxy16.rollEditLog(Unknown Source)	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:152)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:365)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:362)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:504)	at java.util.concurrent.FutureTask.run(FutureTask.java:266)	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)	at java.lang.Thread.run(Thread.java:748)2019-06-28 03:27:27,829 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Exception from remote name node RemoteNameNodeInfo [nnId=nns, ipcAddress=nns/192.168.56.14:8020, httpAddress=http://nns:50070], try next.org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby. Visit https://s.apache.org/sbnn-error	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:88)	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1954)	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1442)	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4716)	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1293)	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:148)	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:14726)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)	at java.security.AccessController.doPrivileged(Native Method)	at javax.security.auth.Subject.doAs(Subject.java:422)	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)	at org.apache.hadoop.ipc.Client.call(Client.java:1457)	at org.apache.hadoop.ipc.Client.call(Client.java:1367)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)	at com.sun.proxy.$Proxy16.rollEditLog(Unknown Source)	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:152)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:365)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:362)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:504)	at java.util.concurrent.FutureTask.run(FutureTask.java:266)	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)	at java.lang.Thread.run(Thread.java:748)2019-06-28 03:27:27,830 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NNjava.util.concurrent.ExecutionException: java.io.IOException: Cannot find any valid remote NN to service request!	at java.util.concurrent.FutureTask.report(FutureTask.java:122)	at java.util.concurrent.FutureTask.get(FutureTask.java:206)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:380)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:430)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)Caused by: java.io.IOException: Cannot find any valid remote NN to service request!	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:515)	at java.util.concurrent.FutureTask.run(FutureTask.java:266)	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)	at java.lang.Thread.run(Thread.java:748)2019-06-28 03:27:29,843 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1605msNo GCs detected2019-06-28 03:28:30,033 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode2019-06-28 03:28:30,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6d00c3eb expecting start txid #12019-06-28 03:28:30,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://dn3:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true, http://dn1:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true maxTxnsToRead = 92233720368547758072019-06-28 03:28:30,288 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream &#x27;http://dn3:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true, http://dn1:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true&#x27; to transaction ID 12019-06-28 03:28:30,288 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream &#x27;http://dn3:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true&#x27; to transaction ID 12019-06-28 03:28:30,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://dn3:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true, http://dn1:8480/getJournal?jid=mycluster&amp;segmentTxId=1&amp;storageInfo=-65%3A1565240010%3A1561706674134%3ACID-d60aab16-2a77-48ed-8a5f-5699ca87b6bc&amp;inProgressOk=true of size 42 edits # 2 loaded in 0 seconds

解决方法1、原因：两个 namenode 节点均处于 standby 状态，没有 active 状态的节点。
2、解决办法：

集群挂掉时慎用bin/hdfs haadmin -transitionToActive nn1，尽量用bin/hdfs haadmin -failover --forceactive nn1：
These subcommands cause a given NameNode to transition to the Active or Standby state, respectively. These commands do not attempt to perform any fencing, and thus should rarely be used. Instead, one should almost always prefer to use the “hdfs haadmin -failover” subcommand

# 在想要转换为 active 状态的 namenode 的节点上操作hdfs haadmin -transitionToActive --forcemanual nn1]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常见错误：Hadoop启动成功，但50070端口无法访问</title>
    <url>/posts/aa689eab/</url>
    <content><![CDATA[目录Hadoop启动成功，但50070端口无法访问先查看自己的hadoop版本
我的 hadoop 是 3.2.3 版本的，hadoop-3.2.3 是我的 hadoop 目录
/app/hadoop-3.2.3

2.x.x 版本的 hadoop 默认端口为 http://IP:50070
但是新出的 3.x.x 版本的默认端口为 http://IP:9870
如果不是这个原因，那就去从机的 hadoop 的根目录下的 log 目录查看 log 文件，看看报的什么错误。再根据错误，查找相应的解决方法。
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常见错误：bash v3.2+ is required. Sorry.</title>
    <url>/posts/9170957e/</url>
    <content><![CDATA[目录bash v3.2+ is required. Sorry.Running with root user:
$ start-dfs.sh Starting namenodes on [master]bash v3.2+ is required. Sorry.Starting datanodesbash v3.2+ is required. Sorry.Starting secondary namenodes [master_bis]bash v3.2+ is required. Sorry

Then I created a hadoop user and gave this user privileges on the Hadoop installation (R&#x2F;W access). After logging in with this new user I have the following output for the command that caused me some troubles:
$ start-dfs.sh Starting namenodes on [master]Starting datanodesStarting secondary namenodes [master_bis]

]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常见错误：hdfs namenode -format 格式化报错找不到 JAVA_HOME</title>
    <url>/posts/e05de508/</url>
    <content><![CDATA[目录hdfs namenode -format 格式化报错找不到 JAVA_HOME找到 etc&#x2F;hadoop 目录下的 hadoop-env.sh
增加如下配置：
# The java implementation to use. By default, this environment# variable is REQUIRED on ALL platforms except OS X!export JAVA_HOME=/app/jdk1.8.0_212]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据常见错误：重新format namenode后，datanode无法正常启动</title>
    <url>/posts/d2341114/</url>
    <content><![CDATA[目录重新format namenode后，datanode无法正常启动测试环境，由于测试需求，重新format namenode后，导致datanode无法正常启动。
查看datanode日志，可以发现错误“Initialization failed for Block pool  (Datanode Uuid unassigned)”
2018-01-27 20:09:49,052 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool &lt;registering&gt; (Datanode Uuid unassigned) service to c6704/192.168.67.104:9000. Exiting.java.io.IOException: All specified directories are failed to load.at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)at java.lang.Thread.run(Thread.java:745)2018-01-27 20:09:49,056 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool &lt;registering&gt; (Datanode Uuid unassigned) service to c6705/192.168.67.105:9000. Exiting.java.io.IOException: All specified directories are failed to load.at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1361)at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1326)at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:801)at java.lang.Thread.run(Thread.java:745)2018-01-27 20:09:49,069 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool &lt;registering&gt; (Datanode Uuid unassigned) service to c6705/192.168.67.105:90002018-01-27 20:09:49,070 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool &lt;registering&gt; (Datanode Uuid unassigned) service to c6704/192.168.67.104:90002018-01-27 20:09:49,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool &lt;registering&gt; (Datanode Uuid unassigned)2018-01-27 20:09:51,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode2018-01-27 20:09:51,204 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 02018-01-27 20:09:51,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:/************************************************************SHUTDOWN_MSG: Shutting down DataNode at c6706.python279.org/192.168.67.106************************************************************/

经过百度，根据日志描述，原因是datanode的clusterID 和 namenode的clusterID 不匹配。打开hdfs-site.xml中关于datanode和namenode对应的目录，分别打开其中的current&#x2F;VERSION文件，进行对比。
namenode的VERSION内容如下：
[hdfs@c6704 $ cat /data/hadoop/hdfs/name/current/VERSION#Sat Jan 27 00:46:30 UTC 2018namespaceID=1148548909clusterID=CID-aedb2e82-77f2-4056-b676-dca88083215dcTime=0storageType=NAME_NODEblockpoolID=BP-1099214307-192.168.67.104-1517013990445layoutVersion=-63

datanode的VERSION文件内容如下：
[hdfs@c6706 ~]$ cat /data/hadoop/hdfs/data/current/VERSION#Sat Jan 27 00:20:21 UTC 2018storageID=DS-8f0fdd04-e967-43cd-bd41-93b826b675b8clusterID=CID-b27ecfd8-64ba-4e43-bd82-4ef6f2edd60ccTime=0datanodeUuid=264b1b43-82c0-411c-859f-32761edc7465storageType=DATA_NODElayoutVersion=-56

namenode和datanode的版本是不同的，决定备份datanode，并清空VERSION，然后启动datanode，问题依旧。检查VERSION，内容是空的。
[hdfs@c6706 current]$ cp VERSION VERSION.bk[hdfs@c6706 current]$ echo &gt; VERSION[hdfs@c6706 current]$ cat VERSION

删除VERSION，再次启动datanode，VERSION内容已经同步。
$ cat VERSION#Sun Jan 28 01:29:46 UTC 2018storageID=DS-1c1f5e05-df2c-40de-b39b-d6d54e3c4894clusterID=CID-aedb2e82-77f2-4056-b676-dca88083215d    ##&lt;&lt;&lt;&lt;&lt;同步了cTime=0datanodeUuid=948d5780-053e-4752-9476-fb1d1debda72storageType=DATA_NODElayoutVersion=-56

通过页面也可以查询到datanode了。
问题原因分析
执行hdfs namenode -format后，current目录会删除并重新生成，其中VERSION文件中的clusterID也会随之变化，而datanode的VERSION文件中的clusterID保持不变，造成两个clusterID不一致。
所以为了避免这种情况，可以再执行的namenode格式化之后，删除datanode的current文件夹，或者修改datanode的VERSION文件中出clusterID与namenode的VERSION文件中的clusterID一样，然后重新启动datanode。
参考链接http://blog.csdn.net/liuxinghao/article/details/40121843
]]></content>
      <categories>
        <category>大数据</category>
        <category>安装部署</category>
        <category>常见错误</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 中文乱码</title>
    <url>/posts/d91b8c97/</url>
    <content><![CDATA[解决centos7中文乱码查看本地的中文语言包[root@61c1a2f92913 ~]# locale  -aCPOSIXen_US.utf8[root@61c1a2f92913 ~]# locale LANG=LC_CTYPE=&quot;POSIX&quot;LC_NUMERIC=&quot;POSIX&quot;LC_TIME=&quot;POSIX&quot;LC_COLLATE=&quot;POSIX&quot;LC_MONETARY=&quot;POSIX&quot;`在这里插入代码片`LC_MESSAGES=&quot;POSIX&quot;LC_PAPER=&quot;POSIX&quot;LC_NAME=&quot;POSIX&quot;LC_ADDRESS=&quot;POSIX&quot;LC_TELEPHONE=&quot;POSIX&quot;LC_MEASUREMENT=&quot;POSIX&quot;LC_IDENTIFICATION=&quot;POSIX&quot;LC_ALL=

安装中文环境包yum -y install kde-l10n-Chinese

设置环境变量vim  /etc/profileexport LC_ALL=&quot;zh_CN.UTF-8&quot;# 更新环境变量source /etc/profile

此时已经支持中文了
localeLANG=LC_CTYPE=&quot;zh_CN.UTF-8&quot;LC_NUMERIC=&quot;zh_CN.UTF-8&quot;LC_TIME=&quot;zh_CN.UTF-8&quot;LC_COLLATE=&quot;zh_CN.UTF-8&quot;LC_MONETARY=&quot;zh_CN.UTF-8&quot;LC_MESSAGES=&quot;zh_CN.UTF-8&quot;LC_PAPER=&quot;zh_CN.UTF-8&quot;LC_NAME=&quot;zh_CN.UTF-8&quot;LC_ADDRESS=&quot;zh_CN.UTF-8&quot;LC_TELEPHONE=&quot;zh_CN.UTF-8&quot;LC_MEASUREMENT=&quot;zh_CN.UTF-8&quot;LC_IDENTIFICATION=&quot;zh_CN.UTF-8&quot;

设置locale.confvim /etc/locale.conf LANG=&quot;zh_CN.UTF-8&quot;source /etc/locale.conf 

设置系统语言localedef -c -f UTF-8 -i zh_CN zh_CN.utf8

]]></content>
      <categories>
        <category>运维</category>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title>redis 面试题</title>
    <url>/posts/9657a236/</url>
    <content><![CDATA[1、什么是 Redis?Redis 是完全开源免费的，遵守 BSD 协议，是一个高性能的 key-value 数据库。
Redis 与其他 key - value 缓存产品有以下三个特点：
（1）Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。
（2）Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。
（3）Redis 支持数据的备份，即 master-slave 模式的数据备份。
Redis 优势
（1）性能极高 – Redis 能读的速度是 110000 次&#x2F;s,写的速度是 81000 次&#x2F;s 。
（2）丰富的数据类型 – Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。
（3）原子 – Redis 的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过 MULTI 和 EXEC指令包起来。
（4）丰富的特性 – Redis 还支持 publish&#x2F;subscribe, 通知, key 过期等等特性。
Redis 与其他 key-value 存储有什么不同？
（1）Redis 有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis 的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。
（2）Redis 运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样 Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。
2、Redis 的数据类型？Redis 支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及 zsetsorted set：有序集合)。
我们实际项目中比较常用的是 string，hash 如果你是 Redis 中高级用户，还需要加上下面几种数据结构 HyperLogLog、Geo、Pub&#x2F;Sub。
如果你说还玩过 Redis Module，像 BloomFilter，RedisSearch，Redis-ML，面试官得眼睛就开始发亮了。
3、使用 Redis 有哪些好处？（1）速度快，因为数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O1)
（2）支持丰富数据类型，支持 string，list，set，Zset，hash 等
（3）支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
（4）丰富的特性：可用于缓存，消息，按 key 设置过期时间，过期后将会自动删除
4、Redis 相比 Memcached 有哪些优势？（1）Memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类
（2）Redis 的速度比 Memcached 快很
（3）Redis 可以持久化其数据
5、Memcache 与 Redis 的区别都有哪些？（1）存储方式 Memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis 有部份存在硬盘上，这样能保证数据的持久性。
（2）数据支持类型 Memcache 对数据类型支持相对简单。 Redis 有复杂的数据类型。
（3）使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
6、Redis 是单进程单线程的？Redis 是单进程单线程的，redis 利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。
7、一个字符串类型的值能存储最大容量是多少？512M
8、Redis 的持久化机制是什么？各自的优缺点？Redis提供两种持久化机制 RDB 和 AOF 机制:
1、RDB Redis DataBase 持久化方式：是指用数据集快照的方式半持久化模式)记录 redis 数据库的所有键值对,在某个时间点将数据写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。
优点：
（1）只有一个文件 dump.rdb，方便持久化。
（2）容灾性好，一个文件可以保存到安全的磁盘。
（3）性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了redis的高性能)
（4）相对于数据集大时，比 AOF 的启动效率更高。
缺点：
数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
2、AOF Append-only file 持久化方式：是指所有的命令行记录以 redis 命令请求协议的格式完全持久化存储)保存为 aof 文件。
优点：
（1）数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 aof 文件中一次。
（2）通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。
（3）AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)
缺点：
（1）AOF 文件比 RDB 文件大，且恢复速度慢。
（2）数据集大的时候，比 rdb 启动效率低。
9、Redis 常见性能问题和解决方案：（1）Master 最好不要写内存快照，如果 Master 写内存快照，save 命令调度 rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务
（2）如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一
（3）为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网
（4）尽量避免在压力很大的主库上增加从
（5）主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1&lt;- Slave2 &lt;- Slave3…这样的结构方便解决单点故障问题，实现 Slave 对 Master的替换。如果 Master 挂了，可以立刻启用 Slave1 做 Master，其他不变。
10、redis 过期键的删除策略？（1）定时删除：在设置键的过期时间的同时，创建一个定时器 timer。让定时器在键的过期时间来临时，立即执行对键的删除操作。
（2）惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键;如果没有过期，就返回该键。
（3）定期删除：每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。
11、Redis 的回收策略（淘汰策略）?volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
no-enviction（驱逐）：禁止驱逐数据
注意这里的 6 种机制，volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的 lru、ttl 以及 random 是三种不同的淘汰策略，再加上一种 no-enviction 永不回收的策略。
使用策略规则：
（1）如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru
（2）如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random
12、为什么 redis 需要把所有数据放到内存中？答 ：Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I&#x2F;O 速度为严重影响 redis 的性能。在内存越来越便宜的今天，redis 将会越来越受欢迎。如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。
13、Redis 的同步机制了解么？Redis 可以使用主从同步，从从同步。第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 rdb 文件全量同步到复制节点，复制节点接受完成后将 rdb 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。
14、Pipeline 有什么好处，为什么要用 pipeline？可以将多次 IO 往返的时间缩减为一次，前提是 pipeline 执行的指令之间没有因果相关性。使用 redis-benchmark 进行压测的时候可以发现影响 redis 的 QPS峰值的一个重要因素是 pipeline 批次指令的数目。
15、是否使用过 Redis 集群，集群的原理是什么？（1）Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为master，继续提供服务。
（2）Redis Cluster 着眼于扩展性，在单个 redis 内存不足时，使用 Cluster 进行分片存储。
16、Redis 集群方案什么情况下会导致整个集群不可用？有 A，B，C 三个节点的集群,在没有复制模型的情况下,如果节点 B 失败了，那么整个集群就会以为缺少 5501-11000 这个范围的槽而不可用。
17、Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？Redisson、Jedis、lettuce 等等，官方推荐使用 Redisson。
18、Jedis 与 Redisson 对比有什么优缺点？Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持；Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等 Redis 特性。
Redisson 的宗旨是促进使用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。
19、Redis 如何设置密码及验证密码？设置密码：config set requirepass 123456
授权密码：auth 123456
20、说说 Redis 哈希槽的概念？Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。
21、Redis 集群的主从复制模型是怎样的？为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有 N-1 个复制品.
22、Redis 集群会有写操作丢失吗？为什么？Redis 并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。
23、Redis 集群之间是如何复制的？异步复制
24、Redis 集群最大节点个数是多少？16384 个。
25、Redis 集群如何选择数据库？Redis 集群目前无法做数据库选择，默认在 0 数据库。
26、怎么测试 Redis 的连通性？使用 ping 命令。
27、怎么理解 Redis 事务？（1）事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
（2）事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。
28、Redis 事务相关的命令有哪几个？MULTI、EXEC、DISCARD、WATCH
29、Redis key 的过期时间和永久有效分别怎么设置？EXPIRE 和 PERSIST 命令。
30、Redis 如何做内存优化？尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的 web 系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的 key，而是应该把这个用户的所有信息存储到一张散列表里面。
31、Redis 回收进程如何工作的？一个客户端运行了新的命令，添加了新的数据。Redi 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。一个新的命令被执行，等等。所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。
32、都有哪些办法可以降低 Redis 的内存使用情况呢？如果你使用的是 32 位的 Redis 实例，可以好好利用 Hash,list,sorted set,set 等集合类型数据，因为通常情况下很多小的 Key-Value 可以用更紧凑的方式存放到一起。
33、Redis 的内存用完了会发生什么？如果达到设置的上限，Redis 的写命令会返回错误信息（但是读命令还可以正常返回）。或者你可以将 Redis 当缓存来使用配置淘汰机制，当 Redis 达到内存上限时会冲刷掉旧的内容。
34、一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？理论上 Redis 可以处理多达 232 的 keys，并且在实际中进行了测试，每个实例至少存放了 2 亿 5 千万的 keys。我们正在测试一些较大的值。任何 list、set、和 sorted set 都可以放 232 个元素。换句话说，Redis 的存储极限是系统中的可用内存值。
35、MySQL 里有 2000w 数据，redis 中只存 20w 的数据，如何保证 redis 中的数据都是热点数据？Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。
相关知识：Redis 提供 6 种数据淘汰策略：
volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
no-enviction（驱逐）：禁止驱逐数据
36、Redis 最适合的场景？1、会话缓存（Session Cache）
最常用的一种使用 Redis 的情景是会话缓存（session cache）。用 Redis 缓存会话比其他存储（如 Memcached）的优势在于：Redis 提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用 Redis 来缓存会话的文档。甚至广为人知的商业平台Magento 也提供 Redis 的插件。
2、全页缓存（FPC）
除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到一致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似 PHP 本地 FPC。 再次以 Magento 为例，Magento提供一个插件来使用 Redis 作为全页缓存后端。 此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。
3、队列
Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis能作为一个很好的消息队列平台来使用。Redis 作为队列使用的操作，就类似于本地程序语言（如 Python）对 list 的 push&#x2F;pop 操作。 如果你快速的在 Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用 Redis 创建非常好的后端工具，以满足各种队列需求。例如，Celery 有一个后台就是使用 Redis 作为 broker，你可以从这里去查看。
4，排行榜&#x2F;计数器
Redis 在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的 10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储数据的，你可以在这里看到。
5、发布&#x2F;订阅
最后（但肯定不是最不重要的）是 Redis 的发布&#x2F;订阅功能。发布&#x2F;订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布&#x2F;订阅的脚本触发器，甚至用 Redis 的发布&#x2F;订阅功能来建立聊天系统！
37、假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？使用 keys 指令可以扫出指定模式的 key 列表。
对方接着追问：如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？
这个时候你要回答 redis 关键的一个特性：redis 是单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。
38、如果有大量的 key 需要设置同一时间过期，一般需要注意什么？如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。
39、使用过 Redis 做异步队列么，你是怎么用的？一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。如果对方追问能不能生产一次消费多次呢？使用 pub&#x2F;sub 主题订阅者模式，可以实现1:N 的消息队列。
如果对方追问 pub&#x2F;sub 有什么缺点？
在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 RabbitMQ等。
如果对方追问 redis 如何实现延时队列？
我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用 sortedset，拿时间戳作为score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。
40、使用过 Redis 分布式锁么，它是什么回事？先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。
这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
</search>
